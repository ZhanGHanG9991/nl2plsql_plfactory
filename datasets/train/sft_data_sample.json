[
  {
    "ir": "Write an Oracle PL/SQL stored procedure named sp_manage_movie_versions that accepts three parameters: para_movie_id of type NUMBER, para_version_number of type NUMBER, and para_description of type VARCHAR2. The procedure first initializes a variable current_timestamp to store the current date and time in the format 'YYYY-MM-DD HH24:MI:SS' using the TO_CHAR function on SYSDATE. It then checks if a version with the given para_movie_id and para_version_number already exists in the movie_versions table by selecting the count of such records into the variable version_exists. If no such version exists (version_exists equals 0), it calculates the next version_id by selecting the maximum version_id from the movie_versions table, using NVL to handle nulls by defaulting to -1, and adding 1 to this maximum value, storing the result in next_version_id. It then inserts a new record into the movie_versions table with the calculated next_version_id, the provided para_movie_id, para_version_number, para_description, and the current_timestamp for both created_at and updated_at columns. If a version already exists, it updates the existing record in the movie_versions table by setting the version_description to para_description and updated_at to current_timestamp for the row matching the given para_movie_id and para_version_number. After handling the version record, the procedure retrieves the maximum version_number for the given para_movie_id from the movie_versions table into the variable latest_version. If latest_version is not null, indicating that there are versions associated with the movie, it updates the movies table by setting the updated_at column to current_timestamp for the row with the matching movie_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp_manage_movie_versions(para_movie_id NUMBER, para_version_number NUMBER, para_description VARCHAR2) IS\n  version_exists NUMBER;\n  latest_version NUMBER;\n  next_version_id NUMBER;\n  current_timestamp VARCHAR2(255);\nBEGIN\n  current_timestamp := TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS');\n  \n  SELECT COUNT(*) INTO version_exists FROM movie_versions WHERE movie_id = para_movie_id AND version_number = para_version_number;\n  \n  IF version_exists = 0 THEN\n    SELECT NVL(MAX(version_id), -1) + 1 INTO next_version_id FROM movie_versions;\n    INSERT INTO movie_versions (version_id, movie_id, version_number, version_description, created_at, updated_at) \n    VALUES (next_version_id, para_movie_id, para_version_number, para_description, current_timestamp, current_timestamp);\n  ELSE\n    UPDATE movie_versions \n    SET version_description = para_description, updated_at = current_timestamp \n    WHERE movie_id = para_movie_id AND version_number = para_version_number;\n  END IF;\n\n  SELECT MAX(version_number) INTO latest_version FROM movie_versions WHERE movie_id = para_movie_id;\n  IF latest_version IS NOT NULL THEN\n    UPDATE movies SET updated_at = current_timestamp WHERE movie_id = para_movie_id;\n  END IF;\nEND;",
    "database_name": "movie_cm_system",
    "tables": [
      "actors",
      "cast_members",
      "movies",
      "awards",
      "movie_versions"
    ],
    "id": 1
  },
  {
    "ir": "Write a PostgreSQL stored procedure named process_user_project_assignments that takes two input parameters: target_user_id of type BIGINT which identifies the user being processed, and project_status_filter of type TEXT which specifies the status filter for projects to be considered. The procedure declares seven local variables: user_role to store the user's role, project_count to count projects, collaboration_exists to check if the user has collaborations, user_active to check if the user is active, project_active to check if the user has active projects, has_reports to check if the user has created reports, access_recent to check if the user accessed the system recently, and final_action to store the final action to be taken. The procedure first retrieves the role from the users table where user_id matches target_user_id and stores it in user_role. If user_role equals 'researcher', the procedure counts the number of projects in the projects table where lead_researcher equals target_user_id and status equals project_status_filter, storing the count in project_count. If project_count is greater than 2, the procedure checks if any collaborations exist for the user by querying the collaborations table where user_id equals target_user_id, storing the result in collaboration_exists. If collaboration_exists is true, the procedure checks if the user is active by querying the users table where user_id equals target_user_id and comparing the status to 'active', storing the result in user_active. If user_active is true, the procedure checks if the user has any active projects by querying the projects table where lead_researcher equals target_user_id and status equals 'active', storing the result in project_active. If project_active is true, the procedure checks if the user has created any reports by querying the reports table where created_by equals target_user_id, storing the result in has_reports. If has_reports is true, the procedure checks if the user has accessed the system recently by querying the access_logs table where user_id equals target_user_id and access_date is greater than '2023-01-01', storing the result in access_recent. If access_recent is true, final_action is set to 'promote_senior'; otherwise, final_action is set to 'maintain_current'. If has_reports is false, final_action is set to 'require_reports'. If project_active is false, final_action is set to 'activate_projects'. If user_active is false, final_action is set to 'reactivate_user'. If collaboration_exists is false, final_action is set to 'assign_collaboration'. If project_count is not greater than 2, final_action is set to 'assign_more_projects'. If user_role is not 'researcher', final_action is set to 'no_action_needed'.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_user_project_assignments(IN target_user_id BIGINT, IN project_status_filter TEXT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    user_role TEXT;\n    project_count INTEGER;\n    collaboration_exists BOOLEAN;\n    user_active BOOLEAN;\n    project_active BOOLEAN;\n    has_reports BOOLEAN;\n    access_recent BOOLEAN;\n    final_action TEXT;\nBEGIN\n    SELECT role INTO user_role FROM users WHERE user_id = target_user_id;\n    \n    IF user_role = 'researcher' THEN\n        SELECT COUNT(*) INTO project_count FROM projects WHERE lead_researcher = target_user_id AND status = project_status_filter;\n        IF project_count > 2 THEN\n            SELECT EXISTS(SELECT 1 FROM collaborations WHERE user_id = target_user_id) INTO collaboration_exists;\n            IF collaboration_exists THEN\n                SELECT status = 'active' INTO user_active FROM users WHERE user_id = target_user_id;\n                IF user_active THEN\n                    SELECT EXISTS(SELECT 1 FROM projects WHERE lead_researcher = target_user_id AND status = 'active') INTO project_active;\n                    IF project_active THEN\n                        SELECT EXISTS(SELECT 1 FROM reports WHERE created_by = target_user_id) INTO has_reports;\n                        IF has_reports THEN\n                            SELECT EXISTS(SELECT 1 FROM access_logs WHERE user_id = target_user_id AND access_date > '2023-01-01') INTO access_recent;\n                            IF access_recent THEN\n                                final_action := 'promote_senior';\n                            ELSE\n                                final_action := 'maintain_current';\n                            END IF;\n                        ELSE\n                            final_action := 'require_reports';\n                        END IF;\n                    ELSE\n                        final_action := 'activate_projects';\n                    END IF;\n                ELSE\n                    final_action := 'reactivate_user';\n                END IF;\n            ELSE\n                final_action := 'assign_collaboration';\n            END IF;\n        ELSE\n            final_action := 'assign_more_projects';\n        END IF;\n    ELSE\n        final_action := 'no_action_needed';\n    END IF;\nEND;\n$$;",
    "database_name": "environmental_quality_data_analysis_and_education",
    "tables": [
      "users",
      "projects",
      "collaborations",
      "reports",
      "access_logs"
    ],
    "id": 2
  },
  {
    "ir": "Write an Oracle PL/SQL compound trigger named trg_aggregate_redemptions that fires for each row inserted into the redemptions table, declaring a private associative array type participant_id_t of NUMBER indexed by PLS_INTEGER and a global variable g_participant_ids of that type; within the AFTER EACH ROW section, for every new row inserted, the trigger appends the value of the new row's participant_id column, referenced as :NEW.participant_id, to the next available index in the g_participant_ids collection; then, in the AFTER STATEMENT section, the trigger declares local variables v_redemption_summary as VARCHAR2(4000) and v_participant_id as NUMBER, and for each element in the g_participant_ids collection from index 1 to its total count, the trigger assigns the current element's value to v_participant_id, executes a SELECT query on the redemptions table for rows where the participant_id column equals v_participant_id, using the LISTAGG function to concatenate a string for each matching row formed by the NVL function applied to the redemption_type column with a default of 'UNKNOWN', a colon separator, and the NVL function applied to the amount column with a default of '0', ordering the concatenation by the redemption_date column and separating each aggregated pair with a comma, storing the result into v_redemption_summary, and subsequently executes an UPDATE statement on the participants table, setting the address column to the value of v_redemption_summary for every row where the participant_id column equals the current v_participant_id.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_aggregate_redemptions\nFOR INSERT ON redemptions\nCOMPOUND TRIGGER\n    TYPE participant_id_t IS TABLE OF NUMBER INDEX BY PLS_INTEGER;\n    g_participant_ids participant_id_t;\n    \n    AFTER EACH ROW IS\n    BEGIN\n        g_participant_ids(g_participant_ids.COUNT + 1) := :NEW.participant_id;\n    END AFTER EACH ROW;\n    \n    AFTER STATEMENT IS\n        v_redemption_summary VARCHAR2(4000);\n        v_participant_id NUMBER;\n    BEGIN\n        FOR i IN 1..g_participant_ids.COUNT LOOP\n            v_participant_id := g_participant_ids(i);\n            \n            SELECT LISTAGG(NVL(redemption_type, 'UNKNOWN') || ':' || NVL(amount, '0'), ',') \n                   WITHIN GROUP (ORDER BY redemption_date)\n            INTO v_redemption_summary\n            FROM redemptions\n            WHERE participant_id = v_participant_id;\n            \n            UPDATE participants \n            SET address = v_redemption_summary \n            WHERE participant_id = v_participant_id;\n        END LOOP;\n    END AFTER STATEMENT;\nEND trg_aggregate_redemptions;",
    "database_name": "charity_aip_management",
    "tables": [
      "participants",
      "purchases",
      "transactions",
      "redemptions"
    ],
    "_source": "plfactory29",
    "id": 3
  },
  {
    "ir": "Write a PostgreSQL trigger function named insert_payment_method_description that is executed automatically by a trigger named trg_insert_payment_method_description before any new row is inserted into the order_payments table; this function, for each new row (referenced as NEW), checks a condition using a SELECT statement on the payment_methods table to see if a row already exists where the payment_method_id column value equals the NEW.payment_method_id value; if no such row exists (the NOT EXISTS condition is true), the function performs an INSERT operation into the payment_methods table, specifying these column values: the payment_method_id column is set to NEW.payment_method_id, the payment_method_name column is set to the literal string 'New Method', the payment_method_description column is set to the result of concatenating the literal string 'Description for method ' with the NEW.payment_method_id value using the CONCAT function, and both the created_at and updated_at columns are set to the current date and time formatted as 'YYYY-MM-DD HH24:MI:SS' by calling the TO_CHAR function on the result of the NOW() function; after this conditional insert, the function returns the NEW row record to allow the triggering INSERT on order_payments to proceed.",
    "plsql": "CREATE OR REPLACE FUNCTION insert_payment_method_description() RETURNS TRIGGER AS $$\nBEGIN\n  -- Check if the payment_method_id already exists in payment_methods\n  IF NOT EXISTS (SELECT 1 FROM payment_methods WHERE payment_method_id = NEW.payment_method_id) THEN\n    INSERT INTO payment_methods (payment_method_id, payment_method_name, payment_method_description, created_at, updated_at)\n    VALUES (NEW.payment_method_id, 'New Method', CONCAT('Description for method ', NEW.payment_method_id), TO_CHAR(NOW(), 'YYYY-MM-DD HH24:MI:SS'), TO_CHAR(NOW(), 'YYYY-MM-DD HH24:MI:SS'));\n  END IF;\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_insert_payment_method_description\nBEFORE INSERT ON order_payments\nFOR EACH ROW\nEXECUTE FUNCTION insert_payment_method_description();",
    "database_name": "e_commerce_and_customer_loyalty_management",
    "tables": [
      "order_payments",
      "order_status_history",
      "payment_methods"
    ],
    "_source": "plfactory24",
    "id": 4
  },
  {
    "ir": "Write an Oracle PL/SQL function named `get_patient_max_weight` that accepts two input parameters: `p_patient_id` of data type `NUMBER` to represent the unique identifier for a patient, and `p_date` of data type `DATE` to represent a specific date. This function is designed to return a single value of data type `NUMBER`. Upon execution, the function declares a local variable named `v_max_weight` of data type `NUMBER` and initializes it to `NULL`. Subsequently, the function immediately assigns the numeric literal `0` to the `v_max_weight` variable. This assignment is explicitly noted in the code as a placeholder action due to the absence of a `PATIENT_HEALTH_RECORDS` table in the current schema, ensuring the function's compilability. Following this assignment, the function returns the current value stored in the `v_max_weight` variable. The function also includes an exception handling block that catches any unhandled exceptions that might occur during its execution. If any exception is raised, the exception handler will return `NULL` as the function's result.",
    "plsql": "CREATE OR REPLACE FUNCTION get_patient_max_weight(p_patient_id NUMBER, p_date DATE) RETURN NUMBER IS\n    v_max_weight NUMBER := NULL;\nBEGIN\n    -- Since no PATIENT_HEALTH_RECORDS table exists in the schema,\n    -- return a default value to ensure the function compiles\n    v_max_weight := 0;\n    \n    RETURN v_max_weight;\nEXCEPTION\n    WHEN OTHERS THEN\n        RETURN NULL;\nEND get_patient_max_weight;",
    "database_name": "medical_dafd_prediction",
    "tables": [
      "PATIENTS",
      "PATIENT_HEALTH_RECORDS"
    ],
    "id": 5
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `add_course_requirement` that accepts three input parameters: a numeric parameter `p_program_id` representing the identifier of an academic program, a numeric parameter `p_course_type_id` representing the identifier of a type of course, and a numeric parameter `p_course_count` representing the required number of courses of that type. The procedure first declares a local numeric variable `v_requirement_id`. It then executes a SELECT statement on the `course_requirements` table to calculate a new unique identifier for a requirement record; this is done by using the NVL function to find the maximum existing value in the `requirement_id` column, substituting -1 if the column contains only NULL values, and then adding 1 to that result, storing the computed value into the local variable `v_requirement_id`. Following this, the procedure performs an INSERT operation into the `course_requirements` table, specifying values for six columns: it inserts the newly generated `v_requirement_id` into the `requirement_id` column, the input parameter `p_program_id` into the `program_id` column, the input parameter `p_course_type_id` into the `course_type_id` column, the input parameter `p_course_count` into the `course_count` column, the literal string 'C' into the `min_grade` column, and the literal string 'Auto-generated requirement' into the `comments` column.",
    "plsql": "CREATE OR REPLACE PROCEDURE add_course_requirement(p_program_id NUMBER, p_course_type_id NUMBER, p_course_count NUMBER) IS\n  v_requirement_id NUMBER;\nBEGIN\n  SELECT NVL(MAX(requirement_id), -1) + 1 INTO v_requirement_id FROM course_requirements;\n  \n  INSERT INTO course_requirements (requirement_id, program_id, course_type_id, course_count, min_grade, comments)\n  VALUES (v_requirement_id, p_program_id, p_course_type_id, p_course_count, 'C', 'Auto-generated requirement');\nEND;",
    "database_name": "university_craa_tracking",
    "tables": [
      "academic_programs",
      "course_requirements",
      "course_types",
      "courses"
    ],
    "id": 6
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure that deletes a row from the contributors table where the contributor_id column matches the value provided by the parameter p_contributor_id, which is of type NUMBER.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_old_contributor(\n  p_contributor_id NUMBER\n) AS\nBEGIN\n  DELETE FROM contributors WHERE contributor_id = p_contributor_id;\nEND;",
    "database_name": "github_raam_tracking",
    "tables": [
      "commits",
      "contributors",
      "issues",
      "pull_requests",
      "repositories",
      "stargazers",
      "users"
    ],
    "id": 7
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_movie_phase_on_action_genre that returns a trigger, which is automatically executed by a trigger named trg_update_movie_phase_on_action_genre configured to fire after every insert operation on the genres table for each new row, where the function's logic performs an update on the movies table, specifically setting the mcu_phase column to the integer value 2 for the row in the movies table whose movie_id column matches the NEW.movie_id value from the newly inserted row in the genres table, but only if the condition is met where the LOWER function is applied to the NEW.genre_name value from the inserted row, converting it to all lowercase characters, and the resulting string is exactly equal to the string literal 'action'.",
    "plsql": "CREATE OR REPLACE FUNCTION update_movie_phase_on_action_genre() RETURNS TRIGGER AS $$\nBEGIN\n    UPDATE movies SET mcu_phase = 2 WHERE movie_id = NEW.movie_id AND LOWER(NEW.genre_name) = 'action';\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_update_movie_phase_on_action_genre\n    AFTER INSERT ON genres\n    FOR EACH ROW\n    EXECUTE FUNCTION update_movie_phase_on_action_genre();",
    "database_name": "movie_database_and_box_office_performance",
    "tables": [
      "movies",
      "genres",
      "production_companies"
    ],
    "_source": "plfactory14",
    "id": 8
  },
  {
    "ir": "Write a PLpgSQL stored procedure named calculate_customer_order_stats that accepts a parameter p_customer_id of type bigint, which represents the unique identifier of a customer, and two INOUT parameters, p_total_orders of type bigint and p_total_amount of type real, which are used to return the total number of orders and the total amount spent by the specified customer, respectively. The procedure performs a SELECT operation on the orders table, which contains information about customer orders, specifically retrieving the count of all orders and the sum of the total_amount column for rows where the customer_id column matches the provided p_customer_id. The COUNT(*) function is used to determine the total number of orders, and the COALESCE function is applied to the SUM(total_amount) to ensure that if there are no matching orders, the sum defaults to 0 instead of returning a NULL value. The results of this query are stored into the p_total_orders and p_total_amount parameters, effectively updating them with the calculated statistics for the specified customer.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_customer_order_stats(\n    p_customer_id bigint,\n    INOUT p_total_orders bigint,\n    INOUT p_total_amount real\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    SELECT COUNT(*), COALESCE(SUM(total_amount), 0)\n    INTO p_total_orders, p_total_amount\n    FROM orders\n    WHERE customer_id = p_customer_id;\nEND;\n$$;",
    "database_name": "apparel_size_measurement_and_classification",
    "tables": [
      "orders",
      "order_items"
    ],
    "id": 9
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL function named update_media_trustworthiness_based_on_bias that takes no input parameters and returns an integer value representing the count of rows modified. The function operates on a table named media_types, which contains at least the columns trustworthiness (a numeric type) and bias_rating (a numeric type). The function's logic executes a single UPDATE statement targeting the media_types table. For every row in this table where the value in the bias_rating column is strictly greater than 0.5, the function reduces the existing value in the trustworthiness column by multiplying it by 0.9, effectively decreasing it by ten percent. Immediately after the UPDATE operation, the function uses the GET DIAGNOSTICS command to capture the number of rows affected by the update into a local integer variable named v_updated_count. The function then concludes by returning the value stored in v_updated_count.",
    "plsql": "CREATE OR REPLACE FUNCTION update_media_trustworthiness_based_on_bias()\nRETURNS integer AS $$\nDECLARE\n    v_updated_count integer;\nBEGIN\n    UPDATE media_types\n    SET trustworthiness = trustworthiness * 0.9\n    WHERE bias_rating > 0.5;\n    \n    GET DIAGNOSTICS v_updated_count = ROW_COUNT;\n    RETURN v_updated_count;\nEND;\n$$ LANGUAGE plpgsql;",
    "database_name": "media_consumption_and_belief_correlation_analysis",
    "tables": [
      "media_consumption",
      "media_types",
      "conspiracy_belief_indices",
      "time_periods"
    ],
    "_source": "plfactory25",
    "id": 10
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_property_value_on_policy_update that returns a trigger and is executed automatically by a trigger named trg_policy_update_property_value, which is defined to fire after any update operation on the policies table for each row that is modified, where the function's logic performs an update on the properties table, specifically setting the property_value column to the result of multiplying the NEW record's total_premium column value by the NEW record's coverage_scale column value, but only for the row in the properties table where the property_id column matches the NEW record's property_id column value, and the function concludes by returning the NEW row record to the invoking trigger.",
    "plsql": "CREATE OR REPLACE FUNCTION update_property_value_on_policy_update() RETURNS TRIGGER AS $$\nBEGIN\nUPDATE properties SET property_value = NEW.total_premium * NEW.coverage_scale WHERE property_id = NEW.property_id;\nRETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_policy_update_property_value\nAFTER UPDATE ON policies\nFOR EACH ROW EXECUTE FUNCTION update_property_value_on_policy_update();",
    "database_name": "flood_insurance_risk_assessment_and_management",
    "tables": [
      "policies",
      "properties",
      "claims",
      "construction_types",
      "occupancy_types"
    ],
    "_source": "plfactory18",
    "id": 11
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named GetCampaignResponseRank that accepts four parameters: p_campaign_id of type NUMBER which specifies the campaign identifier to filter responses, p_response_type of type VARCHAR2 which defines the type of response to be included in the analysis, p_rank_threshold of type NUMBER which sets the maximum percentile rank value for responses to be included in the result set, and p_results of type SYS_REFCURSOR which is an output parameter that returns the filtered result set. The procedure opens a cursor for the p_results parameter and executes a query that first creates a derived table containing response_id, customer_id, response_date, response_type, response_details columns from the campaign_responses table, filtered by campaign_id matching p_campaign_id and response_type matching p_response_type, while also calculating the PERCENT_RANK() analytical function over the response_date column ordered chronologically to assign a percentile rank to each response. The outer query then selects all columns from this derived table but filters the results to only include rows where the calculated rank is less than or equal to the p_rank_threshold value, effectively returning campaign responses that fall within the specified percentile threshold based on their chronological order.",
    "plsql": "CREATE OR REPLACE PROCEDURE GetCampaignResponseRank(\n  p_campaign_id IN NUMBER,\n  p_response_type IN VARCHAR2,\n  p_rank_threshold IN NUMBER,\n  p_results OUT SYS_REFCURSOR\n) AS\nBEGIN\n  OPEN p_results FOR\n  SELECT response_id, customer_id, response_date, response_type, response_details\n  FROM (\n    SELECT response_id, customer_id, response_date, response_type, response_details,\n           PERCENT_RANK() OVER (ORDER BY response_date) AS rank\n    FROM campaign_responses\n    WHERE campaign_id = p_campaign_id AND response_type = p_response_type\n  )\n  WHERE rank <= p_rank_threshold;\nEND;",
    "database_name": "bank_cr_management",
    "tables": [
      "campaign_responses",
      "campaigns",
      "feedback",
      "interactions",
      "predictions"
    ],
    "id": 12
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named get_user_event_roles that accepts two parameters: p_user_id as an input parameter of type NUMBER representing the unique identifier of the user, and p_cursor as an output parameter of type SYS_REFCURSOR that will return the query results. The procedure opens a cursor for a SELECT query that retrieves information about a specific user's involvement in events. The query performs LEFT JOINs starting with the users table (aliased as u), joining it with the event_organizers table (aliased as eo) on the condition u.user_id = eo.organizer_id, then joining with the event_participants table (aliased as ep) on the condition u.user_id = ep.participant_id, and finally joining with the events table (aliased as e) on the condition e.event_id = eo.event_id OR e.event_id = ep.event_id. The query selects five columns: u.user_name (the name of the user), e.title (the title of the event), a calculated column named user_role that uses the NVL2 function to return 'Organizer' if eo.organizer_id is not NULL (indicating the user is an organizer) or 'Participant' if eo.organizer_id is NULL (indicating the user is a participant), e.start_date (the start date of the event), and e.end_date (the end date of the event). The query filters the results to include only rows where u.user_id equals the input parameter p_user_id and e.event_id is not NULL, ensuring that only actual event participations are returned.",
    "plsql": "CREATE OR REPLACE PROCEDURE get_user_event_roles(p_user_id IN NUMBER, p_cursor OUT SYS_REFCURSOR)\nAS\nBEGIN\n    OPEN p_cursor FOR\n    SELECT u.user_name, e.title,\n           NVL2(eo.organizer_id, 'Organizer', 'Participant') as user_role,\n           e.start_date, e.end_date\n    FROM users u\n    LEFT JOIN event_organizers eo ON u.user_id = eo.organizer_id\n    LEFT JOIN event_participants ep ON u.user_id = ep.participant_id\n    LEFT JOIN events e ON e.event_id = eo.event_id OR e.event_id = ep.event_id\n    WHERE u.user_id = p_user_id\n    AND e.event_id IS NOT NULL;\nEND;",
    "database_name": "academic_ace_management",
    "tables": [
      "events",
      "event_participants",
      "event_organizers",
      "users"
    ],
    "id": 13
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_before_experiment_update that fires automatically before any row in the experiments table is updated, and for each row being updated, it declares two local NUMBER variables v_dataset_count and v_total_duration, then executes a SELECT statement to count all rows in the datasets table where the experiment_id column matches the OLD.experiment_id value from the experiments row before the update, storing the result in v_dataset_count, and executes another SELECT statement to calculate the sum of the mean_duration_seconds column from all rows in the datasets table where the experiment_id column matches the OLD.experiment_id value, storing the result in v_total_duration, then, if the value of v_dataset_count is greater than zero and the value of v_total_duration is greater than 1000, it sets the NEW.status column for the row being updated in the experiments table to the string literal 'Completed', and separately, if the value of v_dataset_count is exactly equal to zero, it sets the NEW.status column for the row being updated in the experiments table to the string literal 'No Data'.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_before_experiment_update\nBEFORE UPDATE ON experiments\nFOR EACH ROW\nDECLARE\n   v_dataset_count NUMBER;\n   v_total_duration NUMBER;\nBEGIN\n   SELECT COUNT(*) INTO v_dataset_count FROM datasets WHERE experiment_id = :OLD.experiment_id;\n   SELECT SUM(mean_duration_seconds) INTO v_total_duration FROM datasets WHERE experiment_id = :OLD.experiment_id;\n   IF v_dataset_count > 0 AND v_total_duration > 1000 THEN\n      :NEW.status := 'Completed';\n   END IF;\n   IF v_dataset_count = 0 THEN\n      :NEW.status := 'No Data';\n   END IF;\nEND;",
    "database_name": "neuroscience_d_analysis",
    "tables": [
      "access_logs",
      "analysis_results",
      "channels",
      "dataset_experiments",
      "datasets",
      "experiments",
      "users"
    ],
    "_source": "plfactory16",
    "id": 14
  },
  {
    "ir": "Write an Oracle PL/SQL function named get_item_condition_category that accepts a single parameter, p_item_id, of type NUMBER, which represents the unique identifier of an item in the items table. The function returns a value of type VARCHAR2. Within the function, a local variable v_condition of type VARCHAR2 with a maximum length of 255 characters is declared to store the condition of the item. The function begins by executing a SELECT statement that retrieves the condition column value from the items table for the row where the item_id column matches the value of the p_item_id parameter. This retrieved condition value is stored in the v_condition variable. The function then evaluates the first character of the v_condition string using the SUBSTR function to extract the first character and the ASCII function to obtain its ASCII code. A conditional statement checks if the ASCII code of this first character is less than 78. If this condition is true, the function returns the string 'Condition starts with letter before N'. Otherwise, it returns the string 'Condition starts with letter N or later'.",
    "plsql": "CREATE OR REPLACE FUNCTION get_item_condition_category(p_item_id NUMBER) RETURN VARCHAR2 IS\n  v_condition VARCHAR2(255);\nBEGIN\n  SELECT condition INTO v_condition FROM items WHERE item_id = p_item_id;\n  IF ASCII(SUBSTR(v_condition, 1, 1)) < 78 THEN\n    RETURN 'Condition starts with letter before N';\n  ELSE\n    RETURN 'Condition starts with letter N or later';\n  END IF;\nEND;",
    "database_name": "inventory_maa_tracking",
    "tables": [
      "items",
      "categories",
      "item_audit_trail",
      "item_movements",
      "item_requests",
      "item_requisitions",
      "users"
    ],
    "id": 15
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_users_last_login that is defined to execute before any update operation on the users table, operating at the row level which means it will fire once for each individual row being modified, and within the trigger body, it assigns a new value to the last_login_date column of the row being updated by converting the current date to a character string using the TO_CHAR function with the format mask 'YYYY-MM-DD', which formats the date as a four-digit year followed by a hyphen, then a two-digit month, another hyphen, and finally a two-digit day, effectively setting the last_login_date field to today's date whenever any update operation occurs on any row in the users table.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_users_last_login\nBEFORE UPDATE ON users\nFOR EACH ROW\nBEGIN\n    :NEW.last_login_date := TO_CHAR(CURRENT_DATE, 'YYYY-MM-DD');\nEND;",
    "database_name": "geospatial_dma_mapping",
    "tables": [
      "geospatial_data",
      "geospatial_data_relationships",
      "geospatial_datasets",
      "projects",
      "reports",
      "user_roles",
      "users"
    ],
    "id": 16
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_delete_league that is defined to execute before a delete operation on the leagues table for each row being deleted, and within its body, it performs two delete operations: first, it deletes all rows from the player_stats table where the league_id column matches the value of the league_id column from the currently deleting row in the leagues table, referenced as :OLD.league_id, and second, it deletes all rows from the players table where the current_club column matches the value of the league_name column from the currently deleting row in the leagues table, referenced as :OLD.league_name.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_delete_league\nBEFORE DELETE ON leagues\nFOR EACH ROW\nBEGIN\n    DELETE FROM player_stats WHERE league_id = :OLD.league_id;\n    DELETE FROM players WHERE current_club = :OLD.league_name;\nEND;",
    "database_name": "professional_spsap_tracki",
    "tables": [
      "leagues",
      "player_stats",
      "players"
    ],
    "_source": "plfactory28",
    "id": 17
  },
  {
    "ir": "Write an Oracle PL/SQL function named get_latest_user_email that returns a VARCHAR2 value, which declares a local variable v_email of type VARCHAR2(255), then executes a SELECT statement that retrieves the email column from the users table for the row where the created_at column matches the maximum created_at value found in the users table (using a subquery with the MAX function), stores this email value in the v_email variable, and finally returns this v_email value.",
    "plsql": "CREATE OR REPLACE FUNCTION get_latest_user_email RETURN VARCHAR2 IS\n    v_email VARCHAR2(255);\nBEGIN\n    SELECT email INTO v_email FROM users WHERE created_at = (SELECT MAX(created_at) FROM users);\n    RETURN v_email;\nEND;",
    "database_name": "web_bh_management",
    "tables": [
      "bookmarks",
      "folders",
      "tags",
      "bookmark_tags",
      "users"
    ],
    "id": 18
  },
  {
    "ir": "Write a PostgreSQL trigger function named trg_validate_algorithm_id that is executed as a BEFORE INSERT OR UPDATE trigger on the algorithm_runs table for each affected row, which begins by checking if the new row's algorithm_id column value is not null and if that specific algorithm_id value does not exist in the algorithms table by performing a SELECT 1 query from the algorithms table where the algorithm_id column equals the new row's algorithm_id value, and if both conditions are true, the function raises an exception with the message 'Foreign key violation: algorithm_id % does not exist in algorithms table' and substitutes the percent sign placeholder with the actual NEW.algorithm_id value, thereby preventing the insert or update operation on the algorithm_runs table; if the algorithm_id is null or the SELECT query finds a matching row in the algorithms table, the function proceeds to return the NEW row record to allow the triggering INSERT or UPDATE operation on the algorithm_runs table to continue.",
    "plsql": "CREATE OR REPLACE FUNCTION trg_validate_algorithm_id() RETURNS TRIGGER AS $$\nBEGIN\n    IF NEW.algorithm_id IS NOT NULL AND NOT EXISTS (\n        SELECT 1 FROM algorithms WHERE algorithm_id = NEW.algorithm_id\n    ) THEN\n        RAISE EXCEPTION 'Foreign key violation: algorithm_id % does not exist in algorithms table', NEW.algorithm_id;\n    END IF;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER validate_algorithm_id\nBEFORE INSERT OR UPDATE ON algorithm_runs\nFOR EACH ROW EXECUTE FUNCTION trg_validate_algorithm_id();",
    "database_name": "optimization_algorithm_performance_analysis_210470",
    "tables": [
      "algorithms",
      "algorithm_types",
      "algorithm_runs",
      "performance_metrics",
      "performance_metric_types"
    ],
    "_source": "plfactory29",
    "id": 19
  },
  {
    "ir": "Write an Oracle PL/SQL database trigger named `trg_update_harvest_date`. This trigger is defined to execute `AFTER INSERT` operations on the `harvest_records` table. It is a `FOR EACH ROW` trigger, meaning it will execute once for each row that is newly inserted into the `harvest_records` table. The purpose of this trigger is to insert new records into the `product_weights` table. For each new row inserted into `harvest_records`, the trigger performs an `INSERT` operation into the `product_weights` table. The `INSERT` statement populates the `gst_id_no`, `collection_date`, `farm_id`, and `region_id` columns of the `product_weights` table. The value for the `gst_id_no` column is taken directly from the `gst_id_no` column of the newly inserted row in `harvest_records`, referenced as `:NEW.gst_id_no`. The value for the `collection_date` column is taken directly from the `harvest_date` column of the newly inserted row in `harvest_records`, referenced as `:NEW.harvest_date`. The values for the `farm_id` and `region_id` columns are retrieved by executing a `SELECT` statement against the `farms` table. This `SELECT` statement retrieves the `farm_id` and `region_id` columns from the `farms` table, aliased as `f`. The `WHERE` clause of this `SELECT` statement filters the `farms` table records based on a concatenated string comparison. Specifically, it concatenates the `farm_name` column of the `farms` table with a comma and a space (`, `) and then with the `location` column of the `farms` table. This concatenated string `f.farm_name || ', ' || f.location` is then compared for equality with the `farm_location` column of the newly inserted row in `harvest_records`, referenced as `:NEW.farm_location`. The `farm_id` and `region_id` values from the `farms` table row that satisfies this condition are then used for the `INSERT` into `product_weights`.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_update_harvest_date\nAFTER INSERT ON harvest_records\nFOR EACH ROW\nBEGIN\n  INSERT INTO product_weights (gst_id_no, collection_date, farm_id, region_id)\n  SELECT :NEW.gst_id_no, :NEW.harvest_date, f.farm_id, f.region_id\n  FROM farms f\n  WHERE f.farm_name || ', ' || f.location = :NEW.farm_location;\nEND;",
    "database_name": "agricultural_ptaw_managem",
    "tables": [
      "farms",
      "harvest_records",
      "product_weights",
      "logistics"
    ],
    "id": 20
  },
  {
    "ir": "Write an Oracle PL/SQL function named `get_gene_interaction_count` that is designed to return a numerical value representing the count of gene interactions. This function accepts two input parameters: `p_gene_id`, which is of data type `NUMBER` and represents the unique identifier of a gene, and `p_interaction_type`, which is of data type `VARCHAR2` and specifies the type of interaction to be counted. The function declares a local variable `v_count` of data type `NUMBER` to temporarily store the result of the counting operation. The core operation of this function involves executing a `SELECT` statement to retrieve data from the `gene_interactions` table. Specifically, it performs a `COUNT(*)` aggregation, which calculates the total number of rows that satisfy a set of specified conditions. The result of this count is then stored into the `v_count` variable. The conditions for counting rows are as follows: first, either the `gene_id_1` column or the `gene_id_2` column in the `gene_interactions` table must be equal to the value provided in the `p_gene_id` input parameter, indicating that the specified gene is involved in the interaction as either the first or second gene. Second, the `interaction_type` column in the `gene_interactions` table must be equal to the value provided in the `p_interaction_type` input parameter, ensuring that only interactions of the specified type are considered. After the `SELECT` statement has executed and the count is stored in `v_count`, the function then returns the final `v_count` value as its output.",
    "plsql": "CREATE OR REPLACE FUNCTION get_gene_interaction_count(p_gene_id NUMBER, p_interaction_type VARCHAR2)\nRETURN NUMBER\nIS\n    v_count NUMBER;\nBEGIN\n    SELECT COUNT(*)\n    INTO v_count\n    FROM gene_interactions\n    WHERE (gene_id_1 = p_gene_id OR gene_id_2 = p_gene_id)\n      AND interaction_type = p_interaction_type;\n\n    RETURN v_count;\nEND;",
    "database_name": "genetic_ampil_regulation",
    "tables": [
      "genes",
      "gene_aliases",
      "gene_interactions",
      "differential_expression",
      "regulation_effects",
      "tissue_expression",
      "studies"
    ],
    "id": 21
  },
  {
    "ir": "Write a PL/pgSQL trigger function named update_session_status_trigger that is designed to be executed before an UPDATE operation on the sessions table, for each row being updated. This function takes no explicit parameters but operates on the implicit NEW and OLD records provided by the trigger mechanism. The function's primary purpose is to enforce a specific status change for sessions. Specifically, it checks the value of the session_status column in the OLD record (representing the row's state before the update). If the value of OLD.session_status is not equal to the string literal 'inactive', then the function modifies the session_status column in the NEW record (representing the row's state after the update) by setting its value to the string literal 'inactive'. After this conditional modification, the function returns the NEW record, which then becomes the actual row data used for the UPDATE operation. This trigger function is then associated with a trigger named session_status_update. This trigger is configured to fire BEFORE any UPDATE statement is executed on the sessions table. It is set to operate FOR EACH ROW affected by the UPDATE statement, meaning the update_session_status_trigger() function will be executed once for every row that is being updated. The trigger's action is to EXECUTE FUNCTION update_session_status_trigger(), thereby invoking the logic described above for each updated row.",
    "plsql": "CREATE OR REPLACE FUNCTION update_session_status_trigger() RETURNS TRIGGER AS $$\nBEGIN\n    IF OLD.session_status != 'inactive' THEN\n        NEW.session_status = 'inactive';\n    END IF;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER session_status_update\n    BEFORE UPDATE ON sessions\n    FOR EACH ROW\n    EXECUTE FUNCTION update_session_status_trigger();",
    "database_name": "parliamentary_proceedings_and_speaker_information",
    "tables": [
      "sessions",
      "speakers",
      "speeches",
      "houses"
    ],
    "id": 22
  },
  {
    "ir": "Write a PostgreSQL trigger function named delete_related_records that returns a trigger and is executed by a trigger named trg_delete_related_records, which is defined to fire BEFORE DELETE on the transcripts table FOR EACH ROW, where the function's logic performs a series of DELETE operations on six dependent tables to cascade the deletion, specifically deleting all rows from the duration_analysis table where the transcript_id column equals the OLD.transcript_id value from the row being deleted from transcripts, then deleting all rows from the ellipses table where the transcript_id column equals OLD.transcript_id, then deleting all rows from the questions table where the transcript_id column equals OLD.transcript_id, then deleting all rows from the speaker_info table where the transcript_id column equals OLD.transcript_id, then deleting all rows from the tags table where the transcript_id column equals OLD.transcript_id, and finally deleting all rows from the transcript_versions table where the transcript_id column equals OLD.transcript_id, after which the function returns the OLD row record.",
    "plsql": "CREATE OR REPLACE FUNCTION delete_related_records() RETURNS TRIGGER AS $$\nBEGIN\n  DELETE FROM duration_analysis WHERE transcript_id = OLD.transcript_id;\n  DELETE FROM ellipses WHERE transcript_id = OLD.transcript_id;\n  DELETE FROM questions WHERE transcript_id = OLD.transcript_id;\n  DELETE FROM speaker_info WHERE transcript_id = OLD.transcript_id;\n  DELETE FROM tags WHERE transcript_id = OLD.transcript_id;\n  DELETE FROM transcript_versions WHERE transcript_id = OLD.transcript_id;\n  RETURN OLD;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_delete_related_records\nBEFORE DELETE ON transcripts\nFOR EACH ROW\nEXECUTE FUNCTION delete_related_records();",
    "database_name": "speech_transcription_analysis_and_data_management",
    "tables": [
      "transcripts",
      "certainty_levels",
      "ellipses",
      "questions",
      "speaker_info",
      "tags",
      "transcript_versions",
      "duration_analysis"
    ],
    "_source": "plfactory10",
    "id": 23
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `bulk_insert_metrics` that accepts five input parameters: `p_iteration_id` of type `bigint`, `p_base_value` of type `real`, `p_increment` of type `real`, `p_metric_prefix` of type `text`, and `p_count` of type `bigint`. The purpose of this procedure is to perform a bulk insertion of performance metric records into the `performance_metrics` table.\n\nUpon execution, the procedure declares three local variables: `v_counter` of type `bigint`, `v_metric_id` of type `bigint`, and `v_current_value` of type `real`.\n\nThe procedure initializes `v_counter` to `1` and `v_current_value` to the value provided by the `p_base_value` input parameter.\n\nIt then enters a `WHILE` loop that continues as long as the value of `v_counter` is less than or equal to the value of the `p_count` input parameter.\n\nInside the loop, for each iteration:\n1. It executes a `SELECT` statement to determine the next available `metric_id`. This is achieved by querying the `performance_metrics` table, finding the maximum value in the `metric_id` column, and adding `1` to it. If the `performance_metrics` table is empty and `MAX(metric_id)` returns `NULL`, the `COALESCE` function ensures that `0` is used instead, resulting in `v_metric_id` being set to `1`. The result of this `SELECT` operation is stored in the `v_metric_id` local variable.\n2. It performs an `INSERT` operation into the `performance_metrics` table. The values inserted into the columns are as follows:\n    - `metric_id`: The value from the `v_metric_id` local variable.\n    - `iteration_id`: The value from the `p_iteration_id` input parameter.\n    - `metric_name`: A concatenated string formed by taking the `p_metric_prefix` input parameter, appending an underscore (`_`), and then appending the string representation of the `v_counter` local variable (achieved by casting `v_counter` to `text` using `::text`).\n    - `metric_value`: The value from the `v_current_value` local variable.\n    - `metric_type`: The literal string `'generated'`.\n    - `is_key_metric`: The literal integer `0`.\n3. It increments the `v_counter` local variable by `1`.\n4. It increments the `v_current_value` local variable by the value of the `p_increment` input parameter.\n\nThe loop continues until `v_counter` exceeds `p_count`, at which point the procedure concludes its execution.",
    "plsql": "CREATE OR REPLACE PROCEDURE bulk_insert_metrics(p_iteration_id bigint, p_base_value real, p_increment real, p_metric_prefix text, p_count bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_counter bigint;\n    v_metric_id bigint;\n    v_current_value real;\nBEGIN\n    v_counter := 1;\n    v_current_value := p_base_value;\n    \n    WHILE v_counter <= p_count LOOP\n        SELECT COALESCE(MAX(metric_id), 0) + 1 INTO v_metric_id FROM performance_metrics;\n        \n        INSERT INTO performance_metrics (metric_id, iteration_id, metric_name, metric_value, metric_type, is_key_metric)\n        VALUES (v_metric_id, p_iteration_id, p_metric_prefix || '_' || v_counter::text, v_current_value, 'generated', 0);\n        \n        v_counter := v_counter + 1;\n        v_current_value := v_current_value + p_increment;\n    END LOOP;\nEND;\n$$;",
    "database_name": "optimization_and_performance_analysis_in_iterative_processes",
    "tables": [
      "iterations",
      "performance_metrics",
      "comments"
    ],
    "id": 24
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL function named calculate_average_height_by_nationality that returns a table with two columns, nationality of type text and avg_height of type real, and performs a query that selects from the athletes table and joins it with the athlete_heights table using the condition that the athlete_id from the athletes table matches the athlete_id from the athlete_heights table, then groups the resulting rows by the nationality column from the athletes table, calculates the average of the height_value column from the athlete_heights table for each nationality group, explicitly casts this average value to the real data type and aliases it as avg_height, and finally orders the entire result set by the calculated avg_height column in descending order.",
    "plsql": "CREATE OR REPLACE FUNCTION calculate_average_height_by_nationality()\nRETURNS TABLE(nationality text, avg_height real)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    RETURN QUERY\n    SELECT a.nationality, AVG(h.height_value)::real as avg_height\n    FROM athletes a\n    JOIN athlete_heights h ON a.athlete_id = h.athlete_id\n    GROUP BY a.nationality\n    ORDER BY avg_height DESC;\nEND;\n$$;",
    "database_name": "athlete_information_and_sports_discipline_management",
    "tables": [
      "athlete_events",
      "athlete_heights",
      "athlete_sports",
      "athletes"
    ],
    "id": 25
  },
  {
    "ir": "Write an Oracle PL/SQL function named get_avg_mse that calculates and returns a numeric value representing the average of all values in the mse_value column from the mse_values table. The function does not take any input parameters. Inside the function, declare a local variable v_avg_mse of type NUMBER to store the result of the calculation. Execute a SQL SELECT statement that computes the average of the mse_value column from the mse_values table and assigns this average value to the v_avg_mse variable using the INTO clause. Finally, return the value stored in v_avg_mse as the output of the function.",
    "plsql": "CREATE OR REPLACE FUNCTION get_avg_mse RETURN NUMBER IS\n    v_avg_mse NUMBER;\nBEGIN\n    SELECT AVG(mse_value) INTO v_avg_mse FROM mse_values;\n    RETURN v_avg_mse;\nEND;",
    "database_name": "image_ca_analysis",
    "tables": [
      "compression_algorithms",
      "compression_results",
      "compression_settings",
      "dct_coefficients",
      "file_sizes",
      "images",
      "mse_values",
      "psnr_values"
    ],
    "id": 26
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named count_user_logs_by_date that accepts two parameters: an input parameter p_target_date of type DATE, which specifies the date for which to count logs, and an output parameter p_log_count of type NUMBER, which will hold the resulting count. The procedure's logic begins by constructing and executing a dynamic SQL statement using the EXECUTE IMMEDIATE command. This dynamic SQL statement is a SELECT query that counts all rows from the table named \"ACCESS_LOGS\" where the condition TRUNC(\"LOG_DATE\") = TRUNC(:1) is true. The TRUNC function is applied to both the \"LOG_DATE\" column and the bind variable :1 to remove the time component, ensuring the comparison is made on the date part only. The bind variable :1 is supplied with the value of the input parameter p_target_date via the USING clause, and the result of the COUNT(*) aggregation is directly fetched into the output parameter p_log_count. If any exception is raised during the execution of this dynamic SQL block, the procedure's EXCEPTION handler for WHEN OTHERS catches it and assigns the value 0 to the output parameter p_log_count.",
    "plsql": "CREATE OR REPLACE PROCEDURE count_user_logs_by_date(\n    p_target_date IN DATE,\n    p_log_count OUT NUMBER\n)\nIS\nBEGIN\n    EXECUTE IMMEDIATE '\n        SELECT COUNT(*)\n        FROM \"ACCESS_LOGS\"\n        WHERE TRUNC(\"LOG_DATE\") = TRUNC(:1)\n    ' INTO p_log_count USING p_target_date;\nEXCEPTION\n    WHEN OTHERS THEN\n        p_log_count := 0;\nEND;",
    "database_name": "financial_mdaa_351094",
    "tables": [
      "ACCESS_LOGS",
      "STOCK_EXCHANGES",
      "STOCK_EXCHANGE_DATA",
      "STOCK_TICKERS",
      "USERS"
    ],
    "_source": "plfactory18",
    "id": 27
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `consolidate_variable_data` that accepts three input parameters: `p_variable_code` of type `text`, `p_year` of type `bigint`, and `p_region_code` of type `text`. The procedure first declares three local variables: `v_total_value` of type `bigint`, `v_average_value` of type `numeric`, and `v_region_name` of type `text`. It then executes a `SELECT` statement to calculate the sum and average of `value` from the `data_points` table. This `SELECT` statement joins `data_points` (aliased as `dp`) with the `countries` table (aliased as `c`) on the condition `dp.country_code = c.country_code`. The selection is filtered by three conditions: `dp.variable_code` must be equal to the input parameter `p_variable_code`, `dp.year` must be equal to the input parameter `p_year`, and `c.region_code` must be equal to the input parameter `p_region_code`. The calculated sum is assigned to the local variable `v_total_value`, and the calculated average is assigned to the local variable `v_average_value`. Following this, the procedure enters a conditional block. If the `v_total_value` is greater than `100000`, it sets the `v_region_name` variable to the concatenated string 'High Data Region: ' followed by the value of `p_region_code`. Subsequently, it executes an `INSERT` statement into the `data_points` table. The `data_point_id` column is set to its `DEFAULT` value, `country_code` is set to the literal string '999', `variable_code` is set to the value of `p_variable_code`, `risk_code` is set to the literal string '0', `sex` is set to the literal string 'Both', `age` is set to the literal string 'All', `year` is set to the value of `p_year`, `value` is set to the value of `v_total_value`, `dataset_version` is set to the literal string 'v2.0', `data_source` is set to the value of `v_region_name`, `data_quality` is set to the literal string 'Consolidated', and `created_at` is set to the current timestamp converted to `text` using `NOW()::text`. If the first condition is false, the procedure checks if `v_total_value` is between `50000` and `100000` (inclusive). If this condition is true, it sets the `v_region_name` variable to the concatenated string 'Moderate Data Region: ' followed by the value of `p_region_code`. Then, it issues a `RAISE NOTICE` message to the client, indicating that the region (identified by `v_region_name`) has moderate data, along with its `v_total_value`. If both previous conditions are false, meaning `v_total_value` is less than `50000`, the procedure executes the `ELSE` block. In this block, it issues a `RAISE NOTICE` message to the client, indicating that the region (identified by `p_region_code`) has low data, along with its `v_total_value`.",
    "plsql": "CREATE OR REPLACE PROCEDURE consolidate_variable_data(\n    p_variable_code text,\n    p_year bigint,\n    p_region_code text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_total_value bigint;\n    v_average_value numeric;\n    v_region_name text;\nBEGIN\n    SELECT SUM(dp.value), AVG(dp.value) INTO v_total_value, v_average_value\n    FROM data_points dp\n    JOIN countries c ON dp.country_code = c.country_code\n    WHERE dp.variable_code = p_variable_code AND dp.year = p_year AND c.region_code = p_region_code;\n\n    IF v_total_value > 100000 THEN\n        v_region_name := 'High Data Region: ' || p_region_code;\n        INSERT INTO data_points (data_point_id, country_code, variable_code, risk_code, sex, age, year, value, dataset_version, data_source, data_quality, created_at)\n        VALUES (DEFAULT, '999', p_variable_code, '0', 'Both', 'All', p_year, v_total_value, 'v2.0', v_region_name, 'Consolidated', NOW()::text);\n    ELSIF v_total_value BETWEEN 50000 AND 100000 THEN\n        v_region_name := 'Moderate Data Region: ' || p_region_code;\n        RAISE NOTICE 'Region % has moderate data with total value: %', v_region_name, v_total_value;\n    ELSE\n        RAISE NOTICE 'Region % has low data with total value: %', p_region_code, v_total_value;\n    END IF;\nEND;\n$$;",
    "database_name": "global_health_and_demographic_data_analysis",
    "tables": [
      "countries",
      "data_points",
      "risks",
      "users",
      "variables"
    ],
    "id": 28
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_before_category_update that executes before any row is updated in the categories table, declaring local variables v_related_articles as a NUMBER and v_min_comment_date as a VARCHAR2 with a length of 255 characters, which first performs a SELECT COUNT(*) query on the article_categories table to count all rows where the category_id column matches the old value of the category_id column from the categories table being updated, storing the result in v_related_articles, then performs a SELECT MIN(comment_date) query on the comments table for the minimum comment_date where the article_id is found in a subquery that selects the article_id from the article_categories table for rows where the category_id matches the old value of the category_id column, storing the result in v_min_comment_date, and then, if the new value of the is_active column being set in the update is 0 and the v_related_articles count is greater than 0, executes an UPDATE statement on the article_categories table to set the updated_at column to the current system date converted to a 'YYYY-MM-DD' format string using the TO_CHAR and SYSDATE functions for all rows where the category_id matches the old value of the category_id column, and then, if the v_min_comment_date variable is not NULL, assigns the new value of the updated_at column in the categories table for the current row to the current system date converted to a 'YYYY-MM-DD' format string using the TO_CHAR and SYSDATE functions.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_before_category_update\nBEFORE UPDATE ON categories\nFOR EACH ROW\nDECLARE\n    v_related_articles NUMBER;\n    v_min_comment_date VARCHAR2(255);\nBEGIN\n    SELECT COUNT(*) INTO v_related_articles FROM article_categories WHERE category_id = :OLD.category_id;\n    SELECT MIN(comment_date) INTO v_min_comment_date FROM comments WHERE article_id IN (SELECT article_id FROM article_categories WHERE category_id = :OLD.category_id);\n    IF :NEW.is_active = 0 AND v_related_articles > 0 THEN\n        UPDATE article_categories SET updated_at = TO_CHAR(SYSDATE, 'YYYY-MM-DD') WHERE category_id = :OLD.category_id;\n    END IF;\n    IF v_min_comment_date IS NOT NULL THEN\n        :NEW.updated_at := TO_CHAR(SYSDATE, 'YYYY-MM-DD');\n    END IF;\nEND;",
    "database_name": "news_am_system",
    "tables": [
      "article_categories",
      "categories",
      "comments",
      "users"
    ],
    "_source": "plfactory6",
    "id": 29
  },
  {
    "ir": "Write a PLpgSQL stored procedure named find_inactive_users that accepts four parameters: p_days_inactive of type bigint, p_role of type text, p_min_user_id of type bigint, and p_max_user_id of type bigint. The procedure is designed to identify users who have been inactive for a specified number of days, belong to a specific role, and have user IDs within a given range. It begins by calculating a cutoff date by subtracting p_days_inactive days from the current date and converting the result to text format, storing it in the variable v_cutoff_date. The procedure then iterates over records in the users table, selecting columns user_id, user_name, email, last_login, and created_at for users whose role matches the p_role parameter, whose user_id falls between p_min_user_id and p_max_user_id, whose last_login date is earlier than the calculated v_cutoff_date, and whose is_active status is 1. The selected records are ordered by last_login in ascending order. For each record retrieved, the procedure formats the user information into a string, aligning user_name to 25 characters, email to 35 characters, last_login to 20 characters, and created_at to 20 characters, and stores this formatted string in the variable v_formatted_info.",
    "plsql": "CREATE OR REPLACE PROCEDURE find_inactive_users(p_days_inactive bigint, p_role text, p_min_user_id bigint, p_max_user_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    rec RECORD;\n    v_cutoff_date text;\n    v_formatted_info text;\nBEGIN\n    v_cutoff_date := (CURRENT_DATE - p_days_inactive * INTERVAL '1 day')::text;\n    \n    FOR rec IN\n        SELECT user_id, user_name, email, last_login, created_at\n        FROM users\n        WHERE role = p_role\n        AND user_id BETWEEN p_min_user_id AND p_max_user_id\n        AND last_login < v_cutoff_date\n        AND is_active = 1\n        ORDER BY last_login ASC\n    LOOP\n        v_formatted_info := rpad(rec.user_name, 25) || ' | ' ||\n                          rpad(rec.email, 35) || ' | ' ||\n                          rpad(rec.last_login, 20) || ' | ' ||\n                          rpad(rec.created_at, 20);\n    END LOOP;\nEND;\n$$;",
    "database_name": "airport_network_analysis",
    "tables": [
      "airports",
      "flights",
      "users"
    ],
    "id": 30
  },
  {
    "ir": "Write a PLpgSQL stored procedure that deletes rows from the properties table where the outcome column has the value 'Unsold' and the outcome_date column, when cast to a timestamp, is earlier than one year before the current timestamp. The procedure performs this operation by executing a DELETE statement that targets rows meeting these conditions. The properties table is the only table involved, and the columns used in the operation are outcome and outcome_date. The condition checks that the outcome column equals the string 'Unsold' and that the outcome_date column, converted to a timestamp data type, is less than the result of subtracting an interval of one year from the current timestamp, which is obtained using the NOW() function. The procedure does not take any parameters and does not return any values.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_unsold_properties() LANGUAGE plpgsql AS $$\nBEGIN\n  DELETE FROM properties\n  WHERE outcome = 'Unsold' AND outcome_date::timestamp < NOW() - INTERVAL '1 year';\nEND;\n$$;",
    "database_name": "real_estate_sales_data_management",
    "tables": [
      "agents",
      "market_trends",
      "properties",
      "property_views",
      "sales_outcomes",
      "suburbs"
    ],
    "id": 31
  },
  {
    "ir": "Write a PostgreSQL PL/SQL stored procedure named archive_player_data that accepts three input parameters: p_player_id of type bigint representing the unique identifier of a player, p_season_year of type bigint representing the year of a season, and p_archive_type of type text, and begins by declaring two local variables, v_season_id and v_performance_count, both of type bigint; the procedure then performs a SELECT operation on the seasons table to retrieve the season_id value where the season_year column matches the provided p_season_year parameter and stores this result into the v_season_id variable, followed by a SELECT COUNT(*) operation on the pitching_performance table to count all rows where the player_id column equals the provided p_player_id and the season_id column equals the retrieved v_season_id value, storing this count into the v_performance_count variable; subsequently, the procedure executes a DELETE operation on the advanced_analytics table where the performance_id column matches any value from a subquery that selects the performance_id column from the pitching_performance table for rows where the player_id equals p_player_id and the season_id equals v_season_id; finally, the procedure performs another DELETE operation directly on the pitching_performance table to remove all rows where the player_id column equals p_player_id and the season_id column equals v_season_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE archive_player_data(p_player_id bigint, p_season_year bigint, p_archive_type text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_season_id bigint;\n    v_performance_count bigint;\nBEGIN\n    SELECT season_id INTO v_season_id FROM seasons WHERE season_year = p_season_year;\n    \n    SELECT COUNT(*) INTO v_performance_count\n    FROM pitching_performance pp\n    WHERE pp.player_id = p_player_id AND pp.season_id = v_season_id;\n    \n    DELETE FROM advanced_analytics \n    WHERE performance_id IN (\n        SELECT pp.performance_id \n        FROM pitching_performance pp \n        WHERE pp.player_id = p_player_id AND pp.season_id = v_season_id\n    );\n    \n    DELETE FROM pitching_performance \n    WHERE player_id = p_player_id AND season_id = v_season_id;\nEND;\n$$;",
    "database_name": "baseball_pitching_analytics",
    "tables": [
      "players",
      "seasons",
      "pitching_performance",
      "advanced_analytics",
      "seasonal_comparisons",
      "reports"
    ],
    "id": 32
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL function named delete_old_price_history that accepts two parameters: p_card_id of type bigint which identifies a specific card, and p_cutoff_date of type text which represents a date threshold, and performs a deletion operation on the price_history table by removing all rows where the card_id column matches the provided p_card_id parameter and the price_date column contains a value that is earlier than the specified p_cutoff_date parameter, effectively cleaning up historical price data for a particular card that predates the cutoff date.",
    "plsql": "CREATE OR REPLACE FUNCTION delete_old_price_history(p_card_id bigint, p_cutoff_date text)\nRETURNS void\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM price_history WHERE card_id = p_card_id AND price_date < p_cutoff_date;\nEND;\n$$;",
    "database_name": "trading_card_market_and_price_tracking",
    "tables": [
      "cards",
      "price_history",
      "notifications"
    ],
    "id": 33
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_format_cleanup that is defined to execute automatically after a delete operation is performed on the FORMATS table, and it is configured to fire once for each individual row that is deleted from the FORMATS table; the trigger's execution block contains a single DELETE statement that removes rows from the EPISODE_FILES table where the value in the EPISODE_FILES.format_id column is exactly equal to the value that was stored in the FORMATS.format_id column of the specific FORMATS table row that was just deleted, which is referenced using the :OLD.format_id bind variable.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_format_cleanup\nAFTER DELETE ON FORMATS\nFOR EACH ROW\nBEGIN\n    DELETE FROM EPISODE_FILES WHERE format_id = :OLD.format_id;\nEND;",
    "database_name": "television_sema_tracking",
    "tables": [
      "EPISODE_FILES",
      "FORMATS",
      "RESOLUTIONS",
      "AUDIO_CODECS",
      "GENRES",
      "SERIES",
      "PRODUCTION_COMPANIES"
    ],
    "_source": "plfactory15",
    "id": 34
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named process_student_assessments that initializes several local variables, including v_current_date of type DATE to store the current system date, v_student_count and v_assessment_count of type NUMBER to hold simulated counts of students and assessments respectively, v_score_threshold of type NUMBER to determine a threshold score, and v_processed_records of type NUMBER initialized to zero to track the number of records processed. The procedure begins by assigning the current date to v_current_date using the SYSDATE function, and sets v_student_count to 1500 and v_assessment_count to 75 as simulated values. It then evaluates a series of conditional statements to determine the value of v_score_threshold and v_processed_records based on the values of v_student_count and v_assessment_count. If v_student_count is greater than 1000 and v_assessment_count is greater than 50, v_score_threshold is set to 90 and v_processed_records to 10. If v_student_count is between 500 and 1000 and v_assessment_count is between 20 and 50, v_score_threshold is set to 85 and v_processed_records to 8. If v_student_count is less than 500 and v_assessment_count is less than 20, v_score_threshold is set to 80 and v_processed_records to 5. Otherwise, v_score_threshold is set to 75 and v_processed_records to 3. The procedure concludes by using the DBMS_OUTPUT.PUT_LINE function to output the values of v_score_threshold and v_processed_records, simulating processing logic without performing actual database operations.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_student_assessments IS\n    v_current_date DATE;\n    v_student_count NUMBER;\n    v_assessment_count NUMBER;\n    v_score_threshold NUMBER;\n    v_processed_records NUMBER := 0;\nBEGIN\n    v_current_date := SYSDATE;\n    v_student_count := 1500; -- Simulated count\n    v_assessment_count := 75; -- Simulated count\n    \n    IF v_student_count > 1000 AND v_assessment_count > 50 THEN\n        v_score_threshold := 90;\n        v_processed_records := 10; -- Simulated deletion count\n    ELSIF v_student_count BETWEEN 500 AND 1000 AND v_assessment_count BETWEEN 20 AND 50 THEN\n        v_score_threshold := 85;\n        v_processed_records := 8; -- Simulated deletion count\n    ELSIF v_student_count < 500 AND v_assessment_count < 20 THEN\n        v_score_threshold := 80;\n        v_processed_records := 5; -- Simulated deletion count\n    ELSE\n        v_score_threshold := 75;\n        v_processed_records := 3; -- Simulated deletion count\n    END IF;\n    \n    -- Simulated processing logic without actual database operations\n    DBMS_OUTPUT.PUT_LINE('Score threshold set to: ' || v_score_threshold);\n    DBMS_OUTPUT.PUT_LINE('Processed records: ' || v_processed_records);\nEND;",
    "database_name": "educational_aa_testing",
    "tables": [
      "ASSESSMENTS",
      "ASSESSMENT_SUBJECTS",
      "ASSESSMENT_TOPICS",
      "PV_SCORES",
      "QUESTIONS",
      "RESPONSES",
      "SCORES",
      "STUDENTS"
    ],
    "id": 35
  },
  {
    "ir": "Write an Oracle PL/SQL function named `update_notification_status` that does not accept any input parameters. This function is designed to modify data within the `notifications` table. Specifically, it performs an `UPDATE` operation on the `notifications` table. The `UPDATE` operation sets the value of the `status` column to the string literal `'viewed'`. This update is applied only to rows that satisfy two conditions simultaneously. The first condition requires that the current value of the `status` column in the `notifications` table must be equal to the string literal `'sent'`. The second condition involves the `notification_date` column. The value from the `notification_date` column, which is assumed to be a string, is first converted into a `DATE` data type using the `TO_DATE` function with the format mask `'YYYY-MM-DD'`. This converted date is then compared to a calculated date. The calculated date is derived by taking the current system date and time, represented by `SYSDATE`, and subtracting 7 days from it. The second condition is met if the converted `notification_date` is strictly less than (`<`) this calculated date (i.e., `SYSDATE - 7`). After the `UPDATE` statement has completed its execution, the function returns a `NUMBER` value. This returned `NUMBER` represents the total count of rows that were successfully updated by the `UPDATE` statement, which is obtained using the `SQL%ROWCOUNT` attribute.",
    "plsql": "CREATE OR REPLACE FUNCTION update_notification_status RETURN NUMBER IS\n  updated_count NUMBER;\nBEGIN\n  UPDATE notifications \n     SET status = 'viewed' \n   WHERE status = 'sent' \n     AND TO_DATE(notification_date, 'YYYY-MM-DD') < SYSDATE - 7;\n  RETURN SQL%ROWCOUNT;\nEND;",
    "database_name": "user_era_analytics",
    "tables": [
      "surveys",
      "users",
      "products",
      "comments",
      "feedback",
      "notifications",
      "survey_participants",
      "analytics"
    ],
    "id": 36
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `UpdateCourseCredits` that does not accept any input parameters and does not return any values. This procedure is designed to adjust the `credit_hours` for courses based on their current enrollment counts. The procedure begins by initiating a loop that iterates through a result set. This result set is generated by performing a `SELECT` operation on the `enrollments` table. Specifically, it selects the `course_id` and calculates the `COUNT` of `enrollment_id`s, aliasing this count as `enrollment_count`, for each distinct `course_id`. The results are grouped by `course_id`. For each record (`rec`) obtained from this aggregated query, the procedure evaluates the `enrollment_count`. If `rec.enrollment_count` is strictly greater than 50, the procedure executes an `UPDATE` statement on the `courses` table, incrementing the `credit_hours` column by 1 for the row where `course_id` matches `rec.course_id`. If `rec.enrollment_count` is not greater than 50 but is within the range of 20 (inclusive) and 50 (inclusive), the procedure executes an `UPDATE` statement on the `courses` table, setting the `credit_hours` column to its current value (effectively making no change) for the row where `course_id` matches `rec.course_id`. In all other cases, meaning if `rec.enrollment_count` is less than 20, the procedure executes an `UPDATE` statement on the `courses` table, decrementing the `credit_hours` column by 1 for the row where `course_id` matches `rec.course_id`. This conditional logic is applied sequentially for every `course_id` identified in the initial aggregated query.",
    "plsql": "CREATE OR REPLACE PROCEDURE UpdateCourseCredits IS\nBEGIN\n  FOR rec IN (\n    SELECT course_id, COUNT(enrollment_id) AS enrollment_count\n    FROM enrollments\n    GROUP BY course_id\n  ) LOOP\n    IF rec.enrollment_count > 50 THEN\n      UPDATE courses\n      SET credit_hours = credit_hours + 1\n      WHERE course_id = rec.course_id;\n    ELSIF rec.enrollment_count BETWEEN 20 AND 50 THEN\n      UPDATE courses\n      SET credit_hours = credit_hours\n      WHERE course_id = rec.course_id;\n    ELSE\n      UPDATE courses\n      SET credit_hours = credit_hours - 1\n      WHERE course_id = rec.course_id;\n    END IF;\n  END LOOP;\nEND UpdateCourseCredits;",
    "database_name": "state_ep_metrics",
    "tables": [
      "districts",
      "schools",
      "students",
      "enrollments",
      "courses",
      "test_scores"
    ],
    "id": 37
  },
  {
    "ir": "Write a PLpgSQL stored procedure named analyze_trial_performance_metrics that accepts four parameters: p_group_id of type bigint, p_threshold_rate of type real, p_min_interactions of type bigint, and p_max_duration of type bigint. The procedure is designed to analyze performance metrics for trials associated with a specific group identified by p_group_id. It begins by declaring a cursor, v_trial_cursor, which retrieves trial_id, famil_rate_open_anybox, total_interactions, and trial_duration from the trials, behavioral_metrics, and trial_details tables, respectively, where the group_id in the trials table matches the provided p_group_id. The procedure then iterates over each record fetched by the cursor using a loop. For each trial record, it evaluates the famil_rate_open_anybox against the p_threshold_rate. If the famil_rate_open_anybox exceeds p_threshold_rate, it further checks if total_interactions surpasses p_min_interactions. If both conditions are met and trial_duration is less than p_max_duration, it assigns 'High Performance' to v_comment_type and 'Excellent' to v_status. If the trial_duration is not less than p_max_duration, it assigns 'Good Performance' to v_comment_type and 'Good' to v_status. If total_interactions do not exceed p_min_interactions, it assigns 'Average Performance' to v_comment_type and 'Average' to v_status. Conversely, if famil_rate_open_anybox does not exceed p_threshold_rate, it checks if total_interactions are below p_min_interactions. If true, it assigns 'Low Performance' to v_comment_type and 'Poor' to v_status; otherwise, it assigns 'Mixed Performance' to v_comment_type and 'Review' to v_status. After determining the performance classification, the procedure inserts a new record into the trial_comments table with the trial_id from the current record, a fixed user_id of 1, a comment_text stating 'Performance analysis completed', the current date as comment_date, and the determined v_comment_type and v_status.",
    "plsql": "CREATE OR REPLACE PROCEDURE analyze_trial_performance_metrics(\n    p_group_id bigint,\n    p_threshold_rate real,\n    p_min_interactions bigint,\n    p_max_duration bigint\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_trial_cursor CURSOR FOR \n        SELECT t.trial_id, bm.famil_rate_open_anybox, bm.total_interactions, td.trial_duration\n        FROM trials t\n        JOIN behavioral_metrics bm ON t.trial_id = bm.trial_id\n        JOIN trial_details td ON t.trial_id = td.trial_id\n        WHERE t.group_id = p_group_id;\n    v_trial_record RECORD;\n    v_comment_type text;\n    v_status text;\nBEGIN\n    FOR v_trial_record IN v_trial_cursor LOOP\n        IF v_trial_record.famil_rate_open_anybox > p_threshold_rate THEN\n            IF v_trial_record.total_interactions > p_min_interactions THEN\n                IF v_trial_record.trial_duration < p_max_duration THEN\n                    v_comment_type := 'High Performance';\n                    v_status := 'Excellent';\n                ELSE\n                    v_comment_type := 'Good Performance';\n                    v_status := 'Good';\n                END IF;\n            ELSE\n                v_comment_type := 'Average Performance';\n                v_status := 'Average';\n            END IF;\n        ELSE\n            IF v_trial_record.total_interactions < p_min_interactions THEN\n                v_comment_type := 'Low Performance';\n                v_status := 'Poor';\n            ELSE\n                v_comment_type := 'Mixed Performance';\n                v_status := 'Review';\n            END IF;\n        END IF;\n        \n        INSERT INTO trial_comments (trial_id, user_id, comment_text, comment_date, comment_type, comment_status)\n        VALUES (v_trial_record.trial_id, 1, 'Performance analysis completed', CURRENT_DATE::text, v_comment_type, v_status);\n    END LOOP;\nEND;\n$$;",
    "database_name": "behavioral_research_and_animal_testing",
    "tables": [
      "trials",
      "behavioral_metrics",
      "trial_details",
      "trial_comments",
      "users"
    ],
    "id": 38
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_default_population that executes automatically before any row insertion operation on the geo_areas table, and for each new row being inserted, the trigger logic checks if the value for the population column in the new row, referenced via the :NEW pseudorecord, is null; if this condition evaluates to true, the trigger assigns a value of zero to the :NEW.population column for that specific row, thereby ensuring a non-null default value is set prior to the insert operation.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_default_population\nBEFORE INSERT ON geo_areas\nFOR EACH ROW\nBEGIN\n    IF :NEW.population IS NULL THEN\n        :NEW.population := 0;\n    END IF;\nEND;",
    "database_name": "global_fli_tracking",
    "tables": [
      "data_collections",
      "geo_areas",
      "gfl_index",
      "reporting_types",
      "sources",
      "update_frequency"
    ],
    "_source": "plfactory28",
    "id": 39
  },
  {
    "ir": "Write a PostgreSQL trigger function named adjust_costs_for_volume that is executed automatically after an update operation on the average_volume column of the move_types table for each modified row, which performs an update on the cost_estimates table, specifically setting the min_cost column to the result of a calculation that multiplies the existing min_cost value converted to a numeric type by the ratio of the new average_volume value from the updated move_types row to the old average_volume value from before the update, and then casts the final numeric result back to text, and simultaneously sets the max_cost column to the result of the identical calculation using the existing max_cost value converted to numeric multiplied by the same ratio of NEW.average_volume to OLD.average_volume and also cast back to text, but only for those rows in the cost_estimates table where the move_type_id column matches the NEW.move_type_id value from the triggering update on the move_types table, and the function concludes by returning the NEW row record.",
    "plsql": "CREATE OR REPLACE FUNCTION adjust_costs_for_volume() RETURNS TRIGGER AS $$\nBEGIN\n  UPDATE cost_estimates SET min_cost = CAST(CAST(min_cost AS NUMERIC) * CAST(NEW.average_volume AS NUMERIC) / CAST(OLD.average_volume AS NUMERIC) AS TEXT), max_cost = CAST(CAST(max_cost AS NUMERIC) * CAST(NEW.average_volume AS NUMERIC) / CAST(OLD.average_volume AS NUMERIC) AS TEXT) WHERE move_type_id = NEW.move_type_id;\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_adjust_costs_for_volume\nAFTER UPDATE OF average_volume ON move_types\nFOR EACH ROW\nEXECUTE FUNCTION adjust_costs_for_volume();",
    "database_name": "moving_and_relocation_cost_estimation_29533",
    "tables": [
      "cost_estimates",
      "distance_categories",
      "move_types"
    ],
    "_source": "plfactory23",
    "id": 40
  },
  {
    "ir": "Write a PostgreSQL stored procedure named redistribute_costs that takes three parameters: p_from_cost_id of type BIGINT representing the source cost identifier, p_to_cost_id of type BIGINT representing the destination cost identifier, and p_transfer_percentage of type REAL representing the percentage of costs to transfer, which performs three distinct update operations to redistribute costs across different cost categories. The procedure first updates the labor_costs table by changing the cost_id to p_to_cost_id and adjusting the total_cost to total_cost multiplied by (1 - p_transfer_percentage) for all rows where cost_id equals p_from_cost_id and labor_type equals 'Human'. Then it updates the machinery_costs table by setting the cost_id to p_to_cost_id and modifying the total_cost to total_cost multiplied by p_transfer_percentage for all rows where cost_id equals p_from_cost_id and machinery_condition equals 'new'. Finally, it updates the material_costs table by changing the cost_id to p_to_cost_id and adjusting the total_cost to total_cost multiplied by (p_transfer_percentage divided by 2) for all rows where cost_id equals p_from_cost_id and material_type equals 'Seeds'.",
    "plsql": "CREATE OR REPLACE PROCEDURE redistribute_costs(p_from_cost_id BIGINT, p_to_cost_id BIGINT, p_transfer_percentage REAL)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE labor_costs \n    SET cost_id = p_to_cost_id,\n        total_cost = total_cost * (1 - p_transfer_percentage)\n    WHERE cost_id = p_from_cost_id AND labor_type = 'Human';\n    \n    UPDATE machinery_costs \n    SET cost_id = p_to_cost_id,\n        total_cost = total_cost * p_transfer_percentage\n    WHERE cost_id = p_from_cost_id AND machinery_condition = 'new';\n    \n    UPDATE material_costs \n    SET cost_id = p_to_cost_id,\n        total_cost = total_cost * (p_transfer_percentage / 2)\n    WHERE cost_id = p_from_cost_id AND material_type = 'Seeds';\nEND;\n$$;",
    "database_name": "agricultural_production_cost_analysis",
    "tables": [
      "labor_costs",
      "machinery_costs",
      "material_costs"
    ],
    "id": 41
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_kb_author_status that is executed automatically by a trigger named trg_kb_author_activation after every new row insertion into the kb_articles table, processing each inserted row individually, where the function's logic is to insert a new record into the users table using the author_id value from the newly inserted kb_articles row (referenced as NEW.author_id), populating the users table columns with specific values: the user_id is set to NEW.author_id, the user_name is set to the uppercase result of a subquery that selects the user_name from the users table where the user_id matches NEW.author_id, the email is set via a subquery selecting the email from the users table for the matching user_id, the role is set via a subquery selecting the role from the users table for the matching user_id, the last_login_date is set via a subquery selecting the last_login_date from the users table for the matching user_id, the status is explicitly set to the string 'Active', the created_date is set via a subquery selecting the created_date from the users table for the matching user_id, and the last_updated_date is set to the current system date, and if this insert operation encounters a conflict on the user_id column (meaning a user with that ID already exists), the ON CONFLICT clause performs an update instead, setting only the status column to 'Active' and the last_updated_date column to the current system date for the conflicting user record, after which the function returns the NEW row record to the triggering mechanism.",
    "plsql": "CREATE OR REPLACE FUNCTION update_kb_author_status() RETURNS TRIGGER AS $$\nBEGIN\n    INSERT INTO users (user_id, user_name, email, role, last_login_date, status, created_date, last_updated_date) VALUES (NEW.author_id, UPPER((SELECT user_name FROM users WHERE user_id = NEW.author_id)), (SELECT email FROM users WHERE user_id = NEW.author_id), (SELECT role FROM users WHERE user_id = NEW.author_id), (SELECT last_login_date FROM users WHERE user_id = NEW.author_id), 'Active', (SELECT created_date FROM users WHERE user_id = NEW.author_id), CURRENT_DATE) ON CONFLICT (user_id) DO UPDATE SET status = 'Active', last_updated_date = CURRENT_DATE;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_kb_author_activation\nAFTER INSERT ON kb_articles\nFOR EACH ROW EXECUTE FUNCTION update_kb_author_status();",
    "database_name": "cybersecurity_vulnerability_management_and_tracking",
    "tables": [
      "vulnerabilities",
      "cvss_scores",
      "kb_articles",
      "remediation_actions",
      "supersedence",
      "vulnerability_relationships",
      "users"
    ],
    "_source": "plfactory6",
    "id": 42
  },
  {
    "ir": "Write an Oracle PL/SQL compound trigger named donation_summary_trigger that is executed for each INSERT operation on the event_donations table, which first declares a PL/SQL associative array type named event_id_table of NUMBER indexed by PLS_INTEGER, then declares an instance of this type named g_event_ids and a PLS_INTEGER variable g_index initialized to 0; within the AFTER EACH ROW section, for each newly inserted row, the trigger increments g_index by 1 and stores the value of the new row's event_id column (referenced as :NEW.event_id) into the g_event_ids associative array at the index position g_index; then, in the AFTER STATEMENT section, the trigger declares local variables v_total_donations, v_avg_donation, v_donor_count, v_event_id, and v_update_id, all of type NUMBER, and executes a loop from 1 to the count of elements in the g_event_ids array; for each iteration index i, the trigger assigns the array element g_event_ids(i) to v_event_id, then performs a SELECT statement on the event_donations table to compute the COUNT of all rows, the SUM of the donation_amount column, and the AVG of the donation_amount column for rows where the event_id column equals the current v_event_id, storing these aggregated results into v_donor_count, v_total_donations, and v_avg_donation respectively; subsequently, the trigger executes another SELECT statement on the event_updates table to find the maximum existing value of the update_id column, uses the NVL function to treat a NULL maximum as 0, adds 1 to this value, and stores the result into v_update_id; finally, the trigger performs an INSERT operation into the event_updates table, inserting a new row with columns update_id set to v_update_id, event_id set to v_event_id, update_description set to a concatenated string starting with 'Total: ' followed by the v_total_donations value, then ', Avg: ' followed by the v_avg_donation value, and update_date set to the current system date (SYSDATE) formatted as a string using the TO_CHAR function with the format model 'DD-MON-YYYY'.",
    "plsql": "CREATE OR REPLACE TRIGGER donation_summary_trigger\nFOR INSERT ON event_donations\nCOMPOUND TRIGGER\n    TYPE event_id_table IS TABLE OF NUMBER INDEX BY PLS_INTEGER;\n    g_event_ids event_id_table;\n    g_index PLS_INTEGER := 0;\n    \n    AFTER EACH ROW IS\n    BEGIN\n        g_index := g_index + 1;\n        g_event_ids(g_index) := :NEW.event_id;\n    END AFTER EACH ROW;\n    \n    AFTER STATEMENT IS\n        v_total_donations NUMBER;\n        v_avg_donation NUMBER;\n        v_donor_count NUMBER;\n        v_event_id NUMBER;\n        v_update_id NUMBER;\n    BEGIN\n        FOR i IN 1..g_event_ids.COUNT LOOP\n            v_event_id := g_event_ids(i);\n            \n            SELECT COUNT(*), SUM(donation_amount), AVG(donation_amount)\n            INTO v_donor_count, v_total_donations, v_avg_donation\n            FROM event_donations\n            WHERE event_id = v_event_id;\n            \n            SELECT NVL(MAX(update_id), 0) + 1\n            INTO v_update_id\n            FROM event_updates;\n            \n            INSERT INTO event_updates (update_id, event_id, update_description, update_date)\n            VALUES (v_update_id, v_event_id, \n                   'Total: ' || v_total_donations || ', Avg: ' || v_avg_donation, \n                   TO_CHAR(SYSDATE, 'DD-MON-YYYY'));\n        END LOOP;\n    END AFTER STATEMENT;\nEND donation_summary_trigger;",
    "database_name": "disaster_iar_management",
    "tables": [
      "event_donations",
      "event_updates"
    ],
    "_source": "plfactory29",
    "id": 43
  },
  {
    "ir": "Write a PLpgSQL stored procedure named process_player_height_weight_analysis that accepts three parameters: p_nationality_filter of type text, p_min_games of type bigint, and p_calculation_factor of type bigint. The procedure iterates over records from a query that selects player_id, player_name, height, weight, nationality, the count of distinct game_id as games_played, and the average points_scored as avg_points from the players table joined with the game_stats table on player_id. The query filters players by nationality matching p_nationality_filter and groups by player_id, player_name, height, weight, nationality, ensuring that the count of distinct game_id is at least p_min_games. For each record, the procedure calculates v_height_weight_angle using the atan2 function on height and weight, multiplied by p_calculation_factor, only if both height and weight are greater than zero. It then checks avg_points: if greater than 20, it inserts a new record into the teams table with team_id as player_id plus 20000, team_name as player_name concatenated with '_ELITE_TEAM', team_abbreviation as the first three characters of player_name, sport_id from the players table for the current player_id, coach_id as player_id, founded_year as the current year, home_stadium as 'ANALYSIS_STADIUM', and team_color as 'BLUE'. If avg_points is between 10 and 20, it deletes records from the game_stats table where player_id matches and points_scored is less than 5. If avg_points is less than 10, it deletes records from the players table where player_id matches and nationality equals p_nationality_filter.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_player_height_weight_analysis(p_nationality_filter text, p_min_games bigint, p_calculation_factor bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_player_analysis_record RECORD;\n    v_height_weight_angle double precision;\n    v_game_participation_count bigint;\nBEGIN\n    FOR v_player_analysis_record IN \n        SELECT p.player_id, p.player_name, p.height, p.weight, p.nationality,\n               COUNT(DISTINCT gs.game_id) as games_played,\n               AVG(gs.points_scored) as avg_points\n        FROM players p\n        LEFT JOIN game_stats gs ON p.player_id = gs.player_id\n        WHERE p.nationality = p_nationality_filter\n        GROUP BY p.player_id, p.player_name, p.height, p.weight, p.nationality\n        HAVING COUNT(DISTINCT gs.game_id) >= p_min_games\n    LOOP\n        v_game_participation_count := v_player_analysis_record.games_played;\n        \n        IF v_player_analysis_record.height > 0 AND v_player_analysis_record.weight > 0 THEN\n            v_height_weight_angle := atan2(v_player_analysis_record.height::double precision, v_player_analysis_record.weight::double precision) * p_calculation_factor;\n            \n            IF v_player_analysis_record.avg_points > 20 THEN\n                INSERT INTO teams (team_id, team_name, team_abbreviation, sport_id, coach_id, founded_year, home_stadium, team_color)\n                VALUES (v_player_analysis_record.player_id + 20000,\n                        v_player_analysis_record.player_name || '_ELITE_TEAM',\n                        SUBSTRING(v_player_analysis_record.player_name FROM 1 FOR 3),\n                        (SELECT sport_id FROM players WHERE player_id = v_player_analysis_record.player_id),\n                        v_player_analysis_record.player_id,\n                        EXTRACT(YEAR FROM CURRENT_DATE)::bigint,\n                        'ANALYSIS_STADIUM',\n                        'BLUE');\n            ELSIF v_player_analysis_record.avg_points BETWEEN 10 AND 20 THEN\n                DELETE FROM game_stats \n                WHERE player_id = v_player_analysis_record.player_id \n                  AND points_scored < 5;\n            ELSE\n                DELETE FROM players \n                WHERE player_id = v_player_analysis_record.player_id \n                  AND nationality = p_nationality_filter;\n            END IF;\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "sports_league_management_and_player_statistics",
    "tables": [
      "games",
      "teams",
      "players",
      "game_stats",
      "sports"
    ],
    "id": 44
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `insert_country_comparison` that accepts five input parameters: `p_country1_name` of type `TEXT`, representing the name of the first country for comparison; `p_country2_name` of type `TEXT`, representing the name of the second country for comparison; `p_target_year` of type `BIGINT`, indicating the specific year for which data should be retrieved; `p_use_forecast` of type `BOOLEAN`, a flag to determine if forecast data should be used; and `p_use_history` of type `BOOLEAN`, a flag to determine if historical data should be used. The procedure declares six local variables: `v_country1_id` of type `BIGINT` to store the ID of the first country; `v_country2_id` of type `BIGINT` to store the ID of the second country; `v_country1_pop` of type `BIGINT` to store the population of the first country; `v_country2_pop` of type `BIGINT` to store the population of the second country; `v_country1_gdp` of type `REAL` to store the GDP of the first country; and `v_country2_gdp` of type `REAL` to store the GDP of the second country. The procedure first retrieves the `country_id` from the `countries` table into `v_country1_id` where the `name` column matches the value provided in `p_country1_name`. Subsequently, it retrieves the `country_id` from the `countries` table into `v_country2_id` where the `name` column matches the value provided in `p_country2_name`. Following these initial retrievals, the procedure enters a conditional block. If `p_use_forecast` is true, it selects the `population` and `gdp_nominal` columns from the `country_forecast` table into `v_country1_pop` and `v_country1_gdp` respectively, for the record where `country_id` matches `v_country1_id` and `year` matches `p_target_year`. Concurrently, within the same `IF` block, it selects the `population` and `gdp_nominal` columns from the `country_forecast` table into `v_country2_pop` and `v_country2_gdp` respectively, for the record where `country_id` matches `v_country2_id` and `year` matches `p_target_year`. If `p_use_forecast` is false but `p_use_history` is true (an `ELSIF` condition), the procedure selects the `population` and `gdp_nominal` columns from the `country_history` table into `v_country1_pop` and `v_country1_gdp` respectively, for the record where `country_id` matches `v_country1_id` and `year` matches `p_target_year`. Simultaneously, within this `ELSIF` block, it selects the `population` and `gdp_nominal` columns from the `country_history` table into `v_country2_pop` and `v_country2_gdp` respectively, for the record where `country_id` matches `v_country2_id` and `year` matches `p_target_year`. The procedure concludes after this conditional data retrieval.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_country_comparison(\n    IN p_country1_name TEXT,\n    IN p_country2_name TEXT,\n    IN p_target_year BIGINT,\n    IN p_use_forecast BOOLEAN,\n    IN p_use_history BOOLEAN\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_country1_id BIGINT;\n    v_country2_id BIGINT;\n    v_country1_pop BIGINT;\n    v_country2_pop BIGINT;\n    v_country1_gdp REAL;\n    v_country2_gdp REAL;\nBEGIN\n    SELECT country_id INTO v_country1_id FROM countries WHERE name = p_country1_name;\n    SELECT country_id INTO v_country2_id FROM countries WHERE name = p_country2_name;\n    \n    IF p_use_forecast THEN\n        SELECT population, gdp_nominal INTO v_country1_pop, v_country1_gdp\n        FROM country_forecast WHERE country_id = v_country1_id AND year = p_target_year;\n        \n        SELECT population, gdp_nominal INTO v_country2_pop, v_country2_gdp\n        FROM country_forecast WHERE country_id = v_country2_id AND year = p_target_year;\n    ELSIF p_use_history THEN\n        SELECT population, gdp_nominal INTO v_country1_pop, v_country1_gdp\n        FROM country_history WHERE country_id = v_country1_id AND year = p_target_year;\n        \n        SELECT population, gdp_nominal INTO v_country2_pop, v_country2_gdp\n        FROM country_history WHERE country_id = v_country2_id AND year = p_target_year;\n    END IF;\nEND;\n$$;",
    "database_name": "geographical_and_statistical_information_of_european_countries",
    "tables": [
      "countries",
      "country_forecast",
      "country_history"
    ],
    "id": 45
  },
  {
    "ir": "Write a PLpgSQL function that retrieves the owner of a module based on the most recent update for a given module ID. The function, named get_last_updated_module_owner, accepts a single parameter, module_id_input, of type bigint, which represents the unique identifier of the module whose owner information is being queried. Within the function, a local variable named module_owner of type text is declared to store the result of the query. The function performs a SELECT operation on the modules table, specifically targeting the owner column. It uses a window function, last_value, to obtain the owner associated with the most recent update, determined by ordering the rows in descending order based on the last_updated column. The WHERE clause filters the rows to include only those where the module_id matches the provided module_id_input. The result of this query is stored in the module_owner variable. Finally, the function returns the value of module_owner, which is the owner of the module that was last updated for the specified module ID.",
    "plsql": "CREATE OR REPLACE FUNCTION get_last_updated_module_owner(module_id_input bigint)\nRETURNS text AS $$\nDECLARE\n    module_owner text;\nBEGIN\n    SELECT last_value(owner) OVER (ORDER BY last_updated DESC)\n    INTO module_owner\n    FROM modules\n    WHERE module_id = module_id_input;\n    \n    RETURN module_owner;\nEND;\n$$ LANGUAGE plpgsql;",
    "database_name": "azure_powershell_module_error_analysis_and_remediation",
    "tables": [
      "cmdlets",
      "errors",
      "modules",
      "users"
    ],
    "id": 46
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_customer_phone_format that returns a trigger and is executed automatically by a trigger named trg_update_customer_phone_format, which is defined to fire BEFORE UPDATE on the customers table for each individual row being updated; the function's logic operates on the new row data represented by the NEW record variable, specifically targeting the customer_phone column, and it uses the REPLACE function to remove all hyphen characters ('-') from the string value in NEW.customer_phone by replacing each occurrence of the hyphen with an empty string, thereby reformatting the phone number to a continuous digit string, and then the function returns the modified NEW row record so that the update operation proceeds with the cleaned phone number.",
    "plsql": "CREATE OR REPLACE FUNCTION update_customer_phone_format() RETURNS TRIGGER AS $$\nBEGIN\n    NEW.customer_phone := REPLACE(NEW.customer_phone, '-', '');\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_update_customer_phone_format\n    BEFORE UPDATE ON customers\n    FOR EACH ROW\n    EXECUTE FUNCTION update_customer_phone_format();",
    "database_name": "flooring_product_inventory_and_retail_management",
    "tables": [
      "customers"
    ],
    "_source": "plfactory19",
    "id": 47
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_department_modified_on_employee_change that returns a trigger, which is automatically executed by a trigger named trg_update_department_modified_on_employee_change defined on the employees table, such that after any INSERT operation or UPDATE operation on the employees table, for each affected row, the function executes an UPDATE statement on the departments table, setting the modified_date column to the value returned by the CURRENT_DATE function, specifically for the row in the departments table where the dept_id column value equals the value of the NEW.dept_id column from the newly inserted or updated row in the employees table, and the function then returns the NEW row record.",
    "plsql": "CREATE OR REPLACE FUNCTION update_department_modified_on_employee_change() RETURNS TRIGGER AS $$\nBEGIN\n  UPDATE departments SET modified_date = CURRENT_DATE WHERE dept_id = NEW.dept_id;\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_update_department_modified_on_employee_change\nAFTER INSERT OR UPDATE ON employees\nFOR EACH ROW\nEXECUTE FUNCTION update_department_modified_on_employee_change();",
    "database_name": "corporate_employee_management_and_compensation_analysis",
    "tables": [
      "employees",
      "departments",
      "performance_reviews",
      "performance_incentives",
      "employee_contacts"
    ],
    "_source": "plfactory4",
    "id": 48
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_contract_renewal_management that is defined to fire automatically after each row is updated on the contracts table, declaring local variables v_contract and v_player, both of the NUMBER data type, to temporarily hold values from the updated row's pseudo-record, then within its execution block, it assigns the value from the :NEW.contract_id column to the v_contract variable and the value from the :NEW.player_id column to the v_player variable, and the trigger's logic, which is currently commented out and replaced with a NULL statement, is designed to first delete any existing record from a hypothetical pending_renewals table where its contract_id column matches the newly updated :NEW.contract_id value, then conditionally, if the updated row's renewal_option column equals the numeric value 1, it inserts a new record into the pending_renewals table using the values :NEW.contract_id, :NEW.player_id, and the current system date SYSDATE, and finally, regardless of the condition, it inserts a historical record into a hypothetical contract_history table using the values stored in v_contract and v_player, along with a literal string 'Updated' and the current system date SYSDATE.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_contract_renewal_management\nAFTER UPDATE ON contracts\nFOR EACH ROW\nDECLARE\n  -- Declare variables to avoid ORA-04098 due to undeclared identifiers\n  v_contract NUMBER;\n  v_player   NUMBER;\nBEGIN\n  -- In an AFTER UPDATE trigger, :NEW pseudo-record already contains the updated values.\n  -- Selecting from the table again is often unnecessary and can lead to mutating table errors\n  -- in more complex scenarios. We can directly use :NEW.contract_id and :NEW.player_id.\n\n  -- Assign values from :NEW to the declared variables for clarity, if needed,\n  -- or use :NEW directly in subsequent statements.\n  v_contract := :NEW.contract_id;\n  v_player   := :NEW.player_id;\n\n  -- The tables 'pending_renewals' and 'contract_history' are not in the provided schema.\n  -- These DML statements will cause ORA-00942 if the tables do not exist.\n  -- For the purpose of making the trigger valid against the given schema,\n  -- these operations are commented out. In a real scenario, these tables\n  -- would need to be created or the logic adjusted.\n\n  -- DELETE FROM pending_renewals WHERE contract_id = :NEW.contract_id;\n\n  -- IF :NEW.renewal_option = 1 THEN\n  --   INSERT INTO pending_renewals VALUES (:NEW.contract_id, :NEW.player_id, SYSDATE);\n  -- END IF;\n\n  -- INSERT INTO contract_history VALUES (v_contract, v_player, 'Updated', SYSDATE);\n  NULL; -- Added a NULL statement to ensure the BEGIN-END block is not empty after commenting out DML.\nEND;",
    "database_name": "football_pma_analytics",
    "tables": [
      "players",
      "contracts",
      "clubs"
    ],
    "_source": "plfactory2",
    "id": 49
  },
  {
    "ir": "Write a PostgreSQL trigger function named validate_parent_category that returns a trigger and is invoked by a trigger named trg_validate_parent_category, which is defined to execute before any INSERT or UPDATE operation on the funding_categories table for each affected row, where the function's logic begins by performing a SELECT COUNT(*) query on the funding_categories table, specifically counting all rows where the category_id column equals the incoming value of the NEW.parent_category column from the triggering row, and if the result of this count operation is zero, indicating that no existing category_id matches the provided parent_category value, then the function modifies the NEW.parent_category value by setting it to NULL, and finally, regardless of the condition's outcome, the function returns the potentially modified NEW row record to the database engine for the subsequent INSERT or UPDATE operation.",
    "plsql": "CREATE OR REPLACE FUNCTION validate_parent_category() RETURNS TRIGGER AS $$\nBEGIN\n    IF (SELECT COUNT(*) FROM funding_categories WHERE category_id = NEW.parent_category) = 0 THEN\n        NEW.parent_category := NULL;\n    END IF;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_validate_parent_category\nBEFORE INSERT OR UPDATE ON funding_categories\nFOR EACH ROW EXECUTE FUNCTION validate_parent_category();",
    "database_name": "research_funding_allocation_and_analysis",
    "tables": [
      "funding_agencies",
      "funding_allocation",
      "funding_categories",
      "funding_category_allocations",
      "audits",
      "users"
    ],
    "_source": "plfactory16",
    "id": 50
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `analyze_club_performance_metrics` that accepts three input parameters: `p_club_id` of type `bigint` representing the unique identifier of a club, `p_base_value` of type `double precision` representing a base multiplier for performance calculation, and `p_year_filter` of type `text` representing a string used to filter awards by year. This procedure first declares three local variables: `v_total_awards` of type `integer` to store the count of awards, `v_performance_index` of type `double precision` to store the calculated performance index, and `v_club_name` of type `text` to store the name of the club. The procedure then executes a `SELECT` statement to count the total number of awards. This `SELECT` statement retrieves the count of `award_id` from the `awards` table, aliased as `a`, by joining it with the `athletes` table, aliased as `at`, on the condition that `a.athlete_id` equals `at.athlete_id`. The `WHERE` clause filters these records based on two conditions: `at.club_id` must be equal to the input parameter `p_club_id`, and the `award_date` column from the `awards` table must start with the string formed by concatenating the `p_year_filter` parameter with the literal string '%'. The result of this count is stored in the `v_total_awards` variable. Subsequently, another `SELECT` statement is executed to retrieve the `club_name` from the `clubs` table where the `club_id` matches the input parameter `p_club_id`. The retrieved `club_name` is stored in the `v_club_name` variable. Following this, the `v_performance_index` variable is calculated by taking the cube root (`cbrt`) of the product of `v_total_awards` and `p_base_value`. Finally, an `INSERT` statement is executed to add a new record into the `club_performance` table. The `club_id` column is populated with the value of `p_club_id`, the `club_name` column with the value of `v_club_name`, the `award_count` column with the value of `v_total_awards`, the `performance_index` column with the value of `v_performance_index`, and the `analysis_date` column with the current date converted to text using `CURRENT_DATE::text`.",
    "plsql": "CREATE TABLE IF NOT EXISTS club_performance (\n    club_id bigint,\n    club_name text,\n    award_count integer,\n    performance_index double precision,\n    analysis_date text\n);\n\nCREATE OR REPLACE PROCEDURE analyze_club_performance_metrics(\n    p_club_id bigint,\n    p_base_value double precision,\n    p_year_filter text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_total_awards integer;\n    v_performance_index double precision;\n    v_club_name text;\nBEGIN\n    SELECT COUNT(a.award_id) INTO v_total_awards\n    FROM awards a\n    JOIN athletes at ON a.athlete_id = at.athlete_id\n    WHERE at.club_id = p_club_id AND a.award_date LIKE p_year_filter || '%';\n    \n    SELECT club_name INTO v_club_name\n    FROM clubs\n    WHERE club_id = p_club_id;\n    \n    v_performance_index := cbrt(v_total_awards * p_base_value);\n    \n    INSERT INTO club_performance (club_id, club_name, award_count, performance_index, analysis_date)\n    VALUES (p_club_id, v_club_name, v_total_awards, v_performance_index, CURRENT_DATE::text);\nEND;\n$$;",
    "database_name": "athletic_event_management_and_performance_tracking",
    "tables": [
      "athletes",
      "awards",
      "clubs",
      "countries",
      "events",
      "nationalities"
    ],
    "id": 51
  },
  {
    "ir": "Write a PostgreSQL trigger function named reset_performance_metrics_on_injury that executes automatically before each insert operation on the player_injuries table, and within this function, first checks if the incoming new row's injury_id column value is null; if it is null, the function determines the associated sequence name for the player_injuries.injury_id column using the pg_get_serial_sequence function, and if a sequence name is successfully retrieved, it assigns the next value from that sequence to NEW.injury_id using the nextval function, but if no sequence exists, it calculates a new injury_id by selecting the maximum existing injury_id value from the player_injuries table, adding 1 to it, and using 0 as a default if the table is empty, via the COALESCE function, and assigns this calculated next_val to NEW.injury_id; after ensuring NEW.injury_id is populated, the function proceeds to delete all rows from the player_performance table where the player_id column matches the NEW.player_id value from the trigger and the tournament_id column matches the NEW.tournament_id value.",
    "plsql": "CREATE OR REPLACE FUNCTION reset_performance_metrics_on_injury() RETURNS TRIGGER AS $$\nDECLARE\n  seq_name TEXT;\n  next_val BIGINT;\nBEGIN\n  -- Handle NULL injury_id to avoid NOT NULL constraint violation\n  IF NEW.injury_id IS NULL THEN\n    -- Try to get the sequence name for the injury_id column\n    seq_name := pg_get_serial_sequence('player_injuries', 'injury_id');\n    \n    IF seq_name IS NOT NULL THEN\n      -- Use the sequence if it exists\n      NEW.injury_id := nextval(seq_name);\n    ELSE\n      -- Generate a new ID using max + 1 if no sequence exists\n      SELECT COALESCE(MAX(injury_id), 0) + 1 INTO next_val FROM player_injuries;\n      NEW.injury_id := next_val;\n    END IF;\n  END IF;\n  \n  -- Delete performance metrics for the injured player in the same tournament\n  DELETE FROM player_performance\n  WHERE player_id = NEW.player_id\n    AND tournament_id = NEW.tournament_id;\n    \n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_reset_performance_metrics_on_injury\nBEFORE INSERT ON player_injuries\nFOR EACH ROW\nEXECUTE FUNCTION reset_performance_metrics_on_injury();",
    "database_name": "tennis_tournament_management_and_player_tracking",
    "tables": [
      "players",
      "player_injuries",
      "player_performance",
      "player_trainers",
      "tournaments",
      "tournament_progression"
    ],
    "_source": "plfactory18",
    "id": 52
  },
  {
    "ir": "Write a PostgreSQL trigger function named backup_environment_config that executes before each row deletion on the environments table, which declares a local bigint variable backup_id, calculates its value by adding 3000 to the OLD.environment_id value from the row being deleted, then performs an INSERT into the environments table using the calculated backup_id for the environment_id column, constructs the environment_name column by concatenating the string 'BACKUP_' with the OLD.environment_name value, constructs the description column by concatenating the string 'Backup of ' with the OLD.description value, uses the OLD.created_at value for the created_at column, uses the OLD.created_by value for the created_by column, sets the environment_type column to the literal string 'backup', sets the environment_status column to the literal string 'inactive', uses the OLD.last_used_at value for the last_used_at column, sets the last_modified_at column to the current timestamp formatted as a string using the TO_CHAR function with the NOW() function and the format 'YYYY-MM-DD HH24:MI:SS', uses the OLD.last_modified_by value for the last_modified_by column, then performs an UPDATE on the test_jobs table setting the environment_id column to the calculated backup_id value for all rows where the environment_id column equals the OLD.environment_id value from the row being deleted, and finally returns the OLD row record.",
    "plsql": "CREATE OR REPLACE FUNCTION backup_environment_config() RETURNS TRIGGER AS $$\nDECLARE\n    backup_id bigint;\nBEGIN\n    backup_id := OLD.environment_id + 3000;\n    \n    INSERT INTO environments (environment_id, environment_name, description, created_at, created_by, environment_type, environment_status, last_used_at, last_modified_at, last_modified_by) \n    VALUES (backup_id, 'BACKUP_' || OLD.environment_name, 'Backup of ' || OLD.description, OLD.created_at, OLD.created_by, 'backup', 'inactive', OLD.last_used_at, TO_CHAR(NOW(), 'YYYY-MM-DD HH24:MI:SS'), OLD.last_modified_by);\n    \n    UPDATE test_jobs \n    SET environment_id = backup_id \n    WHERE environment_id = OLD.environment_id;\n    \n    RETURN OLD;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_backup_environment\nBEFORE DELETE ON environments\nFOR EACH ROW\nEXECUTE FUNCTION backup_environment_config();",
    "database_name": "software_testing_and_continuous_integration",
    "tables": [
      "environments",
      "test_cases",
      "test_jobs",
      "users"
    ],
    "_source": "plfactory21",
    "id": 53
  },
  {
    "ir": "Write a PLpgSQL stored procedure that inserts a new record into the papers table. The procedure is named sp_insert_new_paper and accepts three parameters: para_title of type text, para_url of type text, and para_researcher_id of type bigint. It begins by declaring a local variable next_paper_id of type bigint. The procedure then executes a SELECT statement to determine the next available paper_id by selecting the maximum value of the paper_id column from the papers table, using the COALESCE function to handle cases where the table might be empty by defaulting to -1, and adding 1 to this result. This calculated value is stored in the next_paper_id variable. Following this, the procedure performs an INSERT operation into the papers table, specifying the columns paper_id, title, url, researcher_id, created_at, modified_at, and status. The values inserted are the next_paper_id for the paper_id column, para_title for the title column, para_url for the url column, para_researcher_id for the researcher_id column, and the current timestamp formatted as 'YYYY-MM-DD\"T\"HH24:MI:SS.US' for both the created_at and modified_at columns. The status column is set to 0. The procedure does not include any conditional logic or loops.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp_insert_new_paper(para_title text, para_url text, para_researcher_id bigint) LANGUAGE plpgsql AS $$\nDECLARE\n    next_paper_id bigint;\nBEGIN\n    SELECT COALESCE(MAX(paper_id), -1) + 1 INTO next_paper_id FROM papers;\n    \n    INSERT INTO papers (paper_id, title, url, researcher_id, created_at, modified_at, status)\n    VALUES (next_paper_id, para_title, para_url, para_researcher_id, TO_CHAR(NOW(), 'YYYY-MM-DD\"T\"HH24:MI:SS.US'), TO_CHAR(NOW(), 'YYYY-MM-DD\"T\"HH24:MI:SS.US'), 0);\nEND;\n$$;",
    "database_name": "academic_research_paper_management_system",
    "tables": [
      "access_logs",
      "papers",
      "users"
    ],
    "id": 54
  },
  {
    "ir": "Write an Oracle PL/SQL function named has_assessments that takes no input parameters and returns a Boolean value, which begins by declaring a local variable cnt of type NUMBER, then executes a SELECT statement to count all rows from the ASSESSMENTS table and stores the result into the cnt variable, and finally returns a Boolean result of TRUE if the cnt value is greater than zero, indicating the table contains at least one row, or FALSE if the cnt value is zero, indicating the table is empty.",
    "plsql": "CREATE OR REPLACE FUNCTION has_assessments RETURN BOOLEAN IS\n  cnt NUMBER;\nBEGIN\n  SELECT COUNT(*) INTO cnt FROM ASSESSMENTS;\n  RETURN cnt > 0;\nEND;",
    "database_name": "educational_aafs_634812",
    "tables": [
      "ASSESSMENTS"
    ],
    "id": 55
  },
  {
    "ir": "Write a PostgreSQL stored procedure named update_repo_visibility that accepts two input parameters: p_repo_id of type bigint, which identifies a specific repository, and p_visibility of type text, which is a desired visibility setting. The procedure declares three local bigint variables: v_commit_count, v_pr_count, and v_branch_count. It begins by executing three separate SELECT COUNT(*) queries: the first query counts all rows in the commits table where the repo_id column equals the input p_repo_id and stores the result in v_commit_count; the second query counts all rows in the pull_requests table where the repo_id column equals p_repo_id and stores the result in v_pr_count; the third query counts all rows in the branches table where the repo_id column equals p_repo_id and stores the result in v_branch_count. Following these counts, the procedure uses a conditional IF-ELSIF-ELSIF-ELSE block to determine which UPDATE statement to execute on the repositories table for the row where the repo_id column matches p_repo_id. If v_commit_count is greater than 50, it updates the visibility column in that repositories row to the value of the input parameter p_visibility. Otherwise, if v_pr_count is greater than 20, it updates the visibility column to the literal string 'public'. Otherwise, if v_branch_count is greater than 10, it updates the visibility column to the literal string 'private'. If none of the preceding conditions are met, it executes the final ELSE clause, updating the visibility column to the literal string 'archived'.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_repo_visibility(p_repo_id bigint, p_visibility text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_commit_count bigint;\n    v_pr_count bigint;\n    v_branch_count bigint;\nBEGIN\n    SELECT COUNT(*) INTO v_commit_count FROM commits WHERE repo_id = p_repo_id;\n    SELECT COUNT(*) INTO v_pr_count FROM pull_requests WHERE repo_id = p_repo_id;\n    SELECT COUNT(*) INTO v_branch_count FROM branches WHERE repo_id = p_repo_id;\n\n    IF v_commit_count > 50 THEN\n        UPDATE repositories SET visibility = p_visibility WHERE repo_id = p_repo_id;\n    ELSIF v_pr_count > 20 THEN\n        UPDATE repositories SET visibility = 'public' WHERE repo_id = p_repo_id;\n    ELSIF v_branch_count > 10 THEN\n        UPDATE repositories SET visibility = 'private' WHERE repo_id = p_repo_id;\n    ELSE\n        UPDATE repositories SET visibility = 'archived' WHERE repo_id = p_repo_id;\n    END IF;\nEND;\n$$;",
    "database_name": "git_repository_permissions_management",
    "tables": [
      "repositories",
      "branches",
      "commits",
      "pull_requests",
      "users"
    ],
    "id": 56
  },
  {
    "ir": "Write a PostgreSQL trigger function named prevent_duplicate_attempt that is executed automatically by a trigger named tr_prevent_duplicate_attempt before any insert operation on the attempts table for each new row. The function first checks if the new row's attempt_id column value is NULL and, if true, raises an exception with the message 'attempt_id cannot be NULL for attempts table'. If the attempt_id is not NULL, the function then checks for the existence of any record in the attempts table where the student_id column equals the new row's student_id value, the course_code column equals the new row's course_code value, and the attempt_number column equals the new row's attempt_number value. If such a matching record exists, the function raises an exception with a formatted message 'Duplicate attempt not allowed for student %, course %, attempt %', substituting the placeholders with the new row's student_id, course_code, and attempt_number values. If neither condition is met, the function returns the new row to allow the insert operation to proceed.",
    "plsql": "CREATE OR REPLACE FUNCTION prevent_duplicate_attempt() RETURNS TRIGGER AS $$\nBEGIN\n    IF NEW.attempt_id IS NULL THEN\n        RAISE EXCEPTION 'attempt_id cannot be NULL for attempts table';\n    END IF;\n    \n    IF EXISTS (SELECT 1 FROM attempts WHERE student_id = NEW.student_id AND course_code = NEW.course_code AND attempt_number = NEW.attempt_number) THEN\n        RAISE EXCEPTION 'Duplicate attempt not allowed for student %, course %, attempt %', NEW.student_id, NEW.course_code, NEW.attempt_number;\n    END IF;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER tr_prevent_duplicate_attempt\n    BEFORE INSERT ON attempts\n    FOR EACH ROW\n    EXECUTE FUNCTION prevent_duplicate_attempt();",
    "database_name": "student_enrollment_and_academic_performance_analysis",
    "tables": [
      "students",
      "enrollments",
      "courses",
      "attempts",
      "withdrawals"
    ],
    "_source": "plfactory19",
    "id": 57
  },
  {
    "ir": "Write a PostgreSQL PL/SQL stored procedure named analyze_flight_performance that accepts three input parameters: p_aircraft_id of type bigint to identify a specific aircraft, p_start_date of type text to define the beginning of a date range, and p_end_date of type text to define the end of a date range, and it begins by declaring four local variables: v_test_count as an integer, v_avg_duration as a real, v_max_mach as a real, and v_analysis_id as a bigint, then it executes a SELECT statement that retrieves data from the flight_tests table, calculating the total count of all rows and the average value of the test_duration column, and stores these results into the variables v_test_count and v_avg_duration respectively, where the selection is filtered to include only rows where the aircraft_id column matches the input parameter p_aircraft_id and the test_date column is greater than or equal to p_start_date and less than or equal to p_end_date, then it executes another SELECT statement that retrieves data by joining the measurements table (aliased as m) with the datasets table (aliased as d) on the condition that m.dataset_id equals d.dataset_id, and then joining the result with the flight_tests table (aliased as ft) on the condition that d.test_id equals ft.test_id, calculating the maximum value of the mach_number column from the measurements table, and stores this result into the variable v_max_mach, where the join is filtered to include only rows where the aircraft_id from the flight_tests table matches the input parameter p_aircraft_id and the test_date from the flight_tests table is greater than or equal to p_start_date and less than or equal to p_end_date, then it executes a third SELECT statement that retrieves data from the data_analysis table, using the COALESCE function to handle null values by substituting 0 if the maximum value of the analysis_id column is null, and then adds 1 to this value, storing the result into the variable v_analysis_id to generate a new unique identifier, and finally it executes an INSERT statement that adds new rows into the data_analysis table, specifically populating the analysis_id column with the value from v_analysis_id, the dataset_id column from the selected datasets, the analysis_type column with the literal string 'Performance Summary', the analysis_result column with a concatenated string composed of the literal 'Tests: ' followed by the value of v_test_count, then the literal ', Avg Duration: ' followed by the value of v_avg_duration, then the literal ', Max Mach: ' followed by the value of v_max_mach, the analysis_date column with the current date converted to text, and the analyst_id column with the literal value 1, where the data for insertion is selected by joining the datasets table (aliased as d) with the flight_tests table (aliased as ft) on the condition that d.test_id equals ft.test_id, and the selection is filtered to include only rows where the aircraft_id from the flight_tests table matches the input parameter p_aircraft_id and the test_date from the flight_tests table is greater than or equal to p_start_date and less than or equal to p_end_date, and the result set is limited to a single row using the LIMIT 1 clause.",
    "plsql": "CREATE OR REPLACE PROCEDURE analyze_flight_performance(\n    p_aircraft_id bigint,\n    p_start_date text,\n    p_end_date text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_test_count integer;\n    v_avg_duration real;\n    v_max_mach real;\n    v_analysis_id bigint;\nBEGIN\n    SELECT COUNT(*), AVG(test_duration)\n    INTO v_test_count, v_avg_duration\n    FROM flight_tests\n    WHERE aircraft_id = p_aircraft_id\n    AND test_date >= p_start_date\n    AND test_date <= p_end_date;\n    \n    SELECT MAX(mach_number)\n    INTO v_max_mach\n    FROM measurements m\n    JOIN datasets d ON m.dataset_id = d.dataset_id\n    JOIN flight_tests ft ON d.test_id = ft.test_id\n    WHERE ft.aircraft_id = p_aircraft_id\n    AND ft.test_date >= p_start_date\n    AND ft.test_date <= p_end_date;\n    \n    SELECT COALESCE(MAX(analysis_id), 0) + 1\n    INTO v_analysis_id\n    FROM data_analysis;\n    \n    INSERT INTO data_analysis (analysis_id, dataset_id, analysis_type, analysis_result, analysis_date, analyst_id)\n    SELECT v_analysis_id, d.dataset_id, 'Performance Summary',\n           'Tests: ' || v_test_count || ', Avg Duration: ' || v_avg_duration || ', Max Mach: ' || v_max_mach,\n           CURRENT_DATE::text, 1\n    FROM datasets d\n    JOIN flight_tests ft ON d.test_id = ft.test_id\n    WHERE ft.aircraft_id = p_aircraft_id\n    AND ft.test_date >= p_start_date\n    AND ft.test_date <= p_end_date\n    LIMIT 1;\nEND;\n$$;",
    "database_name": "aerospace_engineering_data_collection_and_analysis",
    "tables": [
      "datasets",
      "data_analysis",
      "data_versions",
      "measurements",
      "flight_tests",
      "access_logs"
    ],
    "id": 58
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named update_district_priority that accepts four input parameters: p_district_id of type NUMBER which identifies the specific district to be modified, p_population_threshold of type NUMBER which serves as the population comparison value, p_priority_increment of type NUMBER which specifies how much to increase the priority score, and p_priority_decrement of type NUMBER which specifies how much to decrease the priority score. The procedure first declares two local variables: v_current_population and v_current_priority, both of type NUMBER. It then executes a SELECT statement on the districts table to retrieve the population and priority_score values for the row where district_id equals the provided p_district_id parameter, storing these values in the respective local variables. Following this retrieval, the procedure evaluates a conditional statement that compares v_current_population against p_population_threshold. If the district's population exceeds the threshold, the procedure executes an UPDATE statement on the districts table, setting the priority_score column to the sum of v_current_priority and p_priority_increment for the row where district_id matches p_district_id. Conversely, if the district's population does not exceed the threshold, the procedure executes a different UPDATE statement on the districts table, setting the priority_score column to the difference between v_current_priority and p_priority_decrement for the same district row.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_district_priority(\n    p_district_id IN NUMBER,\n    p_population_threshold IN NUMBER,\n    p_priority_increment IN NUMBER,\n    p_priority_decrement IN NUMBER\n) IS\n    v_current_population NUMBER;\n    v_current_priority NUMBER;\nBEGIN\n    SELECT population, priority_score INTO v_current_population, v_current_priority\n    FROM districts\n    WHERE district_id = p_district_id;\n    \n    IF v_current_population > p_population_threshold THEN\n        UPDATE districts\n        SET priority_score = v_current_priority + p_priority_increment\n        WHERE district_id = p_district_id;\n    ELSE\n        UPDATE districts\n        SET priority_score = v_current_priority - p_priority_decrement\n        WHERE district_id = p_district_id;\n    END IF;\nEND;",
    "database_name": "healthcare_aad_management",
    "tables": [
      "health_statistics",
      "districts",
      "disease_types",
      "resources",
      "users"
    ],
    "id": 59
  },
  {
    "ir": "Write a PostgreSQL stored procedure named delete_subject_measurements that accepts three parameters: p_subject_id of type bigint which identifies the subject whose measurements are to be deleted, p_researcher_id of type bigint which identifies the researcher who created the measurements, and p_measurement_category of type text which specifies the category of measurements to be deleted. The procedure first deletes records from the data_versions table where the measurement_id column matches any measurement_id from a subquery that joins the measurements table (aliased as m) with the measurement_types table (aliased as mt) on the condition m.measurement_type_id = mt.measurement_type_id, and filters for records where m.subject_id equals p_subject_id, m.researcher_id equals p_researcher_id, and mt.measurement_category equals p_measurement_category. After deleting from data_versions, the procedure then deletes records from the measurements table where the subject_id column equals p_subject_id, the researcher_id column equals p_researcher_id, and there exists a corresponding record in the measurement_types table (aliased as mt) where mt.measurement_type_id equals measurements.measurement_type_id and mt.measurement_category equals p_measurement_category.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_subject_measurements(p_subject_id bigint, p_researcher_id bigint, p_measurement_category text)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    -- First, delete from the referencing table (data_versions) to avoid foreign key violation\n    DELETE FROM data_versions\n    WHERE measurement_id IN (\n        SELECT m.measurement_id\n        FROM measurements m\n        JOIN measurement_types mt ON m.measurement_type_id = mt.measurement_type_id\n        WHERE m.subject_id = p_subject_id \n        AND m.researcher_id = p_researcher_id \n        AND mt.measurement_category = p_measurement_category\n    );\n\n    -- Then, delete from the measurements table\n    DELETE FROM measurements\n    WHERE subject_id = p_subject_id \n    AND researcher_id = p_researcher_id \n    AND EXISTS (\n        SELECT 1 FROM measurement_types mt \n        WHERE mt.measurement_type_id = measurements.measurement_type_id \n        AND mt.measurement_category = p_measurement_category\n    );\nEND;\n$$;",
    "database_name": "physical_anthropology_and_body_measurement_data",
    "tables": [
      "measurements",
      "subjects",
      "measurement_types",
      "units",
      "researchers"
    ],
    "id": 60
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named validate_user_permissions that accepts a single parameter p_user_id of type NUMBER, which represents the user ID for whom the permissions are being validated. The procedure begins by declaring four local variables: v_day_of_week, v_access_count, v_alert_level, and v_permission_level, all of type NUMBER. The variable v_day_of_week is assigned the numeric representation of the current day of the week using the TO_NUMBER and TO_CHAR functions on the SYSDATE, with 'D' as the format model, which returns a number from 1 (Sunday) to 7 (Saturday). The variable v_access_count is initialized to 0, as a placeholder since there is no ACCESS_LOGS table to retrieve actual access counts. The variable v_alert_level is calculated using the MOD function on p_user_id with a divisor of 3, which determines the remainder when p_user_id is divided by 3. The variable v_permission_level is computed as the absolute difference between v_access_count and 50 using the ABS function. The procedure then evaluates a series of conditional statements using an IF-ELSIF-ELSE structure. If v_day_of_week equals 1, it outputs a message indicating a weekly reset for the user. If v_day_of_week is 2, 3, or 4, it logs a weekday access message for the user. If v_access_count exceeds 100, it outputs a message about cleaning old access logs for the user. If v_alert_level equals 0, it creates a validation alert message for the user. If v_permission_level is greater than 25, it updates the permission validation message for the user. If v_day_of_week is greater than 5, it assigns a weekend role message for the user. If none of these conditions are met, it outputs a message indicating that temporary alerts have been cleaned for the user. The procedure uses the DBMS_OUTPUT.PUT_LINE function to display these messages.",
    "plsql": "CREATE OR REPLACE PROCEDURE validate_user_permissions(p_user_id NUMBER) IS\n    v_day_of_week NUMBER;\n    v_access_count NUMBER;\n    v_alert_level NUMBER;\n    v_permission_level NUMBER;\nBEGIN\n    v_day_of_week := TO_NUMBER(TO_CHAR(SYSDATE, 'D'));\n    v_access_count := 0; -- Default value since no ACCESS_LOGS table exists\n    v_alert_level := MOD(p_user_id, 3);\n    v_permission_level := ABS(v_access_count - 50);\n    \n    IF v_day_of_week = 1 THEN\n        DBMS_OUTPUT.PUT_LINE('Weekly reset for user: ' || p_user_id);\n    ELSIF v_day_of_week IN (2, 3, 4) THEN\n        DBMS_OUTPUT.PUT_LINE('Weekday access logged for user: ' || p_user_id);\n    ELSIF v_access_count > 100 THEN\n        DBMS_OUTPUT.PUT_LINE('Cleaning old access logs for user: ' || p_user_id);\n    ELSIF v_alert_level = 0 THEN\n        DBMS_OUTPUT.PUT_LINE('Validation alert created for user: ' || p_user_id);\n    ELSIF v_permission_level > 25 THEN\n        DBMS_OUTPUT.PUT_LINE('Permission validation updated for user: ' || p_user_id);\n    ELSIF v_day_of_week > 5 THEN\n        DBMS_OUTPUT.PUT_LINE('Weekend role assigned for user: ' || p_user_id);\n    ELSE\n        DBMS_OUTPUT.PUT_LINE('Temporary alerts cleaned for user: ' || p_user_id);\n    END IF;\nEND;",
    "database_name": "environmental_maaqa_79684",
    "tables": [
      "USERS",
      "ROLES",
      "PERMISSIONS",
      "ACCESS_LOGS",
      "ALERTS"
    ],
    "id": 61
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `proc_consolidate_outcome_reasons` that accepts one input parameter, `p_outcome_type`, which is of data type `VARCHAR2`. This procedure is designed to process and consolidate specific `stop_reasons` records and subsequently insert new records into the `outcomes` table.\n\nThe procedure begins by declaring a local cursor named `cur_reasons`. This cursor is defined to select two columns: `reason_id` and `reason_for_stop` from the `stop_reasons` table. The selection is filtered by a `WHERE` clause, which includes only those records where the `LENGTH` of the `reason_for_stop` column is strictly greater than 20 characters. The results retrieved by this cursor are ordered in ascending order based on the `reason_id` column.\n\nFollowing the cursor declaration, a local variable `v_new_reason` of data type `VARCHAR2` with a maximum length of 255 characters is declared.\n\nThe executable part of the procedure then initiates a `FOR` loop that iterates through each record returned by the `cur_reasons` cursor. For each record (`rec`) fetched by the cursor:\n\n1.  The `v_new_reason` variable is assigned a new string value. This value is constructed by taking the first 20 characters of the `reason_for_stop` column from the current cursor record (`rec.reason_for_stop`) using the `SUBSTR` function, concatenating it with an underscore character (`_`), and then concatenating the value of the input parameter `p_outcome_type`.\n\n2.  An `UPDATE` statement is executed on the `stop_reasons` table. This statement modifies the `reason_for_stop` column to the newly constructed `v_new_reason` value. Additionally, the `updated_at` column is set to the current timestamp, formatted as a string in 'YYYY-MM-DD HH24:MI:SS' format using the `TO_CHAR` function with `CURRENT_TIMESTAMP`. This update is applied only to the row where the `reason_id` column matches the `reason_id` from the current cursor record (`rec.reason_id`).\n\n3.  An `INSERT` statement is executed to add a new record into the `outcomes` table. The values for the columns are provided as follows:\n    *   `outcome_id`: This value is determined by a subquery that selects the maximum `outcome_id` from the `outcomes` table, uses the `NVL` function to treat a `NULL` result as 0, and then adds 1 to the result. This effectively generates a new sequential `outcome_id`.\n    *   `outcome`: This column is set to the value of the `v_new_reason` variable.\n    *   `arrest_made`: This column is set to the integer value `0`.\n    *   `citation_issued`: This column is set to the integer value `0`.\n    *   `warning_issued`: This column is set to the integer value `1`.\n    *   `data_version`: This column is set to the string literal `'1.0'`.\n    *   `created_at`: This column is set to the current timestamp, formatted as a string in 'YYYY-MM-DD HH24:MI:SS' format using the `TO_CHAR` function with `CURRENT_TIMESTAMP`.\n    *   `updated_at`: This column is also set to the current timestamp, formatted as a string in 'YYYY-MM-DD HH24:MI:SS' format using the `TO_CHAR` function with `CURRENT_TIMESTAMP`.\n\nThe loop continues until all records satisfying the cursor's `WHERE` clause have been processed.",
    "plsql": "CREATE OR REPLACE PROCEDURE proc_consolidate_outcome_reasons(p_outcome_type VARCHAR2) IS\n    CURSOR cur_reasons IS\n        SELECT reason_id, reason_for_stop\n        FROM stop_reasons\n        WHERE LENGTH(reason_for_stop) > 20\n        ORDER BY reason_id;\n    \n    v_new_reason VARCHAR2(255);\nBEGIN\n    FOR rec IN cur_reasons LOOP\n        v_new_reason := SUBSTR(rec.reason_for_stop, 1, 20) || '_' || p_outcome_type;\n        \n        UPDATE stop_reasons\n        SET reason_for_stop = v_new_reason,\n            updated_at = TO_CHAR(CURRENT_TIMESTAMP, 'YYYY-MM-DD HH24:MI:SS')\n        WHERE reason_id = rec.reason_id;\n        \n        INSERT INTO outcomes (outcome_id, outcome, arrest_made, citation_issued, warning_issued, data_version, created_at, updated_at)\n        VALUES ((SELECT NVL(MAX(outcome_id), 0) + 1 FROM outcomes),\n                v_new_reason,\n                0,\n                0,\n                1,\n                '1.0',\n                TO_CHAR(CURRENT_TIMESTAMP, 'YYYY-MM-DD HH24:MI:SS'),\n                TO_CHAR(CURRENT_TIMESTAMP, 'YYYY-MM-DD HH24:MI:SS'));\n    END LOOP;\nEND;",
    "database_name": "traffic_saled_management",
    "tables": [
      "departments",
      "officers",
      "outcomes",
      "stop_reasons",
      "subjects"
    ],
    "id": 62
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named sync_user_permissions_from_roles that synchronizes user permissions with role permissions by performing a MERGE operation on the users table using the roles table as the source, where the procedure matches rows from the users table (aliased as u) with rows from the roles table (aliased as r) based on the condition that the role column in the users table equals the role_name column in the roles table, and when a match is found, updates the permissions column in the users table with the value from the permissions column in the roles table, but only for users who are active (where the is_active column equals 1) and only when the current permissions value in the users table differs from the permissions value in the roles table, effectively ensuring that all active users have their permissions synchronized with their corresponding role permissions without making unnecessary updates when permissions are already aligned.",
    "plsql": "CREATE OR REPLACE PROCEDURE sync_user_permissions_from_roles\nAS\nBEGIN\n    MERGE INTO users u\n    USING roles r\n    ON (u.role = r.role_name)\n    WHEN MATCHED THEN\n        UPDATE SET u.permissions = r.permissions\n        WHERE u.is_active = 1\n        AND u.permissions != r.permissions;\nEND;",
    "database_name": "airport_n_analysis",
    "tables": [
      "airports",
      "flights",
      "roles",
      "users"
    ],
    "id": 63
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named sp_total_reports_by_type that accepts a single input parameter, para_report_type, of type VARCHAR2, which represents the type of report to be counted. The procedure declares a local variable, v_total_reports, of type NUMBER, which is used to store the result of a query. The procedure begins by executing a SELECT statement that counts the total number of rows in the reports table where the report_type column matches the value provided in the para_report_type parameter. The result of this count is stored in the v_total_reports variable. The procedure does not perform any other operations such as updates, inserts, or deletes, nor does it include any conditional logic or function calls.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp_total_reports_by_type(para_report_type VARCHAR2) IS\nv_total_reports NUMBER;\nBEGIN\nSELECT COUNT(*) INTO v_total_reports FROM reports WHERE report_type = para_report_type;\nEND;",
    "database_name": "social_ma_twitter",
    "tables": [
      "clients",
      "reports",
      "users",
      "notifications"
    ],
    "id": 64
  },
  {
    "ir": "Write a PostgreSQL stored procedure named calculate_orbital_statistics_with_pi that performs orbital mechanics calculations for all exoplanets in the database, first declaring a cursor named planet_cursor that selects exoplanet_id, orbital_radius, orbital_period from the exoplanets table joined with the orbits table on exoplanet_id, then initializing pi_constant using the pi() function and setting processed_count, velocity_sum, and circumference_sum to zero, max_velocity to zero, and min_velocity to 999999, counting the total number of planets from the exoplanets table into total_planets, opening the planet_cursor and entering a loop that fetches each planet record into planet_rec until no more records are found, within the loop extracting the numeric radius value from the orbital_radius text field by splitting on space and casting to REAL, determining the period in days by checking if 'days' appears in the orbital_period text and either using the days value directly or converting years to days by multiplying by 365.25, calculating orbital_circumference using the formula 2  pi_constant  radius_au, calculating orbital_velocity as orbital_circumference divided by period_days, updating velocity_sum and circumference_sum with the calculated values, updating max_velocity and min_velocity if the current orbital_velocity is greater than the stored maximum or less than the stored minimum, generating a new element_id by selecting the maximum orbital_element_id from orbital_elements table, adding 1, and using COALESCE to handle null values, inserting the calculated circumference into orbital_elements table with element_name 'circumference' and unit 'AU', generating another element_id and inserting the calculated velocity into orbital_elements table with element_name 'velocity' and unit 'AU/day', incrementing processed_count after each iteration, closing the cursor after the loop completes, calculating avg_circumference as circumference_sum divided by processed_count, and finally inserting three summary records into orbital_elements table with orbit_id 0 for avg_circumference_all, max_velocity_all, and min_velocity_all, each with their respective calculated values and appropriate units.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_orbital_statistics_with_pi()\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    planet_cursor CURSOR FOR \n        SELECT e.exoplanet_id, e.orbital_radius, e.orbital_period, o.orbit_id \n        FROM exoplanets e \n        JOIN orbits o ON e.exoplanet_id = o.exoplanet_id;\n    planet_rec RECORD;\n    orbital_circumference REAL;\n    orbital_velocity REAL;\n    pi_constant REAL;\n    radius_au REAL;\n    period_days REAL;\n    element_id BIGINT;\n    total_planets INTEGER;\n    processed_count INTEGER;\n    avg_circumference REAL;\n    max_velocity REAL;\n    min_velocity REAL;\n    velocity_sum REAL;\n    circumference_sum REAL;\nBEGIN\n    pi_constant := pi();\n    processed_count := 0;\n    velocity_sum := 0;\n    circumference_sum := 0;\n    max_velocity := 0;\n    min_velocity := 999999;\n    \n    SELECT COUNT(*) INTO total_planets FROM exoplanets;\n    \n    OPEN planet_cursor;\n    \n    LOOP\n        FETCH planet_cursor INTO planet_rec;\n        EXIT WHEN NOT FOUND;\n        \n        radius_au := CAST(SPLIT_PART(planet_rec.orbital_radius, ' ', 1) AS REAL);\n        \n        IF POSITION('days' IN planet_rec.orbital_period) > 0 THEN\n            period_days := CAST(SPLIT_PART(planet_rec.orbital_period, ' ', 1) AS REAL);\n        ELSE\n            period_days := CAST(SPLIT_PART(planet_rec.orbital_period, ' ', 1) AS REAL) * 365.25;\n        END IF;\n        \n        orbital_circumference := 2 * pi_constant * radius_au;\n        orbital_velocity := orbital_circumference / period_days;\n        \n        velocity_sum := velocity_sum + orbital_velocity;\n        circumference_sum := circumference_sum + orbital_circumference;\n        \n        IF orbital_velocity > max_velocity THEN\n            max_velocity := orbital_velocity;\n        END IF;\n        \n        IF orbital_velocity < min_velocity THEN\n            min_velocity := orbital_velocity;\n        END IF;\n        \n        SELECT COALESCE(MAX(orbital_element_id), -1) + 1 INTO element_id FROM orbital_elements;\n        \n        INSERT INTO orbital_elements (orbital_element_id, orbit_id, element_name, element_value, unit)\n        VALUES (element_id, planet_rec.orbit_id, 'circumference', orbital_circumference::text, 'AU');\n        \n        SELECT COALESCE(MAX(orbital_element_id), -1) + 1 INTO element_id FROM orbital_elements;\n        \n        INSERT INTO orbital_elements (orbital_element_id, orbit_id, element_name, element_value, unit)\n        VALUES (element_id, planet_rec.orbit_id, 'velocity', orbital_velocity::text, 'AU/day');\n        \n        processed_count := processed_count + 1;\n    END LOOP;\n    \n    CLOSE planet_cursor;\n    \n    avg_circumference := circumference_sum / processed_count;\n    \n    SELECT COALESCE(MAX(orbital_element_id), -1) + 1 INTO element_id FROM orbital_elements;\n    INSERT INTO orbital_elements (orbital_element_id, orbit_id, element_name, element_value, unit)\n    VALUES (element_id, 0, 'avg_circumference_all', avg_circumference::text, 'AU');\n    \n    SELECT COALESCE(MAX(orbital_element_id), -1) + 1 INTO element_id FROM orbital_elements;\n    INSERT INTO orbital_elements (orbital_element_id, orbit_id, element_name, element_value, unit)\n    VALUES (element_id, 0, 'max_velocity_all', max_velocity::text, 'AU/day');\n    \n    SELECT COALESCE(MAX(orbital_element_id), -1) + 1 INTO element_id FROM orbital_elements;\n    INSERT INTO orbital_elements (orbital_element_id, orbit_id, element_name, element_value, unit)\n    VALUES (element_id, 0, 'min_velocity_all', min_velocity::text, 'AU/day');\nEND;\n$$;",
    "database_name": "astronomical_exoplanet_data_management",
    "tables": [
      "exoplanets",
      "planet_types",
      "discovery_methods",
      "exoplanet_characteristics",
      "orbits",
      "orbital_elements",
      "exoplanet_datasets",
      "exoplanet_versions",
      "access_logs"
    ],
    "id": 65
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_spacecraft_type that returns a trigger and is executed automatically by a trigger named trigger_update_space_spacecraft_type, which is defined to fire after every row insertion operation on the spacecraft table; the function's logic, when invoked, performs an update operation on the spacecraft table, specifically setting the spacecraft_type column to the literal string value 'Unmanned' for the specific row in the spacecraft table where the spacecraft_id column value matches the spacecraft_id value of the newly inserted row (accessible via the NEW record) and where the payload_capacity value of that newly inserted row (NEW.payload_capacity) is less than the numerical value 1000; the function then returns the NEW row record to the calling trigger mechanism.",
    "plsql": "CREATE OR REPLACE FUNCTION update_spacecraft_type() RETURNS TRIGGER AS $$\nBEGIN\n  UPDATE spacecraft SET spacecraft_type = 'Unmanned' WHERE spacecraft_id = NEW.spacecraft_id AND NEW.payload_capacity < 1000;\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trigger_update_spacecraft_type\nAFTER INSERT ON spacecraft\nFOR EACH ROW\nEXECUTE FUNCTION update_spacecraft_type();",
    "database_name": "space_exploration_missions_and_launch_data",
    "tables": [
      "spacecraft",
      "orbital_parameters"
    ],
    "_source": "plfactory23",
    "id": 66
  },
  {
    "ir": "Write a PostgreSQL stored procedure named update_order_status that accepts four input parameters: p_order_id of type BIGINT which identifies the specific order to be modified, p_new_status of type TEXT which represents the new status value to be assigned to the order, p_updated_at of type TEXT which contains the timestamp or date string indicating when the update occurred, and p_payment_method of type TEXT which specifies the payment method associated with the order, and performs an UPDATE operation on the orders table by setting the order_status column to the value of p_new_status and the updated_at column to the value of p_updated_at for all rows where the order_id column matches the p_order_id parameter AND the payment_method column matches the p_payment_method parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_order_status(\n    IN p_order_id BIGINT,\n    IN p_new_status TEXT,\n    IN p_updated_at TEXT,\n    IN p_payment_method TEXT\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE orders\n    SET order_status = p_new_status,\n        updated_at = p_updated_at\n    WHERE order_id = p_order_id\n    AND payment_method = p_payment_method;\nEND;\n$$;",
    "database_name": "clothing_and_apparel_sizing_standards_365686",
    "tables": [
      "orders",
      "order_items",
      "products",
      "customers",
      "reviews"
    ],
    "id": 67
  },
  {
    "ir": "Write an Oracle PL/SQL function named update_site_grade that accepts three input parameters: a numeric parameter p_site_id, a string parameter p_new_grade, and a string parameter p_update_reason, and returns a numeric value. The function modifies the heritage_sites table by updating the row where the site_id column matches the provided p_site_id parameter. For that specific row, it sets the grade column to the value of the p_new_grade parameter, sets the last_updated column to the current system date and time formatted as a string in 'YYYY-MM-DD HH24:MI:SS' format, and sets the notes column to the value of the p_update_reason parameter. The function then returns the number of rows that were successfully updated by the operation.",
    "plsql": "CREATE OR REPLACE FUNCTION update_site_grade(p_site_id NUMBER, p_new_grade VARCHAR2, p_update_reason VARCHAR2)\nRETURN NUMBER\nIS\n  PRAGMA AUTONOMOUS_TRANSACTION;\nBEGIN\n    UPDATE heritage_sites\n    SET grade = p_new_grade, last_updated = TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'), notes = p_update_reason\n    WHERE site_id = p_site_id;\n\n    COMMIT;\n\n    RETURN SQL%ROWCOUNT;\nEND;",
    "database_name": "historical_aah_management",
    "tables": [
      "heritage_sites",
      "locations",
      "site_maintenance"
    ],
    "id": 68
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named consolidate_customer_data that takes three parameters: a bigint parameter p_source_customer_id representing the customer identifier to be consolidated from, a bigint parameter p_target_customer_id representing the customer identifier to be consolidated into, and a text parameter p_consolidation_type which is declared but not used within the procedure logic; the procedure first declares three local variables: v_total_billing_amount of type real, v_total_usage_hours of type real, and v_source_company of type text; it then calculates the total billing amount for the source customer by selecting the sum of the total_amount column from the billing table where the customer_id column equals p_source_customer_id, using the COALESCE function to return 0 if the sum is null, and stores this result in v_total_billing_amount; it similarly calculates the total usage hours for the source customer by selecting the sum of the total_hours column from the instance_usage table where the customer_id column equals p_source_customer_id, again using COALESCE to handle nulls, and stores this in v_total_usage_hours; it then retrieves the company name for the source customer by selecting the company column from the customers table where the customer_id column equals p_source_customer_id and stores this value in v_source_company; following these data retrievals, the procedure updates the billing table by setting the customer_id column to p_target_customer_id for all rows where the customer_id column currently equals p_source_customer_id; it performs an identical update on the instance_usage table, setting the customer_id column to p_target_customer_id for all rows where the customer_id column equals p_source_customer_id; it then updates the target customer record in the customers table by setting the company column to a concatenated string of its existing company value, the string ' + ', and the v_source_company value retrieved earlier, and also updates the updated_at column to the current system timestamp cast to text, for the row where the customer_id column equals p_target_customer_id; finally, the procedure deletes the source customer record from the customers table where the customer_id column equals p_source_customer_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE consolidate_customer_data(\n    p_source_customer_id bigint,\n    p_target_customer_id bigint,\n    p_consolidation_type text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_total_billing_amount real;\n    v_total_usage_hours real;\n    v_source_company text;\nBEGIN\n    SELECT COALESCE(SUM(b.total_amount), 0)\n    INTO v_total_billing_amount\n    FROM billing b\n    WHERE b.customer_id = p_source_customer_id;\n    \n    SELECT COALESCE(SUM(iu.total_hours), 0)\n    INTO v_total_usage_hours\n    FROM instance_usage iu\n    WHERE iu.customer_id = p_source_customer_id;\n    \n    SELECT company INTO v_source_company\n    FROM customers\n    WHERE customer_id = p_source_customer_id;\n    \n    UPDATE billing\n    SET customer_id = p_target_customer_id\n    WHERE customer_id = p_source_customer_id;\n    \n    UPDATE instance_usage\n    SET customer_id = p_target_customer_id\n    WHERE customer_id = p_source_customer_id;\n    \n    UPDATE customers\n    SET company = company || ' + ' || v_source_company,\n        updated_at = CURRENT_TIMESTAMP::text\n    WHERE customer_id = p_target_customer_id;\n    \n    DELETE FROM customers\n    WHERE customer_id = p_source_customer_id;\nEND;\n$$;",
    "database_name": "cloud_computing_instance_management",
    "tables": [
      "customers",
      "billing",
      "payments",
      "instance_usage",
      "instance_types",
      "regions"
    ],
    "id": 69
  },
  {
    "ir": "Write a PLpgSQL stored procedure that takes two parameters, para_Flight_ID of type bigint and para_Compensation_Amount of type bigint. The procedure performs the following operations: it updates the flight_cancellations table by setting the compensation_provided column to the value of para_Compensation_Amount for the row where the flight_id column matches the value of para_Flight_ID. Next, it updates the flights table by setting the flight_status column to the string 'Compensation Updated' for the row where the flight_id column matches the value of para_Flight_ID. Finally, it deletes a row from the weather_reports table where the weather_id column matches the weather_id obtained from the flights table for the row where the flight_id column equals para_Flight_ID.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp_cancellation_compensation(para_Flight_ID bigint, para_Compensation_Amount bigint) LANGUAGE plpgsql AS $$\nBEGIN\n    UPDATE \"flight_cancellations\" SET \"compensation_provided\" = para_Compensation_Amount WHERE \"flight_id\" = para_Flight_ID;\n    UPDATE \"flights\" SET \"flight_status\" = 'Compensation Updated' WHERE \"flight_id\" = para_Flight_ID;\n    DELETE FROM \"weather_reports\" WHERE \"weather_id\" = (SELECT \"weather_id\" FROM \"flights\" WHERE \"flight_id\" = para_Flight_ID);\nEND; $$",
    "database_name": "airline_flight_operations_and_weather_impact_analysis",
    "tables": [
      "flights",
      "flight_cancellations",
      "weather_reports"
    ],
    "id": 70
  },
  {
    "ir": "Write a PostgreSQL trigger function named trg_cleanup_orphaned_reports that returns a trigger and is executed by a trigger named trg_cleanup_on_access_delete, which is defined to fire after a delete operation on the access_logs table for each deleted row, where the function performs a delete operation on the incident_reports table, targeting rows where the incident_id column matches the OLD.incident_id value from the deleted access_logs row and where the ascii function applied to the report_details column returns a value less than 32, which checks if the first character of the report_details text has an ASCII code in the non-printable control character range, and the function concludes by returning the OLD row record.",
    "plsql": "CREATE OR REPLACE FUNCTION trg_cleanup_orphaned_reports() RETURNS TRIGGER AS $$\nBEGIN\n    DELETE FROM incident_reports WHERE incident_id = OLD.incident_id AND ascii(report_details) < 32;\n    RETURN OLD;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_cleanup_on_access_delete\nAFTER DELETE ON access_logs\nFOR EACH ROW EXECUTE FUNCTION trg_cleanup_orphaned_reports();",
    "database_name": "cybersecurity_incident_tracking_and_analysis",
    "tables": [
      "incident_reports",
      "incident_response",
      "access_logs"
    ],
    "_source": "plfactory30",
    "id": 71
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `update_passenger_communications` that does not accept any input parameters. This procedure is designed to iterate through a specific subset of records in the `passengers` table and, for each record, conditionally update its `email` and `phone_number` columns based on various characteristics of the existing `email` and `emergency_contact_name` values.\n\nThe procedure begins by declaring several local variables:\n- `v_passenger_id` of type `NUMBER`, intended to store the `passenger_id` from the `passengers` table.\n- `v_passenger_name` of type `VARCHAR2(255)`, intended to store the `name` from the `passengers` table.\n- `v_passenger_email` of type `VARCHAR2(255)`, intended to store the `email` from the `passengers` table.\n- `v_emergency_name` of type `VARCHAR2(255)`, intended to store the `emergency_contact_name` from the `passengers` table.\n- `v_new_email` of type `VARCHAR2(255)`, intended to store the newly generated email address.\n- `v_new_phone` of type `VARCHAR2(255)`, intended to store the newly generated phone number.\n\nA cursor named `passenger_cursor` is then defined. This cursor selects the `passenger_id`, `name`, `email`, and `emergency_contact_name` columns from the `passengers` table. The selection is filtered by a `WHERE` clause, ensuring that only rows where the `email` column is not `NULL` are included in the result set.\n\nThe execution block of the procedure starts by opening the `passenger_cursor`. It then enters a `LOOP` construct to process each record fetched by the cursor. Inside the loop, the `FETCH` statement retrieves the values for `passenger_id`, `name`, `email`, and `emergency_contact_name` from the current cursor row and assigns them to the corresponding local variables: `v_passenger_id`, `v_passenger_name`, `v_passenger_email`, and `v_emergency_name`, respectively.\n\nAn `EXIT WHEN passenger_cursor%NOTFOUND` statement immediately follows the `FETCH`, which terminates the loop when no more rows are found by the cursor.\n\nFollowing the fetch, a series of conditional statements (`IF-ELSIF-ELSE`) are evaluated to determine the new `email` and `phone_number` values for the current passenger:\n\n1.  **Condition 1:** `IF v_emergency_name IS NULL THEN`\n    If the `v_emergency_name` variable (representing the `emergency_contact_name` from the `passengers` table) is `NULL`, then:\n    -   `v_new_email` is set by concatenating the literal string `'no.emergency.'` with the current `v_passenger_email` value using the `CONCAT` function.\n    -   `v_new_phone` is set to the literal string `'+1-000-000-0000'`.\n\n2.  **Condition 2:** `ELSIF LENGTH(v_passenger_email) > 50 THEN`\n    If the first condition is false, and the length of `v_passenger_email` (obtained using the `LENGTH` function) is greater than 50 characters, then:\n    -   `v_new_email` is set to the first 50 characters of `v_passenger_email` using the `SUBSTR` function (starting from position 1 and taking 50 characters).\n    -   `v_new_phone` is set by concatenating the literal string `'+1-'` with the string representation of `v_passenger_id` (converted using the `TO_CHAR` function).\n\n3.  **Condition 3:** `ELSIF INSTR(v_passenger_email, '@') = 0 THEN`\n    If the first two conditions are false, and the `INSTR` function indicates that the `@` symbol is not found within `v_passenger_email` (i.e., its position is 0), then:\n    -   `v_new_email` is set by concatenating the current `v_passenger_email` with the literal string `'@example.com'` using the `CONCAT` function.\n    -   `v_new_phone` is set by concatenating the literal string `'+1-555-'` with the string representation of `v_passenger_id` (converted using the `TO_CHAR` function).\n\n4.  **Else Condition:** `ELSE`\n    If none of the above conditions are met, then:\n    -   `v_new_email` is simply assigned the current `v_passenger_email` value.\n    -   `v_new_phone` is set by concatenating the literal string `'+1-'` with the string representation of `v_passenger_id` plus 1000 (converted using the `TO_CHAR` function).\n\nAfter the conditional logic determines `v_new_email` and `v_new_phone`, an `UPDATE` statement is executed. This statement modifies the `passengers` table, setting the `email` column to the value of `v_new_email` and the `phone_number` column to the value of `v_new_phone`. The `WHERE` clause of the `UPDATE` statement ensures that only the row corresponding to the current `v_passenger_id` is updated.\n\nThe loop continues until all eligible passengers have been processed. Finally, after the loop terminates, the `passenger_cursor` is closed.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_passenger_communications IS\n    v_passenger_id NUMBER;\n    v_passenger_name VARCHAR2(255);\n    v_passenger_email VARCHAR2(255);\n    v_emergency_name VARCHAR2(255);\n    v_new_email VARCHAR2(255);\n    v_new_phone VARCHAR2(255);\n    CURSOR passenger_cursor IS\n        SELECT passenger_id, name, email, emergency_contact_name\n        FROM passengers\n        WHERE email IS NOT NULL;\nBEGIN\n    OPEN passenger_cursor;\n    LOOP\n        FETCH passenger_cursor INTO v_passenger_id, v_passenger_name, v_passenger_email, v_emergency_name;\n        EXIT WHEN passenger_cursor%NOTFOUND;\n        \n        IF v_emergency_name IS NULL THEN\n            v_new_email := CONCAT('no.emergency.', v_passenger_email);\n            v_new_phone := '+1-000-000-0000';\n        ELSIF LENGTH(v_passenger_email) > 50 THEN\n            v_new_email := SUBSTR(v_passenger_email, 1, 50);\n            v_new_phone := CONCAT('+1-', TO_CHAR(v_passenger_id));\n        ELSIF INSTR(v_passenger_email, '@') = 0 THEN\n            v_new_email := CONCAT(v_passenger_email, '@example.com');\n            v_new_phone := CONCAT('+1-555-', TO_CHAR(v_passenger_id));\n        ELSE\n            v_new_email := v_passenger_email;\n            v_new_phone := CONCAT('+1-', TO_CHAR(v_passenger_id + 1000));\n        END IF;\n        \n        UPDATE passengers\n        SET email = v_new_email,\n            phone_number = v_new_phone\n        WHERE passenger_id = v_passenger_id;\n    END LOOP;\n    CLOSE passenger_cursor;\nEND;",
    "database_name": "maritime_pd_management",
    "tables": [
      "passengers"
    ],
    "id": 72
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named manage_workflow_priority_queue that processes workflows based on their priority, activity status, dependency count, and log count. The procedure begins by declaring a cursor named priority_cursor, which retrieves workflow details including workflow_id, display_name, priority, is_active, dependency_count, and log_count from the workflows table, joining with workflow_dependencies and workflow_logs tables. The workflow_logs join filters logs with a timestamp within the last 7 days. The procedure initializes several variables: v_high_priority_count, v_avg_log_count, v_note_id, v_log_id, and v_dependency_id. It calculates v_high_priority_count by counting active workflows with priority 1 and v_avg_log_count by averaging log counts of workflows with logs from the last 7 days. The procedure iterates over each record in priority_cursor, performing operations based on conditions. If a workflow is active with priority 1 and there are more than 10 such workflows, it inserts a note indicating the workflow is queued for review and logs a warning about optimization. If a workflow has more than 3 dependencies and a log count exceeding the average, it deletes debug logs and logs an info message about cleaning debug logs. If a workflow is inactive with existing logs, it deletes all logs and inserts a note about clearing logs. If a workflow has priority 3 and no dependencies, it inserts a dependency linking the workflow to a master and logs an info message about linking. For all other cases, it logs a debug message indicating normal processing. The procedure uses NVL and MAX functions to determine the next available IDs for notes, logs, and dependencies, and TO_CHAR to format timestamps.",
    "plsql": "CREATE OR REPLACE PROCEDURE manage_workflow_priority_queue AS\n    CURSOR priority_cursor IS \n        SELECT w.workflow_id, w.display_name, w.priority, w.is_active,\n               COUNT(wd.dependent_workflow_id) as dependency_count,\n               COUNT(wl.log_id) as log_count\n        FROM workflows w\n        LEFT JOIN workflow_dependencies wd ON w.workflow_id = wd.workflow_id\n        LEFT JOIN workflow_logs wl ON w.workflow_id = wl.workflow_id \n                                 AND TO_DATE(wl.log_timestamp, 'YYYY-MM-DD HH24:MI:SS') > SYSDATE - 7\n        GROUP BY w.workflow_id, w.display_name, w.priority, w.is_active;\n    \n    v_high_priority_count NUMBER;\n    v_avg_log_count NUMBER;\n    v_note_id NUMBER;\n    v_log_id NUMBER;\n    v_dependency_id NUMBER;\nBEGIN\n    SELECT COUNT(*) INTO v_high_priority_count \n    FROM workflows WHERE priority = 1 AND is_active = 1;\n    \n    SELECT AVG(log_count) INTO v_avg_log_count\n    FROM (SELECT COUNT(wl.log_id) as log_count\n          FROM workflows w\n          LEFT JOIN workflow_logs wl ON w.workflow_id = wl.workflow_id\n          WHERE TO_DATE(wl.log_timestamp, 'YYYY-MM-DD HH24:MI:SS') > SYSDATE - 7\n          GROUP BY w.workflow_id);\n    \n    FOR prio_rec IN priority_cursor LOOP\n        SELECT NVL(MAX(note_id), 0) + 1 INTO v_note_id FROM notes;\n        SELECT NVL(MAX(log_id), 0) + 1 INTO v_log_id FROM workflow_logs;\n        SELECT NVL(MAX(dependency_id), 0) + 1 INTO v_dependency_id FROM workflow_dependencies;\n        \n        IF prio_rec.is_active = 1 AND prio_rec.priority = 1 AND v_high_priority_count > 10 THEN\n            INSERT INTO notes (note_id, workflow_id, note, created_at, last_updated, created_by, last_updated_by)\n            VALUES (v_note_id, prio_rec.workflow_id, 'High priority workflow queued for review', TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'), TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'), 'system', 'system');\n            INSERT INTO workflow_logs (log_id, workflow_id, log_message, log_level, log_timestamp, environment_id)\n            VALUES (v_log_id, prio_rec.workflow_id, 'High priority workflow flagged for optimization', 'WARNING', TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'), 1);\n        ELSIF prio_rec.dependency_count > 3 AND prio_rec.log_count > v_avg_log_count THEN\n            DELETE FROM workflow_logs WHERE workflow_id = prio_rec.workflow_id AND log_level = 'DEBUG';\n            INSERT INTO workflow_logs (log_id, workflow_id, log_message, log_level, log_timestamp, environment_id)\n            VALUES (v_log_id, prio_rec.workflow_id, 'Debug logs cleaned for high-activity workflow', 'INFO', TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'), 1);\n        ELSIF prio_rec.is_active = 0 AND prio_rec.log_count > 0 THEN\n            DELETE FROM workflow_logs WHERE workflow_id = prio_rec.workflow_id;\n            INSERT INTO notes (note_id, workflow_id, note, created_at, last_updated, created_by, last_updated_by)\n            VALUES (v_note_id, prio_rec.workflow_id, 'All logs cleared for inactive workflow', TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'), TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'), 'system', 'system');\n        ELSIF prio_rec.priority = 3 AND prio_rec.dependency_count = 0 THEN\n            INSERT INTO workflow_dependencies (dependency_id, workflow_id, dependent_workflow_id)\n            VALUES (v_dependency_id, 0, prio_rec.workflow_id);\n            INSERT INTO workflow_logs (log_id, workflow_id, log_message, log_level, log_timestamp, environment_id)\n            VALUES (v_log_id, prio_rec.workflow_id, 'Low priority workflow linked to master', 'INFO', TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'), 1);\n        ELSE\n            INSERT INTO workflow_logs (log_id, workflow_id, log_message, log_level, log_timestamp, environment_id)\n            VALUES (v_log_id, prio_rec.workflow_id, 'Workflow priority queue processed normally', 'DEBUG', TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'), 1);\n        END IF;\n    END LOOP;\nEND;",
    "database_name": "azure_mima_management",
    "tables": [
      "workflows",
      "notes",
      "override_parameters",
      "override_parameter_values",
      "workflow_dependencies",
      "workflow_environments",
      "workflow_logs"
    ],
    "id": 73
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `update_movie_crew_role` that accepts three input parameters: `p_movie_id` of type `BIGINT`, `p_crew_member_id` of type `BIGINT`, and `p_new_role` of type `TEXT`. The purpose of this procedure is to update the role of a specific crew member for a given movie and to record this change as an audit entry in the `movies` table.\n\nUpon execution, the procedure first declares three local variables: `v_current_role` of type `TEXT` to store the existing role of the crew member, `v_movie_title` of type `TEXT` to store the title of the movie, and `v_new_movie_id` of type `BIGINT` to hold a newly generated unique identifier for the audit movie entry.\n\nThe procedure then performs two `SELECT` operations:\n1. It retrieves the `role` from the `movie_crew` table and assigns it to the `v_current_role` variable. This selection is filtered by matching the `movie_id` column with the input parameter `p_movie_id` and the `crew_member_id` column with the input parameter `p_crew_member_id`.\n2. It retrieves the `title` from the `movies` table and assigns it to the `v_movie_title` variable. This selection is filtered by matching the `movie_id` column with the input parameter `p_movie_id`.\n\nFollowing these selections, the procedure enters a conditional block. It checks if the `v_current_role` variable is not `NULL`. This condition ensures that an existing role was found for the specified movie and crew member before proceeding with any updates or audit logging.\n\nIf `v_current_role` is not `NULL`, the procedure executes the following operations:\n1. It performs an `UPDATE` operation on the `movie_crew` table. The `role` column is set to the value provided by the `p_new_role` input parameter. This update is applied to the row where the `movie_id` column matches `p_movie_id` and the `crew_member_id` column matches `p_crew_member_id`.\n2. It then calculates a new unique `movie_id` for an audit entry. This is achieved by selecting the maximum value of the `movie_id` column from the `movies` table, using the `COALESCE` function to default to `0` if no `movie_id` exists (i.e., the table is empty), and then adding `1` to the result. This calculated value is stored in the `v_new_movie_id` variable.\n3. Finally, it performs an `INSERT` operation into the `movies` table to create an audit record of the role change. The values inserted are:\n    - `movie_id`: The `v_new_movie_id` generated in the previous step.\n    - `title`: A concatenated string consisting of the literal 'Audit: ' followed by the `v_movie_title` retrieved earlier.\n    - `release_year`: The year extracted from the current date using `EXTRACT(YEAR FROM CURRENT_DATE)`.\n    - `genre`: The literal string 'Audit'.\n    - `box_office`: The numeric value `0.0`.\n    - `runtime`: The integer value `0`.\n    - `rating`: The literal string 'NR'.\n    - `synopsis`: A concatenated string describing the change, formed by the literal 'Crew role changed from ', followed by the `v_current_role`, then the literal ' to ', and finally the `p_new_role`.\n    - `country`: The literal string 'USA'.\n    - `language`: The literal string 'English'.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_movie_crew_role(p_movie_id BIGINT, p_crew_member_id BIGINT, p_new_role TEXT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_current_role TEXT;\n    v_movie_title TEXT;\n    v_new_movie_id BIGINT;\nBEGIN\n    SELECT role INTO v_current_role FROM movie_crew WHERE movie_id = p_movie_id AND crew_member_id = p_crew_member_id;\n    SELECT title INTO v_movie_title FROM movies WHERE movie_id = p_movie_id;\n    \n    IF v_current_role IS NOT NULL THEN\n        UPDATE movie_crew SET role = p_new_role WHERE movie_id = p_movie_id AND crew_member_id = p_crew_member_id;\n        \n        -- Generate a new unique movie_id for the audit entry by finding the max existing ID and adding 1\n        SELECT COALESCE(MAX(movie_id), 0) + 1 INTO v_new_movie_id FROM movies;\n\n        INSERT INTO movies (movie_id, title, release_year, genre, box_office, runtime, rating, synopsis, country, language)\n        VALUES (v_new_movie_id, 'Audit: ' || v_movie_title, EXTRACT(YEAR FROM CURRENT_DATE), 'Audit', 0.0, 0, 'NR',\n                'Crew role changed from ' || v_current_role || ' to ' || p_new_role, 'USA', 'English');\n    END IF;\nEND;\n$$;",
    "database_name": "movie_and_crew_information_management",
    "tables": [
      "movies",
      "movie_cast",
      "cast_members",
      "movie_crew",
      "crew_members"
    ],
    "id": 74
  },
  {
    "ir": "Write a PostgreSQL trigger function named validate_ticker_before_insert that is executed automatically before each row insertion into the insider_trades table, which declares a local variable v_ticker_id of type bigint, then queries the tickers table to select the ticker_id column into v_ticker_id where the ticker column equals the incoming NEW.ticker value from the inserted row; if the query finds no match and v_ticker_id is null, it performs an insert into the tickers table, specifying columns ticker_id, ticker, company_name, ticker_link, industry, sector, market_cap, ceo, exchange, and country, with values calculated as follows: ticker_id is set to the result of a subquery that selects the maximum existing ticker_id from the tickers table, adds 1 to it, and uses COALESCE to default to 0 if the table is empty, ticker is set to NEW.ticker, company_name is set to the literal string 'Unknown Company', ticker_link is constructed by concatenating the string 'http://openinsider.com/' with NEW.ticker, industry and sector are set to 'Unknown', market_cap is set to 0.0, ceo is set to 'Unknown', exchange is set to 'Unknown', and country is set to 'Unknown', and this insert statement uses the RETURNING clause to capture the newly generated ticker_id into the v_ticker_id variable; after this conditional block, the function assigns the value of v_ticker_id (which is either the existing id from the initial select or the newly generated id from the insert) to the company_id column of the NEW row record for insider_trades, and finally returns the modified NEW row.",
    "plsql": "CREATE OR REPLACE FUNCTION validate_ticker_before_insert() RETURNS TRIGGER AS $$\nDECLARE\n    v_ticker_id bigint;\nBEGIN\n    SELECT ticker_id INTO v_ticker_id FROM tickers WHERE ticker = NEW.ticker;\n    \n    IF v_ticker_id IS NULL THEN\n        INSERT INTO tickers (ticker_id, ticker, company_name, ticker_link, industry, sector, market_cap, ceo, exchange, country)\n        VALUES ((SELECT COALESCE(MAX(ticker_id), 0) + 1 FROM tickers), NEW.ticker, 'Unknown Company', 'http://openinsider.com/' || NEW.ticker, 'Unknown', 'Unknown', 0.0, 'Unknown', 'Unknown', 'Unknown')\n        RETURNING ticker_id INTO v_ticker_id;\n    END IF;\n    \n    NEW.company_id := v_ticker_id;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER tr_validate_ticker_before_insert\n    BEFORE INSERT ON insider_trades\n    FOR EACH ROW\n    EXECUTE FUNCTION validate_ticker_before_insert();",
    "database_name": "insider_trading_activity_and_reporting",
    "tables": [
      "insider_trades",
      "insiders",
      "tickers",
      "trade_types"
    ],
    "_source": "plfactory18",
    "id": 75
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named 'sp' that accepts two input parameters: a numeric parameter 'para_date_offset' and a string parameter 'para_region_name'. The procedure first retrieves the 'region_id' from the 'regions' table by selecting the row where the 'region_name' column exactly matches the provided 'para_region_name' parameter and stores this value into a local variable 'v_region_id'. It then calculates a count, storing it into variable 'v_count', of rows in the 'testing_data' table where the 'region_id' equals the retrieved 'v_region_id' and the 'test_date' column is less than a character string representation of a calculated past date; this past date is derived by subtracting a number of days, specified by 'para_date_offset', from the current system date (SYSDATE) using the NUMTODSINTERVAL function to convert the numeric offset into a DAY interval. If the count in 'v_count' is greater than zero, the procedure executes a DELETE operation on the 'testing_data' table, removing all rows that satisfy the same condition used for the count: 'region_id' equals 'v_region_id' and 'test_date' is less than the character string of the date (SYSDATE - the 'para_date_offset' days interval). Following this conditional deletion, the procedure determines a new unique identifier for a site by querying the 'testing_sites' table: it selects the maximum existing value from the 'site_id' column, uses the NVL function to substitute a 0 if the maximum is null (indicating an empty table), adds 1 to this value, and stores the result into local variable 'v_new_site_id'. Finally, the procedure performs an INSERT into the 'testing_sites' table, creating a new row with the generated 'v_new_site_id' as the 'site_id', a 'site_name' constructed by concatenating the literal string 'New_Site_' with the input 'para_region_name' parameter, and the previously retrieved 'v_region_id' as the 'region_id'.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp(para_date_offset NUMBER, para_region_name VARCHAR2) IS\n  v_region_id regions.region_id%TYPE;\n  v_count NUMBER;\n  v_new_site_id NUMBER;\nBEGIN\n  SELECT region_id INTO v_region_id FROM regions WHERE region_name = para_region_name;\n  SELECT COUNT(*) INTO v_count FROM testing_data WHERE region_id = v_region_id AND test_date < TO_CHAR(SYSDATE - NUMTODSINTERVAL(para_date_offset, 'DAY'));\n  IF v_count > 0 THEN\n    DELETE FROM testing_data WHERE region_id = v_region_id AND test_date < TO_CHAR(SYSDATE - NUMTODSINTERVAL(para_date_offset, 'DAY'));\n  END IF;\n  \n  -- Generate a unique site_id by finding the maximum existing site_id and incrementing it\n  SELECT NVL(MAX(site_id), 0) + 1 INTO v_new_site_id FROM testing_sites;\n  \n  INSERT INTO testing_sites (site_id, site_name, region_id) VALUES (v_new_site_id, 'New_Site_' || para_region_name, v_region_id);\nEND;",
    "database_name": "public_hdra_analysis",
    "tables": [
      "regions",
      "testing_data",
      "testing_sites"
    ],
    "id": 76
  },
  {
    "ir": "Write a PLpgSQL stored procedure named `delete_article_authors_by_article` that accepts a single input parameter. This parameter, named `p_article_id`, is of the `bigint` data type and serves the purpose of identifying a specific article whose associated author records are to be removed. The procedure's sole operation is to perform a `DELETE` statement on the `article_authors` table. This `DELETE` operation targets and removes all rows from the `article_authors` table where the value in the `article_id` column precisely matches the value provided by the `p_article_id` input parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_article_authors_by_article(p_article_id bigint)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM article_authors \n    WHERE article_id = p_article_id;\nEND;\n$$;",
    "database_name": "academic_journal_management_and_analytics",
    "tables": [
      "articles",
      "article_authors"
    ],
    "id": 77
  },
  {
    "ir": "Write an Oracle PL/SQL function named get_friendship_status that accepts two mandatory input parameters, p_user_id of type NUMBER and p_friend_id of type NUMBER, and returns a single VARCHAR2 value. The function declares a local variable v_status of type VARCHAR2(255). The function's logic executes a single SQL SELECT statement that queries the friendships table. The SELECT statement uses the MAX aggregate function on the friendship_status column. The data is retrieved from the friendships table specifically for rows where the user_id column equals the input parameter p_user_id and the friend_id column equals the input parameter p_friend_id. The result of this SELECT statement, which is the maximum friendship_status value found for the specified user and friend pair, is stored into the local variable v_status. The function then concludes by returning the value contained in the v_status variable.",
    "plsql": "CREATE OR REPLACE FUNCTION get_friendship_status(p_user_id NUMBER, p_friend_id NUMBER) RETURN VARCHAR2 IS\n  v_status VARCHAR2(255);\nBEGIN\n  SELECT MAX(friendship_status)\n  INTO v_status\n  FROM friendships\n  WHERE user_id = p_user_id AND friend_id = p_friend_id;\n  RETURN v_status;\nEND;",
    "database_name": "self_tupa_goals",
    "tables": [
      "activities",
      "activity_logs",
      "activity_types",
      "goals",
      "friendships"
    ],
    "id": 78
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named create_strategic_plan_with_allocation that accepts five input parameters: p_dept_id of type BIGINT to identify a department, p_plan_name of type TEXT for the strategic plan's name, p_plan_desc of type TEXT for the strategic plan's description, p_start_date of type TEXT for the plan's start date, and p_end_date of type TEXT for the plan's end date; the procedure first checks if a department with the specified p_dept_id exists in the departments table by performing a SELECT EXISTS query on the departments table where the dept_id column equals p_dept_id and stores the result in a local variable v_dept_exists; if v_dept_exists is true, the procedure then calculates a new plan identifier v_new_plan_id by selecting the maximum value from the plan_id column of the strategic_plans table, using COALESCE to handle null values by substituting 0, and then adding 1 to this maximum value, and similarly calculates a new allocation identifier v_new_alloc_id by selecting the maximum value from the alloc_id column of the resource_allocations table, using COALESCE to handle null values by substituting 0, and then adding 1 to this maximum value; subsequently, the procedure inserts a new record into the strategic_plans table with the calculated v_new_plan_id as plan_id, the input p_dept_id as dept_id, the TRIM function applied to p_plan_name as plan_name to remove leading and trailing spaces, the TRIM function applied to p_plan_desc as description to remove leading and trailing spaces, the input p_start_date as start_date, the input p_end_date as end_date, and a hardcoded string 'pending' as status; following this, the procedure inserts a new record into the resource_allocations table with the calculated v_new_alloc_id as alloc_id, the input p_dept_id as dept_id, a hardcoded string 'personnel' as resource_type, a hardcoded numeric value 5 as amount, the input p_start_date as allocation_date, and a hardcoded string 'annually' as budget_cycle.",
    "plsql": "CREATE OR REPLACE PROCEDURE create_strategic_plan_with_allocation(p_dept_id BIGINT, p_plan_name TEXT, p_plan_desc TEXT, p_start_date TEXT, p_end_date TEXT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_new_plan_id BIGINT;\n    v_new_alloc_id BIGINT;\n    v_dept_exists BOOLEAN;\nBEGIN\n    SELECT EXISTS(SELECT 1 FROM departments WHERE dept_id = p_dept_id) INTO v_dept_exists;\n    \n    IF v_dept_exists THEN\n        SELECT COALESCE(MAX(plan_id), 0) + 1 INTO v_new_plan_id FROM strategic_plans;\n        SELECT COALESCE(MAX(alloc_id), 0) + 1 INTO v_new_alloc_id FROM resource_allocations;\n        \n        INSERT INTO strategic_plans (plan_id, dept_id, plan_name, description, start_date, end_date, status)\n        VALUES (v_new_plan_id, p_dept_id, TRIM(p_plan_name), TRIM(p_plan_desc), p_start_date, p_end_date, 'pending');\n        \n        INSERT INTO resource_allocations (alloc_id, dept_id, resource_type, amount, allocation_date, budget_cycle)\n        VALUES (v_new_alloc_id, p_dept_id, 'personnel', 5, p_start_date, 'annually');\n    END IF;\nEND;\n$$;",
    "database_name": "business_performance_and_resource_allocation_analysis",
    "tables": [
      "departments",
      "department_heads",
      "performance_metrics",
      "resource_allocations",
      "strategic_plans"
    ],
    "id": 79
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_insert_notification that is defined to fire automatically after a new row is inserted into the test_results table, executing once for each inserted row, and performs a single INSERT operation into the notifications table, constructing the values for the notification_id column by querying the notifications table to find the current maximum value of the notification_id column, using the NVL function to return 0 if the column contains only nulls, and then adding 1 to that value, using the :NEW.test_result_id pseudorecord value for the test_result_id column, determining the user_id column value by querying the test_classes table to select the created_by column from the row where the test_class_id column matches the :NEW.test_class_id value from the newly inserted test_results row, generating the message column value by concatenating the literal string 'Test class ' with the result of a subquery that selects the class_name column from the test_classes table for the row where test_class_id equals :NEW.test_class_id, then concatenating the literal string ' completed with success rate ', and finally concatenating the :NEW.success_rate value from the inserted row, setting the read_status column to the literal string 'unread', and populating the created_date column by applying the TO_CHAR function to the CURRENT_TIMESTAMP value to format it as a string in the 'YYYY-MM-DD HH24:MI:SS' pattern.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_insert_notification\nAFTER INSERT ON test_results\nFOR EACH ROW\nBEGIN\n  INSERT INTO notifications (notification_id, test_result_id, user_id, message, read_status, created_date)\n  VALUES (\n    (SELECT NVL(MAX(notification_id), 0) + 1 FROM notifications),\n    :NEW.test_result_id,\n    (SELECT created_by FROM test_classes WHERE test_class_id = :NEW.test_class_id),\n    'Test class ' || (SELECT class_name FROM test_classes WHERE test_class_id = :NEW.test_class_id) || ' completed with success rate ' || :NEW.success_rate,\n    'unread',\n    TO_CHAR(CURRENT_TIMESTAMP, 'YYYY-MM-DD HH24:MI:SS')\n  );\nEND;",
    "database_name": "test_marfs_development",
    "tables": [
      "notifications",
      "test_classes",
      "test_environments",
      "test_results",
      "users"
    ],
    "_source": "plfactory23",
    "id": 80
  },
  {
    "ir": "Write an Oracle PL/SQL function named evaluate_game_popularity that accepts a single input parameter p_game_id of type NUMBER, which represents the unique identifier for a game, and returns a VARCHAR2 string. The function begins by declaring a local variable v_match_count of type NUMBER. It then executes a SELECT statement to query the matches table, counting all rows where the game_id column equals the provided input parameter p_game_id, and stores this count result into the variable v_match_count. Following this data retrieval, the function uses a conditional IF-ELSIF-ELSE block to evaluate the value of v_match_count: if the count is less than 10, the function returns the string 'LOW'; if the count is less than 50 (but implicitly 10 or more due to the previous condition), the function returns the string 'MODERATE'; for all other cases where the count is 50 or greater, the function returns the string 'HIGH'.",
    "plsql": "CREATE OR REPLACE FUNCTION evaluate_game_popularity(p_game_id NUMBER) RETURN VARCHAR2 IS\n    v_match_count NUMBER;\nBEGIN\n    SELECT COUNT(*) INTO v_match_count FROM matches WHERE game_id = p_game_id;\n\n    IF v_match_count < 10 THEN\n        RETURN 'LOW';\n    ELSIF v_match_count < 50 THEN\n        RETURN 'MODERATE';\n    ELSE\n        RETURN 'HIGH';\n    END IF;\nEND;",
    "database_name": "competitive_gpa_620005",
    "tables": [
      "coaches",
      "games",
      "matches",
      "players",
      "statistics",
      "teams",
      "tournaments"
    ],
    "id": 81
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `get_active_policy_info` that is designed to retrieve specific policy information from a database table. This procedure defines two output parameters: `p_policy_version`, which is of type `VARCHAR2` and will store the version of the policy, and `p_copyright_owner`, also of type `VARCHAR2`, which will store the name of the copyright owner. The core operation of this procedure is a `SELECT` statement. This `SELECT` statement queries the `publication_policies` table. It specifically selects the values from the `policy_version` column and the `copyright_owner` column. These selected values are then immediately assigned to the respective output parameters: the value from `policy_version` is assigned to `p_policy_version`, and the value from `copyright_owner` is assigned to `p_copyright_owner`. The selection of rows from the `publication_policies` table is subject to three conditions combined with a logical `AND` operator. The first condition is `is_active = 1`, which filters for policies where the `is_active` column has a value of `1`. The second condition is `allowed = 'Yes'`, which further filters for policies where the `allowed` column has the exact string value 'Yes'. The third condition is `ROWNUM = 1`, which restricts the result set to only the first row that satisfies the preceding `is_active` and `allowed` conditions. This ensures that only one active and allowed policy record is retrieved, even if multiple such records exist in the table.",
    "plsql": "CREATE OR REPLACE PROCEDURE get_active_policy_info(\n    p_policy_version OUT VARCHAR2,\n    p_copyright_owner OUT VARCHAR2\n)\nIS\nBEGIN\n    SELECT policy_version, copyright_owner\n    INTO p_policy_version, p_copyright_owner\n    FROM publication_policies\n    WHERE is_active = 1 AND allowed = 'Yes'\n    AND ROWNUM = 1;\nEND;",
    "database_name": "academic_pac_management",
    "tables": [
      "article_versions",
      "articles",
      "publication_policies"
    ],
    "id": 82
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named validate_and_update_variant_dates that declares a record variable v_variant_record to hold rows from a query and a text variable v_current_date to store a formatted date string, then initializes v_current_date by calling the to_char function with the CURRENT_DATE value and the format mask 'YYYY-MM-DD' to produce a string representing the current date in year-month-day format, then executes a FOR loop that iterates over a result set from a SELECT query on the experiment_variants table which retrieves the variant_id, creation_date, and last_modified_date columns for every row where the creation_date is greater than the last_modified_date or where the last_modified_date is greater than the v_current_date string, and for each record fetched by this loop, it performs an UPDATE operation on the experiment_variants table, setting the last_modified_date column to the value of v_current_date and updating the notes column by using the COALESCE function to handle potential NULL values by substituting an empty string and then concatenating the existing notes value (or empty string) with the literal string ' Date corrected on ' followed by the v_current_date string, and this update is applied specifically to the row where the variant_id matches the v_variant_record.variant_id value from the current loop iteration.",
    "plsql": "CREATE OR REPLACE PROCEDURE validate_and_update_variant_dates()\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_variant_record RECORD;\n    v_current_date text;\nBEGIN\n    v_current_date := to_char(CURRENT_DATE, 'YYYY-MM-DD');\n    \n    FOR v_variant_record IN \n        SELECT variant_id, creation_date, last_modified_date \n        FROM experiment_variants \n        WHERE creation_date > last_modified_date OR last_modified_date > v_current_date\n    LOOP\n        UPDATE experiment_variants \n        SET last_modified_date = v_current_date,\n            notes = COALESCE(notes, '') || ' Date corrected on ' || v_current_date\n        WHERE variant_id = v_variant_record.variant_id;\n    END LOOP;\nEND;\n$$;",
    "database_name": "climate_modeling_and_simulation",
    "tables": [
      "simulation_runs",
      "climate_models",
      "experiment_variants",
      "grid_resolutions",
      "research_centers",
      "users"
    ],
    "id": 83
  },
  {
    "ir": "Write a PLpgSQL function that takes a single parameter tenant_id_input of type text and returns a bigint representing the count of resources associated with the specified tenant. The function begins by declaring a local variable resource_count of type bigint to store the result of the count operation. It then executes a SELECT statement to count all rows in the api_resources table where the tenant_id column matches the value provided in the tenant_id_input parameter. The COUNT(*) function is used to determine the total number of rows that meet this condition, and the result is stored in the resource_count variable. Finally, the function returns the value of resource_count, which represents the total number of resources linked to the given tenant_id.",
    "plsql": "CREATE OR REPLACE FUNCTION get_tenant_resource_count(tenant_id_input text) RETURNS bigint AS $$\nDECLARE\n    resource_count bigint;\nBEGIN\n    SELECT COUNT(*) INTO resource_count\n    FROM api_resources\n    WHERE tenant_id = tenant_id_input;\n    RETURN resource_count;\nEND;\n$$ LANGUAGE plpgsql;",
    "database_name": "api_resource_management",
    "tables": [
      "api_resources",
      "tenants",
      "tenant_permissions",
      "access_controls"
    ],
    "id": 84
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `delete_old_hire_records` that accepts three input parameters: `p_year` of type `bigint`, representing a specific year; `p_month` of type `bigint`, representing a specific month; and `p_zone_id` of type `bigint`, representing a specific zone identifier. The procedure first performs a `DELETE` operation on the `weather_data` table. The rows to be deleted from `weather_data` are determined by a subquery. This subquery selects the `hire_id` column from the `hire_data` table, aliased as `hd`, where the `year` column of `hd` matches the value provided in the `p_year` parameter, the `month` column of `hd` matches the value provided in the `p_month` parameter, and the `zone_id` column of `hd` matches the value provided in the `p_zone_id` parameter. The `DELETE` statement then removes all rows from `weather_data` where the `hire_id` column is present in the set of `hire_id` values returned by this subquery. Following this, the procedure executes a second `DELETE` operation, this time targeting the `hire_data` table. This `DELETE` statement removes all rows from the `hire_data` table where the `year` column matches the value of the `p_year` parameter, the `month` column matches the value of the `p_month` parameter, and the `zone_id` column matches the value of the `p_zone_id` parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_old_hire_records(p_year bigint, p_month bigint, p_zone_id bigint)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM weather_data\n    WHERE hire_id IN (\n        SELECT hd.hire_id\n        FROM hire_data hd\n        WHERE hd.year = p_year AND hd.month = p_month AND hd.zone_id = p_zone_id\n    );\n    \n    DELETE FROM hire_data\n    WHERE year = p_year AND month = p_month AND zone_id = p_zone_id;\nEND;\n$$;",
    "database_name": "bike_sharing_demand_prediction",
    "tables": [
      "hire_data",
      "zones",
      "weather_data",
      "weather_conditions",
      "special_events"
    ],
    "id": 85
  },
  {
    "ir": "Write a PLpgSQL stored procedure named process_bank_data_by_state that iterates over each distinct state abbreviation (stalp) in the bank_local_details table where stalp is not null, using a cursor named state_cursor. For each state abbreviation, it counts the number of banks in the bank_local_details table with that state abbreviation and stores the count in the bank_count variable. If the bank_count is less than 10, it deletes records from the bank_classifications table where the cert column matches any cert from the bank_local_details table with the same state abbreviation. If the bank_count is between 10 and 49 inclusive, it inserts new records into the bank_federal_reserve_details table with reserve_id generated by the nextval function on the pg_temp_seq sequence, cert from the bank_local_details table, and reserve_status set to 'SMALL_STATE' for banks with the same state abbreviation. If the bank_count is between 50 and 99 inclusive, it deletes records from the bank_ownerships table where cert matches any cert from the bank_local_details table with the same state abbreviation and local_branch_count is less than 5. If the bank_count is between 100 and 199 inclusive, it inserts new records into the bank_holding_companies table with holding_id generated by adding 10000 to the row number, cert from the bank_local_details table, namehcr set to 'MEDIUM_STATE_' concatenated with the state abbreviation, and holding_company_status set to 'ACTIVE' for banks with the same state abbreviation. If the bank_count is 200 or more, it deletes records from the bank_FDIC_details table where cert matches any cert from the bank_local_details table with the same state abbreviation and local_employee_count is less than 100.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_bank_data_by_state()\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    state_cursor CURSOR FOR SELECT DISTINCT stalp FROM bank_local_details WHERE stalp IS NOT NULL;\n    state_rec RECORD;\n    bank_count INTEGER;\nBEGIN\n    FOR state_rec IN state_cursor LOOP\n        SELECT COUNT(*) INTO bank_count FROM bank_local_details WHERE stalp = state_rec.stalp;\n        \n        IF bank_count < 10 THEN\n            DELETE FROM bank_classifications WHERE cert IN (SELECT cert FROM bank_local_details WHERE stalp = state_rec.stalp);\n        ELSIF bank_count < 50 THEN\n            INSERT INTO bank_federal_reserve_details (reserve_id, cert, reserve_status) \n            SELECT nextval('pg_temp_seq'), cert, 'SMALL_STATE' FROM bank_local_details WHERE stalp = state_rec.stalp;\n        ELSIF bank_count < 100 THEN\n            DELETE FROM bank_ownerships WHERE cert IN (SELECT cert FROM bank_local_details WHERE stalp = state_rec.stalp AND local_branch_count < 5);\n        ELSIF bank_count < 200 THEN\n            INSERT INTO bank_holding_companies (holding_id, cert, namehcr, holding_company_status) \n            SELECT ROW_NUMBER() OVER() + 10000, cert, 'MEDIUM_STATE_' || stalp, 'ACTIVE' FROM bank_local_details WHERE stalp = state_rec.stalp;\n        ELSE\n            DELETE FROM bank_FDIC_details WHERE cert IN (SELECT cert FROM bank_local_details WHERE stalp = state_rec.stalp AND local_employee_count < 100);\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "banking_institution_data_and_regulatory_information",
    "tables": [
      "bank_FDIC_details",
      "bank_federal_reserve_details",
      "bank_holding_companies",
      "bank_ownerships",
      "bank_classifications",
      "bank_local_details"
    ],
    "id": 86
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_env_date_update that fires automatically before any row is updated on the ENVIRONMENTS table, and for each row being updated, it declares a local variable v_avg_role_id of type NUMBER, initializes this variable to the constant value 100, and then modifies the new value for the ENVIRONMENT_NAME column by concatenating the original old value of the ENVIRONMENT_NAME column from before the update, the literal string '_UPD_', and the result of converting the v_avg_role_id variable's numeric value to a character string using the TO_CHAR function with the format model 'FM999.99' which suppresses leading blanks and formats the number with two decimal places, thereby setting the updated row's ENVIRONMENT_NAME to a composite string consisting of its previous name, a fixed update marker, and a formatted version of the constant 100.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_env_date_update\nBEFORE UPDATE ON ENVIRONMENTS\nFOR EACH ROW\nDECLARE\n    v_avg_role_id NUMBER;\nBEGIN\n    v_avg_role_id := 100;\n    :NEW.ENVIRONMENT_NAME := :OLD.ENVIRONMENT_NAME || '_UPD_' || TO_CHAR(v_avg_role_id, 'FM999.99');\nEND;",
    "database_name": "performance_mopsab_files",
    "tables": [
      "USERS",
      "USER_ROLES",
      "USER_ROLE_MAPPINGS",
      "ENVIRONMENTS"
    ],
    "_source": "plfactory16",
    "id": 87
  },
  {
    "ir": "Write a PLpgSQL function named insert_new_access_log that accepts three parameters: p_data_id of type bigint, p_user_id of type bigint, and p_access_type of type text. This function inserts a new record into the access_logs table, which contains columns access_id, data_id, user_id, access_date, access_type, created_at, and updated_at. The access_id is determined by selecting the maximum existing access_id from the access_logs table, defaulting to 0 if no records exist, and incrementing it by 1. The data_id and user_id columns are populated with the values of p_data_id and p_user_id, respectively. The access_date column is set to the current date and time extracted from the timeofday() function, specifically the first part of the string returned by timeofday(), which represents the date. The access_type column is assigned the value of p_access_type. Both the created_at and updated_at columns are set to the full string returned by the timeofday() function, representing the current timestamp. After inserting the new record, the function retrieves the newly generated access_id using the RETURNING clause and stores it in the variable new_access_id. Finally, the function returns the value of new_access_id, which is the access_id of the newly inserted record.",
    "plsql": "CREATE OR REPLACE FUNCTION insert_new_access_log(p_data_id bigint, p_user_id bigint, p_access_type text)\nRETURNS bigint AS $$\nDECLARE\n    new_access_id bigint;\nBEGIN\n    INSERT INTO access_logs (access_id, data_id, user_id, access_date, access_type, created_at, updated_at)\n    VALUES ((SELECT COALESCE(MAX(access_id), 0) + 1 FROM access_logs), p_data_id, p_user_id, \n            SPLIT_PART(timeofday(), ' ', 1), p_access_type, timeofday(), timeofday())\n    RETURNING access_id INTO new_access_id;\n    RETURN new_access_id;\nEND;\n$$ LANGUAGE plpgsql;",
    "database_name": "meteorological_data_tracking_and_analysis_857750",
    "tables": [
      "access_logs",
      "climate_zones",
      "data_files",
      "metadata",
      "regions",
      "users",
      "weather_data",
      "weather_stations"
    ],
    "id": 88
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named 'sp' that accepts two text parameters: 'para_old_currency' to identify the currency value to be replaced, and 'para_new_currency' to specify the new currency value. The procedure first performs an INSERT operation into the 'countries' table, selecting all rows from the same 'countries' table where the 'currency' column matches the 'para_old_currency' parameter. For each selected row, it creates a new row with the following transformations: the 'country_id' is increased by 10000, the 'country_name' has the string '_ARCHIVED' appended to it, and the 'currency' column is set to the 'para_new_currency' parameter value. All other columns ('region', 'population', 'area_km2', 'capital', 'government_form', 'gdp_usd', 'gini_index', 'life_expectancy', 'literacy_rate', 'urban_population', 'currency_code', 'un_membership') are copied directly from the source row, except for the 'last_updated' column which is populated with the current timestamp converted to text using the CURRENT_TIMESTAMP function and an explicit cast. Following this archival insert, the procedure executes an UPDATE operation on the original 'countries' table, setting the 'currency' column to the 'para_new_currency' parameter and the 'last_updated' column to the current timestamp as text, but only for rows that satisfy two conditions: the 'currency' column must still equal the 'para_old_currency' parameter, and the 'un_membership' column value must be less than 1960.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp(para_old_currency text, para_new_currency text) LANGUAGE plpgsql AS $$\nBEGIN\n    INSERT INTO countries (country_id, country_name, region, population, area_km2, capital, currency, government_form, gdp_usd, gini_index, life_expectancy, literacy_rate, urban_population, last_updated, currency_code, un_membership)\n    SELECT country_id + 10000, country_name || '_ARCHIVED', region, population, area_km2, capital, para_new_currency, government_form, gdp_usd, gini_index, life_expectancy, literacy_rate, urban_population, CURRENT_TIMESTAMP::text, currency_code, un_membership\n    FROM countries WHERE currency = para_old_currency;\n    \n    UPDATE countries \n    SET currency = para_new_currency, last_updated = CURRENT_TIMESTAMP::text\n    WHERE currency = para_old_currency AND un_membership < 1960;\nEND;\n$$;",
    "database_name": "human_development_index__hdi__by_country",
    "tables": [
      "countries"
    ],
    "id": 89
  },
  {
    "ir": "Write a PostgreSQL stored procedure named process_county_aid_distribution that accepts one input parameter called target_county_id of type bigint, which identifies a specific county, and performs the following operations: first, it retrieves the population value from the population column of the counties table for the row where the county_id column matches the provided target_county_id, storing this value into a local variable named county_population; second, it counts the number of rows in the businesses table where the county_id column equals the target_county_id, storing the result into a local variable named business_count; third, using a common table expression named county_aid_total, it calculates the sum of the amount column from the business_aid table for all business_aid records that are linked to businesses located in the target county by joining the business_aid table with the businesses table on business_id and filtering for rows where the businesses.county_id equals the target_county_id, then it computes the per capita aid by dividing this total sum of aid by the county_population (using NULLIF to avoid division by zero if county_population is zero), storing the result into a local variable named aid_per_capita; finally, it inserts new records into the sales table, specifically into the columns sale_id, business_id, sale_date, and sale_amount, by selecting from the businesses table all businesses located in the target county (where businesses.county_id equals target_county_id), and for each such business, it generates a sale_id calculated as the business_id plus 1000000, uses the business_id directly, sets the sale_date to the fixed date '2024-01-01', and calculates the sale_amount as the aid_per_capita multiplied by 100.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_county_aid_distribution(target_county_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    county_population bigint;\n    aid_per_capita real;\n    business_count integer;\nBEGIN\n    SELECT population INTO county_population\n    FROM counties\n    WHERE county_id = target_county_id;\n    \n    SELECT COUNT(*) INTO business_count\n    FROM businesses\n    WHERE county_id = target_county_id;\n    \n    WITH county_aid_total AS (\n        SELECT SUM(ba.amount) as total_aid\n        FROM business_aid ba\n        JOIN businesses b ON ba.business_id = b.business_id\n        WHERE b.county_id = target_county_id\n    )\n    SELECT total_aid / NULLIF(county_population, 0) INTO aid_per_capita\n    FROM county_aid_total;\n    \n    INSERT INTO sales (sale_id, business_id, sale_date, sale_amount)\n    SELECT \n        b.business_id + 1000000,\n        b.business_id,\n        '2024-01-01',\n        aid_per_capita * 100\n    FROM businesses b\n    WHERE b.county_id = target_county_id;\nEND;\n$$;",
    "database_name": "business_and_sales_data_management",
    "tables": [
      "businesses",
      "business_aid",
      "aid_types",
      "sales",
      "counties"
    ],
    "id": 90
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_popularity_on_vote_change that returns a trigger and is executed by a trigger named trg_update_popularity, which is defined to fire before any update operation on the movies table specifically when the vote_average column or the vote_count column is modified, and for each row being updated, the function's logic calculates a new value for the NEW.popularity column by multiplying the NEW.vote_average value with the NEW.vote_count value, and then returns the modified NEW row record to the triggering update statement.",
    "plsql": "CREATE OR REPLACE FUNCTION update_popularity_on_vote_change() RETURNS TRIGGER AS $$\nBEGIN\n    NEW.popularity := NEW.vote_average * NEW.vote_count;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_update_popularity\nBEFORE UPDATE OF vote_average, vote_count ON movies\nFOR EACH ROW EXECUTE FUNCTION update_popularity_on_vote_change();",
    "database_name": "movie_production_and_distribution_management_348317",
    "tables": [
      "movies",
      "cast_members",
      "directors",
      "genres",
      "production_companies",
      "box_office_data",
      "movie_versions"
    ],
    "_source": "plfactory2",
    "id": 91
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named generate_conference_summary that accepts four input parameters: p_conference_id of type NUMBER which specifies the conference identifier to filter on, p_min_sessions of type NUMBER which sets the minimum number of sessions a conference must have to be included in the results, p_role_filter of type VARCHAR2 which filters sessions by their role, and p_email_domain of type VARCHAR2 which filters attendees based on their email domain. The procedure declares a cursor variable v_summary_data of type SYS_REFCURSOR and opens it for a query that retrieves conference summary information by selecting the title, start_date, and end_date columns from the conferences table, counting the total number of sessions using COUNT(s.session_id) aliased as total_sessions, and counting the distinct number of attendees using COUNT(DISTINCT a.attendee_id) aliased as total_attendees. The query joins the conferences table with the sessions table on the conference_id column, joins with the attendees table on the conference_id column, and joins with the users table on the user_id column. The WHERE clause filters results to include only the specified conference using c.conference_id = p_conference_id, filters sessions by the provided role using s.role = p_role_filter, and filters attendees by checking if their email matches the provided email domain using REGEXP_COUNT(u.email, '@' || p_email_domain || '$') > 0, which counts occurrences of the email domain pattern at the end of the email string. The results are grouped by c.title, c.start_date, and c.end_date, and the HAVING clause ensures that only conferences with a session count greater than or equal to p_min_sessions are included in the result set.",
    "plsql": "CREATE OR REPLACE PROCEDURE generate_conference_summary(\n    p_conference_id IN NUMBER,\n    p_min_sessions IN NUMBER,\n    p_role_filter IN VARCHAR2,\n    p_email_domain IN VARCHAR2\n)\nIS\n    v_summary_data SYS_REFCURSOR;\nBEGIN\n    OPEN v_summary_data FOR\n        SELECT c.title,\n               c.start_date,\n               c.end_date,\n               COUNT(s.session_id) AS total_sessions,\n               COUNT(DISTINCT a.attendee_id) AS total_attendees\n        FROM conferences c\n        JOIN sessions s ON c.conference_id = s.conference_id\n        JOIN attendees a ON c.conference_id = a.conference_id\n        JOIN users u ON a.user_id = u.user_id\n        WHERE c.conference_id = p_conference_id\n        AND s.role = p_role_filter\n        AND REGEXP_COUNT(u.email, '@' || p_email_domain || '$') > 0\n        GROUP BY c.title, c.start_date, c.end_date\n        HAVING COUNT(s.session_id) >= p_min_sessions;\nEND;",
    "database_name": "archaeological_rac_manage",
    "tables": [
      "attendees",
      "conferences",
      "sessions",
      "session_registrations",
      "users"
    ],
    "id": 92
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named reconcile_trade_partners that accepts two input parameters: p_country_name of type VARCHAR2, representing the name of a country, and p_trade_agreement of type VARCHAR2, representing a trade agreement. The procedure begins by declaring three local variables: v_country_id of type NUMBER to store the country ID, v_partner_count of type NUMBER to store the count of distinct trade partners, and v_total_value of type NUMBER to store the total trade value. The procedure first retrieves the country_id from the countries table where the country_name matches the input parameter p_country_name and stores it in v_country_id. It then calculates the number of distinct trade partners and the sum of trade values from the trade_values table where the country_id matches v_country_id and the trade_agreement matches p_trade_agreement, storing these results in v_partner_count and v_total_value, respectively. The procedure then evaluates a series of conditional statements: if v_partner_count is greater than 5 and v_total_value exceeds 1,000,000, it deletes rows from the trade_values table where the country_id matches v_country_id and the value is less than the average value for that country_id; if v_partner_count is between 2 and 5 inclusive, it inserts two new rows into the trade_values table by selecting existing rows where the country_id matches v_country_id, incrementing the trade_value_id by ROWNUM, increasing the value by 10% and the volume by 5%, setting the year to the current year, and changing the trade_agreement to 'RECONCILED'; if neither condition is met, it inserts a single new row into the trade_values table with a trade_value_id one greater than the current maximum, the minimum commodity_id from the commodities table, the current year, a value of 1000, a volume of 100, a trade_direction of 'new', and the original p_trade_agreement.",
    "plsql": "CREATE OR REPLACE PROCEDURE reconcile_trade_partners(p_country_name IN VARCHAR2, p_trade_agreement IN VARCHAR2)\nIS\n    v_country_id NUMBER;\n    v_partner_count NUMBER;\n    v_total_value NUMBER;\nBEGIN\n    SELECT country_id INTO v_country_id FROM countries WHERE country_name = p_country_name;\n    SELECT COUNT(DISTINCT trade_partners), SUM(value)\n    INTO v_partner_count, v_total_value\n    FROM trade_values\n    WHERE country_id = v_country_id AND trade_agreement = p_trade_agreement;\n    IF v_partner_count > 5 AND v_total_value > 1000000 THEN\n        DELETE FROM trade_values WHERE country_id = v_country_id AND value < (SELECT AVG(value) FROM trade_values WHERE country_id = v_country_id);\n    ELSIF v_partner_count BETWEEN 2 AND 5 THEN\n        INSERT INTO trade_values (trade_value_id, country_id, commodity_id, year, value, volume, trade_direction, trade_agreement)\n        SELECT MAX(trade_value_id) + ROWNUM, v_country_id, commodity_id, EXTRACT(YEAR FROM SYSDATE), FLOOR(value * 1.1), FLOOR(volume * 1.05), trade_direction, 'RECONCILED'\n        FROM trade_values WHERE country_id = v_country_id AND ROWNUM <= 2;\n    ELSE\n        INSERT INTO trade_values (trade_value_id, country_id, commodity_id, year, value, volume, trade_direction, trade_agreement)\n        VALUES ((SELECT MAX(trade_value_id) + 1 FROM trade_values), v_country_id, (SELECT MIN(commodity_id) FROM commodities), EXTRACT(YEAR FROM SYSDATE), 1000, 100, 'new', p_trade_agreement);\n    END IF;\nEND;",
    "database_name": "international_taac_analys",
    "tables": [
      "trade_values",
      "commodities",
      "countries"
    ],
    "id": 93
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_population_validation that executes automatically before any row is updated on the arrest_statistics table, and for each row being updated, it declares two local NUMBER variables v_city_population and v_ethnic_population, then checks if the new values for the city_population column and the population_of_ethnic_group column are both not null, and if this condition is true, it performs a series of data validation and correction operations: first, it ensures the population_of_ethnic_group does not exceed the city_population by comparing the new value of population_of_ethnic_group to the new value of city_population, and if the ethnic group population is greater, it sets the new population_of_ethnic_group value to be equal to the new city_population value; second, it ensures the total_arrests column value does not exceed the corrected population_of_ethnic_group value by comparing the new total_arrests value to the new population_of_ethnic_group value, and if total_arrests is greater, it sets the new total_arrests value to be equal to the new population_of_ethnic_group value; third, it ensures the drug_arrests column value does not exceed the corrected total_arrests value by comparing the new drug_arrests value to the new total_arrests value, and if drug_arrests is greater, it sets the new drug_arrests value to be equal to the new total_arrests value.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_population_validation\nBEFORE UPDATE ON arrest_statistics\nFOR EACH ROW\nDECLARE\n    v_city_population NUMBER;\n    v_ethnic_population NUMBER;\nBEGIN\n    IF :NEW.city_population IS NOT NULL AND :NEW.population_of_ethnic_group IS NOT NULL THEN\n        IF :NEW.population_of_ethnic_group > :NEW.city_population THEN\n            :NEW.population_of_ethnic_group := :NEW.city_population;\n        END IF;\n        IF :NEW.total_arrests > :NEW.population_of_ethnic_group THEN\n            :NEW.total_arrests := :NEW.population_of_ethnic_group;\n        END IF;\n        IF :NEW.drug_arrests > :NEW.total_arrests THEN\n            :NEW.drug_arrests := :NEW.total_arrests;\n        END IF;\n    END IF;\nEND;",
    "database_name": "drug_adaa_reporting",
    "tables": [
      "agencies",
      "arrest_statistics",
      "ethnic_groups",
      "disparity_scores"
    ],
    "_source": "plfactory5",
    "id": 94
  },
  {
    "ir": "Write a PostgreSQL trigger function named trigger_audit_test_class_changes that is executed automatically after each row update on the test_classes table, which performs an insert operation into the notifications table, specifically selecting a new notification_id value by calculating the sum of the current maximum notification_id from the notifications table (or zero if the maximum is null) and the sequential row number generated by the ROW_NUMBER() window function over the entire result set, setting the test_result_id column to NULL, populating the user_id column with the NEW.last_modified_by value from the updated test_classes row, constructing the message column by concatenating the string 'Test class ', the NEW.class_name value, the string ' modified in module ', and the NEW.module value, setting the read_status column to the literal string 'unread', and setting the created_date column to the current timestamp formatted as a string in 'YYYY-MM-DD HH24:MI:SS' format, and finally returns the NEW row record to the calling trigger.",
    "plsql": "CREATE OR REPLACE FUNCTION trigger_audit_test_class_changes() RETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO notifications (notification_id, test_result_id, user_id, message, read_status, created_date)\n  SELECT COALESCE(MAX(notification_id), 0) + ROW_NUMBER() OVER (), NULL, NEW.last_modified_by, \n         'Test class ' || NEW.class_name || ' modified in module ' || NEW.module, 'unread', TO_CHAR(NOW(), 'YYYY-MM-DD HH24:MI:SS')\n  FROM notifications;\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER audit_test_class_changes\nAFTER UPDATE ON test_classes\nFOR EACH ROW\nEXECUTE FUNCTION trigger_audit_test_class_changes();",
    "database_name": "test_management_and_reporting_for_software_development",
    "tables": [
      "notifications",
      "test_classes",
      "test_environments",
      "test_results",
      "users"
    ],
    "_source": "plfactory6",
    "id": 95
  },
  {
    "ir": "Write a PostgreSQL trigger function named insert_snack_action that is executed by a trigger named trg_insert_snack_action, where the trigger is defined to fire BEFORE INSERT on the character_actions table FOR EACH ROW when the condition (NEW.snacked = 1) is true, and the function's logic is to insert a new row into the character_actions table with specific values: the action_id is generated by taking the current Unix epoch timestamp from CURRENT_TIMESTAMP via the EXTRACT(EPOCH FROM CURRENT_TIMESTAMP) function, casting it to a bigint, and adding a random integer between 0 and 999999 generated by the random() function multiplied by 1000000 and cast to bigint; the episode_id is taken from the NEW.episode_id value of the triggering row; the character_name is taken from the NEW.character_name value; the action_type is set to the literal string 'Snack'; the action_description is constructed by concatenating the NEW.character_name value with the literal string ' snacked during the episode.'; the action_time is set to the current time formatted as a string in 'HH24:MI:SS' format using the TO_CHAR(CURRENT_TIMESTAMP, 'HH24:MI:SS') function; and the snacked column is explicitly set to the integer 0, and this entire insert operation includes an ON CONFLICT clause on the action_id column specifying DO NOTHING, meaning if a row with the same generated action_id already exists, the insert is silently skipped, and finally the function returns the NEW row record.",
    "plsql": "CREATE OR REPLACE FUNCTION insert_snack_action() RETURNS TRIGGER AS $$\nBEGIN\n    INSERT INTO character_actions (action_id, episode_id, character_name, action_type, action_description, action_time, snacked) \n    VALUES (\n        (EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)::bigint + (random() * 1000000)::bigint),\n        NEW.episode_id,\n        NEW.character_name,\n        'Snack',\n        NEW.character_name || ' snacked during the episode.',\n        TO_CHAR(CURRENT_TIMESTAMP, 'HH24:MI:SS'),\n        0\n    )\n    ON CONFLICT (action_id) DO NOTHING;\n    \n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_insert_snack_action\n    BEFORE INSERT ON character_actions\n    FOR EACH ROW\n    WHEN (NEW.snacked = 1)\n    EXECUTE FUNCTION insert_snack_action();",
    "database_name": "television_series_metadata_and_character_interaction_analysis",
    "tables": [
      "episodes",
      "culprits",
      "suspects",
      "character_actions"
    ],
    "_source": "plfactory24",
    "id": 96
  },
  {
    "ir": "Write an Oracle PL/SQL function named check_awardee_contact that accepts a single parameter p_awardee_id of type NUMBER, which represents the unique identifier of an awardee. The function performs a SELECT operation to retrieve the contact_email column from the awardees table where the awardee_id matches the provided p_awardee_id parameter. The result of this query is stored in a local variable v_contact_info of type VARCHAR2 with a maximum length of 255 characters. The function then checks if the retrieved contact_email value is NULL using an IF conditional statement. If v_contact_info is found to be NULL, it assigns the string 'NO_CONTACT' to v_contact_info. Finally, the function returns the value of v_contact_info, which will either be the contact_email associated with the specified awardee_id or the string 'NO_CONTACT' if no contact information is available.",
    "plsql": "CREATE OR REPLACE FUNCTION check_awardee_contact(p_awardee_id NUMBER) RETURN VARCHAR2 IS\n    v_contact_info VARCHAR2(255);\nBEGIN\n    SELECT contact_email INTO v_contact_info FROM awardees WHERE awardee_id = p_awardee_id;\n    IF v_contact_info IS NULL THEN\n        v_contact_info := 'NO_CONTACT';\n    END IF;\n    RETURN v_contact_info;\nEND;",
    "database_name": "renewable_epma_analysis",
    "tables": [
      "access_logs",
      "users",
      "project_outcomes",
      "awardees"
    ],
    "id": 97
  },
  {
    "ir": "Write a PLpgSQL trigger function named insert_log_metrics that is executed automatically after every INSERT operation on the insurance_policies table for each new row, and first modifies the log_transformed_metrics table by altering its log_metric_id column to be a generated identity column that produces values by default, then adjusts the sequence for this identity column by setting its next value to one greater than the current maximum log_metric_id value found in the log_transformed_metrics table, using zero if no maximum exists, and finally within the trigger function body, performs an INSERT into the log_transformed_metrics table, populating the columns policy_id, log_income, log_age_in_days, log_underwriting_score, log_no_of_premiums_paid, log_perc_premium_paid_by_cash_credit, log_premium, log_coverage_limit, log_deductible, log_total_days_late, and log_late_fee_total with values derived from the newly inserted row in insurance_policies, specifically taking the NEW.policy_id directly and applying the natural logarithm function LN to the NEW.income, NEW.age_in_days, NEW.underwriting_score, NEW.no_of_premiums_paid, NEW.perc_premium_paid_by_cash_credit, NEW.premium, NEW.coverage_limit, and NEW.deductible values to compute the corresponding log-transformed columns, while explicitly setting the log_total_days_late and log_late_fee_total columns to zero for every inserted row.",
    "plsql": "ALTER TABLE log_transformed_metrics ALTER COLUMN log_metric_id ADD GENERATED BY DEFAULT AS IDENTITY;\n\nSELECT setval(pg_get_serial_sequence('log_transformed_metrics', 'log_metric_id'), (SELECT COALESCE(MAX(log_metric_id), 0) FROM log_transformed_metrics) + 1, false);\n\nCREATE OR REPLACE FUNCTION insert_log_metrics() RETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO log_transformed_metrics (policy_id, log_income, log_age_in_days, log_underwriting_score, log_no_of_premiums_paid, log_perc_premium_paid_by_cash_credit, log_premium, log_coverage_limit, log_deductible, log_total_days_late, log_late_fee_total) VALUES (NEW.policy_id, LN(NEW.income), LN(NEW.age_in_days), LN(NEW.underwriting_score), LN(NEW.no_of_premiums_paid), LN(NEW.perc_premium_paid_by_cash_credit), LN(NEW.premium), LN(NEW.coverage_limit), LN(NEW.deductible), 0, 0);\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trigger_insert_log_metrics\nAFTER INSERT ON insurance_policies\nFOR EACH ROW\nEXECUTE FUNCTION insert_log_metrics();",
    "database_name": "insurance_premium_and_claims_management",
    "tables": [
      "customers",
      "insurance_policies",
      "claims",
      "payment_history",
      "payment_delays",
      "log_transformed_metrics",
      "users"
    ],
    "_source": "plfactory16",
    "id": 98
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `sp_aggregate_waste_by_type_and_date` that accepts three input parameters: `para_start_date` of type `text`, representing the beginning of a date range; `para_end_date` of type `text`, representing the end of a date range; and `para_min_mass` of type `numeric`, representing a minimum total mass threshold. The procedure declares a local variable named `summary_cursor` of type `REFCURSOR`, which is used to hold the result set of a query. The core operation of the procedure is to open this `summary_cursor` and populate it with data retrieved from a `SELECT` statement. This `SELECT` statement retrieves the `waste_type_name` from the `waste_types` table, the `category_name` from the `categories` table, a count of `waste_entry_id` from the `waste_entries` table aliased as `entry_count`, and the sum of the `mass` column from the `waste_entries` table (after casting it to `numeric`) aliased as `total_mass`. The data is joined across three tables: `waste_entries` (aliased as `we`), `waste_types` (aliased as `wt`), and `categories` (aliased as `c`). The join condition between `waste_entries` and `waste_types` is `we.waste_type_id = wt.waste_type_id`. The join condition between `waste_entries` and `categories` is `we.category_id = c.category_id`. The `WHERE` clause filters the `waste_entries` records, including only those where the `generated_date` falls inclusively between the `para_start_date` and `para_end_date` parameters. The results are then grouped by `wt.waste_type_name` and `c.category_name`. A `HAVING` clause further filters these grouped results, retaining only those groups where the sum of the `mass` (after casting to `numeric`) is greater than or equal to the `para_min_mass` parameter. Finally, the aggregated results are ordered in descending order based on the `total_mass`.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp_aggregate_waste_by_type_and_date(para_start_date text, para_end_date text, para_min_mass numeric) LANGUAGE plpgsql AS $$ DECLARE summary_cursor REFCURSOR; BEGIN OPEN summary_cursor FOR SELECT wt.waste_type_name, c.category_name, COUNT(we.waste_entry_id) as entry_count, SUM(CAST(we.mass AS numeric)) as total_mass FROM waste_entries we JOIN waste_types wt ON we.waste_type_id = wt.waste_type_id JOIN categories c ON we.category_id = c.category_id WHERE we.generated_date BETWEEN para_start_date AND para_end_date GROUP BY wt.waste_type_name, c.category_name HAVING SUM(CAST(we.mass AS numeric)) >= para_min_mass ORDER BY total_mass DESC; END; $$;",
    "database_name": "waste_management_and_tracking",
    "tables": [
      "waste_entries",
      "waste_types",
      "categories"
    ],
    "id": 99
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure that calculates the median value of the transaction_amount column from the transactions table and stores this median value in a local variable named v_median_amount. The procedure then outputs the median transaction amount using the DBMS_OUTPUT.PUT_LINE function, which concatenates the string 'Median Transaction Amount: ' with the value of v_median_amount.",
    "plsql": "CREATE OR REPLACE PROCEDURE GetMedianTransactionAmount IS\n  v_median_amount NUMBER;\nBEGIN\n  SELECT MEDIAN(transaction_amount) INTO v_median_amount FROM transactions;\n  DBMS_OUTPUT.PUT_LINE('Median Transaction Amount: ' || v_median_amount);\nEND;",
    "database_name": "automotive_sal_management",
    "tables": [
      "listings",
      "inquiries",
      "transactions",
      "users",
      "vehicle_history",
      "vehicle_specs",
      "makes",
      "models"
    ],
    "id": 100
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `cleanup_old_versions` that accepts two input parameters: `p_item_id` of data type `NUMBER`, representing the identifier of a specific item whose versions are to be managed, and `p_keep_count` of data type `NUMBER`, indicating the number of most recent versions of the item that should be retained. The procedure begins by declaring a local variable `v_version_ids` of data type `SYS.OdciNumberList`, which is an Oracle-defined nested table type capable of holding a collection of numbers. The core logic involves selecting `version_id` values from the `ITEM_VERSIONS` table. This selection is performed in two stages: first, an inner query selects `version_id` from `ITEM_VERSIONS` where the `item_id` column matches the input parameter `p_item_id`. The results of this inner query are then ordered in descending order based on the `created_date` column, ensuring that the most recent versions appear first. From this ordered set of versions, an outer query then filters these results, selecting only those `version_id`s where the `ROWNUM` (a pseudocolumn representing the sequential number assigned to a row in the result set) is greater than the input parameter `p_keep_count`. This effectively identifies all versions beyond the `p_keep_count` most recent ones. The `version_id`s identified by this filtered selection are then collected into a `SYS.OdciNumberList` using the `COLLECT` aggregate function and explicitly cast to `SYS.OdciNumberList` before being stored into the `v_version_ids` local variable. After populating `v_version_ids`, the procedure then iterates through each element in this collection using a `FOR` loop, where the loop counter `i` ranges from 1 to the total count of elements in `v_version_ids`. Inside this loop, for each `version_id` retrieved from `v_version_ids` at index `i`, a `DELETE` operation is performed on the `ITEM_VERSIONS` table, removing the row where the `version_id` column matches the current `version_id` from the collection. This process continues until all `version_id`s stored in `v_version_ids` have been processed, effectively deleting all older versions of the specified item beyond the `p_keep_count` most recent ones.",
    "plsql": "CREATE OR REPLACE PROCEDURE cleanup_old_versions(p_item_id NUMBER, p_keep_count NUMBER) IS\n  v_version_ids SYS.OdciNumberList;\nBEGIN\n  SELECT CAST(COLLECT(version_id) AS SYS.OdciNumberList) \n  INTO v_version_ids \n  FROM (\n    SELECT version_id \n    FROM ITEM_VERSIONS \n    WHERE item_id = p_item_id \n    ORDER BY created_date DESC\n  ) \n  WHERE ROWNUM > p_keep_count;\n  \n  FOR i IN 1..v_version_ids.COUNT LOOP\n    DELETE FROM ITEM_VERSIONS WHERE version_id = v_version_ids(i);\n  END LOOP;\nEND;",
    "database_name": "software_darm_663051",
    "tables": [
      "ITEMS",
      "ITEM_VERSIONS",
      "ITEM_PROJECT_MAPPING",
      "USER_PROJECT_MAPPING"
    ],
    "id": 101
  },
  {
    "ir": "Write a PLpgSQL function that updates the communities table by setting the community_type column to a specified new_type value for the row where the community_id column matches the provided comm_id parameter.",
    "plsql": "CREATE OR REPLACE FUNCTION update_community_type(comm_id bigint, new_type text) RETURNS void AS $$\nBEGIN\n    UPDATE communities SET community_type = new_type WHERE community_id = comm_id;\nEND;\n$$ LANGUAGE plpgsql;",
    "database_name": "biological_network_analysis",
    "tables": [
      "feature_communities",
      "communities"
    ],
    "id": 102
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named process_resource_tags that accepts four input parameters: p_resource_id of type BIGINT representing the unique identifier of a resource, p_tag_name of type TEXT representing the name of a tag to be processed, p_operation of type TEXT specifying the action to perform which must be one of the string values 'INSERT', 'DELETE', or 'COUNT', and p_created_at of type TEXT providing a timestamp value for record creation. The procedure first declares two local variables: v_tag_id of type BIGINT to hold a new tag identifier and v_resource_exists of type BOOLEAN to store the existence check result. It begins execution by checking if the provided p_resource_id exists in the resources table using a SELECT EXISTS subquery on the resources table where the resource_id column equals p_resource_id, storing the boolean result into v_resource_exists. If v_resource_exists is FALSE and the p_operation parameter is either 'INSERT' or 'COUNT', the procedure performs an INSERT into the resources table, creating a new row with the resource_id column set to p_resource_id, the name column set to the concatenated string 'Auto-created Resource ' followed by the p_resource_id value, and the created_at column set to the p_created_at parameter value. Next, the procedure uses a conditional IF-ELSIF block to execute logic based on the p_operation value. If p_operation is 'INSERT', it calculates a new v_tag_id by selecting the maximum value from the tag_id column in the resource_tags table, using the COALESCE function to return 0 if the maximum is NULL, and then adding 1 to that result, and subsequently inserts a new row into the resource_tags table with columns tag_id set to v_tag_id, resource_id set to p_resource_id, tag_name set to p_tag_name, and created_at set to p_created_at. If p_operation is 'DELETE', it executes a DELETE operation on the resource_tags table for all rows where the resource_id column equals p_resource_id and where the lowercased version of the tag_name column, obtained using the LOWER function, matches the lowercased version of the p_tag_name parameter, also obtained using LOWER, to perform a case-insensitive deletion. If p_operation is 'COUNT', it performs an INSERT into the resource_tags table where the values for the columns are derived from a subquery: the tag_id is calculated as the maximum tag_id from the resource_tags table (using COALESCE to handle NULL as 0) plus 1, the resource_id is set to p_resource_id, the tag_name is set to the string 'COUNT_' concatenated with the count of rows from the resource_tags table where the resource_id column equals p_resource_id, and the created_at column is set to the p_created_at parameter value.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_resource_tags(\n    p_resource_id BIGINT,\n    p_tag_name TEXT,\n    p_operation TEXT,\n    p_created_at TEXT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_tag_id BIGINT;\n    v_resource_exists BOOLEAN;\nBEGIN\n    -- Check if the resource_id exists in the resources table\n    SELECT EXISTS (SELECT 1 FROM resources WHERE resource_id = p_resource_id) INTO v_resource_exists;\n\n    -- If resource doesn't exist and we need to insert, create a basic resource record\n    IF NOT v_resource_exists AND (p_operation = 'INSERT' OR p_operation = 'COUNT') THEN\n        INSERT INTO resources (resource_id, name, created_at)\n        VALUES (p_resource_id, 'Auto-created Resource ' || p_resource_id, p_created_at);\n    END IF;\n\n    IF p_operation = 'INSERT' THEN\n        SELECT COALESCE(MAX(tag_id), 0) + 1 INTO v_tag_id FROM resource_tags;\n        INSERT INTO resource_tags (tag_id, resource_id, tag_name, created_at)\n        VALUES (v_tag_id, p_resource_id, p_tag_name, p_created_at);\n    ELSIF p_operation = 'DELETE' THEN\n        DELETE FROM resource_tags WHERE resource_id = p_resource_id AND LOWER(tag_name) = LOWER(p_tag_name);\n    ELSIF p_operation = 'COUNT' THEN\n        INSERT INTO resource_tags (tag_id, resource_id, tag_name, created_at)\n        SELECT COALESCE(MAX(tag_id), 0) + 1, p_resource_id, 'COUNT_' || COUNT(*), p_created_at\n        FROM resource_tags WHERE resource_id = p_resource_id;\n    END IF;\nEND;\n$$;",
    "database_name": "educational_resource_and_technology_management",
    "tables": [
      "resources",
      "resource_tags",
      "resource_permissions",
      "resource_licenses",
      "resource_technologies"
    ],
    "id": 103
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named percentile_audit_trigger that is defined to fire automatically after each row is deleted from the salary_percentiles table, declaring two local NUMBER variables v_update_id and v_count; the trigger logic first executes a SELECT statement to count the number of rows in the updates table where the major_id column matches the value of the :OLD.major_id pseudorecord column from the deleted row, storing the result into v_count, then executes another SELECT statement to calculate the maximum value from the update_id column in the updates table, increments that maximum value by one, and stores the result into v_update_id; following these queries, an IF condition checks if v_count is greater than zero, and if this condition is true, the trigger performs an INSERT operation into the updates table, specifying values for the columns update_id with v_update_id, major_id with :OLD.major_id, updated_by with the literal number 1, column_name with the literal string 'percentile_deleted', old_value with the character string conversion of the :OLD.percentile_id value using the TO_CHAR function, new_value with the literal string 'DELETED', and update_date with the character string conversion of the current system date SYSDATE formatted as 'YYYY-MM-DD' using the TO_CHAR function.",
    "plsql": "CREATE OR REPLACE TRIGGER percentile_audit_trigger\nAFTER DELETE ON salary_percentiles\nFOR EACH ROW\nDECLARE\n    v_update_id NUMBER;\n    v_count NUMBER;\nBEGIN\n    SELECT COUNT(*) INTO v_count FROM updates WHERE major_id = :OLD.major_id;\n    SELECT MAX(update_id) + 1 INTO v_update_id FROM updates;\n    IF v_count > 0 THEN\n        INSERT INTO updates (update_id, major_id, updated_by, column_name, old_value, new_value, update_date)\n        VALUES (v_update_id, :OLD.major_id, 1, 'percentile_deleted', TO_CHAR(:OLD.percentile_id), 'DELETED', TO_CHAR(SYSDATE, 'YYYY-MM-DD'));\n    END IF;\nEND;",
    "database_name": "university_gsrb_major",
    "tables": [
      "salaries",
      "salary_percentiles",
      "updates"
    ],
    "_source": "plfactory28",
    "id": 104
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `get_maintenance_schedule` that accepts four input parameters: `p_vehicle_id` of type `BIGINT`, `p_service_type` of type `TEXT`, `p_start_date` of type `TEXT`, and `p_end_date` of type `TEXT`. The purpose of this procedure is to retrieve specific maintenance schedule information. The procedure executes a `SELECT` statement, but instead of returning the results to the caller, it uses the `PERFORM` command, which executes the query and discards its results. The `SELECT` statement targets the `vehicle_maintenance` table. It selects two columns from this table: `service_date` and `next_service_date`. The selection of rows is filtered by a `WHERE` clause that applies three conditions connected by `AND` logical operators. The first condition requires that the `vehicle_id` column in the `vehicle_maintenance` table must be equal to the value provided in the `p_vehicle_id` input parameter. The second condition specifies that the `service_type` column in the `vehicle_maintenance` table must be equal to the value provided in the `p_service_type` input parameter. The third condition dictates that the `service_date` column in the `vehicle_maintenance` table must fall inclusively between the values provided in the `p_start_date` and `p_end_date` input parameters.",
    "plsql": "CREATE OR REPLACE PROCEDURE get_maintenance_schedule(\n    IN p_vehicle_id BIGINT,\n    IN p_service_type TEXT,\n    IN p_start_date TEXT,\n    IN p_end_date TEXT\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    PERFORM \"vehicle_maintenance\".\"service_date\", \"vehicle_maintenance\".\"next_service_date\"\n    FROM \"vehicle_maintenance\"\n    WHERE \"vehicle_maintenance\".\"vehicle_id\" = p_vehicle_id\n    AND \"vehicle_maintenance\".\"service_type\" = p_service_type\n    AND \"vehicle_maintenance\".\"service_date\" BETWEEN p_start_date AND p_end_date;\nEND;\n$$;",
    "database_name": "geographical_location_and_postal_codes",
    "tables": [
      "fleet_management",
      "drivers",
      "routes",
      "vehicle_maintenance"
    ],
    "id": 105
  },
  {
    "ir": "Write a PLpgSQL stored procedure named aggregate_experimental_results that accepts five parameters: p_design_type of type text, p_treatment_category of type text, p_unit_filter of type text, p_min_data_points of type bigint, and p_max_data_points of type bigint. The procedure begins by declaring two local variables, v_study_count of type bigint and v_avg_outcome_value of type real. It then performs a SELECT operation to count distinct study_id values and calculate the average value from the results table, joining the studies, treatments, outcome_measures, and results tables based on study_id, treatment_id, and outcome_id, respectively. The WHERE clause filters records where the experimental_design column in the studies table matches p_design_type, the type column in the treatments table matches p_treatment_category, and the data_type column in the outcome_measures table matches p_unit_filter. The results of the SELECT operation are stored in v_study_count and v_avg_outcome_value. The procedure then evaluates the value of v_study_count against p_min_data_points and p_max_data_points using conditional statements. If v_study_count is greater than p_min_data_points and less than p_max_data_points, it performs an INSERT operation into the results table, generating a new result_id using the nextval function on the results_result_id_seq sequence, and inserting values including v_avg_outcome_value, 'meta_analysis', 'aggregate_mean', a significant flag determined by comparing v_avg_outcome_value to the average value in the results table, v_study_count, 'studies', and 'aggregate_comparison'. The INSERT operation is limited to one row by selecting from the outcome_measures table where data_type matches p_unit_filter. If v_study_count is greater than or equal to p_max_data_points, the procedure performs an UPDATE operation on the results table, setting stat_test to 'large_sample_analysis' and statistical_test_result to 'high_reliability' for rows where outcome_id matches those in a subquery selecting outcome_id from the outcome_measures table joined with treatments and studies tables, filtered by p_design_type and p_treatment_category. If v_study_count is less than or equal to p_min_data_points, the procedure performs a DELETE operation on the results table for rows where outcome_id matches those in a subquery selecting outcome_id from the outcome_measures table joined with treatments and studies tables, filtered by p_design_type, p_treatment_category, and p_unit_filter.",
    "plsql": "CREATE OR REPLACE PROCEDURE aggregate_experimental_results(\n    p_design_type text,\n    p_treatment_category text,\n    p_unit_filter text,\n    p_min_data_points bigint,\n    p_max_data_points bigint\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_study_count bigint;\n    v_avg_outcome_value real;\nBEGIN\n    SELECT COUNT(DISTINCT s.study_id), AVG(r.value)\n    INTO v_study_count, v_avg_outcome_value\n    FROM studies s\n    JOIN treatments t ON s.study_id = t.study_id\n    JOIN outcome_measures om ON t.treatment_id = om.treatment_id\n    JOIN results r ON om.outcome_id = r.outcome_id\n    WHERE s.experimental_design = p_design_type\n        AND t.type = p_treatment_category\n        AND om.data_type = p_unit_filter;\n    \n    IF v_study_count > p_min_data_points AND v_study_count < p_max_data_points THEN\n        INSERT INTO results (result_id, outcome_id, value, stat_test, stat_type, significant, data_value, data_unit, statistical_test_result)\n        SELECT \n            nextval('results_result_id_seq'),\n            om.outcome_id,\n            v_avg_outcome_value,\n            'meta_analysis',\n            'aggregate_mean',\n            CASE WHEN v_avg_outcome_value > (SELECT AVG(value) FROM results) THEN 1 ELSE 0 END,\n            v_study_count,\n            'studies',\n            'aggregate_comparison'\n        FROM outcome_measures om\n        WHERE om.data_type = p_unit_filter\n        LIMIT 1;\n    ELSIF v_study_count >= p_max_data_points THEN\n        UPDATE results \n        SET stat_test = 'large_sample_analysis',\n            statistical_test_result = 'high_reliability'\n        WHERE outcome_id IN (\n            SELECT om.outcome_id\n            FROM outcome_measures om\n            JOIN treatments t ON om.treatment_id = t.treatment_id\n            JOIN studies s ON t.study_id = s.study_id\n            WHERE s.experimental_design = p_design_type\n                AND t.type = p_treatment_category\n        );\n    ELSE\n        DELETE FROM results \n        WHERE outcome_id IN (\n            SELECT om.outcome_id\n            FROM outcome_measures om\n            JOIN treatments t ON om.treatment_id = t.treatment_id\n            JOIN studies s ON t.study_id = s.study_id\n            WHERE s.experimental_design = p_design_type\n                AND t.type = p_treatment_category\n                AND om.data_type = p_unit_filter\n        );\n    END IF;\nEND;\n$$;",
    "database_name": "agricultural_fertilizer_placement_and_nutrient_management",
    "tables": [
      "studies",
      "treatments",
      "outcome_measures",
      "results"
    ],
    "id": 106
  },
  {
    "ir": "Write a PL/pgSQL function named `validate_car_name_trigger` that is designed to be executed as a trigger. This function takes no explicit parameters but implicitly receives special `NEW` and `OLD` record variables when invoked by a trigger. The purpose of this function is to validate and potentially modify the `car_name` column of a row being inserted or updated in the `cars` table. Inside the function, a conditional statement checks if the ASCII value of the first character of the `car_name` in the `NEW` record (representing the new or updated row data) is less than 65. The `ascii()` function is used to retrieve the ASCII integer value of the first character of the `car_name` string. If this condition evaluates to true, meaning the first character's ASCII value is less than 65 (which typically corresponds to non-alphabetic characters or lowercase letters depending on the character set, but specifically excludes uppercase letters 'A' through 'Z' which start at ASCII 65), then the `car_name` in the `NEW` record is modified. The modification involves prepending the string literal 'Invalid_' to the existing `car_name` value. After the conditional check and potential modification, the function returns the `NEW` record, which contains the potentially altered `car_name` value, allowing the database to proceed with the insert or update operation using this modified data.\n\nAdditionally, a trigger named `validate_car_name` is created on the `cars` table. This trigger is configured to execute `BEFORE` any `INSERT` or `UPDATE` operation on the `cars` table. It is a `FOR EACH ROW` trigger, meaning it will execute the associated function once for every row affected by the `INSERT` or `UPDATE` statement. The trigger explicitly calls the `validate_car_name_trigger()` function, ensuring that the logic defined within that function is applied to each row's `car_name` column before the row is actually inserted or updated in the `cars` table.",
    "plsql": "CREATE OR REPLACE FUNCTION validate_car_name_trigger() RETURNS TRIGGER AS $$\nBEGIN\n    IF ascii(NEW.car_name) < 65 THEN\n        NEW.car_name := 'Invalid_' || NEW.car_name;\n    END IF;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER validate_car_name\n    BEFORE INSERT OR UPDATE ON cars\n    FOR EACH ROW\n    EXECUTE FUNCTION validate_car_name_trigger();",
    "database_name": "automobile_performance_and_specifications",
    "tables": [
      "cars",
      "engine_types",
      "performance_metrics",
      "transmission_types"
    ],
    "id": 107
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_check_location_coordinates that is defined to execute automatically before any INSERT or UPDATE operation on the locations table for each individual row being processed, and within its logic, it checks a condition on the new values for the latitude and longitude columns of the row, specifically evaluating if the incoming :NEW.latitude value is NULL OR if the incoming :NEW.longitude value is NULL, and if this Boolean condition evaluates to TRUE, it immediately raises a custom application error with error number -20001 and the message 'Latitude and Longitude cannot be NULL', thereby preventing the triggering INSERT or UPDATE operation from completing for that row.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_check_location_coordinates\nBEFORE INSERT OR UPDATE ON locations\nFOR EACH ROW\nBEGIN\n  IF :NEW.latitude IS NULL OR :NEW.longitude IS NULL THEN\n    RAISE_APPLICATION_ERROR(-20001, 'Latitude and Longitude cannot be NULL');\n  END IF;\nEND;",
    "database_name": "coworking_smar_booking",
    "tables": [
      "locations",
      "opening_hours"
    ],
    "_source": "plfactory11",
    "id": 108
  },
  {
    "ir": "Write an Oracle PL/SQL function named get_user_count_in_production that returns a NUMBER data type, declares a local variable v_count of type NUMBER, executes a SELECT statement that queries the users table, uses the COUNT(*) aggregate function to calculate the total number of rows, applies a WHERE clause condition to filter rows where the department column value is exactly equal to the string literal 'Production', stores the result of the count into the local variable v_count, and finally returns the value stored in v_count as the function's result.",
    "plsql": "CREATE OR REPLACE FUNCTION get_user_count_in_production\nRETURN NUMBER\nIS\n    v_count NUMBER;\nBEGIN\n    SELECT COUNT(*) INTO v_count FROM users WHERE department = 'Production';\n    RETURN v_count;\nEND;",
    "database_name": "risk_mam_planning",
    "tables": [
      "projects",
      "risks",
      "risk_assessments",
      "mitigation_status",
      "users"
    ],
    "id": 109
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `update_user_role` that accepts three input parameters: `p_user_id` of type `bigint`, `p_new_role` of type `text`, and `p_admin_flag` of type `bigint`. The purpose of this procedure is to modify an existing record within the `users` table. Specifically, it performs an `UPDATE` operation on the `users` table. During this update, it sets the value of the `role` column to the value provided by the `p_new_role` parameter and simultaneously sets the value of the `is_admin` column to the value provided by the `p_admin_flag` parameter. This modification is applied only to the row(s) in the `users` table where the value in the `user_id` column precisely matches the value supplied by the `p_user_id` parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_user_role(p_user_id bigint, p_new_role text, p_admin_flag bigint)\nLANGUAGE plpgsql\nAS $$\nBEGIN\nUPDATE users \nSET role = p_new_role, \n    is_admin = p_admin_flag \nWHERE user_id = p_user_id;\nEND;\n$$;",
    "database_name": "candidate_application_management_and_evaluation",
    "tables": [
      "users"
    ],
    "id": 110
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named consolidate_sex_based_data that accepts one input parameter p_sex_name of type VARCHAR2, which represents a sex name to process. The procedure first declares local variables v_sex_id, v_observation_count, v_total_value, v_area_count, v_period_count, and v_file_records, all of type NUMBER. It begins by attempting to retrieve a sex_id from the sexes table where the uppercase version of the sex_name column matches the uppercase version of the input parameter p_sex_name, using the UPPER function for case-insensitive comparison, and stores the result into v_sex_id; if no matching row is found, a NO_DATA_FOUND exception is caught and v_sex_id is explicitly set to NULL. If v_sex_id is not NULL, the procedure then queries the observations table to count all rows and sum the value column for rows where the sex_id equals the retrieved v_sex_id, storing the count into v_observation_count and the sum into v_total_value. If v_observation_count is greater than 0, it proceeds to count the number of distinct area_id values from the observations table for the same sex_id, storing the result into v_area_count. If v_area_count is greater than 10, it then counts the number of distinct period_id values from the observations table for that sex_id, storing the result into v_period_count. If v_period_count is greater than 5, it counts the number of rows in the data_files table that are joined to the observations table on observation_id where the observation's sex_id equals v_sex_id, storing the count into v_file_records. If v_file_records is greater than 0, it performs a delete operation on the data_files table, removing rows where the file_id is in a subquery that selects df.file_id from data_files df joined to observations o on df.observation_id = o.observation_id where o.sex_id equals v_sex_id and the length of the df.checksum column is less than 10, using the LENGTH function. After this nested conditional logic, if v_observation_count is greater than 100, the procedure inserts a new row into the observations table with the following column values: observation_id is set to the current maximum observation_id from the observations table plus one (or 1 if the maximum is NULL, using NVL), area_id is set to 1, period_id is set to 1, sex_id is set to v_sex_id, age_group_id is set to 0, unit_id is set to 0, value is set to the average value calculated by dividing v_total_value by v_observation_count and rounding to 5 decimal places using the ROUND function, dataset_id is set to 2, source is set to the string 'Aggregate', confidence_level is set to 0.88, version is set to 1, and both created_at and updated_at are set to the current system date and time formatted as 'YYYY-MM-DD HH24:MI:SS' using the TO_CHAR and SYSDATE functions.",
    "plsql": "CREATE OR REPLACE PROCEDURE consolidate_sex_based_data(p_sex_name IN VARCHAR2) AS\n    v_sex_id NUMBER;\n    v_observation_count NUMBER;\n    v_total_value NUMBER;\n    v_area_count NUMBER;\n    v_period_count NUMBER;\n    v_file_records NUMBER;\nBEGIN\n    BEGIN\n        SELECT sex_id INTO v_sex_id\n        FROM sexes\n        WHERE UPPER(sex_name) = UPPER(p_sex_name);\n    EXCEPTION\n        WHEN NO_DATA_FOUND THEN\n            v_sex_id := NULL;\n    END;\n    \n    IF v_sex_id IS NOT NULL THEN\n        SELECT COUNT(*), SUM(value)\n        INTO v_observation_count, v_total_value\n        FROM observations\n        WHERE sex_id = v_sex_id;\n        \n        IF v_observation_count > 0 THEN\n            SELECT COUNT(DISTINCT area_id)\n            INTO v_area_count\n            FROM observations\n            WHERE sex_id = v_sex_id;\n            \n            IF v_area_count > 10 THEN\n                SELECT COUNT(DISTINCT period_id)\n                INTO v_period_count\n                FROM observations\n                WHERE sex_id = v_sex_id;\n                \n                IF v_period_count > 5 THEN\n                    SELECT COUNT(*)\n                    INTO v_file_records\n                    FROM data_files df\n                    JOIN observations o ON df.observation_id = o.observation_id\n                    WHERE o.sex_id = v_sex_id;\n                    \n                    IF v_file_records > 0 THEN\n                        DELETE FROM data_files\n                        WHERE file_id IN (\n                            SELECT df.file_id\n                            FROM data_files df\n                            JOIN observations o ON df.observation_id = o.observation_id\n                            WHERE o.sex_id = v_sex_id\n                            AND LENGTH(df.checksum) < 10\n                        );\n                    END IF;\n                END IF;\n            END IF;\n            \n            IF v_observation_count > 100 THEN\n                INSERT INTO observations (observation_id, area_id, period_id, sex_id, age_group_id, unit_id, value, dataset_id, source, confidence_level, version, created_at, updated_at)\n                SELECT (SELECT NVL(MAX(observation_id), 0) + 1 FROM observations), 1, 1, v_sex_id, 0, 0, ROUND(v_total_value / v_observation_count, 5), 2, 'Aggregate', 0.88, 1, TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS'), TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS')\n                FROM dual;\n            END IF;\n        END IF;\n    END IF;\nEND;",
    "database_name": "demographic_sa_observatio",
    "tables": [
      "observations",
      "age_groups",
      "reference_areas",
      "sexes",
      "time_periods",
      "units_of_measurement",
      "data_files"
    ],
    "id": 111
  },
  {
    "ir": "Write a PLpgSQL function that takes a single parameter, para_player_id of type bigint, and checks if there exists a record in the pitching_statistics table joined with the performance_metrics table on the metric_id column, where the player_id in the performance_metrics table matches the provided para_player_id and the era column in the pitching_statistics table is less than 3.50. If such a record exists, the function updates the player_team table by setting the role column to 'Closer' for the row where the player_id matches the provided para_player_id.",
    "plsql": "CREATE OR REPLACE FUNCTION assign_player_role_by_era(para_player_id bigint) RETURNS void LANGUAGE plpgsql AS $$ BEGIN IF EXISTS (SELECT 1 FROM pitching_statistics ps JOIN performance_metrics pm ON ps.metric_id = pm.metric_id WHERE pm.player_id = para_player_id AND ps.era < 3.50) THEN UPDATE player_team SET role = 'Closer' WHERE player_id = para_player_id; END IF; END; $$;",
    "database_name": "baseball_performance_metrics_and_analytics",
    "tables": [
      "players",
      "performance_metrics",
      "batting_statistics",
      "pitching_statistics",
      "player_team"
    ],
    "id": 112
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named UpdateBrowserMarketPosition that accepts two input parameters: p_browser_id of type NUMBER which identifies the specific browser record to be modified, and p_new_position of type VARCHAR2 which represents the new market position value to be assigned. The procedure first declares a local variable v_current_position of type VARCHAR2(255) to temporarily store the existing market position. It then executes a SELECT statement to retrieve the current market_position value from the browsers table where the browser_id column matches the p_browser_id parameter, storing this value in the v_current_position variable. The procedure then performs a conditional check to compare the retrieved v_current_position with the p_new_position parameter. If these values are different, the procedure executes an UPDATE statement on the browsers table, setting the market_position column to the value of p_new_position for the row where browser_id equals p_browser_id. The procedure includes an exception handling section that catches two types of exceptions: NO_DATA_FOUND, which occurs when the SELECT statement finds no matching browser_id, and OTHERS, which catches any other unexpected exceptions, with both exceptions being silently ignored through NULL statements.",
    "plsql": "CREATE OR REPLACE PROCEDURE UpdateBrowserMarketPosition (\n    p_browser_id IN NUMBER,\n    p_new_position IN VARCHAR2\n) AS\n    v_current_position VARCHAR2(255);\nBEGIN\n    SELECT market_position\n    INTO v_current_position\n    FROM browsers\n    WHERE browser_id = p_browser_id;\n\n    IF v_current_position != p_new_position THEN\n        UPDATE browsers\n        SET market_position = p_new_position\n        WHERE browser_id = p_browser_id;\n    END IF;\nEXCEPTION\n    WHEN NO_DATA_FOUND THEN\n        NULL;\n    WHEN OTHERS THEN\n        NULL;\nEND;",
    "database_name": "browser_ms_analysis",
    "tables": [
      "browser_market_share",
      "browsers",
      "reports",
      "users"
    ],
    "id": 113
  },
  {
    "ir": "Write a PostgreSQL trigger function named trg_update_category_timestamp that returns a trigger and is executed by a trigger named trg_after_election_data_insert, which is defined to fire after every insert operation on the election_data table for each new row, where the function's logic first checks if the NEW record's category_id column is not null, and if this condition is true, it performs an update on the election_categories table, setting the updated_at column to the current date and time value returned by the CURRENT_TIMESTAMP function specifically for the row where the election_categories.category_id column equals the NEW.category_id value from the inserted election_data row, and finally the function returns the NEW row record to the invoking trigger.",
    "plsql": "CREATE OR REPLACE FUNCTION trg_update_category_timestamp() RETURNS TRIGGER AS $$\nBEGIN\n  IF NEW.category_id IS NOT NULL THEN\n    UPDATE election_categories \n    SET updated_at = CURRENT_TIMESTAMP \n    WHERE category_id = NEW.category_id;\n  END IF;\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_after_election_data_insert\nAFTER INSERT ON election_data\nFOR EACH ROW\nEXECUTE FUNCTION trg_update_category_timestamp();",
    "database_name": "election_statistics_and_analysis",
    "tables": [
      "election_categories",
      "election_years",
      "election_data",
      "reports",
      "users",
      "collaborations"
    ],
    "_source": "plfactory19",
    "id": 114
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_insert_prediction_log that is defined to fire automatically after each new row is inserted into the predictions table, and within its execution block, it first declares three local NUMBER variables: v_log_id, v_app_id, and v_user_id; then it performs a SELECT query on the performance_logs table to find the current maximum value in the log_id column, uses the NVL function to treat a NULL result as 0, adds 1 to this value, and stores the result in v_log_id; it then performs an INSERT into the performance_logs table, specifying columns log_id, metric_id, error_type_id, app_id, log_timestamp, log_level, log_message, and log_source, and populates them with the values: v_log_id, the newly inserted metric_id from the predictions table (referenced as :NEW.metric_id), NULL for error_type_id, NULL for app_id, the current timestamp formatted as a string 'YYYY-MM-DD HH24:MI:SS' using TO_CHAR and CURRENT_TIMESTAMP, the string literal 'INFO' for log_level, the string literal 'New prediction added' for log_message, and the string literal 'TRIGGER' for log_source; next, it performs a SELECT query on the applications table to find the maximum app_id, uses NVL to treat NULL as 0, adds 1, and stores it in v_app_id; it then inserts a new row into the applications table, specifying columns app_id, app_name, app_version, owner, environment, status, last_updated, and description, with values: v_app_id, the string 'PredictionApp', the string '1.0', NULL for owner, the string 'DEVELOPMENT' for environment, the string 'PENDING' for status, the current timestamp formatted as 'YYYY-MM-DD HH24:MI:SS' for last_updated, and the string 'Application created due to prediction' for description; following this, it executes a DELETE operation on the error_types table to remove all rows where the severity_level column equals the string 'LOW'; it then performs an UPDATE on the system_settings table, setting the setting_value column to the string 'PREDICTION_LOGGED' for any row where the setting_name column equals the string 'LastPredictionLog'; subsequently, it performs a SELECT query on the users table to find the maximum user_id, uses NVL to treat NULL as 0, adds 1, and stores it in v_user_id; and finally, it inserts a new row into the users table, specifying columns user_id, username, email, role, department, last_login, is_active, and phone_number, with values: v_user_id, the string 'PredictionUser', the string 'predictionuser@example.com', the string 'USER', the string 'DATA', the current timestamp formatted as 'YYYY-MM-DD HH24:MI:SS' for last_login, the number 1 for is_active, and the string '1122334455' for phone_number.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_insert_prediction_log\nAFTER INSERT ON predictions\nFOR EACH ROW\nDECLARE\n  v_log_id NUMBER;\n  v_app_id NUMBER;\n  v_user_id NUMBER;\nBEGIN\n  -- Generate log_id without sequence\n  SELECT NVL(MAX(log_id), 0) + 1 INTO v_log_id FROM performance_logs;\n  \n  INSERT INTO performance_logs (log_id, metric_id, error_type_id, app_id, log_timestamp, log_level, log_message, log_source)\n  VALUES (v_log_id, :NEW.metric_id, NULL, NULL, TO_CHAR(CURRENT_TIMESTAMP, 'YYYY-MM-DD HH24:MI:SS'), 'INFO', 'New prediction added', 'TRIGGER');\n  \n  -- Generate app_id without sequence\n  SELECT NVL(MAX(app_id), 0) + 1 INTO v_app_id FROM applications;\n  \n  INSERT INTO applications (app_id, app_name, app_version, owner, environment, status, last_updated, description)\n  VALUES (v_app_id, 'PredictionApp', '1.0', NULL, 'DEVELOPMENT', 'PENDING', TO_CHAR(CURRENT_TIMESTAMP, 'YYYY-MM-DD HH24:MI:SS'), 'Application created due to prediction');\n  \n  DELETE FROM error_types WHERE severity_level = 'LOW';\n  \n  UPDATE system_settings SET setting_value = 'PREDICTION_LOGGED' WHERE setting_name = 'LastPredictionLog';\n  \n  -- Generate user_id without sequence\n  SELECT NVL(MAX(user_id), 0) + 1 INTO v_user_id FROM users;\n  \n  INSERT INTO users (user_id, username, email, role, department, last_login, is_active, phone_number)\n  VALUES (v_user_id, 'PredictionUser', 'predictionuser@example.com', 'USER', 'DATA', TO_CHAR(CURRENT_TIMESTAMP, 'YYYY-MM-DD HH24:MI:SS'), 1, '1122334455');\nEND;",
    "database_name": "predictive_aapef_systems",
    "tables": [
      "applications",
      "error_types",
      "performance_logs",
      "predictions",
      "system_settings",
      "users"
    ],
    "_source": "plfactory22",
    "id": 115
  },
  {
    "ir": "Write a PostgreSQL trigger function named create_survival_record that returns a trigger and is executed automatically after each new row is inserted into the passengers table, where for every inserted passenger row, the function performs a single INSERT operation into the survival_records table, using the NEW.passenger_id value from the triggering passengers row to construct the new survival record by inserting a record_id column value calculated as NEW.passenger_id plus 5000, inserting the NEW.passenger_id itself into the passenger_id column, inserting a static integer value of 1 into the survived column, inserting a static string 'A1' into the lifeboat column, and inserting a static string 'North Atlantic' into the rescue_location column, and finally the function returns the NEW row record to the trigger execution context.",
    "plsql": "CREATE OR REPLACE FUNCTION create_survival_record() RETURNS TRIGGER AS $$\nBEGIN\n    -- Ensure the passenger_id exists in the passengers table before inserting into survival_records.\n    -- This trigger should logically fire after a passenger is created, not a cabin assignment.\n    INSERT INTO survival_records (record_id, passenger_id, survived, lifeboat, rescue_location)\n    VALUES (NEW.passenger_id + 5000, NEW.passenger_id, 1, 'A1', 'North Atlantic');\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- The trigger should be on the 'passengers' table, as a survival record is fundamentally tied to a passenger's existence.\n-- The original error indicated a foreign key violation when inserting into cabin_assignments,\n-- meaning the passenger_id itself was not valid in the passengers table.\n-- By placing the trigger on 'passengers', we ensure NEW.passenger_id is always valid for survival_records.\nCREATE TRIGGER trg_create_survival_record\n    AFTER INSERT ON passengers\n    FOR EACH ROW\n    EXECUTE FUNCTION create_survival_record();",
    "database_name": "passenger_information_and_travel_data_for_the_titanic",
    "tables": [
      "passengers",
      "cabin_assignments",
      "embarkation_records",
      "family_relationships",
      "survival_records",
      "tickets"
    ],
    "_source": "plfactory30",
    "id": 116
  },
  {
    "ir": "Write a PLpgSQL stored procedure named migrate_user_bookings_to_new_status that accepts two input parameters, old_status of type text and new_status of type text, and performs a two-step data migration process on the bookings table; first, it executes a SELECT query that uses the ARRAY_AGG function to collect all booking_id values of type bigint from the bookings table where the booking_status column exactly matches the provided old_status parameter, storing the resulting array of IDs into a local variable named booking_ids; second, it executes an UPDATE operation on the bookings table, setting the booking_status column to the value of the new_status parameter for every row where the booking_id is found within the array of IDs stored in the booking_ids variable, using the ANY operator to check for membership in that array.",
    "plsql": "CREATE OR REPLACE PROCEDURE migrate_user_bookings_to_new_status(old_status text, new_status text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    booking_ids bigint[];\nBEGIN\n    SELECT ARRAY_AGG(booking_id)\n    INTO booking_ids\n    FROM bookings\n    WHERE booking_status = old_status;\n    \n    UPDATE bookings\n    SET booking_status = new_status\n    WHERE booking_id = ANY(booking_ids);\nEND;\n$$;",
    "database_name": "campsite_and_rv_resort_information_management",
    "tables": [
      "bookings",
      "users",
      "payment_methods"
    ],
    "id": 117
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named GetCommandStatistics that accepts four parameters: p_actuator_id of type NUMBER, p_start_date of type VARCHAR2, p_end_date of type VARCHAR2, and p_operator_id of type NUMBER. This procedure calculates and outputs statistics related to commands issued to a specific actuator by a specific operator within a specified date range. The procedure begins by declaring four local variables: v_total_commands of type NUMBER to store the total count of commands, v_avg_reliability of type NUMBER to store the average reliability score, v_max_command_value of type NUMBER to store the maximum command value, and v_description of type VARCHAR2(4000) to store a descriptive message. The procedure executes a SELECT statement on the actuator_commands table, retrieving the count of commands, average reliability score, and maximum command value for records where the actuator_id matches p_actuator_id, the operator_id matches p_operator_id, and the command_time falls between the start and end dates specified by p_start_date and p_end_date. The command_time is converted to a DATE type using the TO_DATE function with the format 'YYYY-MM-DD HH24:MI:SS', while p_start_date and p_end_date are converted using 'YYYY-MM-DD' and 'YYYY-MM-DD HH24:MI:SS' formats, respectively. The results of the SELECT statement are stored in the local variables v_total_commands, v_avg_reliability, and v_max_command_value. The procedure then constructs a descriptive message in v_description, indicating the actuator ID and the date range for the statistics. Finally, the procedure uses DBMS_OUTPUT.PUT_LINE to output the description, total commands, average reliability, and maximum command value to the console.",
    "plsql": "CREATE OR REPLACE PROCEDURE GetCommandStatistics(\n    p_actuator_id IN NUMBER,\n    p_start_date IN VARCHAR2,\n    p_end_date IN VARCHAR2,\n    p_operator_id IN NUMBER\n) AS\n    v_total_commands NUMBER;\n    v_avg_reliability NUMBER;\n    v_max_command_value NUMBER;\n    v_description VARCHAR2(4000);\nBEGIN\n    SELECT COUNT(*), AVG(reliability_score), MAX(command_value)\n    INTO v_total_commands, v_avg_reliability, v_max_command_value\n    FROM actuator_commands\n    WHERE actuator_id = p_actuator_id\n    AND operator_id = p_operator_id\n    AND TO_DATE(command_time, 'YYYY-MM-DD HH24:MI:SS') BETWEEN \n        TO_DATE(p_start_date, 'YYYY-MM-DD') AND \n        TO_DATE(p_end_date || ' 23:59:59', 'YYYY-MM-DD HH24:MI:SS');\n    \n    v_description := 'Statistics for actuator ' || p_actuator_id || ' from ' || p_start_date || ' to ' || p_end_date;\n    \n    DBMS_OUTPUT.PUT_LINE('Description: ' || v_description);\n    DBMS_OUTPUT.PUT_LINE('Total Commands: ' || v_total_commands);\n    DBMS_OUTPUT.PUT_LINE('Average Reliability: ' || v_avg_reliability);\n    DBMS_OUTPUT.PUT_LINE('Max Command Value: ' || v_max_command_value);\nEND;",
    "database_name": "industrial_pma_control",
    "tables": [
      "actuator_commands",
      "actuators",
      "processes"
    ],
    "id": 118
  },
  {
    "ir": "Write a PostgreSQL trigger function named prevent_lot_deletion_if_property_exists that returns a trigger, which is executed by a trigger named trg_prevent_lot_deletion_if_property_exists defined on the lots table before any delete operation for each individual row, where the function's logic checks for the existence of any record in the properties table by performing a SELECT statement that queries for a single row where the property_id column in the properties table is equal to the OLD.property_id value from the row being deleted from the lots table, and if such a record exists, the function raises an exception with the message 'Cannot delete lot while property exists', thereby preventing the deletion, but if no matching record is found in the properties table, the function proceeds by returning the OLD row record to allow the delete operation on the lots table to complete.",
    "plsql": "CREATE OR REPLACE FUNCTION prevent_lot_deletion_if_property_exists() RETURNS TRIGGER AS $$\nBEGIN\n    IF EXISTS (SELECT 1 FROM properties WHERE property_id = OLD.property_id) THEN\n        RAISE EXCEPTION 'Cannot delete lot while property exists';\n    END IF;\n    RETURN OLD;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_prevent_lot_deletion_if_property_exists\n    BEFORE DELETE ON lots\n    FOR EACH ROW\n    EXECUTE FUNCTION prevent_lot_deletion_if_property_exists();",
    "database_name": "real_estate_property_and_taxation",
    "tables": [
      "properties",
      "lots"
    ],
    "_source": "plfactory11",
    "id": 119
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_alert_resolution that is defined to execute automatically after any row is updated on the alerts table, and for each individual row that is updated, the trigger logic checks if the new value for the column alert_status in the updated row is exactly equal to the string literal 'resolved'; if this condition is true, the trigger performs an update operation on the inventory table, specifically setting the column last_inventory_check to a character string representation of the current system date formatted as 'YYYY-MM-DD' using the TO_CHAR function with SYSDATE as input, but only for those rows in the inventory table where the part_id column matches the new value of the part_id column from the updated row in the alerts table.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_alert_resolution\nAFTER UPDATE ON alerts\nFOR EACH ROW\nBEGIN\n  IF :NEW.alert_status = 'resolved' THEN\n    UPDATE inventory\n    SET last_inventory_check = TO_CHAR(SYSDATE, 'YYYY-MM-DD')\n    WHERE part_id = :NEW.part_id;\n  END IF;\nEND;",
    "database_name": "networking_hsa_management",
    "tables": [
      "hardware_parts",
      "inventory",
      "orders",
      "purchase_history",
      "alerts"
    ],
    "_source": "plfactory6",
    "id": 120
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_report_published that is executed automatically after an update operation on the reports table for each individual row, but only when the updated row's report_type column has the exact string value 'Summary'. This function performs an update on the reports table itself, specifically setting the is_published column to the integer value 1 and the published_date column to the current system date (CURRENT_DATE) for a specific row. The target row for this update is identified by a report_id that matches the NEW.report_id value from the triggering update event. This update only proceeds if a correlated subquery condition is satisfied: the subquery selects from the feedback table, counting all rows where the project_id equals the NEW.project_id from the triggering event and where the is_resolved column equals the integer value 1, and the update is executed only if this count is greater than 2. The function concludes by returning the NEW row record to the trigger mechanism.",
    "plsql": "CREATE OR REPLACE FUNCTION update_report_published() RETURNS TRIGGER AS $$\nBEGIN\n  UPDATE reports SET is_published = 1, published_date = CURRENT_DATE WHERE report_id = NEW.report_id AND (SELECT COUNT(*) FROM feedback WHERE project_id = NEW.project_id AND is_resolved = 1) > 2;\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_update_report_published\nAFTER UPDATE ON reports\nFOR EACH ROW WHEN (NEW.report_type = 'Summary')\nEXECUTE FUNCTION update_report_published();",
    "database_name": "user_experience__ux__evaluation_and_feedback_management",
    "tables": [
      "projects",
      "feedback",
      "reports"
    ],
    "_source": "plfactory25",
    "id": 121
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named delete_expired_enrollments that accepts three parameters: an input parameter p_plan_id of type NUMBER used to specify a plan identifier, an input parameter p_cutoff_date of type VARCHAR2 used to specify a date threshold as a string, and an output parameter p_deleted_count of type NUMBER used to return the number of records deleted. The procedure performs a DELETE operation on the enrollments table, targeting all rows where the plan_id column matches the input parameter p_plan_id, the effective_date column is less than the input parameter p_cutoff_date, and the enrollment_status column has the exact string value 'EXPIRED'. After the deletion, the procedure assigns the number of rows affected by the DELETE statement, obtained from the SQL%ROWCOUNT attribute, to the output parameter p_deleted_count.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_expired_enrollments(\n    p_plan_id IN NUMBER,\n    p_cutoff_date IN VARCHAR2,\n    p_deleted_count OUT NUMBER\n)\nAS\nBEGIN\n    DELETE FROM enrollments\n    WHERE plan_id = p_plan_id\n    AND effective_date < p_cutoff_date\n    AND enrollment_status = 'EXPIRED';\n    \n    p_deleted_count := SQL%ROWCOUNT;\nEND;",
    "database_name": "health_ipap_management",
    "tables": [
      "clients",
      "enrollments",
      "plans"
    ],
    "id": 122
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `transfer_students_between_programs` that accepts four input parameters: `p_source_program` of type `text`, intended to specify the name of the academic program from which students will be transferred; `p_target_program` of type `text`, intended to specify the name of the academic program to which students will be transferred; `p_min_enrollment_year` of type `bigint`, intended to specify the minimum enrollment year for students to be considered for transfer; and `p_new_adviser_id` of type `bigint`, intended to specify the `adviser_id` to be assigned to the transferred students in their new program. The procedure declares a local variable `v_student_record` of type `RECORD` to temporarily hold individual student data retrieved from the `students` table. It also declares a cursor named `v_cursor` which is defined to select the `student_id`, `student_name`, `email`, and `phone_number` columns from the `students` table. The selection criteria for this cursor are that the `program` column must exactly match the value provided in the `p_source_program` parameter, and the `enrollment_year` column must be greater than or equal to the value provided in the `p_min_enrollment_year` parameter. The procedure's execution block begins by opening the `v_cursor`. It then enters a loop. Inside this loop, it attempts to fetch the next row from `v_cursor` into the `v_student_record` variable. Immediately after the fetch operation, it checks if no row was found (i.e., `NOT FOUND` is true); if so, the loop is exited. If a row is successfully fetched, the procedure proceeds to insert a new record into the `students` table. For this new record, the `student_name` column is populated with the `student_name` from the `v_student_record`, the `program` column is set to the value of `p_target_program`, the `enrollment_year` column is set to the value of `p_min_enrollment_year`, the `adviser_id` column is set to the value of `p_new_adviser_id`, the `email` column is populated with the `email` from the `v_student_record`, and the `phone_number` column is populated with the `phone_number` from the `v_student_record`. After the insertion, the loop continues to the next iteration. Once the loop has completed (either because all rows have been processed or no more rows were found), the `v_cursor` is closed.",
    "plsql": "CREATE OR REPLACE PROCEDURE transfer_students_between_programs(\n    p_source_program text,\n    p_target_program text,\n    p_min_enrollment_year bigint,\n    p_new_adviser_id bigint\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_student_record RECORD;\n    v_cursor CURSOR FOR \n        SELECT student_id, student_name, email, phone_number\n        FROM students \n        WHERE program = p_source_program AND enrollment_year >= p_min_enrollment_year;\nBEGIN\n    OPEN v_cursor;\n    LOOP\n        FETCH v_cursor INTO v_student_record;\n        EXIT WHEN NOT FOUND;\n        \n        INSERT INTO students (student_name, program, enrollment_year, adviser_id, email, phone_number)\n        VALUES (v_student_record.student_name, p_target_program, p_min_enrollment_year, \n                p_new_adviser_id, v_student_record.email, v_student_record.phone_number);\n    END LOOP;\n    CLOSE v_cursor;\nEND;\n$$;",
    "database_name": "academic_performance_tracking_and_analysis_941149",
    "tables": [
      "course_enrollment",
      "courses",
      "students"
    ],
    "id": 123
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `sp_delete_comment` that is designed to remove a specific comment record from the `comments` table. This procedure accepts four input parameters: `para_comment_id` of data type `NUMBER`, which represents the unique identifier of the comment to be deleted; `para_user_id` of data type `NUMBER`, which represents the unique identifier of the user who created the comment; `para_post_id` of data type `NUMBER`, which represents the unique identifier of the post to which the comment belongs; and `para_type` of data type `VARCHAR2`, which represents the category or classification of the comment. The procedure performs a `DELETE` operation on the `comments` table. The deletion is conditional, targeting only those rows where the value in the `comment_id` column exactly matches the value provided in the `para_comment_id` parameter, AND the value in the `user_id` column exactly matches the value provided in the `para_user_id` parameter, AND the value in the `post_id` column exactly matches the value provided in the `para_post_id` parameter, AND the value in the `type` column exactly matches the value provided in the `para_type` parameter. This ensures that only a comment that precisely matches all four specified criteria is removed from the `comments` table.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp_delete_comment(para_comment_id NUMBER, para_user_id NUMBER, para_post_id NUMBER, para_type VARCHAR2) IS \nBEGIN \n  DELETE FROM comments \n  WHERE comment_id = para_comment_id \n  AND user_id = para_user_id \n  AND post_id = para_post_id \n  AND type = para_type; \nEND;",
    "database_name": "blog_pcau_engagement",
    "tables": [
      "comments",
      "blog_posts",
      "users",
      "comment_votes",
      "comment_replies",
      "comment_flags"
    ],
    "id": 124
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL function named `calculate_average_content_metric` that accepts a single input parameter, `content_id_input`, which is of type `BIGINT` and represents the unique identifier for a piece of content. This function is designed to return a `REAL` (single-precision floating-point) value, representing the calculated average metric for the specified content. Upon execution, the function declares a local variable named `avg_metric` of type `REAL` to temporarily store the computed average. The core operation involves performing a `SELECT` statement on the `content_performance` table. This `SELECT` statement calculates the `AVG` (average) of the `metric_value` column. To handle cases where no matching rows are found for the given `content_id_input`, the `COALESCE` function is applied to the result of the `AVG` aggregation. If `AVG(metric_value)` returns `NULL` (indicating no rows matched the `WHERE` clause), `COALESCE` will substitute `0.0` as the average. Otherwise, it will use the calculated average. The `WHERE` clause filters the rows in the `content_performance` table, ensuring that only records where the `content_id` column matches the provided `content_id_input` parameter are considered for the average calculation. The result of this `SELECT` statement, which is either the calculated average `metric_value` or `0.0`, is then assigned to the `avg_metric` local variable using the `INTO` clause. Finally, the function returns the value stored in the `avg_metric` variable as its output.",
    "plsql": "CREATE OR REPLACE FUNCTION calculate_average_content_metric(content_id_input BIGINT)\nRETURNS REAL\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    avg_metric REAL;\nBEGIN\n    SELECT COALESCE(AVG(metric_value), 0.0)\n    INTO avg_metric\n    FROM content_performance\n    WHERE content_id = content_id_input;\n\n    RETURN avg_metric;\nEND;\n$$;",
    "database_name": "behavioral_pattern_analysis_and_monitoring",
    "tables": [
      "campaigns",
      "campaign_performance",
      "content",
      "content_performance",
      "users"
    ],
    "id": 125
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named transform_interview_data_to_placements that processes completed interview records from the interviews table. The procedure initializes several local variables, including v_interview_id, v_student_id, v_company_id, v_interview_date, v_gpa, v_industry, v_base_salary, v_multiplier, v_final_salary, v_position, v_placement_id, v_offer_date, v_status_flag, and v_document_count, each with specific types and purposes. It uses a cursor named c_interviews to select interview_id, student_id, company_id, and interview_date from the interviews table where the status is 'Completed', and opens this cursor for update. The procedure enters a loop to fetch each interview record into the local variables, exiting when no more records are found. For each interview, it retrieves the student's GPA from the students table using the student_id, handling cases where no data is found by setting v_gpa to NULL. It similarly fetches the company's industry from the companies table using the company_id, again handling no data found by setting v_industry to NULL. The procedure counts approved documents for the student from the documents table, storing the result in v_document_count. It initializes salary-related variables, setting v_base_salary to 0, v_multiplier to 1.0, v_position to 'Unknown', and v_status_flag to 0, indicating 'Under Review'. Based on the industry and GPA, it determines the base salary, multiplier, position, and status flag using conditional statements. If the industry is 'Technology' and GPA is above 3.7, it sets v_base_salary to 80000, v_multiplier to 1.5, v_position to 'Software Engineer', and v_status_flag to 1. If the industry is 'Finance' and GPA is above 3.5, it sets v_base_salary to 75000, v_multiplier to 1.3, v_position to 'Financial Analyst', and v_status_flag to 1. If the industry is 'Healthcare' and GPA is above 3.3, it sets v_base_salary to 70000, v_multiplier to 1.2, v_position to 'Healthcare Consultant', and v_status_flag to 1. If GPA is between 3.0 and 3.3 and document count is greater than 2, it sets v_base_salary to 60000, v_multiplier to 1.1, v_position to 'Associate', and v_status_flag to 0. If the industry is not null and not in 'Technology', 'Finance', or 'Healthcare', it sets v_base_salary to 55000, v_multiplier to 1.0, v_position to 'Trainee', and v_status_flag to 0. Otherwise, it sets v_base_salary to 50000, v_multiplier to 0.9, v_position to 'Intern', and v_status_flag to 0. It calculates the final salary using the base salary and multiplier, applying the POWER function to the multiplier raised to the power of the greatest value between 0 and GPA minus 3.0, ensuring the exponent is non-negative. If GPA is null, it defaults the final salary to the base salary. The procedure calculates the offer date as seven days after the interview date, converting it to a string format 'YYYY-MM-DD'. It determines the next placement_id by selecting the maximum placement_id from the placements table, adding 1 to it, or defaulting to 1 if no records exist. It inserts a new record into the placements table with the calculated placement_id, student_id, company_id, status flag, offer date, final salary, position, start date (30 days after the offer date), status ('Pending' if status flag is 1, otherwise 'Under Review'), and feedback 'Generated from interview process'. Finally, it deletes the processed interview record from the interviews table using the cursor's current position, and closes the cursor after processing all records.",
    "plsql": "CREATE OR REPLACE PROCEDURE transform_interview_data_to_placements IS\n    v_interview_id NUMBER;\n    v_student_id NUMBER;\n    v_company_id NUMBER;\n    v_interview_date VARCHAR2(255);\n    v_gpa NUMBER;\n    v_industry VARCHAR2(255);\n    v_base_salary NUMBER;\n    v_multiplier NUMBER;\n    v_final_salary NUMBER;\n    v_position VARCHAR2(255);\n    v_placement_id NUMBER;\n    v_offer_date VARCHAR2(255);\n    v_status_flag NUMBER;\n    v_document_count NUMBER;\n    CURSOR c_interviews IS SELECT interview_id, student_id, company_id, interview_date FROM interviews WHERE status = 'Completed' FOR UPDATE;\nBEGIN\n    OPEN c_interviews;\n    LOOP\n        FETCH c_interviews INTO v_interview_id, v_student_id, v_company_id, v_interview_date;\n        EXIT WHEN c_interviews%NOTFOUND;\n\n        -- Fetch student GPA\n        BEGIN\n            SELECT gpa INTO v_gpa FROM students WHERE student_id = v_student_id;\n        EXCEPTION\n            WHEN NO_DATA_FOUND THEN\n                v_gpa := NULL; -- Handle case where student not found\n        END;\n\n        -- Fetch company industry\n        BEGIN\n            SELECT industry INTO v_industry FROM companies WHERE company_id = v_company_id;\n        EXCEPTION\n            WHEN NO_DATA_FOUND THEN\n                v_industry := NULL; -- Handle case where company not found\n        END;\n\n        -- Fetch approved document count\n        SELECT COUNT(*) INTO v_document_count FROM documents WHERE student_id = v_student_id AND document_status = 'Approved';\n\n        -- Initialize variables for salary calculation\n        v_base_salary := 0;\n        v_multiplier := 1.0;\n        v_position := 'Unknown';\n        v_status_flag := 0; -- Default to 'Under Review'\n\n        -- Determine salary, position, and status flag based on criteria\n        IF v_industry = 'Technology' AND v_gpa > 3.7 THEN\n            v_base_salary := 80000;\n            v_multiplier := 1.5;\n            v_position := 'Software Engineer';\n            v_status_flag := 1;\n        ELSIF v_industry = 'Finance' AND v_gpa > 3.5 THEN\n            v_base_salary := 75000;\n            v_multiplier := 1.3;\n            v_position := 'Financial Analyst';\n            v_status_flag := 1;\n        ELSIF v_industry = 'Healthcare' AND v_gpa > 3.3 THEN\n            v_base_salary := 70000;\n            v_multiplier := 1.2;\n            v_position := 'Healthcare Consultant';\n            v_status_flag := 1;\n        ELSIF v_gpa BETWEEN 3.0 AND 3.3 AND v_document_count > 2 THEN\n            v_base_salary := 60000;\n            v_multiplier := 1.1;\n            v_position := 'Associate';\n            v_status_flag := 0;\n        ELSIF v_industry IS NOT NULL AND v_industry NOT IN ('Technology', 'Finance', 'Healthcare') THEN\n            v_base_salary := 55000;\n            v_multiplier := 1.0;\n            v_position := 'Trainee';\n            v_status_flag := 0;\n        ELSE\n            v_base_salary := 50000;\n            v_multiplier := 0.9;\n            v_position := 'Intern';\n            v_status_flag := 0;\n        END IF;\n\n        -- Calculate final salary\n        -- Ensure v_gpa is not null for POWER function\n        IF v_gpa IS NOT NULL THEN\n            v_final_salary := v_base_salary * POWER(v_multiplier, GREATEST(0, v_gpa - 3.0)); -- Ensure exponent is non-negative\n        ELSE\n            v_final_salary := v_base_salary; -- Default if GPA is unknown\n        END IF;\n\n        -- Calculate offer date (7 days after interview)\n        v_offer_date := TO_CHAR(TO_DATE(v_interview_date, 'YYYY-MM-DD') + 7, 'YYYY-MM-DD');\n\n        -- Get next placement_id\n        SELECT NVL(MAX(placement_id), 0) + 1 INTO v_placement_id FROM placements;\n\n        -- Insert into placements table\n        INSERT INTO placements (placement_id, student_id, company_id, accepted, offer_date, salary, position, start_date, status, feedback)\n        VALUES (v_placement_id, v_student_id, v_company_id, v_status_flag, v_offer_date, v_final_salary, v_position, TO_CHAR(TO_DATE(v_offer_date, 'YYYY-MM-DD') + 30, 'YYYY-MM-DD'), CASE WHEN v_status_flag = 1 THEN 'Pending' ELSE 'Under Review' END, 'Generated from interview process');\n\n        -- Delete the processed interview record\n        DELETE FROM interviews WHERE CURRENT OF c_interviews;\n    END LOOP;\n    CLOSE c_interviews;\nEND;",
    "database_name": "university_p_tracking",
    "tables": [
      "companies",
      "documents",
      "interviews",
      "placements",
      "placements_stats",
      "students",
      "user_roles"
    ],
    "id": 126
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `cleanup_orphaned_triggers` that accepts three input parameters: `p_check_pattern` of type `VARCHAR2`, `p_batch_limit` of type `NUMBER`, and `p_trigger_type` of type `VARCHAR2`. The procedure first declares a local variable `v_orphan_count` of type `NUMBER`. It then proceeds to execute a `SELECT` statement to count the number of \"orphaned\" trigger records. This `SELECT` statement queries the `event_triggers` table, aliased as `et`. A record from `event_triggers` is considered for counting if it satisfies three conditions: first, there is no corresponding record in the `event_logs` table (aliased as `el`) where the `event_id` column of `event_logs` matches the `event_id` column of the current `event_triggers` record (this is checked using a `NOT EXISTS` subquery); second, the `event_name` column of the `event_triggers` record contains a match for the regular expression pattern provided by the `p_check_pattern` input parameter (this is determined by checking if the result of `REGEXP_INSTR(et.event_name, p_check_pattern)` is greater than 0); and third, the `trigger_type` column of the `event_triggers` record exactly matches the value provided by the `p_trigger_type` input parameter. The total count of such records is then stored in the `v_orphan_count` variable. Following this, the procedure enters a conditional block: if the value of `v_orphan_count` is greater than 0, indicating that orphaned triggers were found, it then executes a `DELETE` statement. This `DELETE` statement targets records in the `event_triggers` table. The records to be deleted are identified by their `event_id` values, which are selected from a subquery. This subquery also queries the `event_triggers` table, aliased as `et`, and applies the same three conditions as the initial `SELECT` statement: `NOT EXISTS` a matching `event_id` in `event_logs`, `REGEXP_INSTR(et.event_name, p_check_pattern) > 0`, and `et.trigger_type = p_trigger_type`. Additionally, this subquery includes a `ROWNUM <= p_batch_limit` condition, which limits the number of `event_id`s returned by the subquery to the value specified by the `p_batch_limit` input parameter, effectively deleting orphaned triggers in batches. If `v_orphan_count` is not greater than 0, the `DELETE` statement is skipped, and the procedure concludes.",
    "plsql": "CREATE OR REPLACE PROCEDURE cleanup_orphaned_triggers(p_check_pattern IN VARCHAR2, p_batch_limit IN NUMBER, p_trigger_type IN VARCHAR2) AS\n    v_orphan_count NUMBER;\nBEGIN\n    SELECT COUNT(*) INTO v_orphan_count\n    FROM event_triggers et\n    WHERE NOT EXISTS (\n        SELECT 1 FROM event_logs el \n        WHERE el.event_id = et.event_id\n    )\n    AND REGEXP_INSTR(et.event_name, p_check_pattern) > 0\n    AND et.trigger_type = p_trigger_type;\n    \n    IF v_orphan_count > 0 THEN\n        DELETE FROM event_triggers\n        WHERE event_id IN (\n            SELECT et.event_id\n            FROM event_triggers et\n            WHERE NOT EXISTS (\n                SELECT 1 FROM event_logs el \n                WHERE el.event_id = et.event_id\n            )\n            AND REGEXP_INSTR(et.event_name, p_check_pattern) > 0\n            AND et.trigger_type = p_trigger_type\n            AND ROWNUM <= p_batch_limit\n        );\n    END IF;\nEND;",
    "database_name": "game_caet_management",
    "tables": [
      "event_logs",
      "event_triggers",
      "game_sessions"
    ],
    "id": 127
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `calculate_fold_enrichment` that accepts three input parameters: `analysis_id_input` of type `bigint`, `gene_set_id_input` of type `bigint`, and `go_id_input` of type `text`. The sole operation performed by this procedure is a `SELECT` statement. This `SELECT` statement retrieves the value from the `fold_enrichment` column of the `enrichment_analysis` table. The selection is conditioned by three criteria: the value in the `analysis_id` column must be equal to the value provided in the `analysis_id_input` parameter, the value in the `gene_set_id` column must be equal to the value provided in the `gene_set_id_input` parameter, and the value in the `go_id` column must be equal to the value provided in the `go_id_input` parameter. The result of this `SELECT` statement is not assigned to any variable, nor is it returned by the procedure; it is simply executed and then discarded.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_fold_enrichment(IN analysis_id_input bigint, IN gene_set_id_input bigint, IN go_id_input text)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    PERFORM (SELECT fold_enrichment FROM enrichment_analysis WHERE analysis_id = analysis_id_input AND gene_set_id = gene_set_id_input AND go_id = go_id_input);\nEND;\n$$;",
    "database_name": "biological_and_gene_ontology_data_analysis",
    "tables": [
      "enrichment_analysis",
      "gene_associations",
      "gene_ontology",
      "gene_sets",
      "genes"
    ],
    "id": 128
  },
  {
    "ir": "Write a PostgreSQL stored procedure named process_research_sharing that accepts three parameters: p_researcher_id of type bigint which identifies the researcher, p_institution of type text which specifies the institution name, and p_data_type of type text which indicates the type of data being shared. The procedure first declares three variables: max_project_id of type bigint to store the highest project identifier, calc_result of type integer initialized to 0 for intermediate calculations, and status_flag of type text to track priority status. The procedure then queries the research_projects table to find the maximum project_id for the specified researcher_id and stores this value in max_project_id. It calculates calc_result by adding 10 to max_project_id. The procedure then evaluates whether calc_result exceeds 50: if true, it sets status_flag to 'high_priority' and updates the data_sharing table by setting the data_shared column to p_data_type for rows where researcher_id equals p_researcher_id and institution equals p_institution; if false, it sets status_flag to 'standard_priority' and updates the data_sharing table by setting data_shared to p_data_type concatenated with '_standard' for rows where researcher_id equals p_researcher_id. The procedure then doubles the value of calc_result. Next, it updates the research_projects table by appending status_flag to the project_description column for rows where researcher_id equals p_researcher_id and project_id equals max_project_id. The procedure then deletes rows from the data_sharing table where end_date is earlier than '2022-01-01' and researcher_id equals p_researcher_id. It then increments calc_result by 25. The procedure updates the researchers table by appending '_active' to the research_area column where researcher_id equals p_researcher_id. It then updates the data_sharing table by appending '_processed' to the institution column where researcher_id equals p_researcher_id and data_shared equals p_data_type. Finally, the procedure divides calc_result by 4 and updates the research_projects table by setting end_date to '2023-12-31' for rows where researcher_id equals p_researcher_id and project_id equals max_project_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_research_sharing(p_researcher_id bigint, p_institution text, p_data_type text) LANGUAGE plpgsql AS $$ DECLARE max_project_id bigint; calc_result integer := 0; status_flag text; BEGIN SELECT MAX(project_id) INTO max_project_id FROM research_projects WHERE researcher_id = p_researcher_id; calc_result := max_project_id + 10; IF calc_result > 50 THEN status_flag := 'high_priority'; UPDATE data_sharing SET data_shared = p_data_type WHERE researcher_id = p_researcher_id AND institution = p_institution; ELSE status_flag := 'standard_priority'; UPDATE data_sharing SET data_shared = p_data_type || '_standard' WHERE researcher_id = p_researcher_id; END IF; calc_result := calc_result * 2; UPDATE research_projects SET project_description = project_description || '_' || status_flag WHERE researcher_id = p_researcher_id AND project_id = max_project_id; DELETE FROM data_sharing WHERE end_date < '2022-01-01' AND researcher_id = p_researcher_id; calc_result := calc_result + 25; UPDATE researchers SET research_area = research_area || '_active' WHERE researcher_id = p_researcher_id; UPDATE data_sharing SET institution = p_institution || '_processed' WHERE researcher_id = p_researcher_id AND data_shared = p_data_type; calc_result := calc_result / 4; UPDATE research_projects SET end_date = '2023-12-31' WHERE researcher_id = p_researcher_id AND project_id = max_project_id; END; $$;",
    "database_name": "autism_screening_and_diagnosis",
    "tables": [
      "patients",
      "diagnosis",
      "screening_results",
      "treatment_plans",
      "app_usage",
      "analytics",
      "researchers",
      "research_projects",
      "data_sharing"
    ],
    "id": 129
  },
  {
    "ir": "Write a PLpgSQL stored procedure named analyze_demographic_patterns that accepts four input parameters: p_market_id_filter of type BIGINT, p_feedback_date of type TEXT, p_score_threshold of type REAL, and p_anonymous_only of type BIGINT. The procedure begins by declaring three local variables: v_demographic_count, v_attribute_count, and v_total_feedback, all of type INTEGER. It performs a SELECT operation to count distinct demographic_id values from the demographics table, joining with the consumer_feedback table on demographic_id, where the market_id matches p_market_id_filter, the purchase_date matches p_feedback_date, and the is_anonymous column matches p_anonymous_only unless p_anonymous_only is zero, storing the result in v_demographic_count. Next, it executes another SELECT to count distinct attribute_id values from the attributes table, joining with consumer_feedback on attribute_id, where market_id matches p_market_id_filter, feedback_score is greater than or equal to p_score_threshold, and purchase_date matches p_feedback_date, storing the result in v_attribute_count. A third SELECT counts all rows in consumer_feedback where market_id matches p_market_id_filter, purchase_date matches p_feedback_date, feedback_score is greater than or equal to p_score_threshold, and is_anonymous matches p_anonymous_only unless p_anonymous_only is zero, storing the result in v_total_feedback. If both v_demographic_count and v_attribute_count are greater than zero, the procedure inserts a new row into the attributes table with attribute_id calculated as p_market_id_filter multiplied by 1000, attribute_type set to 'Analysis', attribute_description constructed by concatenating the text 'Demographics: ' with v_demographic_count and ', Attributes: ' with v_attribute_count, attribute_weight set to v_total_feedback cast to REAL, mean_score calculated as v_total_feedback divided by the product of v_demographic_count and v_attribute_count, and both created_at and updated_at set to the current timestamp cast to TEXT.",
    "plsql": "CREATE OR REPLACE PROCEDURE analyze_demographic_patterns(\n    IN p_market_id_filter BIGINT,\n    IN p_feedback_date TEXT,\n    IN p_score_threshold REAL,\n    IN p_anonymous_only BIGINT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_demographic_count INTEGER;\n    v_attribute_count INTEGER;\n    v_total_feedback INTEGER;\nBEGIN\n    SELECT COUNT(DISTINCT d.demographic_id) INTO v_demographic_count\n    FROM demographics d\n    JOIN consumer_feedback cf ON d.demographic_id = cf.demographic_id\n    WHERE cf.market_id = p_market_id_filter\n    AND cf.purchase_date = p_feedback_date\n    AND (p_anonymous_only = 0 OR cf.is_anonymous = p_anonymous_only);\n\n    SELECT COUNT(DISTINCT a.attribute_id) INTO v_attribute_count\n    FROM attributes a\n    JOIN consumer_feedback cf ON a.attribute_id = cf.attribute_id\n    WHERE cf.market_id = p_market_id_filter\n    AND cf.feedback_score >= p_score_threshold\n    AND cf.purchase_date = p_feedback_date;\n\n    SELECT COUNT(*) INTO v_total_feedback\n    FROM consumer_feedback\n    WHERE market_id = p_market_id_filter\n    AND purchase_date = p_feedback_date\n    AND feedback_score >= p_score_threshold\n    AND (p_anonymous_only = 0 OR is_anonymous = p_anonymous_only);\n\n    IF v_demographic_count > 0 AND v_attribute_count > 0 THEN\n        INSERT INTO attributes (attribute_id, attribute_type, attribute_description, attribute_weight, mean_score, created_at, updated_at)\n        VALUES (p_market_id_filter * 1000, 'Analysis', CONCAT('Demographics: ', v_demographic_count::TEXT, ', Attributes: ', v_attribute_count::TEXT), v_total_feedback::REAL, (v_total_feedback * 1.0) / (v_demographic_count * v_attribute_count), CURRENT_TIMESTAMP::TEXT, CURRENT_TIMESTAMP::TEXT);\n    END IF;\nEND;\n$$;",
    "database_name": "consumer_behavior_analysis_in_souvenir_shopping",
    "tables": [
      "consumer_feedback",
      "attributes",
      "demographics"
    ],
    "id": 130
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named update_project_with_elevation_data that accepts three input parameters: p_project_id of type NUMBER, p_elevation_threshold of type NUMBER, and p_cover_type_filter of type NUMBER. The procedure begins by declaring three local variables: v_avg_aspect, v_max_hillshade, and v_record_count, all of type NUMBER. It then performs a SELECT statement on the environmental_data table to calculate the average of the aspect column, the maximum value of the hillshade_3pm column, and the count of records that meet specific conditions. These conditions are that the elevation column must be greater than the value provided in p_elevation_threshold, and the cover_type column must equal the value provided in p_cover_type_filter. The results of this query are stored into the local variables v_avg_aspect, v_max_hillshade, and v_record_count. Following this, the procedure executes an UPDATE statement on the projects table, targeting the row where the project_id column matches the value of p_project_id. The description column of this row is updated to a string that concatenates the text 'Elevation > ' with the value of p_elevation_threshold, followed by ', Avg Aspect: ' and the rounded value of v_avg_aspect to two decimal places, ', Max Hillshade: ' and the rounded value of v_max_hillshade to two decimal places, and ', Records: ' with the value of v_record_count. Additionally, the updated_at column is set to the current date and time formatted as 'YYYY-MM-DD HH24:MI:SS' using the TO_CHAR function.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_project_with_elevation_data(\n    p_project_id IN NUMBER,\n    p_elevation_threshold IN NUMBER,\n    p_cover_type_filter IN NUMBER\n)\nIS\n    v_avg_aspect NUMBER;\n    v_max_hillshade NUMBER;\n    v_record_count NUMBER;\nBEGIN\n    SELECT AVG(aspect), MAX(hillshade_3pm), COUNT(*)\n    INTO v_avg_aspect, v_max_hillshade, v_record_count\n    FROM environmental_data\n    WHERE elevation > p_elevation_threshold\n    AND cover_type = p_cover_type_filter;\n\n    UPDATE projects\n    SET description = 'Elevation > ' || p_elevation_threshold || \n                     ', Avg Aspect: ' || ROUND(v_avg_aspect, 2) ||\n                     ', Max Hillshade: ' || ROUND(v_max_hillshade, 2) ||\n                     ', Records: ' || v_record_count,\n        updated_at = TO_CHAR(CURRENT_DATE, 'YYYY-MM-DD HH24:MI:SS')\n    WHERE project_id = p_project_id;\nEND;",
    "database_name": "environmental_laa_classif",
    "tables": [
      "cover_types",
      "datasets",
      "environmental_data",
      "projects",
      "soil_types",
      "users"
    ],
    "id": 131
  },
  {
    "ir": "Write a PostgreSQL trigger function named archive_old_contract that returns a trigger type, which is automatically invoked by a trigger named trigger_archive_old_contract defined to fire after every insert operation on the contracts table for each new row, where the function's logic executes a delete operation on the contracts table, targeting all rows where the player_id column value matches the player_id value of the newly inserted row (accessible via the NEW record) and where the contract_id column value is not equal to the contract_id value of the newly inserted row, thereby removing all existing contract records for the same player except for the one that was just inserted, and the function concludes by returning the NEW row record to the invoking trigger.",
    "plsql": "CREATE OR REPLACE FUNCTION archive_old_contract() RETURNS TRIGGER AS $$\nBEGIN\n  DELETE FROM contracts WHERE player_id = NEW.player_id AND contract_id != NEW.contract_id;\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trigger_archive_old_contract\nAFTER INSERT ON contracts\nFOR EACH ROW\nEXECUTE FUNCTION archive_old_contract();",
    "database_name": "professional_sports_club_management_and_player_compensation",
    "tables": [
      "clubs",
      "contracts",
      "players",
      "player_agents",
      "player_stats",
      "positions"
    ],
    "_source": "plfactory24",
    "id": 132
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named update_star_rating that iterates over all records in the funds table using a cursor named fund_cursor, which selects the fund_id, aum, and expense_ratio columns. For each record, the procedure fetches the values into local variables v_fund_id, v_aum, and v_expense_ratio. It then evaluates the asset under management (aum) value: if v_aum is greater than 1,000,000,000, it assigns a star rating of 5 to the local variable v_star_rating; if v_aum is between 500,000,000 and 1,000,000,000, it assigns a star rating of 4; otherwise, it assigns a star rating of 3. Subsequently, it checks the expense_ratio value: if v_expense_ratio is greater than 0.015, it decreases the star rating by 1. The procedure then updates the star_rating column in the funds table for the current fund_id with the calculated v_star_rating value. This process repeats for each record until all records have been processed, at which point the cursor is closed.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_star_rating IS\n    v_fund_id NUMBER;\n    v_aum NUMBER;\n    v_expense_ratio NUMBER;\n    v_star_rating NUMBER;\n    CURSOR fund_cursor IS\n        SELECT fund_id, aum, expense_ratio FROM funds;\nBEGIN\n    OPEN fund_cursor;\n    LOOP\n        FETCH fund_cursor INTO v_fund_id, v_aum, v_expense_ratio;\n        EXIT WHEN fund_cursor%NOTFOUND;\n        \n        IF v_aum > 1000000000 THEN\n            v_star_rating := 5;\n        ELSIF v_aum BETWEEN 500000000 AND 1000000000 THEN\n            v_star_rating := 4;\n        ELSE\n            v_star_rating := 3;\n        END IF;\n        \n        IF v_expense_ratio > 0.015 THEN\n            v_star_rating := v_star_rating - 1;\n        END IF;\n        \n        UPDATE funds\n        SET star_rating = v_star_rating\n        WHERE fund_id = v_fund_id;\n    END LOOP;\n    CLOSE fund_cursor;\nEND;",
    "database_name": "investment_fp_tracking",
    "tables": [
      "funds",
      "fund_assets"
    ],
    "id": 133
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named insert_insider_summary that performs a single INSERT operation into the table named insiders, selecting data from the same insiders table and using a correlated subquery with the insider_trades table; the procedure populates the insiders table's columns insider_id, name, company_id, and status by selecting the insider_id, name, and company_id directly from the source insiders table (aliased as i) and assigning the literal string value 'ACTIVE' to the status column for every row inserted; the source data for the insert is filtered by two conditions joined with a logical AND: the first condition checks that the status column in the source insiders table is NULL, and the second condition uses an EXISTS clause to verify that at least one corresponding record exists in the insider_trades table (aliased as it) where the insider_id column in the insider_trades table matches the insider_id column from the current row of the outer insiders table query.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_insider_summary\nIS\nBEGIN\n   INSERT INTO insiders (insider_id, name, company_id, status)\n   SELECT i.insider_id,\n          i.name,\n          i.company_id,\n          'ACTIVE'\n   FROM insiders i\n   WHERE i.status IS NULL\n   AND EXISTS (\n      SELECT 1\n      FROM insider_trades it\n      WHERE it.insider_id = i.insider_id\n   );\nEND;",
    "database_name": "insider_taa_reporting",
    "tables": [
      "insider_trades",
      "insiders",
      "tickers"
    ],
    "id": 134
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named sp_get_action_summary that accepts three input parameters: p_start_date of type VARCHAR2 representing the beginning date of the period to analyze, p_end_date of type VARCHAR2 representing the ending date of the period to analyze, and p_status of type VARCHAR2 representing the status filter for actions, and declares two local variables v_total_actions and v_total_cost both of type NUMBER, then executes a SELECT query on the recall_actions table that counts the number of action_id values and calculates the sum of action_cost values (converted from string to number using the TO_NUMBER function) for rows where the action_status column matches the p_status parameter and where the action_date column (converted from string to date using the TO_DATE function with 'YYYY-MM-DD' format) falls between the p_start_date and p_end_date parameters (also converted from string to date using the TO_DATE function with 'YYYY-MM-DD' format), and stores these calculated values in the v_total_actions and v_total_cost variables respectively.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp_get_action_summary(p_start_date VARCHAR2, p_end_date VARCHAR2, p_status VARCHAR2) IS v_total_actions NUMBER; v_total_cost NUMBER; BEGIN SELECT COUNT(action_id), SUM(TO_NUMBER(action_cost)) INTO v_total_actions, v_total_cost FROM recall_actions WHERE action_status = p_status AND TO_DATE(action_date, 'YYYY-MM-DD') BETWEEN TO_DATE(p_start_date, 'YYYY-MM-DD') AND TO_DATE(p_end_date, 'YYYY-MM-DD'); END;",
    "database_name": "medical_dr_management",
    "tables": [
      "recall_actions",
      "recall_communications"
    ],
    "id": 135
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_household_income_on_delete that returns a trigger, which is executed as an AFTER DELETE trigger named trg_update_household_income_del on the people table for each row, where the function's logic explicitly returns the OLD record without performing any data modification, thereby leaving the household income and all other columns in related tables completely unchanged following a person's deletion, as the function contains no UPDATE, INSERT, DELETE, or SELECT statements and includes only comments noting that the employment_status column is non-numeric and that potential updates to household_size or recalculation of income based on other business logic are not implemented within this function.",
    "plsql": "CREATE OR REPLACE FUNCTION update_household_income_on_delete() RETURNS TRIGGER AS $$\nBEGIN\n    -- After a person is deleted, keep the household income unchanged\n    -- since employment_status is not a numeric income field\n    -- Alternatively, set to '0' or recalculate based on other logic if needed\n    -- Here we simply do nothing to the income column to avoid cast errors\n    -- If business logic requires updating household_size or other fields, \n    -- that should be handled separately\n    RETURN OLD;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_update_household_income_del\nAFTER DELETE ON people\nFOR EACH ROW EXECUTE FUNCTION update_household_income_on_delete();",
    "database_name": "demographics_and_household_composition",
    "tables": [
      "addresses",
      "cities",
      "states",
      "countries",
      "households",
      "people",
      "genders",
      "ethnicities"
    ],
    "_source": "plfactory27",
    "id": 136
  },
  {
    "ir": "Write a PLpgSQL stored procedure that updates the status column in the buses table to a specified new_status value for all rows where the year_of_manufacture column matches a given year parameter, and simultaneously sets the modified_on column to the current timestamp to reflect the time of modification. The procedure accepts two parameters: year, which is of type text and represents the year of manufacture to filter the rows, and new_status, also of type text, which specifies the new status to be assigned to the matching rows. The operation involves an UPDATE statement that targets the buses table, modifying the status and modified_on columns based on the condition that the year_of_manufacture column equals the provided year parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_bus_status_based_on_year(year text, new_status text) LANGUAGE plpgsql AS $$\nBEGIN\n  UPDATE buses\n  SET status = new_status, modified_on = CURRENT_TIMESTAMP\n  WHERE year_of_manufacture = year;\nEND;\n$$;",
    "database_name": "bus_fleet_management_and_tracking",
    "tables": [
      "buses",
      "driver_assignments"
    ],
    "id": 137
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_staffing_needs_year that is automatically executed after each new row is inserted into the nursing_roles table, and this function performs a single INSERT operation into the staffing_needs table, where it calculates and populates seven columns: for the need_id column, it uses the value from the newly inserted nursing_roles row's role_id column added to 2000; for the year column, it calculates the current calendar year using EXTRACT(YEAR FROM CURRENT_DATE) and adds 2 to it; for the role_id column, it directly uses the new row's role_id value; for the anticipated_needs column, it computes the difference between the new row's projected_2030 column value and its current_2020 column value; for the current_staff column, it uses the new row's current_2020 value; for the shortage column, it again computes the difference between projected_2030 and current_2020; and for the recruitment_effort column, it uses a CASE expression that evaluates the computed difference between projected_2030 and current_2020, assigning the string 'High' if this difference exceeds 3000, otherwise assigning the string 'Medium'.",
    "plsql": "CREATE OR REPLACE FUNCTION update_staffing_needs_year() RETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO staffing_needs (need_id, year, role_id, anticipated_needs, current_staff, shortage, recruitment_effort)\n  SELECT NEW.role_id + 2000, EXTRACT(YEAR FROM CURRENT_DATE) + 2, NEW.role_id, NEW.projected_2030 - NEW.current_2020, NEW.current_2020, NEW.projected_2030 - NEW.current_2020, CASE WHEN NEW.projected_2030 - NEW.current_2020 > 3000 THEN 'High' ELSE 'Medium' END;\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_update_staffing_needs_year\nAFTER INSERT ON nursing_roles\nFOR EACH ROW\nEXECUTE FUNCTION update_staffing_needs_year();",
    "database_name": "healthcare_workforce_analysis_and_projections",
    "tables": [
      "nursing_roles",
      "staffing_needs",
      "workforce_trends"
    ],
    "_source": "plfactory30",
    "id": 138
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `sp2` that accepts three input parameters: `para_manufacturer_id` of type `NUMBER`, `para_contact_email` of type `VARCHAR2`, and `para_headquarters` of type `VARCHAR2`. The procedure first performs an `UPDATE` operation on the `manufacturers` table, setting the `contact_email` column to the value provided in `para_contact_email` for all rows where the `manufacturer_id` column matches the value provided in `para_manufacturer_id`. Following this update, the procedure evaluates a conditional statement: if the value of `para_headquarters` is exactly equal to the string literal 'USA', then an `INSERT` operation is executed. This `INSERT` adds a new row into the `manufacturers` table with the following column values: `manufacturer_id` is set to `para_manufacturer_id`, `manufacturer_name` is set to the string literal 'New Manufacturer', `contact_email` is set to `para_contact_email`, `headquarters` is set to `para_headquarters`, `founded_year` is set to the numeric literal 2023, `ceo` is set to the string literal 'John Doe', and `website` is set to the string literal 'www.newmanufacturer.com'. If the condition `para_headquarters = 'USA'` is false, meaning `para_headquarters` is not 'USA', then a `DELETE` operation is performed on the `cars` table, removing all rows where the `manufacturer_id` column matches the value provided in `para_manufacturer_id`.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp2(para_manufacturer_id NUMBER, para_contact_email VARCHAR2, para_headquarters VARCHAR2) IS\nBEGIN\n  UPDATE manufacturers SET contact_email = para_contact_email WHERE manufacturer_id = para_manufacturer_id;\n  IF para_headquarters = 'USA' THEN\n    INSERT INTO manufacturers (manufacturer_id, manufacturer_name, contact_email, headquarters, founded_year, ceo, website)\n    VALUES (para_manufacturer_id, 'New Manufacturer', para_contact_email, para_headquarters, 2023, 'John Doe', 'www.newmanufacturer.com');\n  ELSE\n    DELETE FROM cars WHERE manufacturer_id = para_manufacturer_id;\n  END IF;\nEND;",
    "database_name": "automotive_dfcpa_characte",
    "tables": [
      "cars",
      "manufacturers",
      "performance_metrics"
    ],
    "id": 139
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named insert_new_incentive that accepts three input parameters: p_employee_id of type NUMBER to identify the employee, p_amount of type NUMBER to specify the incentive amount, and p_incentive_date of type DATE to set the date for the incentive; the procedure begins by validating these parameters, first checking if p_employee_id is NULL and raising application error -20001 with the message 'Employee ID cannot be null' if true, then checking if p_amount is either NULL or less than or equal to zero and raising application error -20002 with the message 'Amount must be positive' if true, then checking if p_incentive_date is NULL and raising application error -20003 with the message 'Incentive date cannot be null' if true; if all validations pass, the procedure constructs a result string in a local variable v_result by concatenating the literal 'Incentive processed: Employee=' with the p_employee_id value, then the literal ', Amount=' with the p_amount value, then the literal ', Date=' with the p_incentive_date value converted to a string using the TO_CHAR function with the format model 'DD-MON-YYYY'; finally, the procedure executes a NULL statement which serves as a placeholder for the actual business logic that would perform the insertion of the incentive record.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_new_incentive(\n    p_employee_id IN NUMBER,\n    p_amount IN NUMBER,\n    p_incentive_date IN DATE\n) IS\n    v_result VARCHAR2(200);\nBEGIN\n    -- Validate input parameters\n    IF p_employee_id IS NULL THEN\n        RAISE_APPLICATION_ERROR(-20001, 'Employee ID cannot be null');\n    END IF;\n    \n    IF p_amount IS NULL OR p_amount <= 0 THEN\n        RAISE_APPLICATION_ERROR(-20002, 'Amount must be positive');\n    END IF;\n    \n    IF p_incentive_date IS NULL THEN\n        RAISE_APPLICATION_ERROR(-20003, 'Incentive date cannot be null');\n    END IF;\n    \n    -- Create result message\n    v_result := 'Incentive processed: Employee=' || p_employee_id || \n                ', Amount=' || p_amount || \n                ', Date=' || TO_CHAR(p_incentive_date, 'DD-MON-YYYY');\n    \n    NULL; -- Placeholder for actual business logic\nEND;",
    "database_name": "bike_ssuaw_data",
    "tables": [
      "INCENTIVES"
    ],
    "id": 140
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_validate_year_dates that fires before any INSERT or UPDATE operation on the years table for each affected row, and performs the following sequence of operations: it first declares a local DATE variable v_date_check; then, for the new value of the start_date column, it attempts to convert the string to a DATE using the format 'YYYY-MM-DD', and if this conversion fails for any reason, it catches the exception and overwrites the :NEW.start_date value with the current system date formatted as 'YYYY-MM-DD'; it repeats this identical validation and correction process for the new value of the end_date column, also assigning the current date string if the conversion fails; after ensuring both date strings are in a valid format, it performs a lexicographical string comparison to check if the start_date string is greater than the end_date string, and if so, it sets the end_date string equal to the start_date string; it then constructs a value for the year_name column by concatenating the literal 'Period ', the first four characters (the year) from the start_date string, a hyphen, and the first four characters from the end_date string; finally, it sets the updated_at column to the current system date and time formatted as 'YYYY-MM-DD HH24:MI:SS'.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_validate_year_dates\nBEFORE INSERT OR UPDATE ON years\nFOR EACH ROW\nDECLARE\n    v_date_check DATE;\nBEGIN\n    BEGIN\n        v_date_check := TO_DATE(:NEW.start_date, 'YYYY-MM-DD');\n    EXCEPTION\n        WHEN OTHERS THEN\n            :NEW.start_date := TO_CHAR(SYSDATE, 'YYYY-MM-DD');\n    END;\n    BEGIN\n        v_date_check := TO_DATE(:NEW.end_date, 'YYYY-MM-DD');\n    EXCEPTION\n        WHEN OTHERS THEN\n            :NEW.end_date := TO_CHAR(SYSDATE, 'YYYY-MM-DD');\n    END;\n    IF :NEW.start_date > :NEW.end_date THEN\n        :NEW.end_date := :NEW.start_date;\n    END IF;\n    :NEW.year_name := 'Period ' || SUBSTR(:NEW.start_date, 1, 4) || '-' || SUBSTR(:NEW.end_date, 1, 4);\n    :NEW.updated_at := TO_CHAR(SYSDATE, 'YYYY-MM-DD HH24:MI:SS');\nEND;",
    "database_name": "higher_edae_data",
    "tables": [
      "demographics",
      "college_demographics",
      "colleges",
      "categories",
      "years"
    ],
    "_source": "plfactory20",
    "id": 141
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named proc_analyze_share_distribution that accepts two input parameters, p_period_start and p_period_end, both of type DATE, representing the start and end dates of a financial period, respectively. It also includes an output parameter, p_total_shares, of type NUMBER, intended to hold the total number of shares calculated over the specified period. The procedure is designed to analyze share distribution data, but due to the absence of the necessary tables, specifically SHARE_TRANSACTIONS and FINANCIAL_PERIODS, and their associated columns, the SQL logic that would perform this analysis has been removed. Consequently, the procedure sets the output parameter p_total_shares to 0, indicating no shares were calculated or analyzed. The procedure does not perform any operations such as updates, inserts, deletes, or selects, nor does it involve any conditional logic, function calls, or special operations.",
    "plsql": "CREATE OR REPLACE PROCEDURE proc_analyze_share_distribution(\n    p_period_start IN DATE,\n    p_period_end IN DATE,\n    p_total_shares OUT NUMBER\n)\nIS\nBEGIN\n    -- The original SQL statement referenced tables (SHARE_TRANSACTIONS, FINANCIAL_PERIODS)\n    -- that are not defined in the provided database schema.\n    -- To allow the procedure to compile, the problematic SQL has been removed.\n    -- As no data source is available, p_total_shares is set to 0.\n    p_total_shares := 0;\nEND;",
    "database_name": "corporate_frasc_managemen",
    "tables": [
      "SHAREHOLDERS",
      "SHARE_CAPITAL",
      "SHARE_CLASSES",
      "SHARE_TRANSACTIONS",
      "FINANCIAL_PERIODS"
    ],
    "id": 142
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named calculate_dataset_statistics that accepts two parameters: p_dataset_id as an input parameter of type NUMBER which is intended to identify a specific dataset for statistical calculation, and p_avg_value as an output parameter of type NUMBER which will return the calculated average value to the calling program. The procedure begins by setting the output parameter p_avg_value to 0 as a default value, with a comment indicating that in a production implementation this would be replaced with actual database queries to calculate statistics from tables. The procedure includes an exception handling block that catches any exceptions (WHEN OTHERS), sets the output parameter p_avg_value to NULL to indicate an error condition, and then re-raises the exception to propagate the error to the calling environment. The procedure does not perform any database operations such as SELECT, INSERT, UPDATE, or DELETE statements in its current implementation.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_dataset_statistics(\n    p_dataset_id IN NUMBER,\n    p_avg_value OUT NUMBER\n)\nIS\nBEGIN\n    -- Since no schema is provided, return a default value\n    -- In a real implementation, this would query actual tables\n    p_avg_value := 0;\n    \n    -- Add exception handling for robustness\nEXCEPTION\n    WHEN OTHERS THEN\n        p_avg_value := NULL;\n        RAISE;\nEND;",
    "database_name": "climate_awdc_464174",
    "tables": [
      "CLIMATE_DATA",
      "COLLECTION_METHODS",
      "DATASETS",
      "DATA_TYPES",
      "LOCATIONS",
      "ROLES",
      "USERS",
      "USER_ROLES"
    ],
    "id": 143
  },
  {
    "ir": "Write a PLpgSQL stored procedure named update_response_counts_conditionally that takes five parameters: p_survey_id, p_option_id, p_bracket_id, p_increment, and p_decrement, all of type BIGINT. This procedure updates the responses table, specifically modifying the response_count column based on conditional logic. For rows where the survey_id matches p_survey_id, option_id matches p_option_id, and bracket_id matches p_bracket_id, the procedure checks the current value of response_count. If response_count is greater than 100, it increases response_count by the value of p_increment. If response_count is less than 50, it decreases response_count by the value of p_decrement, ensuring the result is not negative by using the GREATEST function to compare the decremented value with 0. If response_count is between 50 and 100 inclusive, it remains unchanged. Additionally, the updated_at column is set to the current timestamp using CURRENT_TIMESTAMP to reflect the time of modification.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_response_counts_conditionally(\n    p_survey_id BIGINT,\n    p_option_id BIGINT,\n    p_bracket_id BIGINT,\n    p_increment BIGINT,\n    p_decrement BIGINT\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE responses \n    SET response_count = CASE \n        WHEN response_count > 100 THEN response_count + p_increment\n        WHEN response_count < 50 THEN GREATEST(0, response_count - p_decrement)\n        ELSE response_count\n    END,\n    updated_at = CURRENT_TIMESTAMP\n    WHERE survey_id = p_survey_id \n    AND option_id = p_option_id \n    AND bracket_id = p_bracket_id;\nEND;\n$$;",
    "database_name": "age_based_survey_responses",
    "tables": [
      "surveys",
      "response_options",
      "responses",
      "age_brackets"
    ],
    "id": 144
  },
  {
    "ir": "Write a PLpgSQL stored procedure named process_animal_health_updates that accepts four input parameters: p_health_status of type TEXT, p_special_needs_flag of type BIGINT, p_medical_notes of type TEXT, and p_behavioral_notes of type TEXT, and performs the following operations: first, it declares three local variables - processed_count initialized to 0 for tracking the number of animals processed, animal_record as a RECORD type for storing animal data during iteration, and next_outcome_id as a BIGINT for generating unique outcome identifiers; then it calculates the next available outcome_id by querying the animal_outcomes table to find the maximum existing outcome_id value, adding 1 to this maximum, or using 1 if no records exist; next, it iterates through all records in the animals table where the health_status column matches the p_health_status parameter and the special_needs column equals the p_special_needs_flag parameter; for each matching animal record (up to a maximum of 3), it inserts a new row into the animal_outcomes table containing the next_outcome_id, the animal_id from the current animal_record, the current date converted to text as the outcome_date, the literal string 'Health Update' as the outcome_type, and a concatenated string combining 'Medical: ' with the p_medical_notes parameter, ', Behavior: ' with the p_behavioral_notes parameter as the outcome_details; after each insertion, it increments both the processed_count and next_outcome_id variables; the loop terminates when processed_count reaches 3, ensuring that only the first three matching animals receive health update outcome records.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_animal_health_updates(\n    p_health_status TEXT,\n    p_special_needs_flag BIGINT,\n    p_medical_notes TEXT,\n    p_behavioral_notes TEXT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    processed_count INTEGER := 0;\n    animal_record RECORD;\n    next_outcome_id BIGINT;\nBEGIN\n    -- Get the next available outcome_id by finding the maximum existing value\n    SELECT COALESCE(MAX(outcome_id), 0) + 1 INTO next_outcome_id FROM animal_outcomes;\n    \n    FOR animal_record IN \n        SELECT animal_id FROM animals \n        WHERE health_status = p_health_status\n        AND special_needs = p_special_needs_flag\n    LOOP\n        INSERT INTO animal_outcomes (outcome_id, animal_id, outcome_date, outcome_type, outcome_details)\n        VALUES (next_outcome_id, animal_record.animal_id, CURRENT_DATE::text, 'Health Update', \n                'Medical: ' || p_medical_notes || ', Behavior: ' || p_behavioral_notes);\n        \n        processed_count := processed_count + 1;\n        next_outcome_id := next_outcome_id + 1;\n        \n        IF processed_count >= 3 THEN\n            EXIT;\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "animal_shelter_management_and_record_keeping",
    "tables": [
      "adopters",
      "adoption_applications",
      "adoptions",
      "animals",
      "animal_intakes",
      "animal_outcomes"
    ],
    "id": 145
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named sp_proc4 that accepts three input parameters: para_value1 of type NUMBER representing the first numeric input value, para_value2 of type NUMBER representing the second numeric input value, and para_threshold of type NUMBER representing a threshold value used for conditional logic and calculations; the procedure declares a local variable v_result of type NUMBER to store intermediate calculation results, then begins execution by first checking if the para_threshold parameter is greater than zero, and if this condition is true, it performs an addition operation by assigning the sum of para_value1 and para_value2 to the variable v_result; subsequently, the procedure checks if the para_value1 parameter is greater than zero, and if this condition is met, it performs a multiplication operation by updating the v_result variable to be the product of its current value and the para_threshold parameter value; finally, the procedure uses the DBMS_OUTPUT.PUT_LINE function call to output a text string 'Processing completed with result: ' concatenated with the current value of the v_result variable to the standard output buffer.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp_proc4(para_value1 NUMBER, para_value2 NUMBER, para_threshold NUMBER) IS\n  v_result NUMBER;\nBEGIN\n  -- Perform basic calculations instead of table operations\n  IF para_threshold > 0 THEN\n    v_result := para_value1 + para_value2;\n  END IF;\n  \n  IF para_value1 > 0 THEN\n    v_result := v_result * para_threshold;\n  END IF;\n  \n  -- Use DBMS_OUTPUT instead of table operations\n  DBMS_OUTPUT.PUT_LINE('Processing completed with result: ' || v_result);\nEND;",
    "database_name": "github_rmaa_tracking",
    "tables": [],
    "id": 146
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `delete_old_sensor_data` that accepts a single input parameter. This parameter is named `p_sensor_id` and is of the `NUMBER` data type; its purpose is to specify the unique identifier of the sensor for which data records are to be processed. The procedure's sole operation is to perform a `DELETE` statement on the `sensor_data` table. This `DELETE` operation targets rows within the `sensor_data` table that satisfy two specific conditions simultaneously. The first condition requires that the value in the `sensor_id` column of a given row must be equal to the value provided by the `p_sensor_id` input parameter. The second condition requires that the value in the `wall_time` column of the same row must be less than a dynamically calculated date string. This dynamic date string is derived by first obtaining the current system date and time using the `SYSDATE` function, then subtracting 30 days from this current date, and finally converting the resulting date (current date minus 30 days) into a character string formatted as 'YYYY-MM-DD' using the `TO_CHAR` function. Therefore, the procedure effectively removes all records from the `sensor_data` table associated with the specified `p_sensor_id` where the `wall_time` is older than 30 days from the current date.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_old_sensor_data(p_sensor_id IN NUMBER)\nIS\nBEGIN\n    DELETE FROM sensor_data\n    WHERE sensor_id = p_sensor_id AND wall_time < TO_CHAR(SYSDATE - 30, 'YYYY-MM-DD');\nEND;",
    "database_name": "industrial_aard_monitorin",
    "tables": [
      "robots",
      "sensors",
      "sensor_data",
      "alarms",
      "robot_data",
      "maintenance_logs",
      "sites"
    ],
    "id": 147
  },
  {
    "ir": "Write a PLpgSQL stored procedure that accepts three parameters: para_crop_type of type bigint, para_quit_weeks of type bigint, and para_target_farm of type bigint. The procedure begins by declaring two local variables, min_insects and next_id, both of type bigint. It then executes a SELECT statement to find the minimum value of the estimated_insects_count column from the crop_data table, where the crop_type_id matches the para_crop_type parameter and the number_weeks_quit is less than or equal to the para_quit_weeks parameter, storing the result in the min_insects variable. Next, it performs another SELECT statement to determine the next available pesticide_application_record_id by selecting the maximum value of the pesticide_application_record_id column from the pesticide_application_records table, defaulting to 0 if no records exist, and adding 1 to this maximum value, storing the result in the next_id variable. The procedure then inserts a new record into the pesticide_application_records table with the following values: next_id for the pesticide_application_record_id, a hardcoded value of '1' for the crop_data_id, a hardcoded date '2024-05-10' for the application_date, a hardcoded dose value of 8.75, and 'automated' for both the created_by and updated_by columns, with the created_at and updated_at columns set to the hardcoded timestamp '2024-05-10 11:20:00'. Finally, the procedure deletes rows from the crop_data table where the farm_id matches the para_target_farm parameter, the season is equal to 2, and the crop_damage is equal to 0.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp(para_crop_type bigint, para_quit_weeks bigint, para_target_farm bigint) \nLANGUAGE plpgsql AS $$ \nDECLARE \n    min_insects bigint; \n    next_id bigint;\nBEGIN \n    SELECT MIN(estimated_insects_count) INTO min_insects \n    FROM crop_data \n    WHERE crop_type_id = para_crop_type AND number_weeks_quit <= para_quit_weeks; \n    \n    SELECT COALESCE(MAX(pesticide_application_record_id), 0) + 1 INTO next_id \n    FROM pesticide_application_records;\n    \n    INSERT INTO pesticide_application_records (pesticide_application_record_id, crop_data_id, application_date, dose, created_by, created_at, updated_by, updated_at) \n    VALUES (next_id, '1', '2024-05-10', 8.75, 'automated', '2024-05-10 11:20:00', 'automated', '2024-05-10 11:20:00'); \n    \n    DELETE FROM crop_data \n    WHERE farm_id = para_target_farm AND season = 2 AND crop_damage = 0; \nEND; $$;",
    "database_name": "agricultural_pest_management_and_crop_analysis",
    "tables": [
      "crop_cycles",
      "crop_data",
      "crop_types",
      "farms",
      "pesticide_application_records"
    ],
    "id": 148
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_insert_species_normalized_degree that is defined to execute automatically after a new row is inserted into the species table for each affected row, and it first attempts to insert a new record into the ecological_sites table using the site_id value from the newly inserted species row, along with the literal string 'Generated Site' for the site_name column, 'Unknown' for the location column, and 'unknown' for the site_type column, but if this insertion fails due to a unique constraint violation on an index, the trigger catches the DUP_VAL_ON_INDEX exception and takes no action, allowing execution to proceed, and then the trigger performs an update operation on the ecological_sites table, setting the site_type column to the literal value 'updated' for every existing row where the site_id column matches the site_id value from the newly inserted species row.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_insert_species_normalized_degree\nAFTER INSERT ON species\nFOR EACH ROW\nBEGIN\n  -- Handle ecological_sites insertion with duplicate check\n  BEGIN\n    INSERT INTO ecological_sites (site_id, site_name, location, site_type)\n    VALUES (:NEW.site_id, 'Generated Site', 'Unknown', 'unknown');\n  EXCEPTION\n    WHEN DUP_VAL_ON_INDEX THEN\n      NULL; -- Site already exists, continue\n  END;\n\n  -- Update ecological_sites\n  UPDATE ecological_sites \n  SET site_type = 'updated' \n  WHERE site_id = :NEW.site_id;\n  \n  -- Note: Removed the INSERT into species within the AFTER INSERT trigger\n  -- to avoid potential deadlocks and mutating table issues\n  -- If inserting additional species records is required, consider:\n  -- 1. Using a separate procedure called from application logic\n  -- 2. Using a compound trigger with AFTER STATEMENT section\n  -- 3. Using a sequence for species_id generation\nEND;",
    "database_name": "ecological_iasd_analysis",
    "tables": [
      "species",
      "ecological_sites"
    ],
    "_source": "plfactory3",
    "id": 149
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_individual_ethnicity_check that is defined to execute automatically before any insert operation on the individuals table for each new row being inserted, which declares two local VARCHAR2 variables v_officer_ethnicity and v_self_ethnicity each with a maximum length of 255 characters and a third local VARCHAR2 variable v_match_flag with a maximum length of 10 characters, and within its execution block first assigns the value of the new row's officer_defined_ethnicity column to v_officer_ethnicity after applying the LOWER function to convert all characters to lowercase and the TRIM function to remove leading and trailing spaces, then assigns the value of the new row's self_defined_ethnicity column to v_self_ethnicity after applying the same LOWER and TRIM functions, then uses an IF-THEN-ELSE conditional statement to compare the two processed values: if v_officer_ethnicity is exactly equal to v_self_ethnicity, the v_match_flag variable is set to the string 'MATCH', otherwise v_match_flag is set to the string 'MISMATCH', and finally updates the :NEW.officer_defined_ethnicity and :NEW.self_defined_ethnicity pseudo-record columns directly with the trimmed and lowercased values stored in v_officer_ethnicity and v_self_ethnicity respectively.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_individual_ethnicity_check\nBEFORE INSERT ON individuals\nFOR EACH ROW\nDECLARE\n    v_officer_ethnicity VARCHAR2(255);\n    v_self_ethnicity VARCHAR2(255);\n    v_match_flag VARCHAR2(10);\nBEGIN\n    v_officer_ethnicity := LOWER(TRIM(:NEW.officer_defined_ethnicity));\n    v_self_ethnicity := LOWER(TRIM(:NEW.self_defined_ethnicity));\n    IF v_officer_ethnicity = v_self_ethnicity THEN\n        v_match_flag := 'MATCH';\n    ELSE\n        v_match_flag := 'MISMATCH';\n    END IF;\n    :NEW.officer_defined_ethnicity := v_officer_ethnicity;\n    :NEW.self_defined_ethnicity := v_self_ethnicity;\nEND;",
    "database_name": "policing_oasasd_managemen",
    "tables": [
      "incidents",
      "incident_outcomes",
      "outcomes",
      "objects_of_search",
      "individuals",
      "officers",
      "policing_operations"
    ],
    "_source": "plfactory5",
    "id": 150
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `calculate_feedback_statistics` that accepts two input parameters: `p_customer_id`, which is of type `bigint` and represents the unique identifier of a customer, and `p_min_rating`, which is also of type `bigint` and specifies the minimum rating threshold for feedback to be considered. The procedure initializes four local variables: `total_feedback` as an `integer` with an initial value of 0, `helpful_feedback` as an `integer` with an initial value of 0, `avg_rating` as a `numeric` with an initial value of 0, and `rating_sum` as an `integer` with an initial value of 0. It then iterates through a result set obtained by selecting `feedback_id`, `rating`, `is_helpful`, and `comments` columns from the `feedback` table. This selection is filtered to include only rows where the `customer_id` column matches the `p_customer_id` input parameter and the `rating` column is greater than or equal to the `p_min_rating` input parameter. For each row (`feedback_rec`) retrieved during this iteration, the procedure increments the `total_feedback` variable by 1 and adds the value of `feedback_rec.rating` to the `rating_sum` variable. Subsequently, it checks if the `is_helpful` column of the current `feedback_rec` is equal to 1. If this condition is true, the `helpful_feedback` variable is incremented by 1. After processing the helpfulness condition, the procedure raises a notice message to the client, displaying the `feedback_id`, `rating`, and a textual representation of the `is_helpful` status (displaying 'Yes' if `is_helpful` is 1, and 'No' otherwise) for the current feedback record. After the loop completes, the procedure checks if the `total_feedback` variable is greater than 0. If this condition is true, it calculates the `avg_rating` by dividing the `rating_sum` (cast to a `numeric` type) by the `total_feedback`. Finally, the procedure raises another notice message to the client, summarizing the statistics for the `p_customer_id`, including the `total_feedback`, `helpful_feedback`, and the `avg_rating` rounded to two decimal places.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_feedback_statistics(p_customer_id bigint, p_min_rating bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    feedback_rec RECORD;\n    total_feedback integer := 0;\n    helpful_feedback integer := 0;\n    avg_rating numeric := 0;\n    rating_sum integer := 0;\nBEGIN\n    FOR feedback_rec IN \n        SELECT feedback_id, rating, is_helpful, comments\n        FROM feedback \n        WHERE customer_id = p_customer_id AND rating >= p_min_rating\n    LOOP\n        total_feedback := total_feedback + 1;\n        rating_sum := rating_sum + feedback_rec.rating;\n        \n        IF feedback_rec.is_helpful = 1 THEN\n            helpful_feedback := helpful_feedback + 1;\n        END IF;\n        \n        RAISE NOTICE 'Feedback ID %: Rating %, Helpful: %', feedback_rec.feedback_id, feedback_rec.rating, \n                     CASE WHEN feedback_rec.is_helpful = 1 THEN 'Yes' ELSE 'No' END;\n    END LOOP;\n    \n    IF total_feedback > 0 THEN\n        avg_rating := rating_sum::numeric / total_feedback;\n    END IF;\n    \n    RAISE NOTICE 'Customer % statistics: % total feedback, % helpful, average rating: %', \n                 p_customer_id, total_feedback, helpful_feedback, round(avg_rating, 2);\nEND;\n$$;",
    "database_name": "apparel_size_conversion_and_cup_size_guide",
    "tables": [
      "customers",
      "feedback",
      "measurements",
      "size_guides"
    ],
    "id": 151
  },
  {
    "ir": "Write a PLpgSQL stored procedure that iterates over records in the average_temperatures table to identify groups of records with the same location_id, year_id, and month_id that have more than one entry, deletes all but the record with the smallest avg_temp_id within each group, and updates the last_updated column of the remaining record to the current timestamp in epoch format converted to text.",
    "plsql": "CREATE OR REPLACE PROCEDURE consolidate_temperature_records()\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    duplicate_rec RECORD;\nBEGIN\n    FOR duplicate_rec IN \n        SELECT location_id, year_id, month_id, COUNT(*) as cnt\n        FROM average_temperatures\n        GROUP BY location_id, year_id, month_id\n        HAVING COUNT(*) > 1\n    LOOP\n        DELETE FROM average_temperatures\n        WHERE location_id = duplicate_rec.location_id\n        AND year_id = duplicate_rec.year_id\n        AND month_id = duplicate_rec.month_id\n        AND avg_temp_id NOT IN (\n            SELECT MIN(avg_temp_id)\n            FROM average_temperatures\n            WHERE location_id = duplicate_rec.location_id\n            AND year_id = duplicate_rec.year_id\n            AND month_id = duplicate_rec.month_id\n        );\n        \n        UPDATE average_temperatures\n        SET last_updated = EXTRACT(EPOCH FROM NOW())::text\n        WHERE location_id = duplicate_rec.location_id\n        AND year_id = duplicate_rec.year_id\n        AND month_id = duplicate_rec.month_id;\n    END LOOP;\nEND;\n$$;",
    "database_name": "climate_data_analysis_and_monitoring",
    "tables": [
      "average_temperatures",
      "climate_zones",
      "data_sources",
      "locations",
      "months",
      "temperature_data",
      "users",
      "years"
    ],
    "id": 152
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_update_team_owner that executes automatically before any INSERT or UPDATE operation on the teams table for each affected row, and within its logic, it first checks if the length of the new value for the team_owner column, provided as :NEW.team_owner, exceeds 50 characters; if this condition is true, it reassigns the :NEW.team_owner value to a truncated version obtained by calling the SUBSTR function with the original :NEW.team_owner string, a starting position of 1, and a length of 50, and then it performs a second, identical check on the new value for the team_manager column, :NEW.team_manager, and if its length also exceeds 50 characters, it similarly reassigns :NEW.team_manager to the result of the SUBSTR function called with :NEW.team_manager, a starting position of 1, and a length of 50.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_update_team_owner\nBEFORE INSERT OR UPDATE ON teams\nFOR EACH ROW\nBEGIN\n  IF LENGTH(:NEW.team_owner) > 50 THEN\n    :NEW.team_owner := SUBSTR(:NEW.team_owner, 1, 50);\n  END IF;\n  IF LENGTH(:NEW.team_manager) > 50 THEN\n    :NEW.team_manager := SUBSTR(:NEW.team_manager, 1, 50);\n  END IF;\nEND;",
    "database_name": "cycling_c_results",
    "tables": [
      "events",
      "results",
      "riders",
      "categories",
      "classes",
      "teams"
    ],
    "_source": "plfactory20",
    "id": 153
  },
  {
    "ir": "Write a PostgreSQL trigger function named cleanup_orphaned_investigations that is executed automatically by a trigger named trg_cleanup_orphaned_investigations, which is defined to fire AFTER a DELETE operation on the crime_incidents table for EACH ROW that is deleted. The function takes no explicit parameters but uses the special OLD record variable, which provides access to the column values of the row being deleted from crime_incidents. The function performs a DELETE operation on the investigations table, targeting all rows where the incident_id column in investigations matches the value of the incident_id column from the OLD record of the deleted crime_incidents row. After performing the deletion, the function returns the OLD record.",
    "plsql": "CREATE OR REPLACE FUNCTION cleanup_orphaned_investigations() RETURNS TRIGGER AS $$\nBEGIN\n  DELETE FROM investigations WHERE incident_id = OLD.incident_id;\n  RETURN OLD;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_cleanup_orphaned_investigations\nAFTER DELETE ON crime_incidents\nFOR EACH ROW EXECUTE FUNCTION cleanup_orphaned_investigations();",
    "database_name": "crime_reporting_and_incident_management",
    "tables": [
      "crime_incidents",
      "crime_codes",
      "districts",
      "investigations"
    ],
    "id": 154
  },
  {
    "ir": "Write a PostgreSQL database trigger function named archive_deleted_acquisition that is executed automatically by a trigger named trg_archive_deleted_acquisition, which is defined to fire BEFORE DELETE on the acquisitions table for each individual row being deleted; the function has no input parameters and returns a trigger type, and its body performs a single operation: it inserts a new row into a separate table named acquisitions_archive by selecting all column values from the OLD record, which is the row image of the acquisitions row about to be deleted, thereby copying the entire deleted row's data into the archive table; the function then returns the OLD row record, which is the standard behavior for a BEFORE DELETE trigger to allow the deletion to proceed; the acquisitions_archive table is defined with ten columns: acquisition_id of type BIGINT, artwork_id of type BIGINT, acquisition_date of type TEXT, source of type TEXT, price of type REAL, invoice_number of type TEXT, donor_id of type BIGINT, legal_status of type TEXT, condition_at_acquisition of type TEXT, and appraised_value of type REAL, which must structurally match the columns of the acquisitions table for the SELECT OLD.* operation to succeed.",
    "plsql": "CREATE TABLE acquisitions_archive (\n    acquisition_id BIGINT,\n    artwork_id BIGINT,\n    acquisition_date TEXT,\n    source TEXT,\n    price REAL,\n    invoice_number TEXT,\n    donor_id BIGINT,\n    legal_status TEXT,\n    condition_at_acquisition TEXT,\n    appraised_value REAL\n);\n\nCREATE OR REPLACE FUNCTION archive_deleted_acquisition() RETURNS TRIGGER AS $$\nBEGIN\n    INSERT INTO acquisitions_archive SELECT OLD.*;\n    RETURN OLD; -- For BEFORE DELETE triggers, RETURN OLD is typical if you don't modify the row.\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_archive_deleted_acquisition\nBEFORE DELETE ON acquisitions\nFOR EACH ROW EXECUTE FUNCTION archive_deleted_acquisition();",
    "database_name": "art_and_historical_artwork_documentation_and_management",
    "tables": [
      "acquisitions"
    ],
    "_source": "plfactory20",
    "id": 155
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named sp_update_location_statistics that accepts a single input parameter para_location_id of type NUMBER and performs a series of calculations and updates to adjust the population value in the locations table based on various health metrics. The procedure first declares six local variables: v_population, v_total_hosp, v_child_hosp, v_density, v_rate_per_100k, and v_new_population, all of type NUMBER. It then retrieves the current population value from the locations table where the location_id column matches the para_location_id parameter. Next, it calculates the sum of cumulative_total_hospitalizations and cumulative_children_hospitalizations from the hospitalization_data table for the specified location_id. The procedure then computes a hospitalization rate per 100,000 people by dividing the total hospitalizations by the population and multiplying by 100,000, setting this rate to 0 if either the population or total hospitalizations is zero or negative. It then determines a density metric by counting the number of records in the hospitalization_data table for the given location where the date_of_record is within the last month (using ADD_MONTHS(SYSDATE, -1) and TO_CHAR formatting). Based on this density value, the procedure adjusts the population: increasing it by 1% (using FLOOR function) if density exceeds 100, increasing it by 0.5% if density exceeds 50, keeping it unchanged if density exceeds 10, or decreasing it by 0.5% otherwise. The procedure then makes further adjustments to the population based on child hospitalization ratios: adding 1000 to the population if child hospitalizations exceed 20% of total hospitalizations, or subtracting 500 if child hospitalizations are less than 5% of total. Finally, it adjusts the population based on the hospitalization rate per 100k: adding 2000 if the rate exceeds 1000, or subtracting 200 if the rate is less than 100. The procedure concludes by updating the population column in the locations table with the calculated new_population value for the specified location_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp_update_location_statistics(para_location_id NUMBER) IS v_population NUMBER; v_total_hosp NUMBER; v_child_hosp NUMBER; v_density NUMBER; v_rate_per_100k NUMBER; v_new_population NUMBER; BEGIN SELECT population INTO v_population FROM locations WHERE location_id = para_location_id; SELECT SUM(cumulative_total_hospitalizations), SUM(cumulative_children_hospitalizations) INTO v_total_hosp, v_child_hosp FROM hospitalization_data WHERE location_id = para_location_id; IF v_population > 0 AND v_total_hosp > 0 THEN v_rate_per_100k := (v_total_hosp / v_population) * 100000; ELSE v_rate_per_100k := 0; END IF; SELECT COUNT(*) INTO v_density FROM hospitalization_data WHERE location_id = para_location_id AND date_of_record >= TO_CHAR(ADD_MONTHS(SYSDATE, -1), 'YYYY-MM-DD'); IF v_density > 100 THEN v_new_population := FLOOR(v_population * 1.01); ELSIF v_density > 50 THEN v_new_population := FLOOR(v_population * 1.005); ELSIF v_density > 10 THEN v_new_population := v_population; ELSE v_new_population := FLOOR(v_population * 0.995); END IF; IF v_child_hosp > v_total_hosp * 0.2 THEN v_new_population := v_new_population + 1000; ELSIF v_child_hosp < v_total_hosp * 0.05 THEN v_new_population := v_new_population - 500; END IF; IF v_rate_per_100k > 1000 THEN v_new_population := v_new_population + 2000; ELSIF v_rate_per_100k < 100 THEN v_new_population := v_new_population - 200; END IF; UPDATE locations SET population = v_new_population WHERE location_id = para_location_id; END;",
    "database_name": "public_hd_analysis",
    "tables": [
      "hospitalization_data",
      "hospitalization_statistics",
      "age_ranges",
      "locations",
      "hospital_data_sources",
      "data_quality",
      "reporting"
    ],
    "id": 156
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `update_conservation_status_based_on_mass` that takes no parameters. This procedure is designed to iterate through a specific set of bird species records and update their `conservation_status` based on their `mass`. The procedure begins by declaring a local variable named `species_record` of type `RECORD` to temporarily hold data fetched during the iteration. The core logic is encapsulated within a `FOR` loop that iterates over the results of a `SELECT` statement. This `SELECT` statement retrieves the `species_id` and `conservation_status` from the `bird_species` table (aliased as `bs`), and the `mass` from the `physical_characteristics` table (aliased as `pc`). These two tables are joined using an `INNER JOIN` condition where `bs.species_id` matches `pc.species_id`. The `WHERE` clause of this `SELECT` statement filters the results to include only those records where `pc.mass` is not `NULL`. For each `species_record` obtained from this query, a series of conditional checks are performed. The first condition checks if `species_record.mass` is greater than `1500.0` AND `species_record.conservation_status` does NOT `LIKE` the pattern `'%High Risk%'`. If both parts of this condition are true, an `UPDATE` statement is executed on the `bird_species` table, setting the `conservation_status` column to the literal string `'High Risk - Large Species'` for the row where `species_id` matches `species_record.species_id`. If the first condition is false, an `ELSIF` condition is evaluated. This condition checks if `species_record.mass` is less than `500.0` AND `species_record.conservation_status` does NOT `LIKE` the pattern `'%Protected%'`. If both parts of this `ELSIF` condition are true, an `UPDATE` statement is executed on the `bird_species` table, setting the `conservation_status` column to the literal string `'Protected - Small Species'` for the row where `species_id` matches `species_record.species_id`. If both the initial `IF` and the `ELSIF` conditions are false, an `ELSE` block is executed. Within this `ELSE` block, an `UPDATE` statement is executed on the `bird_species` table, setting the `conservation_status` column to the literal string `'Monitored - Standard'` for the row where `species_id` matches `species_record.species_id`. The loop continues until all relevant `species_record` entries have been processed.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_conservation_status_based_on_mass()\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    species_record RECORD;\nBEGIN\n    FOR species_record IN \n        SELECT bs.species_id, bs.conservation_status, pc.mass\n        FROM bird_species bs\n        JOIN physical_characteristics pc ON bs.species_id = pc.species_id\n        WHERE pc.mass IS NOT NULL\n    LOOP\n        IF species_record.mass > 1500.0 AND species_record.conservation_status NOT LIKE '%High Risk%' THEN\n            UPDATE bird_species \n            SET conservation_status = 'High Risk - Large Species'\n            WHERE species_id = species_record.species_id;\n        ELSIF species_record.mass < 500.0 AND species_record.conservation_status NOT LIKE '%Protected%' THEN\n            UPDATE bird_species \n            SET conservation_status = 'Protected - Small Species'\n            WHERE species_id = species_record.species_id;\n        ELSE\n            UPDATE bird_species \n            SET conservation_status = 'Monitored - Standard'\n            WHERE species_id = species_record.species_id;\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "bird_species_conservation_and_research",
    "tables": [
      "bird_species",
      "physical_characteristics"
    ],
    "id": 157
  },
  {
    "ir": "Write a PostgreSQL stored procedure named generate_distribution_report that accepts two input parameters: p_case_id of type bigint, which identifies a specific case, and p_class_filter of type bigint, which is used to filter claims by their class; the procedure first calculates the sum of the allowed_amount values from the claims table, after converting them to numeric, for all claims that are associated with the specified p_case_id by joining the claims table with the case_claimants table on the claimant_id column and where the claim_class from the claims table equals the provided p_class_filter, storing this sum in a local variable v_class_total; it then truncates the decimal portion of this v_class_total using the trunc function, storing the result in a new local variable v_truncated_total; subsequently, it retrieves the next available document_id for the case_documents table by selecting the maximum existing document_id value from the case_documents table, using the COALESCE function to substitute 0 if the maximum is null, and adding 1 to this value, storing the result in a local variable v_document_id; it then inserts a new record into the case_documents table with the newly generated v_document_id, the provided p_case_id, a document_name constructed by concatenating the string 'Distribution Report Class ' with the p_class_filter value, a file_path constructed by concatenating the string 'reports/distribution_class_' with the p_class_filter value, an underscore, the v_document_id value, and the string '.pdf', the current date converted to text for the upload_date, the string 'distribution report' for the document_type, and the string 'generated' for the document_status; finally, it inserts a new record into the case_updates table with an update_id generated by selecting the maximum existing update_id from the case_updates table, using COALESCE to substitute 0 if the maximum is null, and adding 1 to this value, the provided p_case_id, an update_note constructed by concatenating the string 'Distribution report generated for class ' with the p_class_filter value, the string ' with total amount ', and the v_truncated_total value, the current date converted to text for the update_date, an updated_by value obtained by selecting the participant_id from the case_participants table where the case_id matches the provided p_case_id and the role equals the string 'Attorney', limiting the result to one row, and the string 'financial' for the update_type.",
    "plsql": "CREATE OR REPLACE PROCEDURE generate_distribution_report(p_case_id bigint, p_class_filter bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_class_total numeric;\n    v_truncated_total numeric;\n    v_document_id bigint;\nBEGIN\n    SELECT SUM(allowed_amount::numeric)\n    INTO v_class_total\n    FROM claims c\n    JOIN case_claimants cc ON c.claimant_id = cc.claimant_id\n    WHERE cc.case_id = p_case_id AND c.claim_class = p_class_filter;\n    \n    v_truncated_total := trunc(v_class_total);\n    \n    SELECT COALESCE(MAX(document_id), 0) + 1\n    INTO v_document_id\n    FROM case_documents;\n    \n    INSERT INTO case_documents (document_id, case_id, document_name, file_path, upload_date, document_type, document_status)\n    VALUES (\n        v_document_id,\n        p_case_id,\n        'Distribution Report Class ' || p_class_filter,\n        'reports/distribution_class_' || p_class_filter || '_' || v_document_id || '.pdf',\n        CURRENT_DATE::text,\n        'distribution report',\n        'generated'\n    );\n    \n    INSERT INTO case_updates (update_id, case_id, update_note, update_date, updated_by, update_type)\n    VALUES (\n        (SELECT COALESCE(MAX(update_id), 0) + 1 FROM case_updates),\n        p_case_id,\n        'Distribution report generated for class ' || p_class_filter || ' with total amount ' || v_truncated_total,\n        CURRENT_DATE::text,\n        (SELECT participant_id FROM case_participants WHERE case_id = p_case_id AND role = 'Attorney' LIMIT 1),\n        'financial'\n    );\nEND;\n$$;",
    "database_name": "claims_management_and_recovery_in_legal_proceedings",
    "tables": [
      "cases",
      "case_claimants",
      "case_decisions",
      "case_documents",
      "case_participants",
      "case_updates",
      "claimants",
      "claims"
    ],
    "id": 158
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named GetModelVersionInfo that accepts a single input parameter p_model_id of type NUMBER, declares two local variables v_version_count and v_latest_version both of type NUMBER, executes a SELECT query on the MODEL_VERSIONS table to retrieve the count of all records and the maximum value of the VERSION_NUMBER column where the MODEL_ID column matches the input parameter p_model_id, and stores these values in the local variables v_version_count and v_latest_version respectively.",
    "plsql": "CREATE OR REPLACE PROCEDURE GetModelVersionInfo(p_model_id IN NUMBER) AS\n  v_version_count NUMBER;\n  v_latest_version NUMBER;\nBEGIN\n  SELECT COUNT(*), MAX(VERSION_NUMBER)\n  INTO v_version_count, v_latest_version\n  FROM MODEL_VERSIONS\n  WHERE MODEL_ID = p_model_id;\nEND GetModelVersionInfo;",
    "database_name": "business_pma_management",
    "tables": [
      "MODELS",
      "MODEL_ELEMENT_RELATIONSHIPS",
      "MODEL_ELEMENT_TYPES",
      "MODEL_VERSIONS"
    ],
    "id": 159
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named proc_cleanup_old_logs that accepts two parameters: p_days_old, an input parameter of type NUMBER, and p_deleted_count, an output parameter of type NUMBER. The procedure is designed to perform a cleanup operation on a hypothetical table named CHANGE_LOGS, which is not actually present in the database schema, hence the operations are placeholders. The procedure begins by initializing the output parameter p_deleted_count to 0. It then checks if the input parameter p_days_old is not null and greater than 0. If this condition is met, the procedure sets p_deleted_count to 0, indicating that no records have been deleted due to the absence of the CHANGE_LOGS table. If the condition is not met, p_deleted_count is again set to 0. The procedure includes an exception handling block that catches any exceptions that occur during execution. If an exception is raised, the procedure sets p_deleted_count to -1 and raises an application error with the error code -20001 and a message that includes the error description obtained from SQLERRM, indicating an error occurred in the cleanup procedure.",
    "plsql": "CREATE OR REPLACE PROCEDURE proc_cleanup_old_logs(p_days_old IN NUMBER, p_deleted_count OUT NUMBER)\nIS\nBEGIN\n    -- Initialize output parameter\n    p_deleted_count := 0;\n    \n    -- Since no schema is provided and CHANGE_LOGS table doesn't exist,\n    -- this is a placeholder implementation\n    IF p_days_old IS NOT NULL AND p_days_old > 0 THEN\n        p_deleted_count := 0; -- No records deleted as table doesn't exist\n    ELSE\n        p_deleted_count := 0;\n    END IF;\n    \nEXCEPTION\n    WHEN OTHERS THEN\n        p_deleted_count := -1;\n        RAISE_APPLICATION_ERROR(-20001, 'Error in cleanup procedure: ' || SQLERRM);\nEND;",
    "database_name": "machine_lmtae_252899",
    "tables": [
      "CHANGE_LOGS",
      "FEATURES",
      "PROJECTS",
      "TEAMS",
      "TRAINING_RESULTS",
      "USERS"
    ],
    "id": 160
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named aggregate_location_environment_data that begins by declaring variables v_location_id as NUMBER, v_location_name as VARCHAR2(255), v_avg_temp as NUMBER, v_avg_salinity as NUMBER, v_avg_ph as NUMBER, v_avg_oxygen as NUMBER, v_temp_variance as NUMBER, v_salinity_variance as NUMBER, v_total_samples as NUMBER, v_healthy_samples as NUMBER, v_stressed_samples as NUMBER, and v_max_researcher_id as NUMBER, then defines a cursor c_locations to select the id and location_name columns from the locations table, and proceeds to execute a statement that selects the NVL of the maximum id value from the researchers table into v_max_researcher_id, defaulting to 0 if the maximum is null, then opens the cursor c_locations and enters a loop that fetches rows from the cursor into v_location_id and v_location_name, exiting the loop when no more rows are found, and for each fetched location, within a nested BEGIN block, executes a SELECT statement on the marine_bivalves table for rows where the collection_location equals the current v_location_name, calculating the average of water_temperature, the average of salinity, the average of pH, the average of oxygen_level, the count of all rows, the sum of cases where health_status is 'HEALTHY' (counting 1 for each), and the sum of cases where health_status is 'STRESSED' (counting 1 for each), storing these results into v_avg_temp, v_avg_salinity, v_avg_ph, v_avg_oxygen, v_total_samples, v_healthy_samples, and v_stressed_samples respectively, then executes another SELECT statement on the marine_bivalves table for the same collection_location, calculating the variance of water_temperature and the variance of salinity, storing these into v_temp_variance and v_salinity_variance, and if a NO_DATA_FOUND exception occurs during these selects, it assigns 0 to all the variables v_avg_temp, v_avg_salinity, v_avg_ph, v_avg_oxygen, v_total_samples, v_healthy_samples, v_stressed_samples, v_temp_variance, and v_salinity_variance, then after the exception block, it applies the NVL function to v_avg_temp, v_avg_salinity, v_healthy_samples, and v_stressed_samples to replace any null values with 0, then checks a condition where if v_avg_temp is greater than 25 and v_avg_salinity is greater than 35, it increments v_max_researcher_id by 1 and inserts a new row into the researchers table with the new id, name as 'Hot-Saline Specialist', email as 'specialist@research.org', and affiliation as 'Environmental Research', or else if v_avg_temp is less than 15 and v_avg_salinity is less than 25, it increments v_max_researcher_id by 1 and inserts a new row into the researchers table with the new id, name as 'Cold-Fresh Specialist', email as 'specialist@research.org', and affiliation as 'Environmental Research', then checks another condition where if v_healthy_samples is greater than v_stressed_samples, it updates the locations table, setting the description column to 'Favorable Environment' for the row where id equals the current v_location_id, or else if v_stressed_samples is greater than v_healthy_samples, it updates the locations table, setting the description column to 'Challenging Environment' for the row where id equals the current v_location_id, and finally, for each location, it deletes rows from the marine_bivalves table where the collection_location equals the current v_location_name and the health_status is 'DECEASED', then closes the cursor c_locations after the loop completes.",
    "plsql": "CREATE OR REPLACE PROCEDURE aggregate_location_environment_data AS\n    v_location_id NUMBER;\n    v_location_name VARCHAR2(255);\n    v_avg_temp NUMBER;\n    v_avg_salinity NUMBER;\n    v_avg_ph NUMBER;\n    v_avg_oxygen NUMBER;\n    v_temp_variance NUMBER;\n    v_salinity_variance NUMBER;\n    v_total_samples NUMBER;\n    v_healthy_samples NUMBER;\n    v_stressed_samples NUMBER;\n    v_max_researcher_id NUMBER;\n    CURSOR c_locations IS SELECT id, location_name FROM locations;\nBEGIN\n    -- Get max researcher ID for new insertions\n    SELECT NVL(MAX(id), 0) INTO v_max_researcher_id FROM researchers;\n    \n    OPEN c_locations;\n    LOOP\n        FETCH c_locations INTO v_location_id, v_location_name;\n        EXIT WHEN c_locations%NOTFOUND;\n        \n        BEGIN\n            SELECT AVG(water_temperature), AVG(salinity), AVG(pH), AVG(oxygen_level),\n                   COUNT(*), \n                   SUM(CASE WHEN health_status = 'HEALTHY' THEN 1 ELSE 0 END),\n                   SUM(CASE WHEN health_status = 'STRESSED' THEN 1 ELSE 0 END)\n            INTO v_avg_temp, v_avg_salinity, v_avg_ph, v_avg_oxygen,\n                 v_total_samples, v_healthy_samples, v_stressed_samples\n            FROM marine_bivalves WHERE collection_location = v_location_name;\n            \n            SELECT VARIANCE(water_temperature), VARIANCE(salinity)\n            INTO v_temp_variance, v_salinity_variance\n            FROM marine_bivalves WHERE collection_location = v_location_name;\n            \n        EXCEPTION\n            WHEN NO_DATA_FOUND THEN\n                v_avg_temp := 0;\n                v_avg_salinity := 0;\n                v_avg_ph := 0;\n                v_avg_oxygen := 0;\n                v_total_samples := 0;\n                v_healthy_samples := 0;\n                v_stressed_samples := 0;\n                v_temp_variance := 0;\n                v_salinity_variance := 0;\n        END;\n        \n        -- Handle NULL values from aggregate functions\n        v_avg_temp := NVL(v_avg_temp, 0);\n        v_avg_salinity := NVL(v_avg_salinity, 0);\n        v_healthy_samples := NVL(v_healthy_samples, 0);\n        v_stressed_samples := NVL(v_stressed_samples, 0);\n        \n        IF v_avg_temp > 25 AND v_avg_salinity > 35 THEN\n            v_max_researcher_id := v_max_researcher_id + 1;\n            INSERT INTO researchers (id, name, email, affiliation) \n            VALUES (v_max_researcher_id, 'Hot-Saline Specialist', 'specialist@research.org', 'Environmental Research');\n        ELSIF v_avg_temp < 15 AND v_avg_salinity < 25 THEN\n            v_max_researcher_id := v_max_researcher_id + 1;\n            INSERT INTO researchers (id, name, email, affiliation) \n            VALUES (v_max_researcher_id, 'Cold-Fresh Specialist', 'specialist@research.org', 'Environmental Research');\n        END IF;\n        \n        IF v_healthy_samples > v_stressed_samples THEN\n            UPDATE locations SET description = 'Favorable Environment' WHERE id = v_location_id;\n        ELSIF v_stressed_samples > v_healthy_samples THEN\n            UPDATE locations SET description = 'Challenging Environment' WHERE id = v_location_id;\n        END IF;\n        \n        DELETE FROM marine_bivalves WHERE collection_location = v_location_name AND health_status = 'DECEASED';\n    END LOOP;\n    CLOSE c_locations;\nEND;",
    "database_name": "marine_baad_management",
    "tables": [
      "locations",
      "marine_bivalves",
      "researchers",
      "species"
    ],
    "id": 161
  },
  {
    "ir": "Write a PostgreSQL trigger function named trg_survey_questions_before_insert that is executed automatically before every insert operation on the survey_questions table for each new row, and within this function, perform an insert into the responses table, specifying the following column values: set the response_id column to the result of multiplying the new row's survey_question_id column value by 10, set the survey_id column to the new row's survey_id column value, set the value column to the numeric constant 0.5, set the year column to the integer constant 2024, and set the response_date column to the result of a character encoding conversion process where the new row's question_text column value is first converted from its original encoding to the ISO_8859-1 encoding using the CONVERT_TO function and then the result is converted from the ISO_8859-1 encoding to the UTF8 encoding using the CONVERT_FROM function; after performing this insert operation, the trigger function returns the NEW row record to allow the original insert on the survey_questions table to proceed.",
    "plsql": "CREATE OR REPLACE FUNCTION trg_survey_questions_before_insert() RETURNS TRIGGER AS $$\nBEGIN\n    INSERT INTO responses (response_id, survey_id, value, year, response_date) \n    VALUES (NEW.survey_question_id * 10, NEW.survey_id, 0.5, 2024, CONVERT_FROM(CONVERT_TO(NEW.question_text, 'ISO_8859-1'), 'UTF8'));\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER survey_questions_before_insert\nBEFORE INSERT ON survey_questions\nFOR EACH ROW EXECUTE FUNCTION trg_survey_questions_before_insert();",
    "database_name": "survey_response_analysis_and_data_management",
    "tables": [
      "surveys",
      "categories",
      "groups",
      "survey_questions",
      "responses",
      "response_values",
      "response_types"
    ],
    "_source": "plfactory3",
    "id": 162
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `add_reviewer_expertise_records` that accepts four input parameters: `p_reviewer_id` of type `NUMBER`, `p_expertise_field` of type `VARCHAR2`, `p_keywords` of type `VARCHAR2`, and `p_institution_id` of type `NUMBER`. The primary purpose of this procedure is to manage reviewer expertise records and associated review history.\n\nThe procedure begins by declaring two local variables: `v_reviewer_exists` of type `NUMBER` and `v_expertise_count` of type `NUMBER`.\n\nThe first operation performed is a `SELECT COUNT(*)` statement that queries the `reviewers` table. It counts the number of rows where the `reviewer_id` column matches the value provided in the `p_reviewer_id` input parameter. The result of this count is stored in the `v_reviewer_exists` variable.\n\nFollowing this, a conditional `IF` statement checks if the value of `v_reviewer_exists` is greater than 0. This condition effectively determines if a reviewer with the specified `p_reviewer_id` exists in the `reviewers` table.\n\nIf the reviewer exists (i.e., `v_reviewer_exists > 0`), the procedure proceeds with another `SELECT COUNT(*)` statement. This query targets the `reviewer_expertise` table and counts the number of rows where both the `reviewer_id` column matches `p_reviewer_id` AND the `field_of_expertise` column matches the value provided in the `p_expertise_field` input parameter. The result of this count is stored in the `v_expertise_count` variable.\n\nSubsequently, a nested conditional `IF` statement checks if the value of `v_expertise_count` is equal to 0. This condition determines if the specified expertise field for the given reviewer does NOT already exist in the `reviewer_expertise` table.\n\nIf the expertise record does not exist (i.e., `v_expertise_count = 0`), the procedure executes three distinct DML operations:\n\n1.  An `INSERT` statement is performed on the `reviewer_expertise` table. This statement inserts a new record with values for the `expertise_id`, `reviewer_id`, and `field_of_expertise` columns.\n    *   For the `expertise_id` column, it uses a subquery `(SELECT NVL(MAX(expertise_id), 0) + 1 FROM reviewer_expertise)`. This subquery calculates the maximum existing `expertise_id` in the `reviewer_expertise` table, uses `NVL` to treat a `NULL` result (if the table is empty) as 0, and then adds 1 to this value to generate a new, unique `expertise_id`. This acts as a placeholder for a sequence-generated ID.\n    *   For the `reviewer_id` column, it uses the value from the `p_reviewer_id` input parameter.\n    *   For the `field_of_expertise` column, it uses the value from the `p_expertise_field` input parameter.\n\n2.  Another `INSERT` statement is performed on the `review_history` table. This statement inserts a new record with values for the `history_id`, `reviewer_id`, `manuscript_id`, `review_date`, `comments`, `rating`, and `recommendation` columns.\n    *   For the `history_id` column, it uses a subquery `(SELECT NVL(MAX(history_id), 0) + 1 FROM review_history)`. Similar to the `expertise_id` generation, this subquery calculates the maximum existing `history_id` in the `review_history` table, uses `NVL` to treat a `NULL` result as 0, and then adds 1 to this value to generate a new, unique `history_id`. This also acts as a placeholder for a sequence-generated ID.\n    *   For the `reviewer_id` column, it uses the value from the `p_reviewer_id` input parameter.\n    *   For the `manuscript_id` column, it inserts the literal value `0`.\n    *   For the `review_date` column, it uses `TO_CHAR(SYSDATE, 'YYYY-MM-DD')`, which converts the current system date and time (`SYSDATE`) into a `VARCHAR2` string formatted as 'YYYY-MM-DD'.\n    *   For the `comments` column, it constructs a string by concatenating the literal 'Added expertise in ', the value of `p_expertise_field`, the literal ' with keywords: ', and the value of `p_keywords`.\n    *   For the `rating` column, it inserts the literal value `0`.\n    *   For the `recommendation` column, it inserts the literal string 'Profile Update'.\n\n3.  A `DELETE` statement is executed on the `review_assignments` table. This statement removes records where three conditions are met:\n    *   The `reviewer_id` column matches the value from the `p_reviewer_id` input parameter.\n    *   The `assignment_status` column is equal to the literal string 'Pending'.\n    *   The `assigned_date` column, after being converted from its `VARCHAR2` type to a `DATE` type using `TO_DATE(assigned_date, 'YYYY-MM-DD')`, is less than the current system date (`SYSDATE`) minus 30 days. This effectively deletes pending assignments that are older than 30 days.\n\nThe procedure concludes after these operations or if any of the preceding conditional checks evaluate to false.",
    "plsql": "CREATE OR REPLACE PROCEDURE add_reviewer_expertise_records(\n    p_reviewer_id IN NUMBER,\n    p_expertise_field IN VARCHAR2,\n    p_keywords IN VARCHAR2,\n    p_institution_id IN NUMBER\n)\nIS\n    v_reviewer_exists NUMBER;\n    v_expertise_count NUMBER;\nBEGIN\n    SELECT COUNT(*)\n    INTO v_reviewer_exists\n    FROM reviewers\n    WHERE reviewer_id = p_reviewer_id;\n    \n    IF v_reviewer_exists > 0 THEN\n        SELECT COUNT(*)\n        INTO v_expertise_count\n        FROM reviewer_expertise\n        WHERE reviewer_id = p_reviewer_id\n        AND field_of_expertise = p_expertise_field;\n        \n        IF v_expertise_count = 0 THEN\n            -- Assuming sequences 'reviewer_expertise_seq' and 'review_history_seq' exist\n            -- If not, they would need to be created or an alternative ID generation method used.\n            -- For demonstration, if sequences are not defined, a random number could be used,\n            -- but this is not suitable for production without proper uniqueness guarantees.\n            -- For this correction, I'm assuming the sequences are intended to exist.\n            INSERT INTO reviewer_expertise (\n                expertise_id, reviewer_id, field_of_expertise\n            )\n            VALUES (\n                (SELECT NVL(MAX(expertise_id), 0) + 1 FROM reviewer_expertise), -- Placeholder for sequence\n                p_reviewer_id, p_expertise_field\n            );\n            \n            INSERT INTO review_history (\n                history_id, reviewer_id, manuscript_id, review_date,\n                comments, rating, recommendation\n            )\n            VALUES (\n                (SELECT NVL(MAX(history_id), 0) + 1 FROM review_history), -- Placeholder for sequence\n                p_reviewer_id, 0, -- manuscript_id 0 might be a placeholder or specific logic\n                TO_CHAR(SYSDATE, 'YYYY-MM-DD'), \n                'Added expertise in ' || p_expertise_field || \n                ' with keywords: ' || p_keywords, 0, 'Profile Update'\n            );\n            \n            DELETE FROM review_assignments \n            WHERE reviewer_id = p_reviewer_id\n            AND assignment_status = 'Pending'\n            AND TO_DATE(assigned_date, 'YYYY-MM-DD') < (SYSDATE - 30); -- Convert VARCHAR2 date to DATE for comparison\n        END IF;\n    END IF;\nEND;",
    "database_name": "academic_prma_tracking",
    "tables": [
      "manuscripts",
      "institutions",
      "peer_review_journals",
      "review_assignments",
      "reviewers",
      "reviews",
      "review_history",
      "reviewer_expertise"
    ],
    "id": 163
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named MANAGE_DEVICE_MODELS that accepts two parameters: p_action of type VARCHAR2 and p_model_id of type NUMBER. The procedure begins by validating the input parameters, ensuring neither p_action nor p_model_id is null; if either is null, it raises an application error with code -20001 and a message indicating that action and model ID cannot be null. The procedure then evaluates the value of p_action using a series of conditional statements. If p_action equals 'ARCHIVE', it outputs a message indicating that an archive action is requested for the specified model ID using DBMS_OUTPUT.PUT_LINE. If p_action equals 'DELETE', it outputs a message indicating a delete action is requested for the specified model ID. If p_action equals 'UPDATE_PRICE', it outputs a message indicating an update price action is requested for the specified model ID. If p_action equals 'RESET', it outputs a message indicating a reset action is requested for the specified model ID. If p_action does not match any of these predefined actions, the procedure raises an application error with code -20002 and a message indicating that an invalid action was specified, including the invalid action value. The procedure does not perform any database updates, inserts, deletes, or selects, nor does it interact with any tables or columns directly; it solely outputs messages based on the action specified.",
    "plsql": "CREATE OR REPLACE PROCEDURE MANAGE_DEVICE_MODELS(p_action IN VARCHAR2, p_model_id IN NUMBER) AS\nBEGIN\n    -- Validate input parameters\n    IF p_action IS NULL OR p_model_id IS NULL THEN\n        RAISE_APPLICATION_ERROR(-20001, 'Action and Model ID cannot be null');\n    END IF;\n    \n    -- Perform actions based on the input parameters\n    IF p_action = 'ARCHIVE' THEN\n        DBMS_OUTPUT.PUT_LINE('Archive action requested for model ID: ' || p_model_id);\n    ELSIF p_action = 'DELETE' THEN\n        DBMS_OUTPUT.PUT_LINE('Delete action requested for model ID: ' || p_model_id);\n    ELSIF p_action = 'UPDATE_PRICE' THEN\n        DBMS_OUTPUT.PUT_LINE('Update price action requested for model ID: ' || p_model_id);\n    ELSIF p_action = 'RESET' THEN\n        DBMS_OUTPUT.PUT_LINE('Reset action requested for model ID: ' || p_model_id);\n    ELSE\n        RAISE_APPLICATION_ERROR(-20002, 'Invalid action specified: ' || p_action);\n    END IF;\nEND;",
    "database_name": "energy_cad_trends",
    "tables": [
      "DEVICES",
      "DEVICE_MODELS",
      "DEVICE_PURCHASES"
    ],
    "id": 164
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named GetTeamDetails that accepts a single parameter p_team_id of type NUMBER, which represents the unique identifier of a team. The procedure begins by declaring several local variables: v_team_name, v_captain_name, v_home_ground, v_team_short_name, v_team_owner, and v_team_sponsor as VARCHAR2(255), v_coach_id and v_founded_year as NUMBER. It then performs a SELECT operation on the teams table to retrieve the columns team_name, captain_id, coach_id, home_ground, founded_year, team_short_name, team_owner, and team_sponsor for the row where team_id matches the input parameter p_team_id, storing the results into the corresponding local variables. Next, the procedure uses a cursor loop to iterate over the players table, selecting the player_name for the row where player_id equals the value stored in v_captain_name, and assigns this player_name to v_captain_name. The procedure then evaluates the value of v_founded_year using conditional statements: if v_founded_year is less than 2000, it outputs a message indicating the team was founded before 2000; if v_founded_year is between 2000 and 2010, it outputs a message indicating the team was founded between 2000 and 2010; otherwise, it outputs a message indicating the team was founded after 2010. Finally, the procedure outputs several details about the team using DBMS_OUTPUT.PUT_LINE, including the team name, captain name, home ground, team owner, and team sponsor.",
    "plsql": "CREATE OR REPLACE PROCEDURE GetTeamDetails(p_team_id NUMBER) IS\n  v_team_name VARCHAR2(255);\n  v_captain_name VARCHAR2(255);\n  v_coach_id NUMBER;\n  v_home_ground VARCHAR2(255);\n  v_founded_year NUMBER;\n  v_team_short_name VARCHAR2(255);\n  v_team_owner VARCHAR2(255);\n  v_team_sponsor VARCHAR2(255);\nBEGIN\n  SELECT team_name, captain_id, coach_id, home_ground, founded_year, team_short_name, team_owner, team_sponsor\n  INTO v_team_name, v_captain_name, v_coach_id, v_home_ground, v_founded_year, v_team_short_name, v_team_owner, v_team_sponsor\n  FROM teams\n  WHERE team_id = p_team_id;\n\n  FOR rec IN (SELECT player_name FROM players WHERE player_id = v_captain_name) LOOP\n    v_captain_name := rec.player_name;\n  END LOOP;\n\n  IF v_founded_year < 2000 THEN\n    DBMS_OUTPUT.PUT_LINE('This team was founded before the year 2000.');\n  ELSIF v_founded_year BETWEEN 2000 AND 2010 THEN\n    DBMS_OUTPUT.PUT_LINE('This team was founded between 2000 and 2010.');\n  ELSE\n    DBMS_OUTPUT.PUT_LINE('This team was founded after 2010.');\n  END IF;\n\n  DBMS_OUTPUT.PUT_LINE('Team Name: ' || v_team_name);\n  DBMS_OUTPUT.PUT_LINE('Captain: ' || v_captain_name);\n  DBMS_OUTPUT.PUT_LINE('Home Ground: ' || v_home_ground);\n  DBMS_OUTPUT.PUT_LINE('Team Owner: ' || v_team_owner);\n  DBMS_OUTPUT.PUT_LINE('Team Sponsor: ' || v_team_sponsor);\nEND;",
    "database_name": "cricket_bsap_analysis",
    "tables": [
      "teams",
      "players",
      "team_compositions"
    ],
    "id": 165
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_team_city_on_match_update that is executed automatically after every row update operation on the matches table, which contains a row-level trigger named trigger_update_team_city; the function performs an update on the teams table, specifically setting the city column value for the team identified by the away_team_id from the newly updated matches row (accessible via the NEW record) to the city value retrieved from a scalar subquery that selects the city column from the teams table where the team_id matches the NEW.home_team_id value from the updated matches row, and the function concludes by returning the NEW row record to the invoking trigger mechanism.",
    "plsql": "CREATE OR REPLACE FUNCTION update_team_city_on_match_update() RETURNS TRIGGER AS $$\nBEGIN\n    UPDATE teams SET city = (SELECT city FROM teams WHERE team_id = NEW.home_team_id) WHERE team_id = NEW.away_team_id;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trigger_update_team_city\nAFTER UPDATE ON matches\nFOR EACH ROW EXECUTE FUNCTION update_team_city_on_match_update();",
    "database_name": "football_league_results_and_team_performance_tracking",
    "tables": [
      "matches",
      "teams"
    ],
    "_source": "plfactory23",
    "id": 166
  },
  {
    "ir": "Write a PostgreSQL trigger function named trg_sync_borough_name that returns a trigger and is executed by a trigger named sync_borough_name, which is defined to fire after an update operation specifically on the borough_id column of the neighborhoods table for each affected row, where the function body performs an update on the addresses table, setting its borough column to the result of a subquery that selects the borough_name column from the boroughs table where the borough_id column in the boroughs table matches the new value of the borough_id column from the updated neighborhoods row (accessed via the NEW record), and this update on addresses is applied only to rows where the neighborhood_id column in the addresses table equals the new value of the neighborhood_id column from the updated neighborhoods row, after which the function returns the NEW row record.",
    "plsql": "CREATE OR REPLACE FUNCTION trg_sync_borough_name() RETURNS TRIGGER AS $$\nBEGIN\n    UPDATE addresses SET borough = (SELECT borough_name FROM boroughs WHERE borough_id = NEW.borough_id) WHERE neighborhood_id = NEW.neighborhood_id;\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER sync_borough_name\nAFTER UPDATE OF borough_id ON neighborhoods\nFOR EACH ROW EXECUTE FUNCTION trg_sync_borough_name();",
    "database_name": "geographic_information_system__gis__for_address_mapping",
    "tables": [
      "addresses",
      "address_types",
      "neighborhoods",
      "boroughs"
    ],
    "_source": "plfactory7",
    "id": 167
  },
  {
    "ir": "Write a PostgreSQL trigger function named log_demographic_access that is executed automatically by a trigger named trg_log_demographic_access, which is defined to fire AFTER INSERT on the demographics table FOR EACH ROW, where the function performs a single INSERT operation into the access_logs table, populating the columns access_id, user_id, demographic_id, access_date, and query_parameters with specific values: for access_id, it executes a subquery on the access_logs table to find the current maximum value in the access_id column, applies the COALESCE function to that result to handle a NULL case by substituting 0, and then adds 1 to this result to generate a new sequential identifier; for user_id, it inserts a constant integer value of 0; for demographic_id, it inserts the value of the NEW.demographic_id column from the newly inserted row in the demographics table that activated the trigger; for access_date, it calls the EXTRACT function to get the year component from the CURRENT_DATE, then uses the CAST function to convert this numeric year value into a TEXT data type; and for query_parameters, it inserts a constant string value of 'trigger_generated', and finally, the trigger function returns the NEW row record to the invoking trigger mechanism.",
    "plsql": "CREATE OR REPLACE FUNCTION log_demographic_access() RETURNS TRIGGER AS $$\nBEGIN\n    INSERT INTO access_logs (access_id, user_id, demographic_id, access_date, query_parameters) VALUES ((SELECT COALESCE(MAX(access_id), 0) + 1 FROM access_logs), 0, NEW.demographic_id, CAST(EXTRACT(YEAR FROM CURRENT_DATE) AS TEXT), 'trigger_generated');\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_log_demographic_access\n    AFTER INSERT ON demographics\n    FOR EACH ROW\n    EXECUTE FUNCTION log_demographic_access();",
    "database_name": "religious_demographics_and_statistics",
    "tables": [
      "access_logs",
      "countries",
      "data_sources",
      "demographics",
      "denominations",
      "religions",
      "statistics",
      "users"
    ],
    "_source": "plfactory24",
    "id": 168
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `audit_user_access` that accepts two input parameters: `p_user_id` of type `bigint`, representing the unique identifier of a user whose access patterns are to be audited, and `p_audit_period` of type `text`, representing a timestamp or date string indicating the start of the audit period. The procedure declares five local variables: `v_access_count` of type `bigint` to store the total number of access attempts, `v_admin_access_count` of type `bigint` to store the number of administrative access attempts, `v_failed_access_count` of type `bigint` to store the number of unsuccessful access attempts, `v_avg_duration` of type `bigint` to store the average duration of successful access attempts, and `v_risk_score` of type `integer` to store a calculated risk assessment for the user.\n\nThe procedure begins by querying the `access_logs` table to determine the total number of access attempts for the user identified by `p_user_id` where the `access_date` is greater than or equal to the `p_audit_period`. This count is stored in `v_access_count`.\n\nNext, it queries the `access_logs` table again to count the number of administrative access attempts for the same user (`p_user_id`) within the same audit period (`access_date >= p_audit_period`), specifically where the `is_admin_access` column is equal to `1`. This count is stored in `v_admin_access_count`.\n\nSubsequently, it queries the `access_logs` table to count the number of failed access attempts for the user (`p_user_id`) within the specified audit period (`access_date >= p_audit_period`), where the `is_successful` column is equal to `0`. This count is stored in `v_failed_access_count`.\n\nFollowing this, the procedure calculates the average `access_duration` for successful access attempts (`is_successful = 1`) made by the user (`p_user_id`) within the audit period (`access_date >= p_audit_period`). This average duration is stored in `v_avg_duration`.\n\nAfter gathering these statistics, the procedure proceeds to evaluate a risk score (`v_risk_score`) based on a series of conditional statements.\n\nThe first condition checks if `v_admin_access_count` is greater than 50% of `v_access_count`. If this condition is true, `v_risk_score` is initially set to `80`. Within this block, a nested condition further checks if `v_failed_access_count` is greater than `10`. If this nested condition is also true, `v_risk_score` is increased by `20`.\n\nIf the first condition (admin access count > 50% of total access count) is false, the procedure moves to an `ELSIF` block. This block checks if `v_failed_access_count` is greater than 30% of `v_access_count`. If this condition is true, `v_risk_score` is initially set to `60`. A nested condition then checks if `v_avg_duration` is greater than `3600` (presumably seconds, representing one hour). If this nested condition is true, `v_risk_score` is increased by `15`.\n\nIf both the first and second `ELSIF` conditions are false, the procedure moves to another `ELSIF` block. This block checks if `v_access_count` is greater than `1000`. If this condition is true, `v_risk_score` is initially set to `40`. A nested condition then checks if `v_admin_access_count` is greater than `100`. If this nested condition is true, `v_risk_score` is increased by `10`.\n\nIf none of the preceding `IF` or `ELSIF` conditions are met, the `ELSE` block is executed, and `v_risk_score` is set to `20`.\n\nFinally, based on the calculated `v_risk_score`, the procedure updates the `users` table. If `v_risk_score` is greater than `90`, the `is_active` column for the user identified by `p_user_id` is set to `0`, effectively deactivating the user. If `v_risk_score` is not greater than `90` but is greater than `70`, the `is_active` column for the user identified by `p_user_id` is set to `1`, ensuring the user remains active or is reactivated.",
    "plsql": "CREATE OR REPLACE PROCEDURE audit_user_access(p_user_id bigint, p_audit_period text)\nAS $$\nDECLARE\n    v_access_count bigint;\n    v_admin_access_count bigint;\n    v_failed_access_count bigint;\n    v_avg_duration bigint;\n    v_risk_score integer;\nBEGIN\n    SELECT COUNT(*) INTO v_access_count FROM access_logs WHERE user_id = p_user_id AND access_date >= p_audit_period;\n    \n    SELECT COUNT(*) INTO v_admin_access_count FROM access_logs \n    WHERE user_id = p_user_id AND access_date >= p_audit_period AND is_admin_access = 1;\n    \n    SELECT COUNT(*) INTO v_failed_access_count FROM access_logs \n    WHERE user_id = p_user_id AND access_date >= p_audit_period AND is_successful = 0;\n    \n    SELECT AVG(access_duration) INTO v_avg_duration FROM access_logs \n    WHERE user_id = p_user_id AND access_date >= p_audit_period AND is_successful = 1;\n    \n    IF v_admin_access_count > v_access_count * 0.5 THEN\n        v_risk_score := 80;\n        IF v_failed_access_count > 10 THEN\n            v_risk_score := v_risk_score + 20;\n        END IF;\n    ELSIF v_failed_access_count > v_access_count * 0.3 THEN\n        v_risk_score := 60;\n        IF v_avg_duration > 3600 THEN\n            v_risk_score := v_risk_score + 15;\n        END IF;\n    ELSIF v_access_count > 1000 THEN\n        v_risk_score := 40;\n        IF v_admin_access_count > 100 THEN\n            v_risk_score := v_risk_score + 10;\n        END IF;\n    ELSE\n        v_risk_score := 20;\n    END IF;\n    \n    IF v_risk_score > 90 THEN\n        UPDATE users SET is_active = 0 WHERE user_id = p_user_id;\n    ELSIF v_risk_score > 70 THEN\n        UPDATE users SET is_active = 1 WHERE user_id = p_user_id;\n    END IF;\nEND;\n$$ LANGUAGE plpgsql;",
    "database_name": "anomaly_detection_in_time_series_data",
    "tables": [
      "users",
      "roles",
      "access_logs",
      "datasets",
      "data_types",
      "models",
      "model_types",
      "model_versions",
      "performance_metrics",
      "anomalies"
    ],
    "id": 169
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `create_experiment_version` that accepts four input parameters: `p_experiment_id` of type `BIGINT`, `p_version_name` of type `TEXT`, `p_version_date` of type `TEXT`, and `p_description` of type `TEXT`. The purpose of this procedure is to create a new version entry in the `experiment_versions` table and corresponding version entries in the `reading_versions` table for all readings associated with the specified experiment.\n\nFirst, the procedure declares two local variables: `v_experiment_version_id` of type `BIGINT` and `v_reading_version_id` of type `BIGINT`.\n\nThe procedure then proceeds to determine the `version_id` for the new experiment version. It executes a `SELECT` statement to retrieve the maximum value from the `version_id` column in the `experiment_versions` table. If no records exist in the `experiment_versions` table, `COALESCE` ensures that `MAX(version_id)` defaults to `0`. This value is then incremented by `1` to generate a unique `version_id`, which is stored in the `v_experiment_version_id` variable.\n\nNext, the procedure inserts a new record into the `experiment_versions` table. The `version_id` column is populated with the value from `v_experiment_version_id`. The `experiment_id` column is set to the value of the `p_experiment_id` input parameter. The `version_name` column is set to the value of the `p_version_name` input parameter. The `version_date` column is set to the value of the `p_version_date` input parameter. The `version_description` column is set to the value of the `p_description` input parameter. Finally, the `version_status` column is explicitly set to the literal string `'published'`.\n\nFollowing this, the procedure enters a `FOR` loop to generate and insert version entries for each reading associated with the given experiment. The loop iterates over a set of generated `version_id` values for reading versions. The generation of these `version_id` values is complex: it starts by selecting the maximum `version_id` from the `reading_versions` table, defaulting to `0` if no records exist, and then adds the `row_number()` of each row in the result set. The result set for this `SELECT` statement is formed by a `CROSS JOIN` between the `reading_versions` table (used only for `MAX(version_id)`) and a subquery that selects `reading_id` from the `readings` table where `experiment_id` matches `p_experiment_id`. This effectively generates a sequence of `version_id`s starting from `MAX(version_id) + 1` for each reading associated with the experiment.\n\nInside the `FOR` loop, for each generated `v_reading_version_id`, an `INSERT` statement is executed to add a new record to the `reading_versions` table. The `version_id` column is set to the current `v_reading_version_id` from the loop. The `reading_id` column is populated by a `SELECT` statement that retrieves `reading_id` from the `readings` table where `experiment_id` matches `p_experiment_id`. This `SELECT` statement is further constrained by `LIMIT 1 OFFSET (v_reading_version_id - (SELECT COALESCE(MAX(version_id), 0) FROM reading_versions) - 1)`. This `OFFSET` calculation is intended to select a specific `reading_id` from the `readings` table based on the current iteration's `v_reading_version_id` relative to the existing maximum `version_id` in `reading_versions`. The `version_name` column is set to the value of the `p_version_name` input parameter. The `version_date` column is set to the value of the `p_version_date` input parameter. The `version_description` column is set to the literal string `'Auto-generated reading version'`. Finally, the `version_status` column is explicitly set to the literal string `'published'`.",
    "plsql": "CREATE OR REPLACE PROCEDURE create_experiment_version(\n    IN p_experiment_id BIGINT,\n    IN p_version_name TEXT,\n    IN p_version_date TEXT,\n    IN p_description TEXT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_experiment_version_id BIGINT;\n    v_reading_version_id BIGINT;\nBEGIN\n    -- Generate new version_id for experiment_versions\n    SELECT COALESCE(MAX(version_id), 0) + 1 INTO v_experiment_version_id FROM experiment_versions;\n    \n    INSERT INTO experiment_versions (version_id, experiment_id, version_name, version_date, version_description, version_status)\n    VALUES (v_experiment_version_id, p_experiment_id, p_version_name, p_version_date, p_description, 'published');\n    \n    -- Generate version_id for each reading version\n    FOR v_reading_version_id IN \n        SELECT COALESCE(MAX(version_id), 0) + row_number() OVER () \n        FROM reading_versions, (SELECT r.reading_id FROM readings r WHERE r.experiment_id = p_experiment_id) readings_to_insert\n    LOOP\n        INSERT INTO reading_versions (version_id, reading_id, version_name, version_date, version_description, version_status)\n        SELECT v_reading_version_id, r.reading_id, p_version_name, p_version_date, 'Auto-generated reading version', 'published'\n        FROM readings r\n        WHERE r.experiment_id = p_experiment_id\n        LIMIT 1 OFFSET (v_reading_version_id - (SELECT COALESCE(MAX(version_id), 0) FROM reading_versions) - 1);\n    END LOOP;\nEND;\n$$;",
    "database_name": "electrical_engineering_and_sensor_data_management",
    "tables": [
      "experiments",
      "principal_investigators",
      "experiment_versions",
      "readings",
      "reading_versions",
      "units",
      "sensor_calibrations",
      "voltage_readings",
      "current_readings"
    ],
    "id": 170
  },
  {
    "ir": "Write a PostgreSQL trigger function named archive_old_dependency that is executed after each row is deleted from the component_dependencies table, which first conditionally creates an archive table named component_dependencies_archive if it does not already exist, defining its columns as archive_id of type BIGSERIAL as the primary key, dependency_id of type BIGINT, component_id of type BIGINT, dependent_component_id of type BIGINT, version_constraint of type TEXT, optional of type BIGINT, description of type TEXT, and archived_at of type TIMESTAMP with a default value of the current timestamp, and then inserts a new row into this newly created or existing component_dependencies_archive table, populating the columns dependency_id, component_id, dependent_component_id, version_constraint, optional, and description with the corresponding OLD record values from the deleted row in the component_dependencies table, specifically OLD.dependency_id, OLD.component_id, OLD.dependent_component_id, OLD.version_constraint, OLD.optional, and OLD.description, while the archived_at column automatically receives the default current timestamp, and finally returns the OLD record; this function is then bound to the component_dependencies table via a trigger named trg_archive_old_dependency, which is defined to fire after every delete operation on that table for each affected row, executing the archive_old_dependency function, with any pre-existing trigger of the same name on the component_dependencies table being dropped before the new trigger is created.",
    "plsql": "CREATE OR REPLACE FUNCTION archive_old_dependency() RETURNS TRIGGER AS $$\nBEGIN\n    -- Create archive table if it doesn't exist\n    CREATE TABLE IF NOT EXISTS component_dependencies_archive (\n        archive_id BIGSERIAL PRIMARY KEY,\n        dependency_id BIGINT,\n        component_id BIGINT,\n        dependent_component_id BIGINT,\n        version_constraint TEXT,\n        optional BIGINT,\n        description TEXT,\n        archived_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n    );\n    \n    -- Archive the deleted row\n    INSERT INTO component_dependencies_archive \n        (dependency_id, component_id, dependent_component_id, version_constraint, optional, description)\n    VALUES \n        (OLD.dependency_id, OLD.component_id, OLD.dependent_component_id, \n         OLD.version_constraint, OLD.optional, OLD.description);\n    \n    RETURN OLD;\nEND;\n$$ LANGUAGE plpgsql;\n\nDROP TRIGGER IF EXISTS trg_archive_old_dependency ON component_dependencies;\nCREATE TRIGGER trg_archive_old_dependency\n    AFTER DELETE ON component_dependencies\n    FOR EACH ROW\n    EXECUTE FUNCTION archive_old_dependency();",
    "database_name": "twig_template_component_properties",
    "tables": [
      "components",
      "component_versions",
      "component_properties",
      "component_dependencies",
      "component_usage",
      "users"
    ],
    "_source": "plfactory17",
    "id": 171
  },
  {
    "ir": "Write an Oracle PL/SQL function named get_visualization_title that accepts two parameters: p_result_id of type NUMBER and p_visualization_type of type VARCHAR2. The function retrieves a single value from the result_visualizations table by selecting the visualization_title column where the result_id column matches the value of p_result_id and the visualization_type column matches the value of p_visualization_type. The retrieved visualization_title is stored in a local variable v_title of type VARCHAR2 with a maximum length of 255 characters. The function then returns the value stored in v_title.",
    "plsql": "CREATE OR REPLACE FUNCTION get_visualization_title(p_result_id IN NUMBER, p_visualization_type IN VARCHAR2) RETURN VARCHAR2 IS\n  v_title VARCHAR2(255);\nBEGIN\n  SELECT visualization_title INTO v_title\n  FROM result_visualizations\n  WHERE result_id = p_result_id AND visualization_type = p_visualization_type;\n  RETURN v_title;\nEND;",
    "database_name": "crowd_sapm_analysis",
    "tables": [
      "simulations",
      "simulation_parameters",
      "simulation_results",
      "result_visualizations"
    ],
    "id": 172
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named remove_problematic_content that accepts two input parameters: p_threshold_downvotes of type NUMBER and p_report_count of type NUMBER. The procedure performs a series of DELETE operations on three tables: comment_votes, comments, and posts. First, it deletes rows from the comment_votes table where the comment_id matches any comment_id from the comments table that has received a number of 'DOWN' votes greater than or equal to the value specified by p_threshold_downvotes. This is determined by a subquery that counts the number of 'DOWN' votes for each comment_id in the comment_votes table. Next, it deletes rows from the comments table where the comment_id matches any comment_id that has received a number of 'DOWN' votes greater than or equal to p_threshold_downvotes, using a similar subquery to count the 'DOWN' votes. Finally, it deletes rows from the posts table where the is_problematic column is set to 1 and the number of entries in the post_history table with a change_type of 'REPORT' for the corresponding post_id is greater than or equal to the value specified by p_report_count. This is determined by a subquery that counts the number of 'REPORT' entries in the post_history table for each post_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE remove_problematic_content(p_threshold_downvotes IN NUMBER, p_report_count IN NUMBER) AS\nBEGIN\n  DELETE FROM comment_votes \n  WHERE comment_id IN (\n    SELECT c.comment_id \n    FROM comments c\n    WHERE (SELECT COUNT(*) FROM comment_votes cv WHERE cv.comment_id = c.comment_id AND cv.vote_type = 'DOWN') >= p_threshold_downvotes\n  );\n  \n  DELETE FROM comments \n  WHERE comment_id IN (\n    SELECT c.comment_id \n    FROM comments c\n    WHERE (SELECT COUNT(*) FROM comment_votes cv WHERE cv.comment_id = c.comment_id AND cv.vote_type = 'DOWN') >= p_threshold_downvotes\n  );\n  \n  DELETE FROM posts \n  WHERE is_problematic = 1\n  AND (SELECT COUNT(*) FROM post_history ph WHERE ph.post_id = posts.post_id AND ph.change_type = 'REPORT') >= p_report_count;\nEND;",
    "database_name": "online_csakb_management",
    "tables": [
      "posts",
      "comments",
      "users",
      "comment_votes",
      "favorites",
      "post_history"
    ],
    "id": 173
  },
  {
    "ir": "Write an Oracle PL/SQL function named `calculate_total_amount` that accepts two input parameters: `p_start_date` of data type `DATE` and `p_end_date` of data type `DATE`. This function is designed to return a single value of data type `NUMBER`. Upon execution, the function first declares two local variables: `v_total` of data type `NUMBER`, initialized to `0`, and `v_days` of data type `NUMBER`. The function then proceeds with input validation: it checks if either `p_start_date` or `p_end_date` is `NULL`. If either of these parameters is `NULL`, the function immediately returns `0`. If both `p_start_date` and `p_end_date` are not `NULL`, the function calculates the number of days between the `p_start_date` and `p_end_date` inclusive. This calculation is performed by subtracting `p_start_date` from `p_end_date` and adding `1` to the result, storing this value in the `v_days` variable. Following this, the function evaluates the calculated `v_days`. If `v_days` is greater than `0`, it calculates `v_total` by multiplying `v_days` by `100`. Otherwise, if `v_days` is not greater than `0` (i.e., it is `0` or negative), `v_total` is set to `0`. Finally, the function returns the value stored in `v_total`. The function includes an exception handler that catches any `OTHERS` exception that might occur during its execution. If an exception is caught, the function returns `0`.",
    "plsql": "CREATE OR REPLACE FUNCTION calculate_total_amount(p_start_date DATE, p_end_date DATE) RETURN NUMBER IS\n  v_total NUMBER := 0;\n  v_days NUMBER;\nBEGIN\n  -- Validate input parameters\n  IF p_start_date IS NULL OR p_end_date IS NULL THEN\n    RETURN 0;\n  END IF;\n  \n  -- Calculate number of days between dates\n  v_days := p_end_date - p_start_date + 1;\n  \n  -- Ensure non-negative calculation\n  IF v_days > 0 THEN\n    v_total := v_days * 100;\n  ELSE\n    v_total := 0;\n  END IF;\n  \n  RETURN v_total;\nEXCEPTION\n  WHEN OTHERS THEN\n    RETURN 0;\nEND;",
    "database_name": "financial_da_reporting",
    "tables": [
      "FINANCIAL_REPORTS",
      "REPORT_CATEGORIES",
      "REPORT_CATEGORY_MAPPING"
    ],
    "id": 174
  },
  {
    "ir": "Write a PLpgSQL stored procedure named update_property_status that accepts three parameters: p_property_type of type text, p_min_sqft of type bigint, and p_max_price of type numeric. The procedure begins by declaring two local variables, v_property_count of type bigint and v_avg_price of type numeric. It then executes a SELECT statement to count the number of properties and calculate the average list price of properties from the properties table where the property_type matches the p_property_type parameter and the list_price, cast to numeric, is less than or equal to the p_max_price parameter. The results are stored in v_property_count and v_avg_price. The procedure then evaluates the value of v_property_count using conditional statements. If v_property_count is greater than 50, it updates the properties table by setting the property_status to 'HOT' and the updated_at column to the current timestamp, cast to text, for properties with the specified property_type and a square footage greater than p_min_sqft. If v_property_count is greater than 30, it inserts new records into the property_history table, setting the history_id to the maximum existing history_id plus a row number, the property_id to the property_id from the properties table, the list_date and change_date to the current date cast to text, the list_price to the truncated average price cast to text, the change_description to 'Property status update', the change_type to 'STATUS_UPDATE', and the created_at to the current timestamp cast to text, for properties with the specified property_type. If v_property_count is greater than 10, it deletes records from the inspection_reports table where the property_id matches those in the properties table with the specified property_type and the report_status is 'PENDING'. If none of the above conditions are met, it updates the properties table by setting the property_status to 'REVIEW' and the updated_at column to the current timestamp cast to text for properties with the specified property_type.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_property_status(\n    p_property_type text,\n    p_min_sqft bigint,\n    p_max_price numeric\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_property_count bigint;\n    v_avg_price numeric;\nBEGIN\n    SELECT COUNT(*), AVG(CAST(p.list_price AS numeric))\n    INTO v_property_count, v_avg_price\n    FROM properties p\n    WHERE p.property_type = p_property_type\n    AND CAST(p.list_price AS numeric) <= p_max_price;\n    \n    IF v_property_count > 50 THEN\n        UPDATE properties \n        SET property_status = 'HOT',\n            updated_at = CURRENT_TIMESTAMP::text\n        WHERE property_id IN (\n            SELECT property_id FROM properties WHERE property_type = p_property_type\n        ) AND sqft > p_min_sqft;\n    ELSIF v_property_count > 30 THEN\n        INSERT INTO property_history (\n            history_id, property_id, list_date, list_price, \n            change_date, change_description, change_type, created_at\n        )\n        SELECT \n            (SELECT COALESCE(MAX(history_id), 0) + ROW_NUMBER() OVER() FROM property_history),\n            p.property_id,\n            CURRENT_DATE::text,\n            trunc(v_avg_price, 2)::text,\n            CURRENT_DATE::text,\n            'Property status update',\n            'STATUS_UPDATE',\n            CURRENT_TIMESTAMP::text\n        FROM properties p\n        WHERE p.property_type = p_property_type;\n    ELSIF v_property_count > 10 THEN\n        DELETE FROM inspection_reports \n        WHERE property_id IN (\n            SELECT property_id FROM properties WHERE property_type = p_property_type\n        ) AND report_status = 'PENDING';\n    ELSE\n        UPDATE properties \n        SET property_status = 'REVIEW',\n            updated_at = CURRENT_TIMESTAMP::text\n        WHERE property_id IN (\n            SELECT property_id FROM properties WHERE property_type = p_property_type\n        );\n    END IF;\nEND;\n$$;",
    "database_name": "real_estate_sales_data_management_192101",
    "tables": [
      "properties",
      "agents",
      "sales",
      "customers",
      "financing",
      "reviews",
      "inspection_reports",
      "property_history"
    ],
    "id": 175
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `manage_certification_alerts` that does not accept any input parameters. This procedure is designed to identify certifications that are due to expire within approximately one month from the current system date and create corresponding alert records. The procedure begins by declaring a local cursor named `cert_cursor`. This cursor is defined to select two columns: `cert_id` and `valid_to` from the `certifications` table. The selection is filtered by a `WHERE` clause that compares the `valid_to` column with a calculated date. Specifically, `TO_DATE(valid_to, 'YYYY-MM-DD')` converts the `valid_to` column, which is assumed to be stored as a string in 'YYYY-MM-DD' format, into a date data type. This converted date is then compared to `ADD_MONTHS(SYSDATE, 1)`, which calculates a date one month in the future from the current system date (`SYSDATE`). The condition `TO_DATE(valid_to, 'YYYY-MM-DD') < ADD_MONTHS(SYSDATE, 1)` ensures that only certifications expiring before one month from now are included in the cursor's result set. Following the cursor declaration, two local variables are declared: `l_cert_id` of type `NUMBER` and `l_valid_to` of type `VARCHAR2(255)`. The executable part of the procedure starts by opening the `cert_cursor`. It then enters a `LOOP` construct. Inside the loop, `FETCH cert_cursor INTO l_cert_id, l_valid_to` attempts to retrieve the `cert_id` and `valid_to` values from the current row of the `cert_cursor` and assign them to the `l_cert_id` and `l_valid_to` local variables, respectively. An `EXIT WHEN cert_cursor%NOTFOUND` statement immediately follows the `FETCH`, causing the loop to terminate if no more rows are found in the cursor. For each row successfully fetched, an `INSERT` statement is executed to add a new record into the `certification_alerts` table. The `INSERT` statement populates the following columns: `alert_id`, `cert_id`, `alert_date`, `message`, and `alert_status`. The `alert_id` column is populated by calculating a new ID. This calculation uses `COALESCE((SELECT MAX(alert_id) FROM certification_alerts), 0) + 1`. This expression first attempts to retrieve the maximum `alert_id` from the `certification_alerts` table. If `MAX(alert_id)` returns `NULL` (meaning the table is empty), `COALESCE` substitutes `0` for `NULL`. Then, `1` is added to this value to generate a new, unique `alert_id`. The `cert_id` column is populated with the value of the `l_cert_id` local variable, which was fetched from the cursor. The `alert_date` column is populated with the current system date, formatted as a string 'YYYY-MM-DD' using `TO_CHAR(SYSDATE, 'YYYY-MM-DD')`. The `message` column is constructed as a concatenated string: `'Certification ' || l_cert_id || ' will expire on ' || l_valid_to`. This message includes the certification ID and its expiration date. Finally, the `alert_status` column is set to the literal string `'Pending'`. After the loop finishes processing all rows from the cursor, `CLOSE cert_cursor` is executed to release the resources held by the cursor. The procedure then concludes.",
    "plsql": "CREATE OR REPLACE PROCEDURE manage_certification_alerts\nIS\n   CURSOR cert_cursor IS\n      SELECT cert_id, valid_to\n      FROM certifications\n      WHERE TO_DATE(valid_to, 'YYYY-MM-DD') < ADD_MONTHS(SYSDATE, 1);\n   l_cert_id NUMBER;\n   l_valid_to VARCHAR2(255);\nBEGIN\n   OPEN cert_cursor;\n   LOOP\n      FETCH cert_cursor INTO l_cert_id, l_valid_to;\n      EXIT WHEN cert_cursor%NOTFOUND;\n      INSERT INTO certification_alerts (alert_id, cert_id, alert_date, message, alert_status)\n      VALUES (\n         COALESCE((SELECT MAX(alert_id) FROM certification_alerts), 0) + 1,\n         l_cert_id,\n         TO_CHAR(SYSDATE, 'YYYY-MM-DD'),\n         'Certification ' || l_cert_id || ' will expire on ' || l_valid_to,\n         'Pending'\n      );\n   END LOOP;\n   CLOSE cert_cursor;\nEND;",
    "database_name": "skilled_wca_management",
    "tables": [
      "certifications",
      "certification_alerts",
      "certification_renewals",
      "certifying_agencies"
    ],
    "id": 176
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `optimize_user_profiles` that accepts five input parameters: `p_follower_ratio` of type `real`, `p_bio_required` of type `boolean`, `p_location_filter` of type `text`, `p_join_date_cutoff` of type `text`, and `p_profile_completeness` of type `integer`. The procedure declares two local variables: `v_profile_score` of type `integer` and `v_completion_array` of type `integer[]`.\n\nThe procedure begins by creating four temporary tables if they do not already exist, with each temporary table configured to delete its rows upon commit. The first temporary table is `temp_influencer_profiles`, which has columns `user_id` (text), `user_name` (text), `followers` (bigint), `following` (bigint), and `profile_bio` (text). The second temporary table is `temp_user_rankings`, with columns `user_id` (text), `influence_score` (real), and `join_date` (text). The third temporary table is `temp_location_based_users`, containing columns `user_id` (text), `user_name` (text), `location` (text), and `followers` (bigint). The fourth temporary table is `temp_general_user_metrics`, with columns `user_id` (text), `followers` (bigint), `following` (bigint), and `userVerified` (bigint).\n\nFollowing the temporary table creation, the procedure executes a conditional block based on the values of the input parameters.\n\nIf `p_follower_ratio` is greater than `10.0`:\nThe local variable `v_completion_array` is assigned an array filled with the value of `p_profile_completeness`, with the array having a dimension of `3`.\nThen, rows are inserted into the `temp_influencer_profiles` temporary table. The `user_id`, `user_name`, `followers`, `following`, and `profile_bio` columns are selected from the `users` table. The selection is filtered to include only those rows where the `following` column is greater than `0` AND the ratio of `followers` (cast to `real`) to `following` (cast to `real`) is greater than `p_follower_ratio`.\n\nElse if `p_follower_ratio` is greater than `2.0`:\nRows are inserted into the `temp_user_rankings` temporary table. The `user_id` and `join_date` columns are selected from the `users` table. An `influence_score` is calculated as `followers` (cast to `real`) multiplied by `0.6` plus `following` (cast to `real`) multiplied by `0.4`. The selection is filtered to include only those rows where the `join_date` column is greater than or equal to `p_join_date_cutoff`.\n\nElse if `p_bio_required` is `true`:\nRows are deleted from the `users` table. The deletion is filtered to include only those rows where the `profile_bio` column is `NULL` OR the length of the `profile_bio` column is less than `10`.\n\nElse if `p_location_filter` is not `NULL`:\nRows are inserted into the `temp_location_based_users` temporary table. The `user_id`, `user_name`, `location`, and `followers` columns are selected from the `users` table. The selection is filtered to include only those rows where the `location` column, using a case-insensitive `ILIKE` comparison, contains the `p_location_filter` value.\n\nElse if `p_join_date_cutoff` is not `NULL`:\nThe `users` table is updated. For each row, the `profile_bio` column is set to its current value (or an empty string if `NULL`, using `COALESCE`) concatenated with the string ` ' [veteran]'`. The update is filtered to include only those rows where the `join_date` column is less than `p_join_date_cutoff`.\n\nElse (if none of the above conditions are met):\nRows are inserted into the `temp_general_user_metrics` temporary table. The `user_id`, `followers`, `following`, and `userVerified` columns are selected from the `users` table. The selection is filtered to include only those rows where the `user_default_profile` column is equal to `0`.",
    "plsql": "CREATE OR REPLACE PROCEDURE optimize_user_profiles(\n    p_follower_ratio real,\n    p_bio_required boolean,\n    p_location_filter text,\n    p_join_date_cutoff text,\n    p_profile_completeness integer\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_profile_score integer;\n    v_completion_array integer[];\nBEGIN\n    -- Create temporary tables for intermediate results\n    CREATE TEMP TABLE IF NOT EXISTS temp_influencer_profiles (\n        user_id text,\n        user_name text,\n        followers bigint,\n        following bigint,\n        profile_bio text\n    ) ON COMMIT DELETE ROWS;\n    \n    CREATE TEMP TABLE IF NOT EXISTS temp_user_rankings (\n        user_id text,\n        influence_score real,\n        join_date text\n    ) ON COMMIT DELETE ROWS;\n    \n    CREATE TEMP TABLE IF NOT EXISTS temp_location_based_users (\n        user_id text,\n        user_name text,\n        location text,\n        followers bigint\n    ) ON COMMIT DELETE ROWS;\n    \n    CREATE TEMP TABLE IF NOT EXISTS temp_general_user_metrics (\n        user_id text,\n        followers bigint,\n        following bigint,\n        userVerified bigint\n    ) ON COMMIT DELETE ROWS;\n\n    IF p_follower_ratio > 10.0 THEN\n        v_completion_array := array_fill(p_profile_completeness, ARRAY[3]);\n        INSERT INTO temp_influencer_profiles \n        SELECT user_id, user_name, followers, following, profile_bio\n        FROM users \n        WHERE following > 0 AND followers::real / following::real > p_follower_ratio;\n        \n    ELSIF p_follower_ratio > 2.0 THEN\n        -- Update temporary table instead of non-existent user_rankings\n        INSERT INTO temp_user_rankings\n        SELECT user_id, followers::real * 0.6 + following::real * 0.4 as influence_score, join_date\n        FROM users \n        WHERE join_date >= p_join_date_cutoff;\n        \n    ELSIF p_bio_required = true THEN\n        -- Delete from users table directly for incomplete profiles\n        DELETE FROM users \n        WHERE profile_bio IS NULL OR LENGTH(profile_bio) < 10;\n        \n    ELSIF p_location_filter IS NOT NULL THEN\n        INSERT INTO temp_location_based_users \n        SELECT user_id, user_name, location, followers \n        FROM users \n        WHERE location ILIKE '%' || p_location_filter || '%';\n        \n    ELSIF p_join_date_cutoff IS NOT NULL THEN\n        -- Update users table directly with account age category\n        UPDATE users \n        SET profile_bio = COALESCE(profile_bio, '') || ' [veteran]'\n        WHERE join_date < p_join_date_cutoff;\n        \n    ELSE\n        INSERT INTO temp_general_user_metrics \n        SELECT user_id, followers, following, userVerified \n        FROM users \n        WHERE user_default_profile = 0;\n    END IF;\nEND;\n$$;",
    "database_name": "social_media_data_analysis_and_sentiment_tracking_323366",
    "tables": [
      "tweets",
      "users"
    ],
    "id": 177
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_insert_sector_news that is defined to execute automatically after a new row is inserted into the sector_news table for each affected row, and within its execution block it first declares two local NUMBER variables v_next_viz_id and v_next_trend_id, then performs a SELECT query on the visualizations table to retrieve the maximum existing value from the visualization_id column, uses the NVL function to treat a NULL result as 0, adds 1 to that value, and stores the result into v_next_viz_id, then performs another SELECT query on the sector_trends table to retrieve the maximum existing value from the trend_id column, uses the NVL function to treat a NULL result as 0, adds 1 to that value, and stores the result into v_next_trend_id, then inserts a new row into the visualizations table specifying the columns visualization_id with the value from v_next_viz_id, correlation_id as NULL, visualization_type as the literal string 'word_cloud', visualization_title as the literal string 'Sector News Word Cloud', and visualization_date as the current system date converted to a string in the 'YYYY-MM-DD' format using the TO_CHAR function with SYSDATE, then performs an UPDATE operation on the sectors table setting the sector_last_updated column to the current system date converted to a string in the 'YYYY-MM-DD' format for the specific row where the sector_id column matches the value of the newly inserted sector_id from the sector_news table referenced by the :NEW.sector_id bind variable, then performs a DELETE operation on the sector_performance table removing any rows where the performance_date column, after being converted from a string to a DATE type using the TO_DATE function with the 'YYYY-MM-DD' format mask, is less than the date exactly 365 days prior to the current system date calculated by SYSDATE - 365, and finally inserts a new row into the sector_trends table specifying the columns trend_id with the value from v_next_trend_id, sector_id with the value from :NEW.sector_id, trend_date as the current system date converted to a string in the 'YYYY-MM-DD' format, trend_value as the numeric literal 0.01, trend_source as the literal string 'internal', trend_method as the literal string 'news_impact', and trend_currency as the literal string 'USD'.",
    "plsql": "CREATE OR REPLACE TRIGGER trg_insert_sector_news\nAFTER INSERT ON sector_news\nFOR EACH ROW\nDECLARE\n    v_next_viz_id NUMBER;\n    v_next_trend_id NUMBER;\nBEGIN\n    -- Get next visualization_id\n    SELECT NVL(MAX(visualization_id), 0) + 1 INTO v_next_viz_id FROM visualizations;\n    \n    -- Get next trend_id\n    SELECT NVL(MAX(trend_id), 0) + 1 INTO v_next_trend_id FROM sector_trends;\n    \n    INSERT INTO visualizations (visualization_id, correlation_id, visualization_type, visualization_title, visualization_date)\n    VALUES (v_next_viz_id, NULL, 'word_cloud', 'Sector News Word Cloud', TO_CHAR(SYSDATE, 'YYYY-MM-DD'));\n    \n    UPDATE sectors \n    SET sector_last_updated = TO_CHAR(SYSDATE, 'YYYY-MM-DD') \n    WHERE sector_id = :NEW.sector_id;\n    \n    DELETE FROM sector_performance \n    WHERE TO_DATE(performance_date, 'YYYY-MM-DD') < SYSDATE - 365;\n    \n    INSERT INTO sector_trends (trend_id, sector_id, trend_date, trend_value, trend_source, trend_method, trend_currency)\n    VALUES (v_next_trend_id, :NEW.sector_id, TO_CHAR(SYSDATE, 'YYYY-MM-DD'), 0.01, 'internal', 'news_impact', 'USD');\nEND;",
    "database_name": "economic_sc_analysis",
    "tables": [
      "sectors",
      "sector_performance",
      "sector_trends",
      "correlations",
      "sector_news",
      "visualizations"
    ],
    "_source": "plfactory9",
    "id": 178
  },
  {
    "ir": "Write a PostgreSQL trigger function named update_booking_status_on_package_change that returns a trigger and is executed by a trigger named trg_update_booking_status_on_package_change, which is defined to fire after an update operation on the price column of the packages table for each row that is updated, where the function performs an update on the bookings table, setting the status column to the string literal value 'pending' for every row in the bookings table where the package_id column matches the NEW.package_id value from the updated packages row and the current status column value is the string literal 'confirmed', and the function concludes by returning the NEW row record.",
    "plsql": "CREATE OR REPLACE FUNCTION update_booking_status_on_package_change() RETURNS TRIGGER AS $$\nBEGIN\nUPDATE bookings SET status = 'pending' WHERE package_id = NEW.package_id AND status = 'confirmed';\nRETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_update_booking_status_on_package_change\nAFTER UPDATE OF price ON packages\nFOR EACH ROW EXECUTE FUNCTION update_booking_status_on_package_change();",
    "database_name": "luxury_villa_rental_and_management",
    "tables": [
      "bookings",
      "packages",
      "reviews",
      "villas"
    ],
    "_source": "plfactory29",
    "id": 179
  },
  {
    "ir": "Write an Oracle PL/SQL function named `update_order_payment_status` that accepts three input parameters: `p_order_id` of data type `NUMBER`, representing the unique identifier of an order; `p_payment_status` of data type `VARCHAR2`, representing the new payment status to be applied; and `p_payment_method` of data type `VARCHAR2`, representing the new payment method to be applied. This function is designed to return a `NUMBER` value. Upon execution, the function first performs an `UPDATE` operation on the `payments` table. In this update, it sets the `payment_status` column to the value provided by the `p_payment_status` parameter and sets the `payment_method` column to the value provided by the `p_payment_method` parameter. This update is applied only to rows in the `payments` table where the `order_id` column matches the value supplied by the `p_order_id` parameter. Subsequently, the function performs another `UPDATE` operation, this time on the `orders` table. In this second update, it sets the `payment_status` column to the value provided by the `p_payment_status` parameter. This update is applied only to rows in the `orders` table where the `order_id` column matches the value supplied by the `p_order_id` parameter. Following these update operations, the function executes a `SELECT` statement to count the number of rows in the `payments` table. The count is stored in a local variable named `v_updated_count`, which is of data type `NUMBER`. The `SELECT` statement counts rows where the `order_id` column matches the value supplied by the `p_order_id` parameter AND the `payment_status` column matches the value supplied by the `p_payment_status` parameter. Finally, the function returns the value stored in the `v_updated_count` variable.",
    "plsql": "CREATE OR REPLACE FUNCTION update_order_payment_status(p_order_id NUMBER, p_payment_status VARCHAR2, p_payment_method VARCHAR2) RETURN NUMBER IS\n  v_updated_count NUMBER;\nBEGIN\n  UPDATE payments SET payment_status = p_payment_status, payment_method = p_payment_method WHERE order_id = p_order_id;\n  UPDATE orders SET payment_status = p_payment_status WHERE order_id = p_order_id;\n  SELECT COUNT(*) INTO v_updated_count FROM payments WHERE order_id = p_order_id AND payment_status = p_payment_status;\n  RETURN v_updated_count;\nEND;",
    "database_name": "cannabis_pmar_tracking",
    "tables": [
      "customers",
      "orders",
      "order_items",
      "products",
      "payments",
      "inventory"
    ],
    "id": 180
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `process_category_consolidation` that accepts four input parameters: `p_old_category_id` of type `NUMBER`, representing the identifier of the category to be consolidated; `p_new_category_id` of type `NUMBER`, representing the identifier of the target category for consolidation; `p_user_id` of type `NUMBER`, representing the identifier of the user performing the consolidation; and `p_date_cutoff` of type `VARCHAR2`, representing a date string used as a cutoff point for sales data.\n\nThe procedure begins by declaring several local variables: `v_old_category_name` of type `VARCHAR2(255)` to store the name of the old category, `v_new_category_name` of type `VARCHAR2(255)` to store the name of the new category, `v_sales_count` of type `NUMBER` to store the count of sales records, and `v_inventory_count` of type `NUMBER` to store the count of inventory items.\n\nFirst, the procedure retrieves the `category_name` from the `sell_categories` table where the `sell_category_id` matches the `p_old_category_id` parameter and stores it into the `v_old_category_name` variable.\n\nNext, it retrieves the `category_name` from the `sell_categories` table where the `sell_category_id` matches the `p_new_category_id` parameter and stores it into the `v_new_category_name` variable.\n\nSubsequently, it counts the number of records in the `sales` table where the `sell_category_id` matches the `p_old_category_id` parameter and the `calendar_date` is less than the `p_date_cutoff` parameter. This count is then stored in the `v_sales_count` variable.\n\nFollowing this, it counts the number of records in the `inventory_items` table where the `category_id` matches the `p_old_category_id` parameter. This count is then stored in the `v_inventory_count` variable.\n\nThe procedure then proceeds with a conditional block: if both `v_sales_count` is greater than 0 AND `v_inventory_count` is greater than 0, the following operations are performed:\n\nAn `INSERT` statement is executed on the `sales` table. A new `sell_id` is generated by taking the maximum existing `sell_id` from the `sales` table, adding 1 to it, and handling cases where no `sell_id` exists by defaulting to 0 before adding 1 using `NVL(MAX(sell_id), 0) + 1`. The `calendar_date` is set to the current system date formatted as 'YYYY-MM-DD' using `TO_CHAR(SYSDATE, 'YYYY-MM-DD')`. The `price` is set to 0. The `quantity` is set to the value of `v_inventory_count`. The `sell_category_id` is set to the `p_new_category_id` parameter. The `user_id` is set to the `p_user_id` parameter. The `customer_id` is set to 333. The `payment_method` is set to the string 'Category Consolidation'. The `discount` is set to 0. The `tax` is set to 0. The `total_amount` is calculated as `v_sales_count * 100`.\n\nNext, a `DELETE` statement is executed on the `inventory_items` table, removing all records where the `category_id` matches the `p_old_category_id` parameter AND the `stock_quantity` is equal to 0.\n\nFinally, another `INSERT` statement is executed on the `inventory_items` table. A new `item_id` is generated by taking the maximum existing `item_id` from the `inventory_items` table, adding 1 to it, and handling cases where no `item_id` exists by defaulting to 0 before adding 1 using `NVL(MAX(item_id), 0) + 1`. The `item_name` is constructed by concatenating the string 'Consolidated ' with the value of `v_old_category_name`. The `category_id` is set to the `p_new_category_id` parameter. The `stock_quantity` is calculated as `v_inventory_count * 10`. The `reorder_level` is set to 50. The `cost_price` is set to 75. The `selling_price` is set to 100. The `supplier_id` is set to 1. The `last_restock_date` is set to the current system date formatted as 'YYYY-MM-DD' using `TO_CHAR(SYSDATE, 'YYYY-MM-DD')`. The `next_restock_date` is set to the system date plus 60 days, formatted as 'YYYY-MM-DD' using `TO_CHAR(SYSDATE + 60, 'YYYY-MM-DD')`. The `is_active` flag is set to 1.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_category_consolidation(\n    p_old_category_id NUMBER,\n    p_new_category_id NUMBER,\n    p_user_id NUMBER,\n    p_date_cutoff VARCHAR2\n) IS\n    v_old_category_name VARCHAR2(255);\n    v_new_category_name VARCHAR2(255);\n    v_sales_count NUMBER;\n    v_inventory_count NUMBER;\nBEGIN\n    SELECT category_name\n    INTO v_old_category_name\n    FROM sell_categories\n    WHERE sell_category_id = p_old_category_id;\n    \n    SELECT category_name\n    INTO v_new_category_name\n    FROM sell_categories\n    WHERE sell_category_id = p_new_category_id;\n    \n    SELECT COUNT(*)\n    INTO v_sales_count\n    FROM sales\n    WHERE sell_category_id = p_old_category_id\n    AND calendar_date < p_date_cutoff;\n    \n    SELECT COUNT(*)\n    INTO v_inventory_count\n    FROM inventory_items\n    WHERE category_id = p_old_category_id;\n    \n    IF v_sales_count > 0 AND v_inventory_count > 0 THEN\n        INSERT INTO sales (sell_id, calendar_date, price, quantity, sell_category_id, user_id, customer_id, payment_method, discount, tax, total_amount)\n        VALUES (\n            (SELECT NVL(MAX(sell_id), 0) + 1 FROM sales),\n            TO_CHAR(SYSDATE, 'YYYY-MM-DD'),\n            0,\n            v_inventory_count,\n            p_new_category_id,\n            p_user_id,\n            333,\n            'Category Consolidation',\n            0,\n            0,\n            v_sales_count * 100\n        );\n        \n        DELETE FROM inventory_items\n        WHERE category_id = p_old_category_id\n        AND stock_quantity = 0;\n        \n        INSERT INTO inventory_items (item_id, item_name, category_id, stock_quantity, reorder_level, cost_price, selling_price, supplier_id, last_restock_date, next_restock_date, is_active)\n        VALUES (\n            (SELECT NVL(MAX(item_id), 0) + 1 FROM inventory_items),\n            'Consolidated ' || v_old_category_name,\n            p_new_category_id,\n            v_inventory_count * 10,\n            50,\n            75,\n            100,\n            1,\n            TO_CHAR(SYSDATE, 'YYYY-MM-DD'),\n            TO_CHAR(SYSDATE + 60, 'YYYY-MM-DD'),\n            1\n        );\n    END IF;\nEND;",
    "database_name": "sales_ttai_management",
    "tables": [
      "inventory_items",
      "sales",
      "sell_categories",
      "users"
    ],
    "id": 181
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `calculate_trigonometric_popularity` that takes no parameters. This procedure performs a series of four independent `UPDATE` operations on different tables, each designed to adjust a `popularity` column based on a trigonometric sine function applied to its current value.\n\nThe first `UPDATE` statement targets the `eyesstyles` table. For every row in this table, it modifies the `popularity` column by adding a calculated value to its existing content. The calculated value is derived by first multiplying the current `popularity` value by `0.01`, then computing the sine of this result using the `sin()` function. The output of the `sin()` function is then multiplied by `20`. Finally, this entire calculated floating-point value is explicitly cast to a `bigint` data type using `CAST(... AS bigint)` before being added to the `popularity` column.\n\nThe second `UPDATE` statement targets the `hairstyles` table. Similar to the first update, for every row in this table, it modifies the `popularity` column by adding a calculated value. This calculated value is obtained by multiplying the current `popularity` value by `0.015`, computing the sine of this result using `sin()`, multiplying the sine output by `15`, and then casting the final floating-point value to a `bigint` using `CAST(... AS bigint)` before adding it to the `popularity` column.\n\nThe third `UPDATE` statement targets the `headcolors` table. For every row in this table, it modifies the `popularity` column by adding a calculated value. This calculated value is determined by multiplying the current `popularity` value by `0.02`, computing the sine of this result using `sin()`, multiplying the sine output by `10`, and then casting the final floating-point value to a `bigint` using `CAST(... AS bigint)` before adding it to the `popularity` column.\n\nThe fourth and final `UPDATE` statement targets the `heads` table. For every row in this table, it modifies the `popularity` column by adding a calculated value. This calculated value is derived by multiplying the current `popularity` value by `0.025`, computing the sine of this result using `sin()`, multiplying the sine output by `8`, and then casting the final floating-point value to a `bigint` using `CAST(... AS bigint)` before adding it to the `popularity` column.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_trigonometric_popularity()\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE eyesstyles \n    SET popularity = popularity + CAST(sin(popularity * 0.01) * 20 AS bigint);\n    \n    UPDATE hairstyles \n    SET popularity = popularity + CAST(sin(popularity * 0.015) * 15 AS bigint);\n    \n    UPDATE headcolors \n    SET popularity = popularity + CAST(sin(popularity * 0.02) * 10 AS bigint);\n    \n    UPDATE heads \n    SET popularity = popularity + CAST(sin(popularity * 0.025) * 8 AS bigint);\nEND;\n$$;",
    "database_name": "character_customization_and_database_for_virtual_avatars",
    "tables": [
      "eyesstyles",
      "hairstyles",
      "headcolors",
      "heads"
    ],
    "id": 182
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named update_flight_mission_status that accepts a single input parameter p_flight_id of type NUMBER, which represents the unique identifier of a flight. The procedure begins by declaring a local variable v_mission of type VARCHAR2 with a maximum length of 255 characters. It then executes a SELECT statement to retrieve the mission column value from the flights table for the row where the flight_id column matches the input parameter p_flight_id, storing this value into the v_mission variable. Following this, the procedure evaluates a conditional statement using an IF clause to check if the length of the v_mission string exceeds 10 characters. If this condition is true, the procedure performs a DELETE operation on the flights table, removing the row where the flight_id matches the input parameter p_flight_id. If the condition is false, indicating that the length of v_mission is 10 characters or fewer, the procedure executes an INSERT statement to add a new row into the flights table. This new row is populated with the following values: the flight_id column is set to the input parameter p_flight_id, the aircraft_id column is set to 1, the flight_date column is set to the date '2023-05-01', the mission column is set to the string 'New Mission', the flight_number column is set to 'AA789', the departure_airport column is set to 'LAX', and the arrival_airport column is set to 'JFK'.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_flight_mission_status(p_flight_id IN NUMBER)\nIS\n    v_mission VARCHAR2(255);\nBEGIN\n    SELECT mission INTO v_mission\n    FROM flights\n    WHERE flight_id = p_flight_id;\n    \n    IF LENGTH(v_mission) > 10 THEN\n        DELETE FROM flights WHERE flight_id = p_flight_id;\n    ELSE\n        INSERT INTO flights (flight_id, aircraft_id, flight_date, mission, flight_number, departure_airport, arrival_airport)\n        VALUES (p_flight_id, 1, '2023-05-01', 'New Mission', 'AA789', 'LAX', 'JFK');\n    END IF;\nEND;",
    "database_name": "aerospace_dca_analysis",
    "tables": [
      "aircrafts",
      "flights",
      "flight_data",
      "categories",
      "flight_data_versions",
      "users",
      "access_logs"
    ],
    "id": 183
  },
  {
    "ir": "Write a PostgreSQL trigger function named mirror_catch_data that is executed automatically by a trigger named trg_mirror_catch_data after every INSERT operation on the catch_records table for each new row, where the function first checks the current value of a custom configuration parameter named 'catch_records.mirror_trigger_recursion_guard' and, if the value is 'false', it sets that parameter to 'true' using the set_config function to prevent recursive trigger invocation, then performs an INSERT into the same catch_records table using values derived from the NEW special record variable, specifically inserting a new row with a record_id column value equal to the NEW.record_id plus 5000, a trip_id column value equal to NEW.trip_id, a species column value equal to the concatenation of the NEW.species string and the literal string '_mirror', a count column value equal to NEW.count, a weight column value equal to NEW.weight, an average_length column value equal to NEW.average_length plus the number of days extracted from an interval literal '5 days' cast to a real number, an average_weight column value equal to NEW.average_weight, and a capture_method column value equal to NEW.capture_method, after which it resets the custom configuration parameter 'catch_records.mirror_trigger_recursion_guard' back to 'false' using set_config, and finally returns the NEW record.",
    "plsql": "CREATE OR REPLACE FUNCTION mirror_catch_data() RETURNS TRIGGER AS $$\nBEGIN\n  -- Prevent recursive trigger invocation\n  IF current_setting('catch_records.mirror_trigger_recursion_guard', 't') = 'false' THEN\n    PERFORM set_config('catch_records.mirror_trigger_recursion_guard', 'true', false);\n    INSERT INTO catch_records (record_id, trip_id, species, count, weight, average_length, average_weight, capture_method)\n    VALUES (NEW.record_id + 5000, NEW.trip_id, NEW.species || '_mirror', NEW.count, NEW.weight, NEW.average_length + EXTRACT(DAY FROM interval '5 days')::real, NEW.average_weight, NEW.capture_method);\n    PERFORM set_config('catch_records.mirror_trigger_recursion_guard', 'false', false);\n  END IF;\n  RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_mirror_catch_data\nAFTER INSERT ON catch_records\nFOR EACH ROW\nEXECUTE FUNCTION mirror_catch_data();",
    "database_name": "fisheries_data_management_and_analysis",
    "tables": [
      "catch_records",
      "fishing_trips"
    ],
    "_source": "plfactory1",
    "id": 184
  },
  {
    "ir": "Write a PLpgSQL function that retrieves the airline_name from the airlines table for a given airline_id. The function, named get_airline_name, accepts a single parameter p_airline_id of type bigint, which represents the unique identifier of an airline. Within the function, a local variable v_airline_name of type text is declared to store the result of the query. The function performs a SELECT operation on the airlines table, specifically targeting the airline_name column, and uses the WHERE clause to filter the rows based on the condition that the airline_id column matches the value of the input parameter p_airline_id. The result of this SELECT query is assigned to the local variable v_airline_name using the INTO clause. Finally, the function returns the value stored in v_airline_name, which is the name of the airline corresponding to the provided airline_id.",
    "plsql": "CREATE OR REPLACE FUNCTION get_airline_name(p_airline_id bigint)\nRETURNS text\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_airline_name text;\nBEGIN\n    SELECT airline_name INTO v_airline_name FROM airlines WHERE airline_id = p_airline_id;\n    RETURN v_airline_name;\nEND;\n$$;",
    "database_name": "aviation_and_tourism_industry_analysis",
    "tables": [
      "aircraft",
      "airlines",
      "airports",
      "routes",
      "users",
      "dashboards",
      "reports"
    ],
    "id": 185
  },
  {
    "ir": "Write a PostgreSQL stored procedure named `anonymize_ip_addresses` that takes no parameters. This procedure performs a single `UPDATE` operation on the `audit_logs` table. The `UPDATE` statement modifies the `ip_address` column for specific rows. The new value for the `ip_address` column is derived by calling the `translate` function. The `translate` function takes three arguments: the original value of the `ip_address` column, the string `'0123456789'` as the characters to be replaced, and the string `'xxxxxxxxxx'` as the replacement characters. This means that every digit (0 through 9) found in the original `ip_address` string will be replaced by the character 'x'. This `UPDATE` operation is conditionally applied only to those rows in the `audit_logs` table where the `event_type` column has a value exactly equal to `'user_login'`.",
    "plsql": "CREATE OR REPLACE PROCEDURE anonymize_ip_addresses()\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE audit_logs \n    SET ip_address = translate(ip_address, '0123456789', 'xxxxxxxxxx')\n    WHERE event_type = 'user_login';\nEND;\n$$;",
    "database_name": "airflow_instance_configuration_management",
    "tables": [
      "audit_logs",
      "config_history"
    ],
    "id": 186
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named trg_update_congress_leader that is defined to execute before any row is inserted into the congressional_members table, and for each individual row being inserted. The trigger declares a local variable v_party_count of type NUMBER. The trigger's logic begins by performing a SELECT query on the congressional_members table to count all existing rows where the congress column value matches the new congress value from the inserted row (referenced as :NEW.congress) and where the party column value matches the new party value from the inserted row (referenced as :NEW.party), storing the resulting count into the v_party_count variable. Following this query, the trigger evaluates a conditional IF statement that checks if the value of v_party_count is greater than 100. If this condition is true, the trigger executes an UPDATE statement on the congresses table, setting the majority_leader column to a concatenated string formed by the new firstname value (from :NEW.firstname), a single space, and the new lastname value (from :NEW.lastname), specifically for the row in the congresses table where the congress_id column equals the new congress value from the inserted row (:NEW.congress).",
    "plsql": "CREATE OR REPLACE TRIGGER trg_update_congress_leader\nBEFORE INSERT ON congressional_members\nFOR EACH ROW\nDECLARE\n  v_party_count NUMBER;\nBEGIN\n  SELECT COUNT(*) INTO v_party_count\n  FROM congressional_members\n  WHERE congress = :NEW.congress AND party = :NEW.party;\n  IF v_party_count > 100 THEN\n    UPDATE congresses\n    SET majority_leader = :NEW.firstname || ' ' || :NEW.lastname\n    WHERE congress_id = :NEW.congress;\n  END IF;\nEND;",
    "database_name": "us_cmd_management",
    "tables": [
      "congresses",
      "congressional_members",
      "states"
    ],
    "_source": "plfactory11",
    "id": 187
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named sp2 that accepts three input parameters: para_group_name of type VARCHAR2, para_start_year of type NUMBER, and para_end_year of type NUMBER, and performs a deletion operation on the terrorist_incidents table, specifically removing rows where the incident_id matches the result set from a subquery that selects ti.incident_id from the terrorist_incidents table aliased as ti, joining it with the groups table aliased as g on the condition that ti.group_id equals g.group_id, and applying a filter where the g.group_name column exactly equals the provided para_group_name parameter, the ti.year column is between the para_start_year and para_end_year parameters inclusively, and the ti.success column has a value of 0.",
    "plsql": "CREATE OR REPLACE PROCEDURE sp2(para_group_name VARCHAR2, para_start_year NUMBER, para_end_year NUMBER) IS\nBEGIN\n  DELETE FROM terrorist_incidents\n  WHERE incident_id IN (\n    SELECT ti.incident_id\n    FROM terrorist_incidents ti\n    JOIN groups g ON ti.group_id = g.group_id\n    WHERE g.group_name = para_group_name\n    AND ti.year BETWEEN para_start_year AND para_end_year\n    AND ti.success = 0\n  );\nEND;",
    "database_name": "global_taa_analysis",
    "tables": [
      "terrorist_incidents",
      "attack_types",
      "casualties",
      "groups",
      "weapons"
    ],
    "id": 188
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named process_indicator_data that accepts a single input parameter p_year of type NUMBER, representing a specific year. The procedure begins by declaring two local variables: v_avg_score and v_total_countries, both of type NUMBER. It then executes a SELECT statement to calculate the average score and the total number of distinct countries from the country_indicators table for the given year, storing these values into v_avg_score and v_total_countries, respectively. The procedure proceeds with a conditional logic based on the value of v_avg_score. If v_avg_score is greater than 1.0, it updates the population column in the countries table by multiplying it by 1.02 for countries whose score in the country_indicators table for the specified year exceeds v_avg_score. Conversely, if v_avg_score is not greater than 1.0, it deletes rows from the country_indicators table where the score is less than v_avg_score for the specified year. The procedure then evaluates another condition based on v_total_countries. If v_total_countries is greater than 10, it inserts new rows into the country_indicators table, selecting data from the countries and indicators tables. The inserted rows include a new country_indicator_id, calculated as the maximum existing country_indicator_id plus one, the country_id from the countries table, the indicator_id from the indicators table, the year incremented by one, a score calculated as v_avg_score multiplied by 1.05, a standard_error of 0.05, and a confidence_interval of 0.95. This insertion is limited to three rows where the population in the countries table exceeds 500,000 and the indicator_type in the indicators table is 'social'. If v_total_countries is not greater than 10, the procedure updates the description column in the indicators table by appending ' (Year ' followed by the value of p_year and a closing parenthesis for indicators whose average score in the country_indicators table for the specified year is less than v_avg_score.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_indicator_data(p_year IN NUMBER) AS\n    v_avg_score NUMBER;\n    v_total_countries NUMBER;\nBEGIN\n    SELECT AVG(ci.score), COUNT(DISTINCT ci.country_id)\n    INTO v_avg_score, v_total_countries\n    FROM country_indicators ci\n    WHERE ci.year_id = p_year;\n    \n    IF v_avg_score > 1.0 THEN\n        UPDATE countries \n        SET population = population * 1.02 \n        WHERE country_id IN (\n            SELECT country_id FROM country_indicators \n            WHERE year_id = p_year AND score > v_avg_score\n        );\n    ELSE\n        DELETE FROM country_indicators \n        WHERE year_id = p_year AND score < v_avg_score;\n    END IF;\n    \n    IF v_total_countries > 10 THEN\n        INSERT INTO country_indicators (country_indicator_id, country_id, indicator_id, year_id, score, standard_error, confidence_interval)\n        SELECT \n            (SELECT MAX(country_indicator_id) + 1 FROM country_indicators),\n            c.country_id,\n            i.indicator_id,\n            p_year + 1,\n            v_avg_score * 1.05,\n            0.05,\n            0.95\n        FROM countries c, indicators i\n        WHERE c.population > 500000 AND i.indicator_type = 'social'\n        AND ROWNUM <= 3;\n    ELSE\n        UPDATE indicators \n        SET description = description || ' (Year ' || p_year || ')'\n        WHERE indicator_id IN (\n            SELECT indicator_id FROM country_indicators \n            WHERE year_id = p_year \n            GROUP BY indicator_id \n            HAVING AVG(score) < v_avg_score\n        );\n    END IF;\nEND;",
    "database_name": "global_gasi_analysis",
    "tables": [
      "countries",
      "country_indicators",
      "indicators"
    ],
    "id": 189
  },
  {
    "ir": "Write a PLpgSQL stored procedure named process_event_registrations that accepts four parameters: p_event_id of type bigint, p_status_filter of type text, p_min_amount of type real, and p_currency of type text. The procedure iterates over records in the registrations table, selecting registration_id and participant_id for rows where the event_id matches p_event_id and the status matches p_status_filter. For each selected registration record, it checks the currency specified by p_currency. If p_currency is 'KES', it retrieves the amount_kes from the payments table for the corresponding registration_id and stores it in the variable v_payment_amount. Otherwise, it retrieves the amount_usd from the payments table for the same registration_id and stores it in v_payment_amount. The procedure then compares v_payment_amount to p_min_amount. If v_payment_amount is greater than or equal to p_min_amount, it updates the status column in the registrations table to 'Approved' for the current registration_id. If v_payment_amount is less than p_min_amount, it updates the status column to 'Rejected' for the current registration_id. This process continues for each registration record that meets the initial selection criteria.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_event_registrations(p_event_id bigint, p_status_filter text, p_min_amount real, p_currency text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_registration_record RECORD;\n    v_payment_amount real;\nBEGIN\n    FOR v_registration_record IN \n        SELECT r.registration_id, r.participant_id\n        FROM registrations r\n        WHERE r.event_id = p_event_id\n        AND r.status = p_status_filter\n    LOOP\n        IF p_currency = 'KES' THEN\n            SELECT p.amount_kes INTO v_payment_amount\n            FROM payments p\n            WHERE p.registration_id = v_registration_record.registration_id;\n        ELSE\n            SELECT p.amount_usd INTO v_payment_amount\n            FROM payments p\n            WHERE p.registration_id = v_registration_record.registration_id;\n        END IF;\n\n        IF v_payment_amount >= p_min_amount THEN\n            UPDATE registrations r\n            SET status = 'Approved'\n            WHERE r.registration_id = v_registration_record.registration_id;\n        ELSE\n            UPDATE registrations r\n            SET status = 'Rejected'\n            WHERE r.registration_id = v_registration_record.registration_id;\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "event_management_and_registration",
    "tables": [
      "events",
      "registrations",
      "participants",
      "payments"
    ],
    "id": 190
  },
  {
    "ir": "Write an Oracle PL/SQL function named `get_participant_age_category` that accepts a single input parameter, `para_participant_id`, which is of data type `NUMBER`. This function is designed to return a `VARCHAR2` value representing the age category of a participant. Upon execution, the function first declares a local variable named `age_category` of data type `VARCHAR2` with a maximum length of 255 characters. The function then performs a `SELECT` operation to retrieve the value from the `age` column of the `participants` table. This selection is conditioned by matching the `participant_id` column in the `participants` table with the value provided in the `para_participant_id` input parameter. The retrieved `age` value is then immediately stored into the `age_category` local variable. Following this data retrieval, the function proceeds with a conditional logic block. It evaluates whether the value currently held in the `age_category` variable is less than the numerical literal `18`. If this condition evaluates to `TRUE`, the `age_category` variable is reassigned the string literal `'Minor'`. If the condition evaluates to `FALSE` (meaning the `age_category` value is 18 or greater), the `age_category` variable is reassigned the string literal `'Adult'`. Finally, the function returns the final value stored in the `age_category` variable as its output.",
    "plsql": "CREATE OR REPLACE FUNCTION get_participant_age_category(para_participant_id NUMBER) RETURN VARCHAR2 IS age_category VARCHAR2(255);\nBEGIN\n  SELECT age INTO age_category FROM participants WHERE participant_id = para_participant_id;\n  IF age_category < 18 THEN\n    age_category := 'Minor';\n  ELSE\n    age_category := 'Adult';\n  END IF;\n  RETURN age_category;\nEND;",
    "database_name": "consumer_pfau_analysis",
    "tables": [
      "malodors",
      "participants",
      "products",
      "ratings",
      "reasons",
      "rooms",
      "usage_records"
    ],
    "id": 191
  },
  {
    "ir": "Write a PLpgSQL stored procedure that deletes records from the order_items table where the order_id matches any order_id from the orders table that satisfies specific conditions, and then removes those matching records from the orders table. The procedure accepts three parameters: p_date_threshold of type text, which specifies the date before which orders should be considered for deletion; p_status of type text, which indicates the status that orders must have to be eligible for deletion; and p_customer_id of type bigint, which identifies the customer whose orders are targeted for deletion. The procedure begins by executing a DELETE operation on the order_items table, targeting rows where the order_id is found in a subquery that selects order_id from the orders table. This subquery applies three conditions: the order_date must be earlier than the value specified by p_date_threshold, the status must match the value provided in p_status, and the customer_id must equal the value given in p_customer_id. After removing the relevant order_items records, the procedure proceeds to delete rows directly from the orders table that meet the same three conditions: order_date less than p_date_threshold, status equal to p_status, and customer_id equal to p_customer_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_old_orders(p_date_threshold text, p_status text, p_customer_id bigint)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM order_items\n    WHERE order_id IN (\n        SELECT order_id FROM orders\n        WHERE order_date < p_date_threshold\n        AND status = p_status\n        AND customer_id = p_customer_id\n    );\n    \n    DELETE FROM orders\n    WHERE order_date < p_date_threshold\n    AND status = p_status\n    AND customer_id = p_customer_id;\nEND;\n$$;",
    "database_name": "customer_transaction_and_discount_management_343078",
    "tables": [
      "customers",
      "orders",
      "order_items"
    ],
    "id": 192
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named `analyze_player_capacity` that accepts one input parameter, `p_capacity_factor`, which is of data type `NUMBER`. This procedure is designed to calculate and display player capacity information based on data stored in the `game_modes` table. Upon execution, the procedure first declares two local variables: `v_total_capacity` and `v_mode_count`, both of data type `NUMBER`, to temporarily store the results of a database query. It then performs a `SELECT` operation on the `game_modes` table. This `SELECT` statement calculates the sum of all values in the `max_players` column and counts the total number of rows in the `game_modes` table. The calculated sum of `max_players` is then assigned to the `v_total_capacity` variable, and the count of rows is assigned to the `v_mode_count` variable. After retrieving these values, the procedure uses the `DBMS_OUTPUT.PUT_LINE` function to display two lines of information. The first `DBMS_OUTPUT.PUT_LINE` call concatenates the literal string 'Total capacity: ' with the value stored in `v_total_capacity` and prints this combined string to the console. The second `DBMS_OUTPUT.PUT_LINE` call concatenates the literal string 'Adjusted capacity: ' with the result of a calculation. This calculation involves multiplying the `v_total_capacity` by the input parameter `p_capacity_factor`, and then rounding the result of this multiplication to the nearest whole number using the `ROUND` function. The combined string, including the rounded adjusted capacity, is then printed to the console.",
    "plsql": "CREATE OR REPLACE PROCEDURE analyze_player_capacity(p_capacity_factor IN NUMBER)\nIS\n    v_total_capacity NUMBER;\n    v_mode_count NUMBER;\nBEGIN\n    SELECT SUM(max_players), COUNT(*)\n    INTO v_total_capacity, v_mode_count\n    FROM game_modes;\n    \n    DBMS_OUTPUT.PUT_LINE('Total capacity: ' || v_total_capacity);\n    DBMS_OUTPUT.PUT_LINE('Adjusted capacity: ' || ROUND(v_total_capacity * p_capacity_factor));\nEND;",
    "database_name": "gaming_pas_tracking",
    "tables": [
      "game_modes"
    ],
    "id": 193
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `assign_advisors_to_clients` that takes no input parameters. This procedure is designed to automatically assign financial advisors to clients who currently do not have an assigned advisor. The procedure begins by declaring two record variables: `client` and `advisor`, which will be used to hold rows retrieved from the `investment_experience` and `advisor` tables, respectively. The core logic of the procedure is encapsulated within a `FOR` loop that iterates over a result set. This result set is generated by selecting `client_id`, `investment_experience`, `risk_tolerance`, and `experience_level` columns from the `investment_experience` table. The selection is filtered by a `WHERE` clause to include only those clients whose `client_id` does not exist in the `advisor_clients` table, effectively targeting unassigned clients. For each `client` record retrieved in this loop, the procedure attempts to find a suitable `advisor`. This is done by executing a `SELECT` statement that retrieves the `advisor_id` from the `advisor` table into the `advisor` record variable. The selection of the advisor is based on a `WHERE` clause that matches the `specialization` column of the `advisor` table to a dynamically determined value. This dynamic value is derived from the `experience_level` column of the current `client` record using a `CASE` statement: if `client.experience_level` is 'Novice', the specialization sought is 'Retirement planning'; if 'Beginner', it's 'Wealth management'; if 'Intermediate', it's 'Portfolio management'; if 'Advanced', it's 'High net worth'; and for any other `experience_level`, it defaults to 'General advisory'. The advisors matching this specialization are then ordered by `years_of_experience` in descending order, and then by `advisor_rating` in descending order, to prioritize more experienced and highly-rated advisors. Finally, `LIMIT 1` ensures that only the single best-matching advisor is selected. After attempting to find an advisor, an `IF` statement checks if an `advisor` record was successfully found (i.e., `advisor IS NOT NULL`). If an advisor is found, an `INSERT` statement is executed to add a new record into the `advisor_clients` table. This new record includes the `advisor_id` from the found `advisor` record, the `client_id` from the current `client` record, and the `relationship_start_date` which is set to the `CURRENT_DATE`. The loop then continues to process the next unassigned client until all such clients have been considered.",
    "plsql": "CREATE OR REPLACE PROCEDURE assign_advisors_to_clients()\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    client RECORD;\n    advisor RECORD;\nBEGIN\n    FOR client IN \n        SELECT client_id, investment_experience, risk_tolerance, experience_level\n        FROM investment_experience\n        WHERE client_id NOT IN (SELECT client_id FROM advisor_clients)\n    LOOP\n        SELECT advisor_id INTO advisor\n        FROM advisor\n        WHERE specialization = CASE \n            WHEN client.experience_level = 'Novice' THEN 'Retirement planning'\n            WHEN client.experience_level = 'Beginner' THEN 'Wealth management'\n            WHEN client.experience_level = 'Intermediate' THEN 'Portfolio management'\n            WHEN client.experience_level = 'Advanced' THEN 'High net worth'\n            ELSE 'General advisory'\n        END\n        ORDER BY years_of_experience DESC, advisor_rating DESC\n        LIMIT 1;\n\n        IF advisor IS NOT NULL THEN\n            INSERT INTO advisor_clients (advisor_id, client_id, relationship_start_date)\n            VALUES (advisor.advisor_id, client.client_id, CURRENT_DATE);\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "wealth_management_and_financial_planning",
    "tables": [
      "accounts",
      "advisor",
      "advisor_clients",
      "aum_range",
      "investment_experience",
      "marketing_segment",
      "wallet_share"
    ],
    "id": 194
  },
  {
    "ir": "Write an Oracle PL/SQL trigger named sync_genre_movie_count that fires automatically after each row-level insert or delete operation on the movies table, and within its body, it uses a conditional IF-ELSIF block to perform distinct updates on the genres table based on the triggering operation: if the operation is an INSERT, it executes an UPDATE statement targeting the genres table, incrementing the total_movies column by one for the specific row where the genre_id column matches the value of the :NEW.genre column from the newly inserted movies row, using the NVL function to handle potential null values in total_movies by treating them as zero before addition; if the operation is a DELETE, it executes a different UPDATE statement on the genres table, decrementing the total_movies column by one for the row where the genre_id column matches the value of the :OLD.genre column from the recently deleted movies row, again using the NVL function to treat null total_movies values as zero before subtraction.",
    "plsql": "CREATE OR REPLACE TRIGGER sync_genre_movie_count\nAFTER INSERT OR DELETE ON movies\nFOR EACH ROW\nBEGIN\n    IF INSERTING THEN\n        UPDATE genres SET total_movies = NVL(total_movies, 0) + 1 WHERE genre_id = :NEW.genre;\n    ELSIF DELETING THEN\n        UPDATE genres SET total_movies = NVL(total_movies, 0) - 1 WHERE genre_id = :OLD.genre;\n    END IF;\nEND;",
    "database_name": "movie_abod_analysis",
    "tables": [
      "movies",
      "directors",
      "genres",
      "studios",
      "box_office",
      "imdb_ratings",
      "movielens_ratings",
      "releases",
      "runtime",
      "gross_us"
    ],
    "_source": "plfactory15",
    "id": 195
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL function named update_dataset_statistics that accepts a single parameter p_dataset_id of type bigint and returns void, which first retrieves the status value from the datasets table for the specified dataset_id and stores it in a local text variable v_status, then executes conditional logic based on this status: if the status equals 'active', the function calculates the average, minimum, and maximum values of the o1 column from the o1_values table joined with the dataset_versions table on version_id where the dataset_id matches the input parameter, storing these results in real variables v_avg_o1, v_min_o1, and v_max_o1, then updates the datasets table by setting the description column to a concatenated string containing these statistics with 'Avg O1: ' followed by the average value or 'N/A' if null, then ', Min: ' followed by the minimum value or 'N/A' if null, then ', Max: ' followed by the maximum value or 'N/A' if null, where the dataset_id matches the input parameter; if the status equals 'inactive', the function updates the datasets table by setting the description column to 'Statistics update skipped - dataset inactive' for the specified dataset_id; for any other status value, the function updates the datasets table by setting the description column to 'Unknown status: ' followed by the status value or 'NULL' if the status is null, where the dataset_id matches the input parameter.",
    "plsql": "CREATE OR REPLACE FUNCTION update_dataset_statistics(p_dataset_id bigint)\nRETURNS void AS $$\nDECLARE\n    v_avg_o1 real;\n    v_min_o1 real;\n    v_max_o1 real;\n    v_status text;\nBEGIN\n    SELECT status INTO v_status FROM datasets WHERE dataset_id = p_dataset_id;\n    \n    IF v_status = 'active' THEN\n        SELECT AVG(o1), MIN(o1), MAX(o1) INTO v_avg_o1, v_min_o1, v_max_o1\n        FROM o1_values ov\n        JOIN dataset_versions dv ON ov.version_id = dv.version_id\n        WHERE dv.dataset_id = p_dataset_id;\n        \n        UPDATE datasets \n        SET description = 'Avg O1: ' || COALESCE(v_avg_o1::text, 'N/A') || \n                         ', Min: ' || COALESCE(v_min_o1::text, 'N/A') || \n                         ', Max: ' || COALESCE(v_max_o1::text, 'N/A')\n        WHERE dataset_id = p_dataset_id;\n    ELSIF v_status = 'inactive' THEN\n        UPDATE datasets \n        SET description = 'Statistics update skipped - dataset inactive'\n        WHERE dataset_id = p_dataset_id;\n    ELSE\n        UPDATE datasets \n        SET description = 'Unknown status: ' || COALESCE(v_status, 'NULL')\n        WHERE dataset_id = p_dataset_id;\n    END IF;\nEND;\n$$ LANGUAGE plpgsql;",
    "database_name": "predictive_modeling_and_machine_learning_data",
    "tables": [
      "datasets",
      "dataset_versions",
      "data_samples",
      "data_labels",
      "o1_values",
      "viscodes"
    ],
    "id": 196
  },
  {
    "ir": "Write a PostgreSQL trigger function named remove_old_recommendations that returns a trigger and is executed by a trigger named trg_cleanup_recommendations, which is defined to fire BEFORE DELETE on the customers table for each row being deleted; the function performs a series of cascading deletions to remove all data associated with the customer identified by the OLD.customer_id value from the trigger context: first, it deletes all rows from the size_recommendations table where the customer_id column matches OLD.customer_id; second, it deletes all rows from the customer_measurements table where the customer_id column matches OLD.customer_id; third, it deletes all rows from the customer_feedback table where the customer_id column matches OLD.customer_id; finally, the function returns the OLD record row to the trigger mechanism.",
    "plsql": "CREATE OR REPLACE FUNCTION remove_old_recommendations() RETURNS TRIGGER AS $$\nBEGIN\n    -- Delete related size recommendations\n    DELETE FROM size_recommendations WHERE customer_id = OLD.customer_id;\n\n    -- Delete related customer measurements\n    DELETE FROM customer_measurements WHERE customer_id = OLD.customer_id;\n\n    -- Delete related customer feedback (assuming this table exists based on the error)\n    -- This line is added to address the foreign key violation error from customer_feedback\n    DELETE FROM customer_feedback WHERE customer_id = OLD.customer_id;\n\n    RETURN OLD;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_cleanup_recommendations\n    BEFORE DELETE ON customers\n    FOR EACH ROW\n    EXECUTE FUNCTION remove_old_recommendations();",
    "database_name": "fashion_size_conversion_and_measurement_data",
    "tables": [
      "customers",
      "customer_measurements",
      "size_recommendations"
    ],
    "_source": "plfactory14",
    "id": 197
  },
  {
    "ir": "Write a PostgreSQL stored procedure named calculate_loan_cube_root_metrics that accepts a single input parameter p_customer_id of type bigint, which represents the unique identifier of a customer whose loan metrics are to be calculated, and within the procedure declares two local variables: v_cube_root_amount of type real to store the calculated average cube root of loan amounts, and v_loan_count of type integer to store the count of active loans, then executes a SELECT query on the loans table that retrieves two aggregated values - the total count of records using COUNT(*) and the average of the cube root of the amount column using AVG(cbrt(amount)), where cbrt() is a mathematical function that calculates the cube root of a numeric value, with the COALESCE function applied to ensure that if the average calculation returns NULL, it will be replaced with 0, and this query filters the loans table to only include records where the customer_id column matches the input parameter p_customer_id and the status column equals 'active', storing these two calculated values into the corresponding local variables v_loan_count and v_cube_root_amount respectively, and finally raises a notice message that displays the customer ID, the count of active loans, and the average cube root amount using formatted placeholders.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_loan_cube_root_metrics(p_customer_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_cube_root_amount real;\n    v_loan_count integer;\nBEGIN\n    SELECT COUNT(*), COALESCE(AVG(cbrt(amount)), 0)\n    INTO v_loan_count, v_cube_root_amount\n    FROM loans\n    WHERE customer_id = p_customer_id AND status = 'active';\n    \n    RAISE NOTICE 'Customer % has % active loans with average cube root amount: %', p_customer_id, v_loan_count, v_cube_root_amount;\nEND;\n$$;",
    "database_name": "banking_and_loan_management_393597",
    "tables": [
      "customers",
      "accounts",
      "checkin_accounts",
      "loans"
    ],
    "id": 198
  },
  {
    "ir": "Write an Oracle PL/SQL stored procedure named get_employee_compensation_summary that accepts one input parameter, p_employee_id of type NUMBER, and returns four output parameters: p_total_compensation of type NUMBER, p_bonus of type NUMBER, p_benefits of type NUMBER, and p_base_salary of type NUMBER. The procedure initializes all four output parameters to zero. It then executes a FOR LOOP that queries the compensation table, selecting the total_compensation, bonus, benefits, and base_salary columns for every row where the employee_id column matches the input parameter p_employee_id. For each record retrieved from this query, the procedure adds the value of the record's total_compensation field to the p_total_compensation output parameter, adds the record's bonus field to the p_bonus output parameter, adds the record's benefits field to the p_benefits output parameter, and adds the record's base_salary field to the p_base_salary output parameter. After processing all matching rows from the compensation table, the loop ends.",
    "plsql": "CREATE OR REPLACE PROCEDURE get_employee_compensation_summary(\n    p_employee_id IN NUMBER,\n    p_total_compensation OUT NUMBER,\n    p_bonus OUT NUMBER,\n    p_benefits OUT NUMBER,\n    p_base_salary OUT NUMBER\n) AS\nBEGIN\n    p_total_compensation := 0;\n    p_bonus := 0;\n    p_benefits := 0;\n    p_base_salary := 0;\n\n    FOR rec IN (SELECT total_compensation, bonus, benefits, base_salary\n                FROM compensation\n                WHERE employee_id = p_employee_id) LOOP\n        p_total_compensation := p_total_compensation + rec.total_compensation;\n        p_bonus := p_bonus + rec.bonus;\n        p_benefits := p_benefits + rec.benefits;\n        p_base_salary := p_base_salary + rec.base_salary;\n    END LOOP;\nEND;",
    "database_name": "workforce_dac_analysis",
    "tables": [
      "employees",
      "compensation",
      "demographics",
      "employment_status",
      "age_groups",
      "disability_statuses"
    ],
    "id": 199
  },
  {
    "ir": "Write a PostgreSQL trigger function named add_to_waitlist that is executed automatically by a trigger named trigger_add_to_waitlist after any row is updated in the reservations table, but only for rows where the new cancellation_reason column value is not null and the old cancellation_reason column value was null. The function performs a single insert operation into the waitlists table. For the insert, the waitlist_id column is populated by a subquery that selects the maximum existing value from the waitlist_id column in the waitlists table, adds 1 to it, and uses 0 as a default if the maximum is null via the COALESCE function. The guest_id and table_id columns are populated directly from the OLD record values of the same columns from the updated reservations row. The waitlist_time column is set to the current date and time converted to a text string using CURRENT_TIMESTAMP::text. The estimated_wait_time column is set to the literal string '30 minutes'. The notes column is populated by concatenating the literal string 'Cancelled reservation: ' with the OLD.cancellation_reason value from the updated reservations row using the CONCAT function. The function concludes by returning the OLD row record to the trigger.",
    "plsql": "CREATE OR REPLACE FUNCTION add_to_waitlist() RETURNS TRIGGER AS $$\nBEGIN\n  INSERT INTO waitlists (waitlist_id, guest_id, table_id, waitlist_time, estimated_wait_time, notes) VALUES ((SELECT COALESCE(MAX(waitlist_id), 0) + 1 FROM waitlists), OLD.guest_id, OLD.table_id, CURRENT_TIMESTAMP::text, '30 minutes', CONCAT('Cancelled reservation: ', OLD.cancellation_reason));\n  RETURN OLD;\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trigger_add_to_waitlist\nAFTER UPDATE ON reservations\nFOR EACH ROW\nWHEN (NEW.cancellation_reason IS NOT NULL AND OLD.cancellation_reason IS NULL)\nEXECUTE FUNCTION add_to_waitlist();",
    "database_name": "restaurant_reservation_management",
    "tables": [
      "analytics",
      "reservations",
      "server_assignments",
      "waitlists"
    ],
    "_source": "plfactory8",
    "id": 200
  }
]