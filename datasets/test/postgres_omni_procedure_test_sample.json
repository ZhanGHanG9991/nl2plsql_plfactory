[
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named insert_new_style that accepts five input parameters: p_style_name of type text, which represents the name of the style; p_description of type text, which provides a description of the style; p_gender of type text, which indicates the gender classification for the style; p_category of type text, which specifies the category of the style; and p_season of type text, which denotes the season associated with the style. The procedure begins by declaring a local variable v_style_id of type bigint. It then executes a SELECT statement on the styles table to compute a new style identifier by taking the maximum existing value from the style_id column, using the COALESCE function to substitute a value of 0 if the maximum is NULL, and adding 1 to that result, storing the computed value into the v_style_id variable. Finally, the procedure performs an INSERT operation into the styles table, creating a new row with the following column values: the style_id column is set to the calculated v_style_id, the style_name column is set to the input parameter p_style_name, the description column is set to p_description, the gender column is set to p_gender, the category column is set to p_category, and the season column is set to p_season.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_new_style(p_style_name text, p_description text, p_gender text, p_category text, p_season text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_style_id bigint;\nBEGIN\n    SELECT COALESCE(MAX(style_id), 0) + 1 INTO v_style_id FROM styles;\n    INSERT INTO styles (style_id, style_name, description, gender, category, season) VALUES (v_style_id, p_style_name, p_description, p_gender, p_category, p_season);\nEND;\n$$;",
    "database_name": "clothing_size_specifications_and_inventory_management_966781",
    "tables": [
      "clothing_items",
      "clothing_sizes",
      "styles",
      "order_items",
      "orders",
      "customers"
    ],
    "call_sqls": [
      "CALL insert_new_style('Casual Shirt', 'A comfortable casual shirt', 'Male', 'Shirts', 'Summer');",
      "CALL insert_new_style('Formal Dress', 'Elegant formal dress', 'Female', 'Dresses', 'Winter');",
      "CALL insert_new_style('Running Shorts', 'Lightweight running shorts', 'Unisex', 'Shorts', 'Spring');",
      "CALL insert_new_style('Denim Jacket', 'Classic denim jacket', 'Male', 'Jackets', 'Fall');",
      "CALL insert_new_style('Wool Sweater', 'Warm wool sweater', 'Female', 'Sweaters', 'Winter');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named insert_new_style that adds a new style to the styles table by generating a new style_id as one more than the highest existing style_id (or starting at 1 if none exist), then inserts the provided style name, description, gender, category, and season into the styles table.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called 'insert_new_style' that adds a new style to the styles table by generating a new style identifier based on the highest existing ID plus one, or starting at 1 if no IDs exist, and then inserting the provided style name, description, gender, category, and season.",
    "id": 1,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `insert_new_style`. This procedure accepts five input parameters: `p_style_name` of type `text`, `p_description` of type `text`, `p_gender` of type `text`, `p_category` of type `text`, and `p_season` of type `text`. The procedure returns a `bigint` value, which is the newly generated `style_id` for the inserted style.\n\nThe procedure begins by declaring a local variable `v_new_style_id` of type `bigint`. This variable will hold the calculated identifier for the new style.\n\nThe core logic first determines the next available `style_id`. It performs a `SELECT` query on the `styles` table to retrieve the maximum value currently present in the `style_id` column. This query uses the `MAX` aggregate function. The result of this query is then used in a `COALESCE` function. If the `MAX(style_id)` returns a non-null value (meaning the table is not empty), the `COALESCE` function returns that maximum value plus one. If the `MAX(style_id)` returns `NULL` (meaning the table is empty), the `COALESCE` function returns the value `1`. The result of this `COALESCE(MAX(style_id) + 1, 1)` expression is assigned to the local variable `v_new_style_id`.\n\nNext, the procedure performs an `INSERT` operation into the `styles` table. It inserts a single new row. The values for the columns in this new row are provided as follows:\n- The `style_id` column receives the value stored in the local variable `v_new_style_id`.\n- The `style_name` column receives the value passed in the input parameter `p_style_name`.\n- The `description` column receives the value passed in the input parameter `p_description`.\n- The `gender` column receives the value passed in the input parameter `p_gender`.\n- The `category` column receives the value passed in the input parameter `p_category`.\n- The `season` column receives the value passed in the input parameter `p_season`.\n\nFinally, the procedure concludes by using a `RETURN` statement to output the value of `v_new_style_id`, which is the newly generated and inserted style identifier.",
    "original_summary": "Create a stored procedure named insert_new_style that inserts a new record into the styles table. It calculates a new style_id by finding the maximum existing ID (or starting at 0) and adding 1, then inserts the provided parameters for style name, description, gender, category, and season.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as 'insert_new_style' to insert a new entry into the styles table. The procedure must first compute a new style identifier by determining the maximum existing ID value, or initializing it to 0 if none exist, and subsequently incrementing it by 1. It should then proceed to insert the supplied parameters, which include the style name, description, gender, category, and season."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named consolidate_health_data_records that accepts one input parameter p_year of type bigint, representing a specific year for data processing, and performs a series of operations on a health_data table for each state listed in a states table. The procedure iterates through every record in the states table, using a FOR loop to process each state's state_id and state_name. For each state, it first calculates the total flu cases for the specified year by selecting the sum of the flu_cases column from the health_data table where the state_id matches the current state's ID and the year column equals the input p_year, storing the result in a local variable v_total_cases. If the calculated v_total_cases is NULL, indicating no health data records exist for that state and year, the procedure generates a new data_id by selecting the maximum existing data_id from the health_data table, adding 1 to it, and using 0 as a default if the maximum is NULL, storing this in v_new_data_id, then inserts a new record into the health_data table with this new data_id, the current state_id, flu_cases set to 0, flu_deaths set to 0, the input p_year as the year, week set to 1, and data_source set to 'consolidated'. If v_total_cases is not NULL and exceeds 100000, the procedure calculates the average vaccination percentage by selecting the average of the vac_percent column from health_data for the same state and year, storing it in v_vaccination_rate; if this average is greater than 0.01, it generates a new data_id as before, then inserts a new record into health_data with the new data_id, the current state_id, flu_cases set to the calculated v_total_cases, flu_deaths set to 0, year set to p_year, week set to 52, data_source set to 'annual_summary', and vaccination_coverage set to 'high'. If the average vaccination rate is 0.01 or less in this high-case scenario, it deletes from the health_data table any records for that state and year where the flu_cases column equals 0. If v_total_cases is not NULL and is 100000 or less, the procedure selects the vaccination_coverage value from the first health_data record for that state and year, storing it in v_coverage_type; if this value is 'low', it deletes from health_data any records for that state and year where the week column is greater than 50. If the vaccination_coverage is not 'low', it generates a new data_id and inserts a new record into health_data with the new data_id, the current state_id, flu_cases set to v_total_cases, flu_deaths set to 0, year set to p_year, week set to 53, and data_source set to 'year_end'.",
    "plsql": "CREATE OR REPLACE PROCEDURE consolidate_health_data_records(p_year bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_state_record RECORD;\n    v_total_cases bigint;\n    v_vaccination_rate real;\n    v_coverage_type text;\n    v_new_data_id bigint;\nBEGIN\n    FOR v_state_record IN SELECT state_id, state_name FROM states LOOP\n        SELECT SUM(flu_cases) INTO v_total_cases FROM health_data WHERE state_id = v_state_record.state_id AND year = p_year;\n        \n        IF v_total_cases IS NULL THEN\n            SELECT COALESCE(MAX(data_id), 0) + 1 INTO v_new_data_id FROM health_data;\n            INSERT INTO health_data (data_id, state_id, flu_cases, flu_deaths, year, week, data_source)\n            VALUES (v_new_data_id, v_state_record.state_id, 0, 0, p_year, 1, 'consolidated');\n        ELSIF v_total_cases > 100000 THEN\n            SELECT AVG(vac_percent) INTO v_vaccination_rate FROM health_data WHERE state_id = v_state_record.state_id AND year = p_year;\n            IF v_vaccination_rate > 0.01 THEN\n                SELECT COALESCE(MAX(data_id), 0) + 1 INTO v_new_data_id FROM health_data;\n                INSERT INTO health_data (data_id, state_id, flu_cases, flu_deaths, year, week, data_source, vaccination_coverage)\n                VALUES (v_new_data_id, v_state_record.state_id, v_total_cases, 0, p_year, 52, 'annual_summary', 'high');\n            ELSE\n                DELETE FROM health_data WHERE state_id = v_state_record.state_id AND year = p_year AND flu_cases = 0;\n            END IF;\n        ELSE\n            SELECT vaccination_coverage INTO v_coverage_type FROM health_data WHERE state_id = v_state_record.state_id AND year = p_year LIMIT 1;\n            IF v_coverage_type = 'low' THEN\n                DELETE FROM health_data WHERE state_id = v_state_record.state_id AND year = p_year AND week > 50;\n            ELSE\n                SELECT COALESCE(MAX(data_id), 0) + 1 INTO v_new_data_id FROM health_data;\n                INSERT INTO health_data (data_id, state_id, flu_cases, flu_deaths, year, week, data_source)\n                VALUES (v_new_data_id, v_state_record.state_id, v_total_cases, 0, p_year, 53, 'year_end');\n            END IF;\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "public_health_data_tracking_and_analysis_595280",
    "tables": [
      "access_logs",
      "health_data",
      "states",
      "user_roles",
      "users",
      "vaccination_programs"
    ],
    "call_sqls": [
      "CALL consolidate_health_data_records(2023);",
      "CALL consolidate_health_data_records(2022);",
      "CALL consolidate_health_data_records(2021);",
      "CALL consolidate_health_data_records(2020);",
      "CALL consolidate_health_data_records(2019);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `consolidate_health_data_records` that processes health data for all states in a given year. For each state, calculate the total flu cases from the health_data table for that year. If the total is NULL, insert a new record into health_data with data_source as 'consolidated', flu_cases as 0, and week as 1. If the total exceeds 100,000, calculate the average vaccination rate (vac_percent) from health_data for that state and year. If the average rate is greater than 0.01, insert a new record into health_data with data_source as 'annual_summary', week as 52, and vaccination_coverage as 'high'. If the average rate is 0.01 or less, delete all records from health_data for that state and year where flu_cases are 0. If the total is 100,000 or less, check the vaccination_coverage from health_data for that state and year. If it is 'low', delete all records from health_data for that state and year where week is greater than 50. Otherwise, insert a new record into health_data with data_source as 'year_end', week as 53, and flu_cases as the total calculated.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called consolidate_health_data_records that processes health data records for all states for a given year. For each state, sum the flu_cases from the health_data table for that year. If the sum is NULL, insert a new 'consolidated' record into health_data with flu_cases set to zero. If the sum exceeds 100,000, calculate the average vac_percent for that state and year; if this average is greater than 0.01, insert an 'annual_summary' record with vaccination_coverage as 'high', otherwise delete all records for that state and year where flu_cases equals zero. If the sum is 100,000 or less, check the vaccination_coverage from health_data for that state and year; if it is 'low', delete records where week is greater than 50, otherwise insert a 'year_end' record.",
    "id": 2,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `consolidate_health_data_records` that accepts one input parameter: `p_year` of type `bigint`, representing the specific year for which health data records are to be processed. The procedure processes data for all states in the database for the given year.\n\nThe procedure begins by declaring a cursor named `state_cursor`. This cursor selects all distinct `state_id` values from the `states` table. The procedure will iterate through each state one by one.\n\nFor each state fetched by the cursor, the procedure performs the following steps:\n\nFirst, it declares a local variable `v_sum_flu_cases` of type `bigint` to store the total sum of flu cases for the current state and the input year. It executes a `SELECT` statement with a `SUM` aggregation on the `flu_cases` column from the `health_data` table. The selection is filtered where the `state_id` matches the current state's ID from the cursor and the `year` column matches the input parameter `p_year`. The result of this sum is stored into `v_sum_flu_cases`. If no matching records are found, the sum will be `NULL`.\n\nNext, the procedure enters a conditional logic block based on the value of `v_sum_flu_cases`.\n\nIf `v_sum_flu_cases` is `NULL`, the procedure executes an `INSERT` statement into the `health_data` table. It creates a new record with the following values: `data_id` is set using the `nextval` function on the sequence associated with the `health_data.data_id` column (assuming a sequence exists for the primary key); `state_id` is set to the current state's ID; `flu_cases` is set to 0; `year` is set to the input parameter `p_year`; `data_source` is set to the literal string `'consolidated'`. All other columns in the new record are left as their default values (typically `NULL`).\n\nIf `v_sum_flu_cases` is not `NULL` and is greater than 100,000, the procedure declares another local variable `v_avg_vac_percent` of type `real`. It executes a `SELECT` statement with an `AVG` aggregation on the `vac_percent` column from the `health_data` table. The selection is filtered where the `state_id` matches the current state's ID and the `year` matches `p_year`. The result of this average calculation is stored into `v_avg_vac_percent`.\n\nThe procedure then checks if `v_avg_vac_percent` is greater than 0.01. If true, it executes an `INSERT` statement into the `health_data` table. It creates a new record with: `data_id` from the sequence; `state_id` set to the current state's ID; `vaccination_coverage` set to the literal string `'high'`; `year` set to `p_year`; `data_source` set to `'annual_summary'`. Other columns are defaulted.\n\nIf `v_avg_vac_percent` is not greater than 0.01 (i.e., less than or equal to 0.01), the procedure executes a `DELETE` statement on the `health_data` table. It deletes all records where the `state_id` matches the current state's ID, the `year` matches `p_year`, and the `flu_cases` column equals 0.\n\nIf `v_sum_flu_cases` is not `NULL` and is less than or equal to 100,000, the procedure declares a local variable `v_vaccination_coverage` of type `text`. It executes a `SELECT` statement to retrieve the `vaccination_coverage` from the `health_data` table. The selection uses `DISTINCT` to get a unique value and is filtered where `state_id` matches the current state's ID and `year` matches `p_year`. The result is stored into `v_vaccination_coverage`. If multiple distinct values exist, only one is fetched (typically the first encountered).\n\nThe procedure then checks if `v_vaccination_coverage` is equal to the literal string `'low'`. If true, it executes a `DELETE` statement on the `health_data` table. It deletes all records where the `state_id` matches the current state's ID, the `year` matches `p_year`, and the `week` column is greater than 50.\n\nIf `v_vaccination_coverage` is not `'low'` (which includes cases where it is `NULL` or any other value like `'medium'` or `'high'`), the procedure executes an `INSERT` statement into the `health_data` table. It creates a new record with: `data_id` from the sequence; `state_id` set to the current state's ID; `year` set to `p_year`; `data_source` set to `'year_end'`. Other columns are defaulted.\n\nAfter processing all states from the cursor, the procedure concludes its execution.",
    "original_summary": "Create a stored procedure named `consolidate_health_data_records` that processes health data for all states in a given year. For each state, calculate total flu cases. If total is NULL, insert a new 'consolidated' record with flu_cases=0. If total > 100,000, calculate average vaccination rate. If rate > 0.01, insert an 'annual_summary' record with 'high' coverage. If rate <= 0.01, delete records where flu_cases=0. If total <= 100,000, check vaccination_coverage. If 'low', delete records where week > 50. Otherwise, insert a 'year_end' record.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as `consolidate_health_data_records` to process health data records for all states pertaining to a specified year. For each individual state, compute the aggregate sum of influenza cases. Should this total be NULL, insert a new record of type 'consolidated' with the flu_cases value set to zero. In the event the total exceeds 100,000, proceed to calculate the average vaccination rate. If this computed rate is greater than 0.01, insert an 'annual_summary' record with coverage status marked as 'high'. Conversely, if the rate is less than or equal to 0.01, delete all records for that state where the flu_cases value equals zero. If the total is less than or equal to 100,000, evaluate the vaccination_coverage field. Should the coverage be classified as 'low', delete records where the week number is greater than 50. Otherwise, insert a record of type 'year_end'."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named insert_new_patient that accepts four input parameters: a first_name of type text, a last_name of type text, a dob of type text, and a gender of type text, and performs the following operations: it first declares a local variable new_patient_id of type bigint, then executes a SELECT query on the patients table to calculate a new patient identifier by taking the COALESCE of the maximum existing patient_id value from the patients table and 0, adding 1 to that result, and storing the computed value into the new_patient_id variable, and subsequently performs an INSERT operation into the patients table, specifying values for the columns patient_id (using the new_patient_id variable), first_name (using the first_name parameter), last_name (using the last_name parameter), dob (using the dob parameter), gender (using the gender parameter), patient_status (with the hardcoded string literal 'ACTIVE'), created_at (with the current date and time converted to text using CURRENT_TIMESTAMP::text), and updated_at (also with the current date and time converted to text using CURRENT_TIMESTAMP::text).",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_new_patient(first_name text, last_name text, dob text, gender text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    new_patient_id bigint;\nBEGIN\n    SELECT COALESCE(MAX(patient_id), 0) + 1 INTO new_patient_id FROM patients;\n    INSERT INTO patients (patient_id, first_name, last_name, dob, gender, patient_status, created_at, updated_at)\n    VALUES (new_patient_id, first_name, last_name, dob, gender, 'ACTIVE', CURRENT_TIMESTAMP::text, CURRENT_TIMESTAMP::text);\nEND;\n$$;",
    "database_name": "healthcare_data_management_and_analysis_411552",
    "tables": [
      "condition_occurrence",
      "diagnosis",
      "patients",
      "visits"
    ],
    "call_sqls": [
      "CALL insert_new_patient('John', 'Doe', '1980-01-15', 'Male');",
      "CALL insert_new_patient('Jane', 'Smith', '1992-05-20', 'Female');",
      "CALL insert_new_patient('Peter', 'Jones', '1975-11-01', 'Male');",
      "CALL insert_new_patient('Alice', 'Brown', '2000-03-10', 'Female');",
      "CALL insert_new_patient('Michael', 'Green', '1968-07-25', 'Male');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named insert_new_patient that adds a new patient record to the patients table by generating a new patient_id as the next sequential number, inserting the provided first_name, last_name, dob, and gender, setting the patient_status to 'ACTIVE', and recording the current timestamp for both created_at and updated_at.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called insert_new_patient that adds a new patient record by generating a new patient ID based on the highest existing one, inserting the provided first name, last name, date of birth, and gender into the patients table, setting the patient_status to 'ACTIVE', and recording the current timestamp for both created_at and updated_at.",
    "id": 3,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named insert_new_patient that takes four input parameters: p_first_name of type text, p_last_name of type text, p_dob of type text, and p_gender of type text. The procedure does not return a value. The procedure begins by declaring a local variable v_new_patient_id of type bigint, initialized to 1. The procedure then executes a SELECT statement on the patients table to retrieve the maximum value of the patient_id column, storing this value in the v_new_patient_id variable. If the maximum patient_id is NULL, indicating no existing records, v_new_patient_id remains 1; otherwise, it is set to the maximum patient_id plus 1. Following this, the procedure inserts a new record into the patients table with the following column values: patient_id set to v_new_patient_id, first_name set to p_first_name, last_name set to p_last_name, dob set to p_dob, gender set to p_gender, patient_status set to the string 'ACTIVE', created_at set to the current timestamp formatted as 'YYYY-MM-DD HH24:MI:SS', and updated_at set to the same current timestamp formatted as 'YYYY-MM-DD HH24:MI:SS'. The procedure completes after the INSERT operation.",
    "original_summary": "Create a stored procedure named insert_new_patient that adds a new patient record. It generates a new patient ID, inserts patient details with provided personal information, sets status to 'ACTIVE', and timestamps the creation and update times.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a stored procedure to add a new patient record. It should generate a fresh patient ID, put in the patient's personal details, mark the status as something like 'ACTIVE', and note down the creation and update times."
  },
  {
    "ir": "Write a PLpgSQL stored procedure that accepts three parameters: p_customer_id of type bigint, p_new_status of type text, and p_update_date of type text. The procedure first checks if a record exists in the customers table with a customer_id matching the value of p_customer_id. If such a record exists, it updates the is_active column to 1 if p_new_status is 'Active', or to 0 otherwise, and sets the updated_at column to the value of p_update_date for the matching customer_id. If no such record exists, it inserts a new row into the customers table with the customer_id set to p_customer_id, customer_name set to 'Unknown', email set to 'unknown@example.com', address set to 'Unknown Address', phone_number set to '000-000-0000', both created_at and updated_at columns set to p_update_date, and is_active set to 1 if p_new_status is 'Active', or to 0 otherwise.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_customer_status(p_customer_id bigint, p_new_status text, p_update_date text)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    IF EXISTS (SELECT 1 FROM customers WHERE customer_id = p_customer_id) THEN\n        UPDATE customers SET is_active = CASE WHEN p_new_status = 'Active' THEN 1 ELSE 0 END, updated_at = p_update_date WHERE customer_id = p_customer_id;\n    ELSE\n        INSERT INTO customers (customer_id, customer_name, email, address, phone_number, created_at, updated_at, is_active)\n        VALUES (p_customer_id, 'Unknown', 'unknown@example.com', 'Unknown Address', '000-000-0000', p_update_date, p_update_date, CASE WHEN p_new_status = 'Active' THEN 1 ELSE 0 END);\n    END IF;\nEND;\n$$;",
    "database_name": "garment_measurement_and_inventory_management_826182",
    "tables": [
      "customers",
      "orders",
      "order_items",
      "garment_types",
      "payments",
      "shipments"
    ],
    "call_sqls": [
      "CALL update_customer_status(100, 'Active', '2024-01-15 10:30:00');",
      "CALL update_customer_status(101, 'Inactive', '2024-01-15 11:45:00');",
      "CALL update_customer_status(1, 'Active', '2024-01-16 09:15:00');",
      "CALL update_customer_status(2, 'Inactive', '2024-01-16 14:20:00');",
      "CALL update_customer_status(999, 'Active', '2024-01-17 16:00:00');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_customer_status that takes a customer ID, a new status, and an update date, and if a customer with that ID exists in the customers table, updates their is_active to 1 if the new status is 'Active' (otherwise 0) and sets updated_at to the provided date; if the customer does not exist, inserts a new record with the given ID, default values for customer_name, email, address, and phone_number, sets both created_at and updated_at to the provided date, and sets is_active based on the new status.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called update_customer_status that takes a customer ID, a new status, and an update date. If the customer exists in the customers table, update their is_active field to 1 when the new status is 'Active' or to 0 otherwise, and set their updated_at to the provided date. If the customer does not exist, insert a new record with the given ID, set customer_name to 'Unknown', email to 'unknown@example.com', address to 'Unknown Address', phone_number to '000-000-0000', set both created_at and updated_at to the provided date, and set is_active based on the new status.",
    "id": 4,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named update_customer_status that accepts three parameters: p_customer_id of type bigint to identify the target customer, p_new_status of type text representing the new status to apply, and p_update_date of type text representing the date to use for timestamp updates.\n\nThe procedure first checks if a customer with the given p_customer_id exists in the customers table by performing a SELECT query on the customer_id column where it matches the input parameter p_customer_id, storing the result in a boolean variable v_customer_exists using the FOUND keyword.\n\nIf the customer exists (v_customer_exists is true), the procedure executes an UPDATE operation on the customers table for the row where customer_id equals p_customer_id. It sets the is_active column to 1 if the p_new_status parameter equals the string literal 'Active' (case-sensitive comparison), otherwise it sets is_active to 0. It also sets the updated_at column to the value of the p_update_date parameter.\n\nIf the customer does not exist (v_customer_exists is false), the procedure executes an INSERT operation into the customers table. It inserts a new row with the following values: customer_id set to the p_customer_id parameter, customer_name set to the string literal 'Unknown', email set to the string literal 'unknown@example.com', address set to the string literal 'Unknown Address', phone_number set to the string literal '000-000-0000', created_at set to the p_update_date parameter, updated_at set to the p_update_date parameter, and is_active set to 1 if p_new_status equals the string literal 'Active', otherwise set to 0.",
    "original_summary": "Create a stored procedure with parameters p_customer_id (bigint), p_new_status (text), and p_update_date (text). If a customer with the given ID exists, update their is_active to 1 if p_new_status is 'Active' (else 0) and set updated_at to p_update_date. If the customer does not exist, insert a new record with the given ID, name 'Unknown', email 'unknown@example.com', address 'Unknown Address', phone '000-000-0000', created_at and updated_at set to p_update_date, and is_active set based on p_new_status.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure that takes parameters p_customer_id (bigint), p_new_status (text), and p_update_date (text). If a customer with the provided ID exists, update their is_active field to 1 when p_new_status is 'Active', otherwise set it to 0, and also set their updated_at field to p_update_date. If the customer does not exist, insert a new record using the given ID, set the name to 'Unknown', email to 'unknown@example.com', address to 'Unknown Address', phone to '000-000-0000', set both created_at and updated_at to p_update_date, and set is_active based on the value of p_new_status."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named archive_requests that accepts three input parameters: a bigint parameter p_cutoff_days to specify a number of days, a bigint parameter p_batch_size to control the deletion batch limit, and a text parameter p_status_filter to indicate a request status. The procedure first calculates a cutoff date by subtracting p_cutoff_days days from the current date. It then performs a deletion from the data_requests table, targeting rows where the status column matches the p_status_filter value, and where the created_at column, after being converted from text to a date using the TO_DATE function with the format mask 'YYYY-MM-DD HH24:MI:SS', is earlier than the calculated cutoff date. To limit the number of rows deleted, the procedure uses a subquery in the WHERE clause's IN condition; this subquery selects the request_id column from the same data_requests table, applying identical conditions on the converted created_at date being before the cutoff and the status matching the filter, and restricts the result set to p_batch_size rows using the LIMIT clause, ensuring only that specific batch of identified request IDs is removed.",
    "plsql": "CREATE OR REPLACE PROCEDURE archive_requests(p_cutoff_days bigint, p_batch_size bigint, p_status_filter text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_cutoff_date date;\nBEGIN\n    v_cutoff_date := CURRENT_DATE - INTERVAL '1 day' * p_cutoff_days;\n    \n    DELETE FROM data_requests \n    WHERE TO_DATE(created_at, 'YYYY-MM-DD HH24:MI:SS') < v_cutoff_date \n    AND status = p_status_filter\n    AND request_id IN (\n        SELECT request_id FROM data_requests \n        WHERE TO_DATE(created_at, 'YYYY-MM-DD HH24:MI:SS') < v_cutoff_date \n        AND status = p_status_filter\n        LIMIT p_batch_size\n    );\nEND;\n$$;",
    "database_name": "weather_data_collection_and_analysis_874430",
    "tables": [
      "data_requests",
      "roles",
      "user_roles",
      "users",
      "weather_data_versions",
      "weather_stations"
    ],
    "call_sqls": [
      "CALL archive_requests(30, 100, 'pending');",
      "CALL archive_requests(60, 50, 'completed');",
      "CALL archive_requests(90, 200, 'pending');",
      "CALL archive_requests(120, 150, 'completed');",
      "CALL archive_requests(180, 75, 'pending');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `archive_requests` that archives old data requests by deleting rows from the `data_requests` table where the `status` matches a provided filter and the `created_at` date (stored as text) is older than a specified number of days, limiting the deletion to a given batch size.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `archive_requests` that archives old data requests by deleting records from the `data_requests` table where the `status` matches a given filter and the `created_at` date is older than a specified cutoff period in days, ensuring the total deletions do not exceed a provided maximum batch size.",
    "id": 5,
    "generated_ir": "Write a PostgreSQL PLpgSQL stored procedure named archive_requests that accepts three input parameters: a bigint parameter p_cutoff_days to specify a number of days, a bigint parameter p_batch_size to control the deletion batch limit, and a text parameter p_status_filter to indicate a request status. The procedure first calculates a cutoff date by subtracting p_cutoff_days days from the current date. It then performs a deletion from the data_requests table, targeting rows where the status column matches the p_status_filter value, and where the created_at column, after being converted from text to a date using the TO_DATE function with the format mask 'YYYY-MM-DD HH24:MI:SS', is earlier than the calculated cutoff date. To limit the number of rows deleted, the procedure uses a subquery in the WHERE clause's IN condition; this subquery selects the request_id column from the same data_requests table, applying identical conditions on the converted created_at date being before the cutoff and the status matching the filter, and restricts the result set to p_batch_size rows using the LIMIT clause, ensuring only that specific batch of identified request IDs is removed.",
    "original_summary": "Create a stored procedure named `archive_requests` with parameters for cutoff days, batch size, and status filter. Delete rows from the `data_requests` table where the status matches the filter and the `created_at` date (converted from text) is older than the cutoff date. Limit the deletion to the specified batch size.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as `archive_requests`. This procedure shall accept three parameters: a cutoff period in days, a maximum batch size for operations, and a status value for filtering. The procedure's function is to delete records from the `data_requests` table. The deletion should be applied to rows where the status column corresponds to the provided filter and where the `created_at` column, after conversion from its text representation to a date type, is determined to be older than the date calculated by subtracting the cutoff days from the current date. Furthermore, the total number of rows deleted must not exceed the specified batch size."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named manage_category_hierarchy that accepts a single input parameter p_parent_category_id of type bigint, which represents the identifier of a parent category to process. The procedure begins by declaring variables: v_category_record to hold rows from a query, v_child_count and v_instrument_count as integer counters, and v_new_category_id and v_new_instrument_id as bigint for new identifiers. It then enters a loop that iterates over each row returned from a SELECT query on the categories table, fetching the category_id and category_name for every record where the parent_category_id column matches the provided input parameter p_parent_category_id. For each such category record, it performs two SELECT COUNT(*) queries: the first counts rows in the categories table where the parent_category_id equals the current loop record's category_id, storing the result in v_child_count to determine the number of direct child categories; the second counts rows in the financial_instruments table where the category column equals the current loop record's category_id, storing the result in v_instrument_count to determine the number of financial instruments directly associated with this category. The procedure then evaluates a primary IF condition: if v_child_count is greater than 2, it proceeds to a nested IF condition checking if v_instrument_count is greater than 5; if true, it executes a DELETE operation on the financial_values table where the instrument_id matches any instrument_id from a subquery selecting instrument_id from the financial_instruments table where the category column equals the current loop record's category_id; if v_instrument_count is not greater than 5, it generates a new unique instrument_id by selecting the maximum existing instrument_id from the financial_instruments table, using COALESCE to default to 0 if none exist, adding 1, and storing it in v_new_instrument_id, then inserts a new row into the financial_instruments table with this new instrument_id, a description of 'Auto-generated instrument', a line_item of 'AUTO001', the current loop record's category_id as the category, a status of 'active', and the current timestamp as both created_at and updated_at values, cast to text. If the primary IF condition is false (meaning v_child_count is 2 or less), it proceeds to an alternative nested IF condition checking if the LENGTH of the current category's category_name is greater than 15 characters; if true and if v_child_count equals 0, it executes a DELETE operation on the categories table where the category_id equals the current loop record's category_id; if the length condition is false, it generates a new unique category_id by selecting the maximum existing category_id from the categories table, using COALESCE to default to 0, adding 1, and storing it in v_new_category_id, then inserts a new row into the categories table with this new category_id, a category_name formed by concatenating the string 'Sub-' with the current loop record's category_name, a description of 'Auto-generated subcategory', the current loop record's category_id as the parent_category_id, and the current timestamp as both created_at and updated_at values, cast to text.",
    "plsql": "CREATE OR REPLACE PROCEDURE manage_category_hierarchy(p_parent_category_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_category_record RECORD;\n    v_child_count integer;\n    v_instrument_count integer;\n    v_new_category_id bigint;\n    v_new_instrument_id bigint;\nBEGIN\n    FOR v_category_record IN SELECT category_id, category_name FROM categories WHERE parent_category_id = p_parent_category_id\n    LOOP\n        SELECT COUNT(*) INTO v_child_count FROM categories WHERE parent_category_id = v_category_record.category_id;\n        SELECT COUNT(*) INTO v_instrument_count FROM financial_instruments WHERE category = v_category_record.category_id;\n        \n        IF v_child_count > 2 THEN\n            IF v_instrument_count > 5 THEN\n                DELETE FROM financial_values WHERE instrument_id IN (SELECT instrument_id FROM financial_instruments WHERE category = v_category_record.category_id);\n            ELSE\n                -- Generate a new unique instrument_id\n                SELECT COALESCE(MAX(instrument_id), 0) + 1 INTO v_new_instrument_id FROM financial_instruments;\n                INSERT INTO financial_instruments (instrument_id, description, line_item, category, status, created_at, updated_at)\n                VALUES (v_new_instrument_id, 'Auto-generated instrument', 'AUTO001', v_category_record.category_id, 'active', CURRENT_TIMESTAMP::text, CURRENT_TIMESTAMP::text);\n            END IF;\n        ELSE\n            IF LENGTH(v_category_record.category_name) > 15 THEN\n                DELETE FROM categories WHERE category_id = v_category_record.category_id AND v_child_count = 0;\n            ELSE\n                -- Generate a new unique category_id\n                SELECT COALESCE(MAX(category_id), 0) + 1 INTO v_new_category_id FROM categories;\n                INSERT INTO categories (category_id, category_name, description, parent_category_id, created_at, updated_at)\n                VALUES (v_new_category_id, 'Sub-' || v_category_record.category_name, 'Auto-generated subcategory', v_category_record.category_id, CURRENT_TIMESTAMP::text, CURRENT_TIMESTAMP::text);\n            END IF;\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "banking_and_financial_management_95020",
    "tables": [
      "financial_instruments",
      "financial_reports",
      "financial_values",
      "quarters",
      "report_details",
      "categories"
    ],
    "call_sqls": [
      "CALL manage_category_hierarchy(0);",
      "CALL manage_category_hierarchy(1);",
      "CALL manage_category_hierarchy(2);",
      "CALL manage_category_hierarchy(10);",
      "CALL manage_category_hierarchy(NULL);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named manage_category_hierarchy that accepts a parent category ID (p_parent_category_id) and processes each direct child category of that parent from the categories table. For each child category, count its subcategories and associated financial instruments from the financial_instruments table. If a child has more than 2 subcategories and more than 5 instruments, delete related records from the financial_values table. If it has more than 2 subcategories but 5 or fewer instruments, insert a new auto-generated financial instrument into the financial_instruments table. If it has 2 or fewer subcategories and its category_name length exceeds 15 characters with no subcategories, delete the category from the categories table; otherwise, insert a new auto-generated subcategory into the categories table.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called manage_category_hierarchy that takes a parent category ID as input. For each immediate child category under the given parent, it should assess the child by counting its own subcategories and the financial instruments linked to it. If a child has more than two subcategories and more than five instruments, delete all related financial value records. If it has more than two subcategories but five or fewer instruments, insert a new auto-generated financial instrument. If it has two or fewer subcategories, its name exceeds fifteen characters, and it has no subcategories, delete the entire category. Otherwise, insert a new auto-generated subcategory.",
    "id": 6,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named manage_category_hierarchy that accepts a single input parameter p_parent_category_id of type bigint, which represents the identifier of a parent category to process. The procedure begins by declaring variables: v_category_record to hold rows from a query, v_child_count and v_instrument_count as integer counters, and v_new_category_id and v_new_instrument_id as bigint for new identifiers. It then enters a loop that iterates over each row returned from a SELECT query on the categories table, fetching the category_id and category_name for every record where the parent_category_id column matches the provided input parameter p_parent_category_id. For each such category record, it performs two SELECT COUNT(*) queries: the first counts rows in the categories table where the parent_category_id equals the current loop record's category_id, storing the result in v_child_count to determine the number of direct child categories; the second counts rows in the financial_instruments table where the category column equals the current loop record's category_id, storing the result in v_instrument_count to determine the number of financial instruments directly associated with this category. The procedure then evaluates a primary IF condition: if v_child_count is greater than 2, it proceeds to a nested IF condition checking if v_instrument_count is greater than 5; if true, it executes a DELETE operation on the financial_values table where the instrument_id matches any instrument_id from a subquery selecting instrument_id from the financial_instruments table where the category column equals the current loop record's category_id; if v_instrument_count is not greater than 5, it generates a new unique instrument_id by selecting the maximum existing instrument_id from the financial_instruments table, using COALESCE to default to 0 if none exist, adding 1, and storing it in v_new_instrument_id, then inserts a new row into the financial_instruments table with this new instrument_id, a description of 'Auto-generated instrument', a line_item of 'AUTO001', the current loop record's category_id as the category, a status of 'active', and the current timestamp as both created_at and updated_at values, cast to text. If the primary IF condition is false (meaning v_child_count is 2 or less), it proceeds to an alternative nested IF condition checking if the LENGTH of the current category's category_name is greater than 15 characters; if true and if v_child_count equals 0, it executes a DELETE operation on the categories table where the category_id equals the current loop record's category_id; if the length condition is false, it generates a new unique category_id by selecting the maximum existing category_id from the categories table, using COALESCE to default to 0, adding 1, and storing it in v_new_category_id, then inserts a new row into the categories table with this new category_id, a category_name formed by concatenating the string 'Sub-' with the current loop record's category_name, a description of 'Auto-generated subcategory', the current loop record's category_id as the parent_category_id, and the current timestamp as both created_at and updated_at values, cast to text.",
    "original_summary": "Create a stored procedure named manage_category_hierarchy that accepts a p_parent_category_id (bigint). For each direct child category of the given parent, it counts its child categories and associated financial instruments. If a child has more than 2 subcategories and more than 5 instruments, it deletes related financial values. If it has more than 2 subcategories but 5 or fewer instruments, it inserts a new auto-generated financial instrument. If it has 2 or fewer subcategories and its name length exceeds 15 characters with no children, it deletes the category. Otherwise, it inserts a new auto-generated subcategory.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Design a stored procedure called manage_category_hierarchy that takes a single input parameter, specifically a p_parent_category_id of type bigint. This procedure will systematically process each immediate child category belonging to the specified parent. For every such child, it will first perform a detailed assessment by calculating the total number of its own nested subcategories and also tallying all the financial instruments linked to it. Based on this comprehensive evaluation, it will then execute precise actions: if a child category is found to possess a substantial number of more than two subcategories and also has an extensive portfolio of more than five associated instruments, it will proceed to delete all related financial value records. Conversely, if the child has that same considerable count of over two subcategories but a more modest collection of five or fewer instruments, it will instead insert a brand new, auto-generated financial instrument. In a different scenario, if the child has a relatively small number of two or fewer subcategories, and additionally, its descriptive name is unusually long, exceeding fifteen characters in length, and it has no child categories of its own, then the procedure will delete that entire category. For all other cases that do not meet the above conditions, the procedure will generatively insert a new, auto-generated subcategory."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `update_company_contact` that accepts four input parameters: `p_company_id` of type `BIGINT`, `p_new_email` of type `TEXT`, `p_new_phone` of type `TEXT`, and `p_new_website` of type `TEXT`. The purpose of this procedure is to modify the contact information and website URL for a specific company record within the `companies` table. Upon execution, the procedure performs a single `UPDATE` operation on the `companies` table. This `UPDATE` statement sets the value of the `contact_email` column to the value provided by the `p_new_email` parameter, sets the value of the `contact_phone` column to the value provided by the `p_new_phone` parameter, and sets the value of the `website` column to the value provided by the `p_new_website` parameter. This modification is applied only to the row(s) in the `companies` table where the value in the `company_id` column exactly matches the value supplied by the `p_company_id` input parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_company_contact(\n    p_company_id BIGINT,\n    p_new_email TEXT,\n    p_new_phone TEXT,\n    p_new_website TEXT\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE companies\n    SET contact_email = p_new_email,\n        contact_phone = p_new_phone,\n        website = p_new_website\n    WHERE company_id = p_company_id;\nEND;\n$$;",
    "database_name": "telecommunication_number_allocation_and_usage",
    "tables": [
      "cities",
      "counties",
      "companies",
      "number_allocations",
      "number_prefixes",
      "usage_types",
      "users"
    ],
    "call_sqls": [
      "CALL update_company_contact(0, 'new.support@asttelecom.com', '+1 684 248 9999', 'https://www.asttelecom-new.com');",
      "CALL update_company_contact(1, 'info@aslicense.com', '+1 684 252 8888', 'https://www.aslicense-updated.com');",
      "CALL update_company_contact(0, 'admin@asttelecom.as', '+1 684 248 1111', NULL);",
      "CALL update_company_contact(1, NULL, '+1 684 252 0000', 'https://license.gov.as');",
      "CALL update_company_contact(0, 'contact@asttelecom.net', NULL, 'https://asttelecom.net');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_company_contact that updates the contact information for a specific company in the companies table, using the provided company ID to update the contact_email, contact_phone, and website columns with new email, phone, and website values.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named update_company_contact that updates the contact_email, contact_phone, and website in the companies table for a specific company, using the provided company_id, new_email, new_phone, and new_website.",
    "id": 7,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named update_company_contact that accepts four input parameters: a p_company_id parameter of type bigint which specifies the unique identifier for the company record to be modified, a p_new_email parameter of type text which provides the new contact email address value, a p_new_phone parameter of type text which provides the new contact phone number value, and a p_new_website parameter of type text which provides the new website URL value. This procedure performs a single UPDATE operation on the companies table, setting the contact_email column to the value of the p_new_email parameter, setting the contact_phone column to the value of the p_new_phone parameter, setting the website column to the value of the p_new_website parameter, and setting the last_updated column to a formatted string representation of the current date and time generated by the to_char function called with the CURRENT_TIMESTAMP value and the format model 'YYYY-MM-DD HH24:MI:SS'. This update is applied only to those rows in the companies table where the company_id column value is exactly equal to the value provided by the p_company_id input parameter.",
    "original_summary": "Create a stored procedure named update_company_contact that accepts p_company_id (BIGINT), p_new_email (TEXT), p_new_phone (TEXT), and p_new_website (TEXT). Update the contact_email, contact_phone, and website columns for the specified company in the companies table.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create procedure update_company_contact with inputs p_company_id BIGINT, p_new_email TEXT, p_new_phone TEXT, p_new_website TEXT. Update companies table's contact_email, contact_phone, and website for that company."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `manage_health_freedom_correlation` that accepts four input parameters: `analysis_year` of type `bigint`, `health_min` of type `real`, `freedom_min` of type `real`, and `trust_threshold` of type `real`. The purpose of this procedure is to analyze and potentially modify data across several tables (`countries`, `health_data`, `freedom_data`, `economic_data`, `happiness_data`) based on various conditions related to health, freedom, and trust for a specified `analysis_year`.\n\nThe procedure begins by declaring a cursor named `data_cursor` which is designed to select `country_id`, `country_name`, and `region` from the `countries` table. It also declares a record variable named `current_country` to hold the data fetched by the cursor.\n\nThe procedure then opens `data_cursor` and enters a loop to process each country. In each iteration, it fetches the `country_id`, `country_name`, and `region` of the next country into the `current_country` record. The loop terminates when no more rows are found by the cursor.\n\nInside the loop, for each `current_country`, the procedure first checks if an entry exists in the `health_data` table for the `current_country.country_id` and the `analysis_year`, where the `life_expectancy` is greater than or equal to the `health_min` parameter.\n\nIf such a health data entry exists, the procedure proceeds to check if an entry exists in the `freedom_data` table for the `current_country.country_id` and the `analysis_year`, where the `freedom_score` is greater than or equal to the `freedom_min` parameter.\n\nIf both health and freedom data entries exist under these conditions, the procedure then retrieves the `trust_in_government` value from the `freedom_data` table for the `current_country.country_id` and the `analysis_year`. It checks if this `trust_in_government` value is greater than the `trust_threshold` parameter.\n\nIf the `trust_in_government` is greater than `trust_threshold`, the procedure further checks if the `healthcare_spending` value from the `health_data` table for the `current_country.country_id` and the `analysis_year` is greater than `4000.0`.\n    If `healthcare_spending` is greater than `4000.0`, the procedure executes a `DELETE` statement on the `economic_data` table, removing rows where the `country_id` matches `current_country.country_id`, the `year` is less than `analysis_year - 1`, and the `poverty_rate` is greater than `20.0`.\n    Otherwise (if `healthcare_spending` is not greater than `4000.0`), the procedure executes an `INSERT` statement into the `happiness_data` table. It inserts a new row with `happiness_id` calculated as `COALESCE(MAX(happiness_id), 0) + 1` from the `happiness_data` table, `country_id` set to `current_country.country_id`, `happiness_rank` set to `50`, `happiness_score` set to `6.5`, `year` set to `analysis_year`, `survey_method` set to `'calculated'`, `data_source` set to `'system'`, and `version` set to `'1'`.\n\nIf the `trust_in_government` is not greater than `trust_threshold` (from the earlier check), the procedure executes an `UPDATE` statement on the `freedom_data` table, setting the `trust_in_government` column to `trust_in_government * 0.9` for the row where `country_id` matches `current_country.country_id` and `year` matches `analysis_year`.\n\nIf the freedom data entry does not exist under the specified conditions (i.e., `freedom_score` is not greater than or equal to `freedom_min`), the procedure executes an `INSERT` statement into the `freedom_data` table. It inserts a new row with `freedom_id` calculated as `COALESCE(MAX(freedom_id), 0) + 1` from the `freedom_data` table, `country_id` set to `current_country.country_id`, `freedom_score` set to `0.3`, `trust_in_government` set to `0.2`, `year` set to `analysis_year`, `data_source` set to `'computed'`, and `version` set to `'1'`.\n\nIf the initial health data entry does not exist under the specified conditions (i.e., `life_expectancy` is not greater than or equal to `health_min`), the procedure executes an `UPDATE` statement on the `health_data` table, setting the `healthcare_spending` column to `healthcare_spending * 0.8` for the row where `country_id` matches `current_country.country_id` and `year` matches `analysis_year`.\n\nAfter the loop finishes processing all countries, the procedure closes the `data_cursor`.",
    "plsql": "CREATE OR REPLACE PROCEDURE manage_health_freedom_correlation(IN analysis_year bigint, IN health_min real, IN freedom_min real, IN trust_threshold real)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    data_cursor CURSOR FOR \n        SELECT c.country_id, c.country_name, c.region FROM countries c;\n    current_country RECORD;\nBEGIN\n    OPEN data_cursor;\n    LOOP\n        FETCH data_cursor INTO current_country;\n        EXIT WHEN NOT FOUND;\n        \n        IF EXISTS(SELECT 1 FROM health_data WHERE country_id = current_country.country_id AND year = analysis_year AND life_expectancy >= health_min) THEN\n            IF EXISTS(SELECT 1 FROM freedom_data WHERE country_id = current_country.country_id AND year = analysis_year AND freedom_score >= freedom_min) THEN\n                IF (SELECT trust_in_government FROM freedom_data WHERE country_id = current_country.country_id AND year = analysis_year) > trust_threshold THEN\n                    IF (SELECT healthcare_spending FROM health_data WHERE country_id = current_country.country_id AND year = analysis_year) > 4000.0 THEN\n                        DELETE FROM economic_data WHERE country_id = current_country.country_id AND year < analysis_year - 1 AND poverty_rate > 20.0;\n                    ELSE\n                        INSERT INTO happiness_data (happiness_id, country_id, happiness_rank, happiness_score, year, survey_method, data_source, version)\n                        VALUES ((SELECT COALESCE(MAX(happiness_id), 0) + 1 FROM happiness_data), current_country.country_id, 50, 6.5, analysis_year, 'calculated', 'system', '1');\n                    END IF;\n                ELSE\n                    UPDATE freedom_data SET trust_in_government = trust_in_government * 0.9 WHERE country_id = current_country.country_id AND year = analysis_year;\n                END IF;\n            ELSE\n                INSERT INTO freedom_data (freedom_id, country_id, freedom_score, trust_in_government, year, data_source, version)\n                VALUES ((SELECT COALESCE(MAX(freedom_id), 0) + 1 FROM freedom_data), current_country.country_id, 0.3, 0.2, analysis_year, 'computed', '1');\n            END IF;\n        ELSE\n            UPDATE health_data SET healthcare_spending = healthcare_spending * 0.8 WHERE country_id = current_country.country_id AND year = analysis_year;\n        END IF;\n    END LOOP;\n    CLOSE data_cursor;\nEND;\n$$;",
    "database_name": "global_happiness_and_economic_data_analysis",
    "tables": [
      "countries",
      "economic_data",
      "freedom_data",
      "happiness_data",
      "health_data"
    ],
    "call_sqls": [
      "CALL manage_health_freedom_correlation(2022, 75.0, 0.6, 0.4);",
      "CALL manage_health_freedom_correlation(2021, 70.0, 0.5, 0.3);",
      "CALL manage_health_freedom_correlation(2023, 80.0, 0.7, 0.5);",
      "CALL manage_health_freedom_correlation(2020, 65.0, 0.4, 0.2);",
      "CALL manage_health_freedom_correlation(2022, 72.5, 0.55, 0.35);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `manage_health_freedom_correlation` that, for each country in the COUNTRIES table, processes health and freedom data for a specified `analysis_year`. If a country has health data for that year with `life_expectancy` at least equal to `health_min`, then check if it has freedom data with `freedom_score` at least equal to `freedom_min`. If both conditions are met and the `trust_in_government` from FREEDOM_DATA exceeds `trust_threshold`, then: if `healthcare_spending` from HEALTH_DATA is greater than 4000, delete old economic records from ECONOMIC_DATA where `poverty_rate` exceeds 20 and the year is older than two years before `analysis_year`; otherwise, insert a new default happiness record into HAPPINESS_DATA. If `trust_in_government` does not exceed `trust_threshold`, reduce it by 10% in FREEDOM_DATA. If the freedom data check fails, insert a default freedom record into FREEDOM_DATA. If the initial health data check fails, reduce `healthcare_spending` by 20% in HEALTH_DATA for that country and year.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named manage_health_freedom_correlation that takes analysis_year, health_min, freedom_min, and trust_threshold as inputs, and for each country in the countries table, performs the following: if health data exists for the given analysis_year with life_expectancy at least health_min, then if freedom data exists for that year with freedom_score at least freedom_min, then if trust_in_government exceeds trust_threshold, delete old economic data where healthcare_spending exceeds 4000, otherwise insert a new happiness record; if trust_in_government does not exceed trust_threshold, reduce trust_in_government by 10%; if the freedom check fails, insert a default freedom record; if the initial health check fails, reduce healthcare_spending by 20%.",
    "id": 8,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `manage_health_freedom_correlation` that accepts four input parameters: `analysis_year` of type `bigint`, `health_min` of type `real`, `freedom_min` of type `real`, and `trust_threshold` of type `real`. The procedure operates on the `global_happiness_and_economic_data_analysis` database and processes each country in the `countries` table individually. For each country, it executes a series of conditional checks and corresponding data manipulations based on the existence and values of related health, freedom, and economic data for the specified `analysis_year`.\n\nThe procedure begins by declaring a cursor named `country_cursor` that selects all `country_id` values from the `countries` table. It also declares local variables: `current_country_id` of type `bigint` to store the fetched country ID, `health_exists` of type `boolean` to indicate if health data exists for the current country and year, `freedom_exists` of type `boolean` to indicate if freedom data exists, `current_life_expectancy` of type `real` to store the life expectancy value, `current_freedom_score` of type `real` to store the freedom score, `current_trust` of type `real` to store the trust in government value, and `current_healthcare_spending` of type `real` to store the healthcare spending value.\n\nThe execution starts by opening the `country_cursor`. It then enters a loop where, in each iteration, it fetches the next `country_id` from the cursor into `current_country_id`. The loop continues as long as a record is successfully fetched; it exits when no more records are available.\n\nInside the loop, for each `current_country_id`, the procedure first checks for the existence of health data. It performs a `SELECT` statement on the `health_data` table to retrieve the `life_expectancy` and `healthcare_spending` for the row where `country_id` equals `current_country_id` and `year` equals `analysis_year`. If such a row exists, `health_exists` is set to `TRUE`, and the `life_expectancy` and `healthcare_spending` values are stored in `current_life_expectancy` and `current_healthcare_spending`, respectively. If no row is found, `health_exists` is set to `FALSE`.\n\nIf `health_exists` is `TRUE` and `current_life_expectancy` is greater than or equal to `health_min`, the procedure proceeds to check freedom data. It performs a `SELECT` statement on the `freedom_data` table to retrieve the `freedom_score` and `trust_in_government` for the row where `country_id` equals `current_country_id` and `year` equals `analysis_year`. If such a row exists, `freedom_exists` is set to `TRUE`, and the `freedom_score` and `trust_in_government` values are stored in `current_freedom_score` and `current_trust`, respectively. If no row is found, `freedom_exists` is set to `FALSE`.\n\nIf `freedom_exists` is `TRUE` and `current_freedom_score` is greater than or equal to `freedom_min`, the procedure then evaluates the trust condition. If `current_trust` is greater than `trust_threshold`, it executes a `DELETE` operation on the `economic_data` table. The deletion targets rows where `country_id` equals `current_country_id` and `year` equals `analysis_year` and `healthcare_spending` (from the `health_data` table, accessed via a subquery or join) is greater than 4000.0. Specifically, it deletes from `economic_data` where there exists a matching row in `health_data` for the same `country_id` and `year` with `healthcare_spending` > 4000.0. If `current_trust` is not greater than `trust_threshold`, the procedure executes an `UPDATE` statement on the `freedom_data` table, reducing `trust_in_government` by 10% (i.e., setting it to `current_trust * 0.9`) for the row where `country_id` equals `current_country_id` and `year` equals `analysis_year`.\n\nIf the freedom check fails (i.e., `freedom_exists` is `FALSE` or `current_freedom_score` is less than `freedom_min`), the procedure executes an `INSERT` operation into the `freedom_data` table. It inserts a new row with `country_id` set to `current_country_id`, `year` set to `analysis_year`, `freedom_score` set to a default value of 0.5, `trust_in_government` set to a default value of 0.5, `data_source` set to 'default', and `version` set to '0'. The `freedom_id` is auto-generated as it is the primary key.\n\nIf the initial health check fails (i.e., `health_exists` is `FALSE` or `current_life_expectancy` is less than `health_min`), the procedure executes an `UPDATE` statement on the `health_data` table. It reduces `healthcare_spending` by 20% (i.e., setting it to `current_healthcare_spending * 0.8`) for the row where `country_id` equals `current_country_id` and `year` equals `analysis_year`. This update only occurs if a row exists; if no health data exists for that country and year, no action is taken for the health check failure.\n\nAfter processing all countries, the loop ends, and the `country_cursor` is closed. The procedure does not return a value; it performs data modifications as described.",
    "original_summary": "Create a stored procedure named `manage_health_freedom_correlation` with parameters `analysis_year` (bigint), `health_min` (real), `freedom_min` (real), and `trust_threshold` (real). For each country, check if health data exists for the year with `life_expectancy` >= `health_min`. If yes, check if freedom data exists with `freedom_score` >= `freedom_min`. If yes, check if `trust_in_government` > `trust_threshold`. If yes and `healthcare_spending` > 4000, delete old economic data where `poverty_rate` > 20. If `healthcare_spending` <= 4000, insert a new happiness record. If `trust_in_government` <= `trust_threshold`, update freedom data to reduce trust by 10%. If the freedom check fails, insert a default freedom record. If the initial health check fails, reduce `healthcare_spending` by 20% for that year.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create procedure `manage_health_freedom_correlation` with params `analysis_year`, `health_min`, `freedom_min`, `trust_threshold`. For each country: if health data exists with `life_expectancy` >= `health_min`, then if freedom data exists with `freedom_score` >= `freedom_min`, then if `trust_in_government` > `trust_threshold`, delete old economic data if `healthcare_spending` > 4000, else insert happiness record. If trust <= threshold, update freedom to reduce trust by 10%. If freedom check fails, insert default freedom record. If initial health check fails, reduce `healthcare_spending` by 20%."
  },
  {
    "ir": "Write a PLpgSQL stored procedure that takes a parameter p_commit_id of type bigint and calculates a complexity score for a specific commit by selecting the square root of the product of commit_size and files_changed from the commits table where the commit_id matches p_commit_id, storing this result in a variable named complexity_score. Then, determine the next available change_id by selecting the maximum change_id from the repository_changes table, defaulting to 0 if no records exist, and incrementing it by 1, storing this result in a variable named next_change_id. Finally, insert a new record into the repository_changes table with the calculated next_change_id, the repository_id associated with the given p_commit_id from the commits table, a developer_id of 0, the current date as a string for the change_date, and a change_type of 'complexity_calculated'.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_commit_complexity(p_commit_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    complexity_score real;\n    next_change_id bigint;\nBEGIN\n    SELECT sqrt(commit_size::numeric * files_changed::numeric)\n    INTO complexity_score\n    FROM commits\n    WHERE commit_id = p_commit_id;\n\n    -- Calculate the next change_id based on the current maximum value\n    SELECT COALESCE(MAX(change_id), 0) + 1 INTO next_change_id FROM repository_changes;\n    \n    INSERT INTO repository_changes (change_id, repository_id, developer_id, change_date, change_type)\n    VALUES (next_change_id, (SELECT repository_id FROM commits WHERE commit_id = p_commit_id), 0, CURRENT_DATE::text, 'complexity_calculated');\nEND;\n$$;",
    "database_name": "software_development_and_collaboration_metrics",
    "tables": [
      "code_reviews",
      "commits",
      "repositories",
      "repository_changes"
    ],
    "call_sqls": [
      "CALL calculate_commit_complexity(1);",
      "CALL calculate_commit_complexity(2);",
      "CALL calculate_commit_complexity(10);",
      "CALL calculate_commit_complexity(25);",
      "CALL calculate_commit_complexity(100);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_commit_complexity that accepts a commit ID, calculates a complexity score as the square root of the product of commit_size and files_changed from the commits table for that commit, determines the next available change_id from the repository_changes table, and inserts a new record into repository_changes with that change_id, the corresponding repository_id from commits, a developer_id of 0, the current date as text, and a change_type of 'complexity_calculated'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called calculate_commit_complexity that takes a commit ID as input. It should compute a complexity score from the COMMITS table by taking the square root of the product of the commit size and the number of files changed for that commit. Then, determine the next available change identifier by incrementing the highest current change_id in the REPOSITORY_CHANGES table. Finally, insert a new record into REPOSITORY_CHANGES with that new change_id, the repository_id from the commit, a default developer_id of 0, today's date, and a change_type of 'complexity_calculated'.",
    "id": 9,
    "generated_ir": "Write a PLpgSQL stored procedure that takes a parameter p_commit_id of type bigint and calculates a complexity score for a specific commit by selecting the square root of the product of commit_size and files_changed from the commits table where the commit_id matches p_commit_id, storing this result in a variable named complexity_score. Then, determine the next available change_id by selecting the maximum change_id from the repository_changes table, defaulting to 0 if no records exist, and incrementing it by 1, storing this result in a variable named next_change_id. Finally, insert a new record into the repository_changes table with the calculated next_change_id, the repository_id associated with the given p_commit_id from the commits table, a developer_id of 0, the current date as a string for the change_date, and a change_type of 'complexity_calculated'.",
    "original_summary": "Create a stored procedure that accepts a commit ID (bigint). It calculates a complexity score as the square root of (commit_size * files_changed) from the commits table, determines the next change_id from repository_changes, and inserts a new record into repository_changes with the calculated ID, the associated repository_id, a developer_id of 0, the current date as text, and a change_type of 'complexity_calculated'.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Make a stored procedure that takes a commit ID. It should figure out a kind of complexity number based on the commit size and how many files were altered, get whatever the next change identifier is, and then put a new entry into the changes log. This new entry should have that new ID, the repo it belongs to, set the developer to a default zero, use today's date, and mark the type as something like a calculated complexity."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named `update_incident_and_report` that accepts four input parameters: `incident_id_input` of type `BIGINT`, `new_status` of type `TEXT`, `report_type_input` of type `TEXT`, and `report_content_input` of type `TEXT`. The purpose of `incident_id_input` is to identify the specific incident record to be updated. The `new_status` parameter provides the new status value to be assigned to the incident. The `report_type_input` parameter specifies the type of the new incident report, and `report_content_input` contains the textual content of the new report. The procedure begins by declaring a local variable `new_report_id` of type `BIGINT` to store the identifier for a newly generated incident report. The core logic of the procedure is encapsulated within a conditional block. It first checks for the existence of an incident record in the `incidents` table where the `incident_id` column matches the value provided by `incident_id_input`. This check is performed using a `SELECT 1 FROM incidents WHERE incident_id = incident_id_input` query within an `IF EXISTS` statement. If an incident with the specified `incident_id_input` is found, the procedure proceeds to update that incident record. Specifically, it updates the `incidents` table by setting the `status` column to the value of `new_status` and the `updated_at` column to the current timestamp, cast as `TEXT`, using the `NOW()::TEXT` function. This update is applied only to the row where `incident_id` matches `incident_id_input`. Following the update, the procedure calculates a new `report_id` for the upcoming incident report. It does this by querying the `incident_reports` table to find the maximum existing `report_id`, using `MAX(report_id)`, and then adding 1 to it. If no reports exist, `COALESCE` ensures that `0` is used as the base, resulting in `1` for the first report. This calculated value is then stored in the `new_report_id` variable. Subsequently, a new record is inserted into the `incident_reports` table. The `report_id` column is populated with the value from `new_report_id`, the `incident_id` column is set to `incident_id_input`, the `report_date` column is set to the current timestamp cast as `TEXT` using `NOW()::TEXT`, the `report_type` column is set to `report_type_input`, and the `report_content` column is set to `report_content_input`. If, however, the initial `IF EXISTS` condition evaluates to false, meaning no incident record with the specified `incident_id_input` was found in the `incidents` table, the procedure executes the `ELSE` block. In this case, it raises a notice message indicating that the 'Incident not found' using `RAISE NOTICE 'Incident not found';`.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_incident_and_report(incident_id_input BIGINT, new_status TEXT, report_type_input TEXT, report_content_input TEXT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    new_report_id BIGINT;\nBEGIN\n    IF EXISTS (SELECT 1 FROM incidents WHERE incident_id = incident_id_input) THEN\n        UPDATE incidents\n        SET status = new_status, updated_at = NOW()::TEXT\n        WHERE incident_id = incident_id_input;\n\n        SELECT COALESCE(MAX(report_id), 0) + 1 INTO new_report_id FROM incident_reports;\n        INSERT INTO incident_reports (report_id, incident_id, report_date, report_type, report_content)\n        VALUES (new_report_id, incident_id_input, NOW()::TEXT, report_type_input, report_content_input);\n    ELSE\n        RAISE NOTICE 'Incident not found';\n    END IF;\nEND;\n$$;",
    "database_name": "crime_incident_reporting_and_analysis_893763",
    "tables": [
      "incidents",
      "incident_reports",
      "incident_updates",
      "offenses",
      "offense_types",
      "offense_categories",
      "precincts"
    ],
    "call_sqls": [
      "CALL update_incident_and_report(0, 'closed', 'final', 'Incident resolved and closed.');",
      "CALL update_incident_and_report(1, 'investigating', 'initial', 'Initial report filed, investigation started.');",
      "CALL update_incident_and_report(2, 'pending review', 'interim', 'Investigation complete, awaiting review.');",
      "CALL update_incident_and_report(3, 'open', 'follow-up', 'Additional information received, re-opening case.');",
      "CALL update_incident_and_report(999, 'invalid', 'error', 'Attempted to update non-existent incident.');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_incident_and_report that accepts an incident ID, a new status, a report type, and report content to update an existing incident and create a related report. If the incident exists in the incidents table, update its status and updated_at timestamp, then generate a new report ID by incrementing the maximum existing report_id from the incident_reports table, and insert a new record into incident_reports with the generated ID, incident ID, current date, report type, and report content. If the incident is not found, raise a notice indicating the incident was not found.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called update_incident_and_report that takes an incident_id, a new_status, a report_type, and report_content as inputs. First, verify the incident exists in the incidents table. If it exists, update the incident's status and updated_at timestamp in the incidents table, generate a new report_id by incrementing the maximum existing report_id from the incident_reports table, and insert a new record into the incident_reports table with the generated report_id, incident_id, current date, report_type, and report_content. If the incident does not exist, raise a notice indicating the incident was not found.",
    "id": 10,
    "generated_ir": "Write a PLpgSQL stored procedure named `update_incident_and_report` that accepts four input parameters: `incident_id_input` of type `BIGINT`, `new_status` of type `TEXT`, `report_type_input` of type `TEXT`, and `report_content_input` of type `TEXT`. The purpose of `incident_id_input` is to identify the specific incident record to be updated. The `new_status` parameter provides the new status value to be assigned to the incident. The `report_type_input` parameter specifies the type of the new incident report, and `report_content_input` contains the textual content of the new report. The procedure begins by declaring a local variable `new_report_id` of type `BIGINT` to store the identifier for a newly generated incident report. The core logic of the procedure is encapsulated within a conditional block. It first checks for the existence of an incident record in the `incidents` table where the `incident_id` column matches the value provided by `incident_id_input`. This check is performed using a `SELECT 1 FROM incidents WHERE incident_id = incident_id_input` query within an `IF EXISTS` statement. If an incident with the specified `incident_id_input` is found, the procedure proceeds to update that incident record. Specifically, it updates the `incidents` table by setting the `status` column to the value of `new_status` and the `updated_at` column to the current timestamp, cast as `TEXT`, using the `NOW()::TEXT` function. This update is applied only to the row where `incident_id` matches `incident_id_input`. Following the update, the procedure calculates a new `report_id` for the upcoming incident report. It does this by querying the `incident_reports` table to find the maximum existing `report_id`, using `MAX(report_id)`, and then adding 1 to it. If no reports exist, `COALESCE` ensures that `0` is used as the base, resulting in `1` for the first report. This calculated value is then stored in the `new_report_id` variable. Subsequently, a new record is inserted into the `incident_reports` table. The `report_id` column is populated with the value from `new_report_id`, the `incident_id` column is set to `incident_id_input`, the `report_date` column is set to the current timestamp cast as `TEXT` using `NOW()::TEXT`, the `report_type` column is set to `report_type_input`, and the `report_content` column is set to `report_content_input`. If, however, the initial `IF EXISTS` condition evaluates to false, meaning no incident record with the specified `incident_id_input` was found in the `incidents` table, the procedure executes the `ELSE` block. In this case, it raises a notice message indicating that the 'Incident not found' using `RAISE NOTICE 'Incident not found';`.",
    "original_summary": "Create a stored procedure named update_incident_and_report that accepts incident_id, new_status, report_type, and report_content. It checks if the incident exists. If it does, it updates the incident's status and timestamp, generates a new report ID, and inserts a new incident report. If the incident is not found, it raises a notice.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure called update_incident_and_report that takes incident_id, new_status, report_type, and report_content as inputs. First, verify the incident exists. If it exists, update the incident's status and timestamp, create a new report ID, and insert a new incident report. If the incident does not exist, raise a notice."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `migrate_assessment_data` that accepts two `BIGINT` parameters: `p_source_assessment_id` representing the unique identifier of the source assessment, and `p_target_assessment_id` representing the unique identifier for the target assessment.\n\nThe procedure begins by declaring several local variables: `v_question_count` of type `BIGINT` to store the total number of questions, `v_form_exists` of type `BOOLEAN` to indicate whether a form already exists for the target assessment, `v_difficulty_level` of type `TEXT` to store the difficulty level, `v_target_form_id` of type `BIGINT` to store the unique identifier of the target form, `v_source_assessment_name` of type `TEXT` to store the name of the source assessment, `v_source_total_questions` of type `BIGINT` to store the total number of questions in the source assessment, `v_source_date_conducted` of type `TEXT` to store the date the source assessment was conducted, `v_source_class_id` of type `BIGINT` to store the class identifier associated with the source assessment, `v_source_assessment_type` of type `TEXT` to store the type of the source assessment, and `v_source_duration` of type `BIGINT` to store the duration of the source assessment.\n\nThe procedure then checks if an assessment with `assessment_id` equal to `p_target_assessment_id` already exists in the `assessments` table. This is done by attempting to select `1` from the `assessments` table where `assessment_id` matches `p_target_assessment_id`.\n\nIf no such target assessment exists (i.e., `NOT EXISTS` is true), the procedure proceeds to retrieve details from the source assessment. It selects the `assessment_name`, `total_questions`, `date_conducted`, `class_id`, `assessment_type`, and `duration` columns from the `assessments` table where `assessment_id` matches `p_source_assessment_id`. These retrieved values are then stored into the respective local variables: `v_source_assessment_name`, `v_source_total_questions`, `v_source_date_conducted`, `v_source_class_id`, `v_source_assessment_type`, and `v_source_duration`.\n\nFollowing the retrieval of source assessment details, a new record is inserted into the `assessments` table to create the target assessment. The `assessment_id` is set to `p_target_assessment_id`. The `assessment_name` is constructed by concatenating `v_source_assessment_name` with the literal string ' (Migrated)'. The `form` column is set to the literal character 'M', indicating a default form for migrated assessments. The `total_questions` column is set to `v_source_total_questions`, with `COALESCE(v_source_total_questions, 0)` ensuring a default value of `0` if `v_source_total_questions` is `NULL`. The `date_conducted` column is set to the current date converted to `TEXT` using `CURRENT_DATE::TEXT`. The `class_id` is set to `v_source_class_id`. The `assessment_type` is set to `v_source_assessment_type`. The `duration` is set to `v_source_duration`.\n\nAfter ensuring the target assessment exists (either by finding it or creating it), the procedure calculates the total number of questions and the predominant difficulty level associated with the source assessment. It selects the `COUNT(*)` of questions and the `COALESCE(MAX(af.difficulty_level), 'Moderate')` from the `assessment_questions` table, aliased as `aq`, joined with the `assessment_forms` table, aliased as `af`, on `aq.form_id = af.form_id`. The join condition ensures that only questions belonging to forms associated with the `p_source_assessment_id` are considered. The `MAX(af.difficulty_level)` is used to determine a representative difficulty level, and `COALESCE` ensures that if no difficulty level is found, 'Moderate' is used as a default. These aggregated values are stored into `v_question_count` and `v_difficulty_level`, respectively.\n\nNext, the procedure checks if a form already exists for the target assessment. It selects `EXISTS (SELECT 1 FROM assessment_forms WHERE assessment_id = p_target_assessment_id)` into the `v_form_exists` boolean variable.\n\nIf `v_form_exists` is `FALSE` (meaning no form exists for the target assessment) AND `v_question_count` is greater than `0` (meaning there are questions to migrate), a new form is inserted into the `assessment_forms` table. The `form_id` for this new form is generated by taking the `COALESCE((SELECT MAX(form_id) FROM assessment_forms), 0) + 1`, effectively assigning the next available `form_id`. The `assessment_id` is set to `p_target_assessment_id`. The `form_name` is set to the literal string 'Migrated_Form'. The `total_questions` is set to `v_question_count`. The `difficulty_level` is set to `v_difficulty_level`. The `date_created` is set to the current date converted to `TEXT` using `CURRENT_DATE::TEXT`. The `form_description` is constructed by concatenating the literal string 'Migrated from assessment ' with the `p_source_assessment_id` converted to `TEXT` using `::TEXT`. The `form_id` of the newly inserted record is then returned `INTO v_target_form_id`.\n\nIf a form already exists for the target assessment (i.e., `v_form_exists` is `TRUE`) or if `v_question_count` is `0`, the procedure proceeds to retrieve the `form_id` of the existing form for the target assessment. It selects the `form_id` from the `assessment_forms` table where `assessment_id` matches `p_target_assessment_id`, and `LIMIT 1` is used to ensure only one `form_id` is retrieved in case multiple forms exist (though typically there should be only one per assessment in this context). This retrieved `form_id` is stored into `v_target_form_id`.\n\nFinally, if `v_question_count` is greater than `0` (meaning there are questions to migrate) AND `v_target_form_id` is not `NULL` (meaning a target form has been identified or created), the procedure inserts questions into the `assessment_questions` table. It selects the `question_id`, `form_id`, `question_number`, `question_text`, `answer_choices`, `correct_answer`, and `question_type` from the `assessment_questions` table, aliased as `aq`, joined with the `assessment_forms` table, aliased as `af`, on `aq.form_id = af.form_id`. The join condition ensures that only questions belonging to forms associated with the `p_source_assessment_id` are considered. For the `question_id` of the new records, it calculates `COALESCE((SELECT MAX(question_id) FROM assessment_questions), 0) + ROW_NUMBER() OVER (ORDER BY aq.question_number)`, which assigns a unique `question_id` by taking the maximum existing `question_id` (or `0` if none exist) and adding a sequential number based on the `question_number` of the source questions. The `form_id` for the new questions is set to `v_target_form_id`. The `question_number`, `question_text`, `answer_choices`, `correct_answer`, and `question_type` are directly copied from the source questions.",
    "plsql": "CREATE OR REPLACE PROCEDURE migrate_assessment_data(p_source_assessment_id BIGINT, p_target_assessment_id BIGINT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_question_count BIGINT;\n    v_form_exists BOOLEAN;\n    v_difficulty_level TEXT;\n    v_target_form_id BIGINT;\n    v_source_assessment_name TEXT;\n    v_source_total_questions BIGINT;\n    v_source_date_conducted TEXT;\n    v_source_class_id BIGINT;\n    v_source_assessment_type TEXT;\n    v_source_duration BIGINT;\nBEGIN\n    -- Check if target assessment exists, if not create it\n    IF NOT EXISTS (SELECT 1 FROM assessments WHERE assessment_id = p_target_assessment_id) THEN\n        -- Get source assessment details to create target assessment\n        SELECT \n            assessment_name, \n            total_questions, \n            date_conducted, \n            class_id, \n            assessment_type, \n            duration\n        INTO \n            v_source_assessment_name,\n            v_source_total_questions,\n            v_source_date_conducted,\n            v_source_class_id,\n            v_source_assessment_type,\n            v_source_duration\n        FROM assessments \n        WHERE assessment_id = p_source_assessment_id;\n        \n        -- Create target assessment with modified name\n        INSERT INTO assessments (\n            assessment_id, \n            assessment_name, \n            form, \n            total_questions, \n            date_conducted, \n            class_id, \n            assessment_type, \n            duration\n        ) VALUES (\n            p_target_assessment_id,\n            v_source_assessment_name || ' (Migrated)',\n            'M',  -- Default form for migrated assessments\n            COALESCE(v_source_total_questions, 0),\n            CURRENT_DATE::TEXT,\n            v_source_class_id,\n            v_source_assessment_type,\n            v_source_duration\n        );\n    END IF;\n\n    -- Get the question count and difficulty level from the source assessment form\n    SELECT COUNT(*), COALESCE(MAX(af.difficulty_level), 'Moderate') \n    INTO v_question_count, v_difficulty_level\n    FROM assessment_questions aq\n    JOIN assessment_forms af ON aq.form_id = af.form_id\n    WHERE af.assessment_id = p_source_assessment_id;\n\n    -- Check if the form already exists for the target assessment\n    SELECT EXISTS (\n        SELECT 1 FROM assessment_forms \n        WHERE assessment_id = p_target_assessment_id\n    ) INTO v_form_exists;\n    \n    -- Insert new form if it does not exist\n    IF NOT v_form_exists AND v_question_count > 0 THEN\n        INSERT INTO assessment_forms (\n            form_id, \n            assessment_id, \n            form_name, \n            total_questions, \n            difficulty_level, \n            date_created, \n            form_description\n        )\n        SELECT \n            COALESCE((SELECT MAX(form_id) FROM assessment_forms), 0) + 1,\n            p_target_assessment_id,\n            'Migrated_Form',\n            v_question_count,\n            v_difficulty_level,\n            CURRENT_DATE::TEXT,\n            'Migrated from assessment ' || p_source_assessment_id::TEXT\n        RETURNING form_id INTO v_target_form_id;\n    ELSE\n        -- Get existing form_id for target assessment\n        SELECT form_id INTO v_target_form_id \n        FROM assessment_forms \n        WHERE assessment_id = p_target_assessment_id \n        LIMIT 1;\n    END IF;\n    \n    -- Insert questions if there are any and we have a form_id\n    IF v_question_count > 0 AND v_target_form_id IS NOT NULL THEN\n        INSERT INTO assessment_questions (\n            question_id, \n            form_id, \n            question_number, \n            question_text, \n            answer_choices, \n            correct_answer, \n            question_type\n        )\n        SELECT \n            COALESCE((SELECT MAX(question_id) FROM assessment_questions), 0) + \n            ROW_NUMBER() OVER (ORDER BY aq.question_number),\n            v_target_form_id,\n            question_number,\n            question_text,\n            answer_choices,\n            correct_answer,\n            question_type\n        FROM assessment_questions aq\n        JOIN assessment_forms af ON aq.form_id = af.form_id\n        WHERE af.assessment_id = p_source_assessment_id;\n    END IF;\nEND;\n$$;",
    "database_name": "educational_assessment_and_student_performance_tracking_766875",
    "tables": [
      "assessments",
      "assessment_forms",
      "assessment_questions",
      "assessment_results",
      "incorrect_questions"
    ],
    "call_sqls": [
      "CALL migrate_assessment_data(0, 2);",
      "CALL migrate_assessment_data(1, 3);",
      "CALL migrate_assessment_data(0, 4);",
      "CALL migrate_assessment_data(1, 5);",
      "CALL migrate_assessment_data(0, 6);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_assessment_data that copies an assessment from a source assessment ID to a target assessment ID. If the target assessment does not exist in the assessments table, create it by copying details from the source assessment, appending ' (Migrated)' to the assessment_name, and setting the form to 'M'. Calculate the total number of questions and the predominant difficulty_level from the source assessment using the assessment_questions and assessment_forms tables. If no form exists for the target assessment in the assessment_forms table and there are questions, create a new form named 'Migrated_Form' with the calculated total questions and difficulty level. Then, migrate all questions from the source assessment to the target form in the assessment_questions table, generating new question_ids.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called 'migrate_assessment_data' that copies an assessment from a source assessment ID to a target assessment ID. First, check if the target assessment exists in the assessments table; if not, create it by copying the source assessment's details from the assessments table, appending ' (Migrated)' to its assessment_name, and setting the form to 'M'. Determine the total number of questions and the predominant difficulty level from the source assessment by querying the assessment_questions and assessment_forms tables. If no form exists for the target assessment in the assessment_forms table and there are questions to migrate, create a new form named 'Migrated_Form' in assessment_forms with the determined total questions and difficulty level. Finally, migrate all questions from the source assessment to this new target form in the assessment_questions table, generating new question IDs in the process.",
    "id": 11,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_assessment_data that copies an assessment from a source assessment ID to a target assessment ID. The procedure accepts two input parameters: p_source_assessment_id of type bigint, representing the source assessment ID, and p_target_assessment_id of type bigint, representing the target assessment ID.\n\nThe procedure begins by checking if the target assessment ID exists in the assessments table. If it does not exist, the procedure inserts a new record into the assessments table by copying all columns from the source assessment record identified by p_source_assessment_id, but modifies the assessment_name by appending the string ' (Migrated)' to the original name, and sets the form column to 'M'. The new record uses p_target_assessment_id as the assessment_id.\n\nNext, the procedure determines the total number of questions and the predominant difficulty level for the source assessment. It queries the assessment_questions table to count all questions associated with the source assessment via joins: first joining assessment_questions with assessment_forms on form_id, then joining assessment_forms with assessments on assessment_id, where the assessment_id matches p_source_assessment_id. This count is stored in a variable v_total_questions. Simultaneously, it queries the assessment_forms table to find the most frequent difficulty_level among forms linked to the source assessment (by joining assessment_forms with assessments on assessment_id where assessment_id equals p_source_assessment_id), using a mode aggregation; the result is stored in a variable v_predominant_difficulty. If no difficulty level is found, it defaults to 'Unknown'.\n\nThe procedure then checks if a form already exists for the target assessment in the assessment_forms table by searching for a record where assessment_id equals p_target_assessment_id. If no such form exists and v_total_questions is greater than zero, it inserts a new record into the assessment_forms table. This new form uses a generated form_id (likely via a sequence or max value), sets assessment_id to p_target_assessment_id, form_name to 'Migrated_Form', total_questions to v_total_questions, difficulty_level to v_predominant_difficulty, date_created to the current date (converted to text), and form_description to a concatenated string describing the migration from the source to target assessment IDs.\n\nFinally, the procedure migrates all questions from the source assessment to the target form. It queries the assessment_questions table for all questions linked to the source assessment (by joining assessment_questions with assessment_forms on form_id, then joining assessment_forms with assessments on assessment_id where assessment_id equals p_source_assessment_id). For each source question, it inserts a new record into the assessment_questions table with a new question_id (generated sequentially), form_id set to the newly created target form's form_id, and copies the question_number, question_text, answer_choices, correct_answer, and question_type directly from the source question.\n\nThe procedure does not return a value; it performs data migration operations with conditional logic based on existence checks and aggregations.",
    "original_summary": "Create a stored procedure named 'migrate_assessment_data' that copies an assessment from a source to a target ID. If the target assessment doesn't exist, create it by copying source details and appending ' (Migrated)' to the name. Calculate the total questions and predominant difficulty level from the source. If no form exists for the target and there are questions, create a new 'Migrated_Form'. Then, migrate all questions from the source assessment to the target form, generating new question IDs.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a stored procedure called 'migrate_assessment_data' to copy an assessment from a source ID to a target ID. First, check if the target assessment exists. If it does not, create it by copying the source details and appending ' (Migrated)' to its name. Determine the total number of questions and the predominant difficulty level from the source assessment. If no form exists for the target assessment and there are questions to migrate, create a new form named 'Migrated_Form'. Finally, migrate all questions from the source assessment to this new target form, generating new question IDs in the process."
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `sync_user_experiment_access` that accepts two input parameters: `p_target_department` of type `text` and `p_default_role` of type `text`. The purpose of this procedure is to ensure that all users belonging to a specified department have access to all existing experiments, assigning them a default role if they don't already have access.\n\nThe procedure begins by declaring three local variables: `v_user_record` of type `record` to hold individual user data during iteration, `v_experiment_record` of type `record` to hold individual experiment data during iteration, and `v_new_collaborator_id` of type `bigint` to store a unique identifier for new experiment collaborator entries.\n\nThe core logic involves a nested loop structure. The outer loop iterates through a result set obtained by selecting the `user_id` from the `users` table. This selection is filtered by a `WHERE` clause, specifically `department = p_target_department`, meaning only users whose `department` column matches the value provided in the `p_target_department` input parameter will be considered. For each `v_user_record` retrieved in this outer loop:\n\n1.  The procedure first determines the next available `collaborator_id` for insertion into the `experiment_collaborators` table. This is achieved by executing a `SELECT` statement that retrieves the maximum `collaborator_id` from the `experiment_collaborators` table. The `COALESCE` function is used to ensure that if no records exist in `experiment_collaborators` (i.e., `MAX(collaborator_id)` returns `NULL`), `v_new_collaborator_id` is initialized to `0`. The result of this `SELECT` statement is stored in the `v_new_collaborator_id` variable.\n\n2.  An inner loop then commences. This inner loop iterates through a result set obtained by selecting the `experiment_id` from the `experiments` table. This selection is filtered by a `WHERE` clause: `experiment_id NOT IN (SELECT experiment_id FROM experiment_collaborators WHERE user_id = v_user_record.user_id)`. This condition ensures that only `experiment_id` values are selected for which the current user (identified by `v_user_record.user_id`) does *not* already have an entry in the `experiment_collaborators` table. In simpler terms, it identifies experiments to which the current user does not yet have access.\n\n3.  For each `v_experiment_record` retrieved in this inner loop (representing an experiment the current user needs access to):\n    a.  The `v_new_collaborator_id` variable is incremented by `1` (`v_new_collaborator_id := v_new_collaborator_id + 1;`). This generates a new, unique `collaborator_id` for the upcoming insertion.\n    b.  An `INSERT` statement is executed to add a new record into the `experiment_collaborators` table. The values inserted are:\n        *   `collaborator_id`: The newly generated `v_new_collaborator_id`.\n        *   `experiment_id`: The `experiment_id` from the current `v_experiment_record`.\n        *   `user_id`: The `user_id` from the current `v_user_record` (the user from the outer loop).\n        *   `role`: The value provided in the `p_default_role` input parameter.\n\nThis process continues until all users in the `p_target_department` have been processed, and for each such user, all experiments to which they did not previously have access have been assigned to them with the specified default role.",
    "plsql": "CREATE OR REPLACE PROCEDURE sync_user_experiment_access(p_target_department text, p_default_role text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_user_record record;\n    v_experiment_record record;\n    v_new_collaborator_id bigint;\nBEGIN\n    FOR v_user_record IN SELECT user_id FROM users WHERE department = p_target_department\n    LOOP\n        SELECT COALESCE(MAX(collaborator_id), 0) INTO v_new_collaborator_id FROM experiment_collaborators;\n        FOR v_experiment_record IN SELECT experiment_id FROM experiments WHERE experiment_id NOT IN (SELECT experiment_id FROM experiment_collaborators WHERE user_id = v_user_record.user_id)\n        LOOP\n            v_new_collaborator_id := v_new_collaborator_id + 1;\n            INSERT INTO experiment_collaborators (collaborator_id, experiment_id, user_id, role) VALUES (v_new_collaborator_id, v_experiment_record.experiment_id, v_user_record.user_id, p_default_role);\n        END LOOP;\n    END LOOP;\nEND;\n$$;",
    "database_name": "machine_learning_model_performance_tracking_6768",
    "tables": [
      "experiments",
      "experiment_collaborators",
      "experiment_versions",
      "models",
      "users"
    ],
    "call_sqls": [
      "CALL sync_user_experiment_access('AI Research', 'owner');",
      "CALL sync_user_experiment_access('AI Research', 'contributor');",
      "CALL sync_user_experiment_access('ML Engineering', 'owner');",
      "CALL sync_user_experiment_access('ML Engineering', 'contributor');",
      "CALL sync_user_experiment_access('AI Research', 'collaborator');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named sync_user_experiment_access that accepts a target department and a default role, and for each user in the specified department from the users table, grants access to all experiments from the experiments table they do not already have in the experiment_collaborators table by inserting new records with a sequentially generated collaborator_id, the experiment_id, the user_id, and the provided default role.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called sync_user_experiment_access that takes two text inputs: p_target_department and p_default_role. For all users in the users table whose department matches the provided p_target_department, ensure they have access to all experiments by adding them as collaborators to any experiments from the experiments table they are not already part of in the experiment_collaborators table. For each new entry, generate a unique collaborator_id by incrementing from the highest existing one, and use the provided p_default_role for the role.",
    "id": 12,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named sync_user_experiment_access that accepts two input parameters: p_target_department of type text and p_default_role of type text. The procedure ensures that all users belonging to a specified department have access to all experiments by inserting them as collaborators into the experiment_collaborators table for any experiments they are not already associated with.\n\nFirst, the procedure declares a variable v_max_collaborator_id of type bigint to store the highest existing collaborator_id from the experiment_collaborators table. It also declares a cursor or uses a loop to iterate over a result set.\n\nThe procedure begins by retrieving the maximum current value of the collaborator_id column from the experiment_collaborators table using a SELECT MAX(collaborator_id) INTO v_max_collaborator_id query. This value is used as a starting point for generating new unique IDs.\n\nNext, the procedure identifies all users from the users table whose department column exactly matches the input parameter p_target_department. For each of these users, it identifies all experiments from the experiments table that the user is not already a collaborator for. This is achieved by performing a set operation: selecting all experiment_id values from the experiments table and excluding those where a matching entry exists in the experiment_collaborators table for the specific user_id.\n\nThe core logic involves an INSERT operation into the experiment_collaborators table. The columns to be inserted are collaborator_id, experiment_id, user_id, and role. For each combination of user and experiment where the user lacks access, a new row is inserted. The collaborator_id for each new row is generated by incrementing the v_max_collaborator_id variable by 1 for each successive new record. The experiment_id is taken from the current experiment in the iteration. The user_id is taken from the current user from the filtered users list. The role column is set to the value provided in the p_default_role input parameter.\n\nThe procedure uses a nested loop or a single INSERT...SELECT statement with a cross join and anti-join to achieve this. Specifically, it performs a CROSS JOIN between the filtered list of users (from the users table where department = p_target_department) and all experiments from the experiments table. It then uses a NOT EXISTS subquery to exclude pairs where an entry already exists in the experiment_collaborators table with matching user_id and experiment_id. For the remaining pairs, it generates a new collaborator_id using the ROW_NUMBER() window function added to the previously fetched maximum ID, or alternatively uses a sequence-like increment within a loop.\n\nThe procedure does not return a value; it is a void procedure that performs the insert operations to synchronize access. It operates within the machine_learning_model_performance_tracking_6768 database, modifying the experiment_collaborators table based on conditions involving the users and experiments tables.",
    "original_summary": "Create a stored procedure named sync_user_experiment_access that accepts two text parameters: p_target_department and p_default_role. For each user in the specified department, grant access to all experiments they don't already have by inserting records into the experiment_collaborators table with a generated collaborator_id, the experiment_id, the user_id, and the default role.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a stored procedure called sync_user_experiment_access that takes two text inputs: p_target_department and p_default_role. For users in that general department area, make sure they can get into any experiments they aren't already part of. Do this by adding entries to the experiment_collaborators table with a new collaborator_id, the experiment's ID, the user's ID, and that default role you provide."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `delete_old_citations` that accepts a single input parameter. This parameter, named `citation_date_input`, is of type `TEXT` and is intended to represent a date string. The procedure's sole operation is to perform a `DELETE` statement on the table named `citations`. The `DELETE` operation targets rows within the `citations` table based on a specific condition. This condition compares the date value derived from the `citation_date` column in the `citations` table with the date value derived from the `citation_date_input` parameter. Specifically, the `TO_DATE` function is used to convert the `citation_date` column, which is presumed to be a string, into a date data type using the format mask 'YYYY-MM-DD'. Similarly, the `TO_DATE` function is applied to the `citation_date_input` parameter, converting it from a `TEXT` string to a date data type using the same format mask 'YYYY-MM-DD'. The `DELETE` statement will remove all rows from the `citations` table where the date value obtained from the `citation_date` column is strictly less than the date value obtained from the `citation_date_input` parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_old_citations(citation_date_input TEXT)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM citations\n    WHERE TO_DATE(citation_date, 'YYYY-MM-DD') < TO_DATE(citation_date_input, 'YYYY-MM-DD');\nEND;\n$$;",
    "database_name": "academic_research_publication_management_and_citation_tracking",
    "tables": [
      "authors",
      "citation_metrics",
      "citations",
      "publications"
    ],
    "call_sqls": [
      "CALL delete_old_citations('2023-01-01');",
      "CALL delete_old_citations('2022-06-15');",
      "CALL delete_old_citations('2020-12-31');",
      "CALL delete_old_citations('2019-07-01');",
      "CALL delete_old_citations('2021-03-20');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named delete_old_citations that accepts a date string parameter and deletes all rows from the citations table where the citation_date is earlier than the provided date.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called delete_old_citations that takes a date string as input and removes all entries from the citations table where the citation_date, interpreted as a date, is earlier than the provided input date, which should also be interpreted as a date.",
    "id": 13,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `delete_old_citations` that accepts a single input parameter. This parameter, named `citation_date_input`, is of type `TEXT` and is intended to represent a date string. The procedure's sole operation is to perform a `DELETE` statement on the table named `citations`. The `DELETE` operation targets rows within the `citations` table based on a specific condition. This condition compares the date value derived from the `citation_date` column in the `citations` table with the date value derived from the `citation_date_input` parameter. Specifically, the `TO_DATE` function is used to convert the `citation_date` column, which is presumed to be a string, into a date data type using the format mask 'YYYY-MM-DD'. Similarly, the `TO_DATE` function is applied to the `citation_date_input` parameter, converting it from a `TEXT` string to a date data type using the same format mask 'YYYY-MM-DD'. The `DELETE` statement will remove all rows from the `citations` table where the date value obtained from the `citation_date` column is strictly less than the date value obtained from the `citation_date_input` parameter.",
    "original_summary": "Create a stored procedure named delete_old_citations that accepts a date string parameter. It deletes rows from the citations table where the citation_date (converted to date using 'YYYY-MM-DD' format) is earlier than the provided date parameter (also converted using the same format).",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure called delete_old_citations that takes a date string. It should remove entries from the citations table where the citation_date, treated as a date, is from a while back, specifically before the given date, which should also be interpreted as a date."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named update_repository_metrics that accepts a single input parameter p_repository_id of type bigint, which identifies a specific repository, and performs a series of operations to calculate and update repository metrics for the current calendar year. The procedure first declares local variables v_commit_count, v_merge_count, and v_developer_count as bigint, v_last_activity_date as text, v_activity_level as text, and v_current_year as integer. It initializes v_current_year by extracting the year component from the system's current date using the extract function. It then queries the repository_changes table to count all rows where the repository_id column matches the input p_repository_id, the change_type column equals the string 'commit', and the year extracted from the change_date column (cast to date) equals v_current_year, storing the result in v_commit_count. A second query counts rows from the same repository_changes table where repository_id matches p_repository_id, change_type equals 'merge', and the extracted year from change_date equals v_current_year, storing the count in v_merge_count. A third query counts the distinct developer_id values from the repository_changes table for rows where repository_id matches p_repository_id and the extracted year from change_date equals v_current_year, storing the result in v_developer_count. A fourth query retrieves the maximum change_date value from the repository_changes table for rows where repository_id matches p_repository_id, storing it as text in v_last_activity_date. Following these queries, a conditional IF-ELSIF-ELSE block evaluates v_commit_count to assign a text classification to v_activity_level: if the count is greater than 500, v_activity_level is set to 'very_high'; if between 200 and 500 inclusive, set to 'high'; if between 50 and 199 inclusive, set to 'medium'; if between 10 and 49 inclusive, set to 'low'; otherwise, set to 'minimal'. Finally, the procedure executes an UPDATE statement on the repositories table, setting the number_of_commits column to the value of v_commit_count and the last_commit_date column to the value of v_last_activity_date, specifically for the row where the repository_id column matches the input parameter p_repository_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_repository_metrics(p_repository_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_commit_count bigint;\n    v_merge_count bigint;\n    v_developer_count bigint;\n    v_last_activity_date text;\n    v_activity_level text;\n    v_current_year integer;\nBEGIN\n    v_current_year := extract(year from CURRENT_DATE);\n    \n    SELECT COUNT(*) INTO v_commit_count FROM repository_changes \n    WHERE repository_id = p_repository_id AND change_type = 'commit' \n    AND extract(year from change_date::date) = v_current_year;\n    \n    SELECT COUNT(*) INTO v_merge_count FROM repository_changes \n    WHERE repository_id = p_repository_id AND change_type = 'merge' \n    AND extract(year from change_date::date) = v_current_year;\n    \n    SELECT COUNT(DISTINCT developer_id) INTO v_developer_count FROM repository_changes \n    WHERE repository_id = p_repository_id \n    AND extract(year from change_date::date) = v_current_year;\n    \n    SELECT MAX(change_date) INTO v_last_activity_date FROM repository_changes \n    WHERE repository_id = p_repository_id;\n    \n    IF v_commit_count > 500 THEN\n        v_activity_level := 'very_high';\n    ELSIF v_commit_count BETWEEN 200 AND 500 THEN\n        v_activity_level := 'high';\n    ELSIF v_commit_count BETWEEN 50 AND 199 THEN\n        v_activity_level := 'medium';\n    ELSIF v_commit_count BETWEEN 10 AND 49 THEN\n        v_activity_level := 'low';\n    ELSE\n        v_activity_level := 'minimal';\n    END IF;\n    \n    UPDATE repositories \n    SET number_of_commits = v_commit_count,\n        last_commit_date = v_last_activity_date\n    WHERE repository_id = p_repository_id;\nEND;\n$$;",
    "database_name": "software_development_and_collaboration_metrics",
    "tables": [
      "developers",
      "repositories",
      "repository_changes",
      "msl_changes",
      "scm_changes",
      "scr_changes"
    ],
    "call_sqls": [
      "CALL update_repository_metrics(0);",
      "CALL update_repository_metrics(1);",
      "CALL update_repository_metrics(2);",
      "CALL update_repository_metrics(3);",
      "CALL update_repository_metrics(4);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_repository_metrics that accepts a repository ID (p_repository_id) and updates the repositories table for that repository by calculating and setting its current year's commit count and last activity date from the repository_changes table, where the commit count is determined from changes of type 'commit' and the last activity date is the most recent change_date, and also classifies the activity level as 'very_high', 'high', 'medium', 'low', or 'minimal' based on whether the commit count is greater than 500, between 200 and 500, between 50 and 199, between 10 and 49, or less than 10, respectively.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called update_repository_metrics that takes a p_repository_id as input, calculates the current year's commit count, merge count, distinct developer count, and last activity date for that repository from the repository_changes table, classifies the activity level based on the commit count as very_high for over 500, high for 200 to 500, medium for 50 to 199, low for 10 to 49, and minimal otherwise, and then updates the repositories table with the new number_of_commits and last_commit_date.",
    "id": 14,
    "generated_ir": "Write a PLpgSQL stored procedure named update_repository_metrics that accepts a single input parameter p_repository_id of type bigint, which identifies a specific repository, and performs a series of operations to calculate and update repository metrics for the current calendar year. The procedure first declares local variables v_commit_count, v_merge_count, and v_developer_count as bigint, v_last_activity_date as text, v_activity_level as text, and v_current_year as integer. It initializes v_current_year by extracting the year component from the system's current date using the extract function. It then queries the repository_changes table to count all rows where the repository_id column matches the input p_repository_id, the change_type column equals the string 'commit', and the year extracted from the change_date column (cast to date) equals v_current_year, storing the result in v_commit_count. A second query counts rows from the same repository_changes table where repository_id matches p_repository_id, change_type equals 'merge', and the extracted year from change_date equals v_current_year, storing the count in v_merge_count. A third query counts the distinct developer_id values from the repository_changes table for rows where repository_id matches p_repository_id and the extracted year from change_date equals v_current_year, storing the result in v_developer_count. A fourth query retrieves the maximum change_date value from the repository_changes table for rows where repository_id matches p_repository_id, storing it as text in v_last_activity_date. Following these queries, a conditional IF-ELSIF-ELSE block evaluates v_commit_count to assign a text classification to v_activity_level: if the count is greater than 500, v_activity_level is set to 'very_high'; if between 200 and 500 inclusive, set to 'high'; if between 50 and 199 inclusive, set to 'medium'; if between 10 and 49 inclusive, set to 'low'; otherwise, set to 'minimal'. Finally, the procedure executes an UPDATE statement on the repositories table, setting the number_of_commits column to the value of v_commit_count and the last_commit_date column to the value of v_last_activity_date, specifically for the row where the repository_id column matches the input parameter p_repository_id.",
    "original_summary": "Create a stored procedure named update_repository_metrics that accepts a p_repository_id (bigint). Calculate the current year's commit count, merge count, distinct developer count, and last activity date for the repository. Classify the activity level based on commit count. Update the repositories table with the commit count and last activity date for the specified repository.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure called update_repository_metrics that takes a p_repository_id (bigint) as input, calculates the current year's commit count, merge count, distinct developer count, and last activity date for that repository, classifies the activity level based on the commit count, and then updates the repositories table with the new commit count and last activity date?"
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `process_draft_class` that accepts two input parameters: `p_draft_year`, which is of type `BIGINT` and represents a specific draft year, and `p_min_games`, which is also of type `BIGINT` but is not used within the current implementation of the procedure. The procedure declares three local variables: `v_player_count` of type `BIGINT` to store the total number of players, `v_avg_score` of type `REAL` to store the average game score, and `v_total_points` of type `BIGINT` which is declared but not used. The procedure begins by executing a `SELECT` statement to count the total number of rows in the `players` table where the `draft_year` column matches the value provided by the `p_draft_year` input parameter, storing this count into the `v_player_count` variable. Subsequently, it executes another `SELECT` statement to calculate the average of the `game_score` column from the `game_statistics` table. This calculation involves an `INNER JOIN` operation between the `game_statistics` table (aliased as `gs`) and the `players` table (aliased as `p`) on the condition that `gs.player_id` equals `p.player_id`. The average is computed only for those records where the `draft_year` column in the `players` table matches the value of the `p_draft_year` input parameter, and the result is stored into the `v_avg_score` variable. Following these initial data retrievals, the procedure enters a series of conditional `DELETE` statements. The first condition checks if the value of `v_player_count` is greater than 50. If this condition is true, it executes a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 30. If the first condition is false, the procedure proceeds to an `ELSIF` condition that checks if `v_player_count` is greater than 30. If this condition is true, it executes a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 20. If the second condition is also false, the procedure proceeds to another `ELSIF` condition that checks if `v_avg_score` is greater than 15.0. If this condition is true, it executes a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 15. If the third condition is false, the procedure proceeds to another `ELSIF` condition that checks if `v_avg_score` is greater than 10.0. If this condition is true, it executes a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 10. If the fourth condition is false, the procedure proceeds to another `ELSIF` condition that checks if `v_player_count` is greater than 10. If this condition is true, it executes a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 25. If all preceding conditions are false, the procedure executes the `ELSE` block, which performs a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 40. The procedure concludes after the execution of one of these conditional `DELETE` statements.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_draft_class(p_draft_year BIGINT, p_min_games BIGINT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_player_count BIGINT;\n    v_avg_score REAL;\n    v_total_points BIGINT;\nBEGIN\n    SELECT COUNT(*) INTO v_player_count FROM players WHERE draft_year = p_draft_year;\n    SELECT AVG(game_score) INTO v_avg_score FROM game_statistics gs JOIN players p ON gs.player_id = p.player_id WHERE p.draft_year = p_draft_year;\n    \n    IF v_player_count > 50 THEN\n        DELETE FROM game_statistics WHERE player_id IN (SELECT player_id FROM players WHERE draft_year = p_draft_year AND draft_pick > 30);\n    ELSIF v_player_count > 30 THEN\n        DELETE FROM game_statistics WHERE player_id IN (SELECT player_id FROM players WHERE draft_year = p_draft_year AND draft_pick > 20);\n    ELSIF v_avg_score > 15.0 THEN\n        DELETE FROM game_statistics WHERE player_id IN (SELECT player_id FROM players WHERE draft_year = p_draft_year AND draft_pick > 15);\n    ELSIF v_avg_score > 10.0 THEN\n        DELETE FROM game_statistics WHERE player_id IN (SELECT player_id FROM players WHERE draft_year = p_draft_year AND draft_pick > 10);\n    ELSIF v_player_count > 10 THEN\n        DELETE FROM game_statistics WHERE player_id IN (SELECT player_id FROM players WHERE draft_year = p_draft_year AND draft_pick > 25);\n    ELSE\n        DELETE FROM game_statistics WHERE player_id IN (SELECT player_id FROM players WHERE draft_year = p_draft_year AND draft_pick > 40);\n    END IF;\nEND;\n$$;",
    "database_name": "basketball_player_performance_and_team_statistics_549881",
    "tables": [
      "game_statistics",
      "players"
    ],
    "call_sqls": [
      "CALL process_draft_class(2011, 10);",
      "CALL process_draft_class(2003, 15);",
      "CALL process_draft_class(2015, 20);",
      "CALL process_draft_class(2018, 25);",
      "CALL process_draft_class(2020, 30);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named process_draft_class that accepts a draft year (p_draft_year) and a minimum games parameter (p_min_games) to process a draft class by first counting the number of players from that draft year in the players table and calculating their average game score from the game_statistics table, then conditionally deleting game statistics for players from that draft year based on the player count and average score: if the player count exceeds 50, delete statistics for players with a draft pick greater than 30; if the player count exceeds 30, delete for draft picks greater than 20; if the average score exceeds 15.0, delete for draft picks greater than 15; if the average score exceeds 10.0, delete for draft picks greater than 10; if the player count exceeds 10, delete for draft picks greater than 25; otherwise, delete for draft picks greater than 40.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named 'process_draft_class' that takes 'p_draft_year' and 'p_min_games' as parameters to count players from the specified draft year in the players table, calculate their average game score from the game_statistics table, and then conditionally delete game statistics for players from that draft year based on draft pick thresholds: if the player count exceeds 50, delete for draft picks greater than 30; if it exceeds 30, delete for picks greater than 20; if the average score exceeds 15.0, delete for picks greater than 15; if it exceeds 10.0, delete for picks greater than 10; if the player count exceeds 10, delete for picks greater than 25; otherwise, delete for picks greater than 40.",
    "id": 15,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `process_draft_class` that accepts two input parameters: `p_draft_year`, which is of type `BIGINT` and represents a specific draft year, and `p_min_games`, which is also of type `BIGINT` but is not used within the current implementation of the procedure. The procedure declares three local variables: `v_player_count` of type `BIGINT` to store the total number of players, `v_avg_score` of type `REAL` to store the average game score, and `v_total_points` of type `BIGINT` which is declared but not used. The procedure begins by executing a `SELECT` statement to count the total number of rows in the `players` table where the `draft_year` column matches the value provided by the `p_draft_year` input parameter, storing this count into the `v_player_count` variable. Subsequently, it executes another `SELECT` statement to calculate the average of the `game_score` column from the `game_statistics` table. This calculation involves an `INNER JOIN` operation between the `game_statistics` table (aliased as `gs`) and the `players` table (aliased as `p`) on the condition that `gs.player_id` equals `p.player_id`. The average is computed only for those records where the `draft_year` column in the `players` table matches the value of the `p_draft_year` input parameter, and the result is stored into the `v_avg_score` variable. Following these initial data retrievals, the procedure enters a series of conditional `DELETE` statements. The first condition checks if the value of `v_player_count` is greater than 50. If this condition is true, it executes a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 30. If the first condition is false, the procedure proceeds to an `ELSIF` condition that checks if `v_player_count` is greater than 30. If this condition is true, it executes a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 20. If the second condition is also false, the procedure proceeds to another `ELSIF` condition that checks if `v_avg_score` is greater than 15.0. If this condition is true, it executes a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 15. If the third condition is false, the procedure proceeds to another `ELSIF` condition that checks if `v_avg_score` is greater than 10.0. If this condition is true, it executes a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 10. If the fourth condition is false, the procedure proceeds to another `ELSIF` condition that checks if `v_player_count` is greater than 10. If this condition is true, it executes a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 25. If all preceding conditions are false, the procedure executes the `ELSE` block, which performs a `DELETE` statement that removes rows from the `game_statistics` table where the `player_id` is present in a subquery. This subquery selects `player_id` from the `players` table for records where the `draft_year` matches `p_draft_year` and the `draft_pick` column is greater than 40. The procedure concludes after the execution of one of these conditional `DELETE` statements.",
    "original_summary": "Create a stored procedure named process_draft_class that accepts p_draft_year and p_min_games (both bigint). It counts players from the given draft year and calculates their average game score. Based on these counts and the average score, it conditionally deletes game statistics for players from that draft year with specific draft pick thresholds (e.g., >30, >20, >15, >10, >25, or >40).",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure named 'process_draft_class' that takes 'p_draft_year' and 'p_min_games' as bigint parameters to count players from the specified draft year, calculate their average game score, and then conditionally delete game statistics for players from that draft year based on draft pick thresholds like greater than 30, 20, 15, 10, 25, or 40?"
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `generate_nucleus_report` that accepts three input parameters: `p_sample_id` of type `bigint`, `p_circularity_threshold` of type `real`, and `p_texture` of type `text`. This procedure is designed to process existing nucleus metrics for a specific sample and generate new nucleus metric records based on a circularity threshold and a provided texture.\n\nThe procedure begins by declaring a cursor named `v_nucleus_cursor` which is defined to select the `nucleus_id` and `circularity` columns from the `nucleus_metrics` table for all rows where the `sample_id` column matches the input parameter `p_sample_id`. It also declares a record variable `v_nucleus_rec` to hold the fetched rows from the cursor and a `bigint` variable `v_max_id` to store the maximum nucleus ID.\n\nThe first operation within the procedure's executable block is to determine the starting value for a new sequence. It selects the maximum value from the `nucleus_id` column in the `nucleus_metrics` table. If no `nucleus_id` exists (i.e., `MAX(nucleus_id)` returns `NULL`), it defaults to `0`. This value is then incremented by `1` and stored in the `v_max_id` variable.\n\nNext, the procedure ensures that a sequence named `nucleus_id_seq` is properly set up. It first attempts to drop any existing sequence with the name `nucleus_id_seq` using `DROP SEQUENCE IF EXISTS nucleus_id_seq`. After ensuring no old sequence exists, it dynamically creates a new sequence named `nucleus_id_seq` using the `EXECUTE format` statement, setting its starting value to the `v_max_id` calculated earlier. This ensures that newly generated `nucleus_id` values will be unique and continue from the highest existing ID.\n\nFollowing the sequence setup, the procedure opens the `v_nucleus_cursor`, which was previously defined to retrieve `nucleus_id` and `circularity` for the specified `p_sample_id`.\n\nIt then enters a `LOOP` to iterate through each row returned by the cursor. Inside the loop, it fetches the next row from `v_nucleus_cursor` into the `v_nucleus_rec` record variable. The loop continues until `NOT FOUND` is true, indicating that no more rows are available in the cursor, at which point it `EXIT`s the loop.\n\nFor each fetched `v_nucleus_rec`, a conditional statement (`IF v_nucleus_rec.circularity > p_circularity_threshold THEN`) checks if the `circularity` value of the current nucleus record is greater than the input `p_circularity_threshold`.\n\nIf the `circularity` is greater than `p_circularity_threshold`, the procedure executes an `INSERT` statement into the `nucleus_metrics` table. The `nucleus_id` is generated using `nextval('nucleus_id_seq')`. The `sample_id` is set to the input `p_sample_id`. The `area` is set to `50.0`, `perimeter` to `25.0`, `circularity` to `v_nucleus_rec.circularity`, `max_caliper` to `10.0`, `min_caliper` to `5.0`, `eccentricity` to `0.9`, `nucleus_volume` to `200.0`, `nucleus_shape` to `'Spherical'`, `nucleus_texture` to the input `p_texture`, `nucleus_intensity` to `0.9`, and `nucleus_area_std_dev` to `2.0`.\n\nIf the `circularity` is not greater than `p_circularity_threshold` (i.e., it's less than or equal to the threshold), the procedure executes a different `INSERT` statement into the `nucleus_metrics` table. In this case, the `nucleus_id` is also generated using `nextval('nucleus_id_seq')`. The `sample_id` is set to the input `p_sample_id`. The `area` is set to `40.0`, `perimeter` to `20.0`, `circularity` to `v_nucleus_rec.circularity`, `max_caliper` to `8.0`, `min_caliper` to `4.0`, `eccentricity` to `0.8`, `nucleus_volume` to `180.0`, `nucleus_shape` to `'Ellipsoidal'`, `nucleus_texture` to `'Default'`, `nucleus_intensity` to `0.8`, and `nucleus_area_std_dev` to `1.5`.\n\nAfter the loop has processed all records from the cursor, the procedure closes the `v_nucleus_cursor`.",
    "plsql": "CREATE OR REPLACE PROCEDURE generate_nucleus_report(\n    p_sample_id bigint,\n    p_circularity_threshold real,\n    p_texture text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_nucleus_cursor CURSOR FOR\n        SELECT nucleus_id, circularity\n        FROM nucleus_metrics\n        WHERE sample_id = p_sample_id;\n    v_nucleus_rec RECORD;\n    v_max_id bigint;\nBEGIN\n    -- Get the maximum existing nucleus_id and set sequence accordingly\n    SELECT COALESCE(MAX(nucleus_id), 0) + 1 INTO v_max_id FROM nucleus_metrics;\n    \n    -- Create sequence if it doesn't exist and set its value\n    DROP SEQUENCE IF EXISTS nucleus_id_seq;\n    EXECUTE format('CREATE SEQUENCE nucleus_id_seq START WITH %s', v_max_id);\n    \n    OPEN v_nucleus_cursor;\n    \n    LOOP\n        FETCH v_nucleus_cursor INTO v_nucleus_rec;\n        EXIT WHEN NOT FOUND;\n        \n        IF v_nucleus_rec.circularity > p_circularity_threshold THEN\n            INSERT INTO nucleus_metrics (nucleus_id, sample_id, area, perimeter, circularity, max_caliper, min_caliper, eccentricity, nucleus_volume, nucleus_shape, nucleus_texture, nucleus_intensity, nucleus_area_std_dev)\n            VALUES (nextval('nucleus_id_seq'), p_sample_id, 50.0, 25.0, v_nucleus_rec.circularity, 10.0, 5.0, 0.9, 200.0, 'Spherical', p_texture, 0.9, 2.0);\n        ELSE\n            INSERT INTO nucleus_metrics (nucleus_id, sample_id, area, perimeter, circularity, max_caliper, min_caliper, eccentricity, nucleus_volume, nucleus_shape, nucleus_texture, nucleus_intensity, nucleus_area_std_dev)\n            VALUES (nextval('nucleus_id_seq'), p_sample_id, 40.0, 20.0, v_nucleus_rec.circularity, 8.0, 4.0, 0.8, 180.0, 'Ellipsoidal', 'Default', 0.8, 1.5);\n        END IF;\n    END LOOP;\n    \n    CLOSE v_nucleus_cursor;\nEND;\n$$;",
    "database_name": "biological_sample_analysis_and_metrics",
    "tables": [
      "cell_metrics",
      "cytoplasm_metrics",
      "nucleus_metrics",
      "nucleus_OD_metrics"
    ],
    "call_sqls": [
      "CALL generate_nucleus_report(1, 0.7, 'Smooth');",
      "CALL generate_nucleus_report(0, 0.8, 'Granular');",
      "CALL generate_nucleus_report(1, 0.75, 'Smooth');",
      "CALL generate_nucleus_report(0, 0.85, 'Granular');",
      "CALL generate_nucleus_report(1, 0.9, 'Smooth');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named generate_nucleus_report that accepts a sample ID, a circularity threshold, and a texture, and for each nucleus in the NUCLEUS_METRICS table belonging to the given sample, inserts a new record with a sequentially generated nucleus ID; if the nucleus's circularity exceeds the threshold, the new record uses the provided texture and predefined metrics including an area of 50.0, otherwise it uses 'Default' texture and different predefined metrics including an area of 40.0.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `generate_nucleus_report` that takes a sample ID, a circularity threshold, and a texture as inputs, and for each nucleus in the `nucleus_metrics` table matching the given sample ID, checks if its circularity exceeds the threshold. If it does, insert a new record with the provided texture and predefined metrics including an area of 50.0; otherwise, insert a record with a 'Default' texture and different predefined metrics like an area of 40.0, while generating new nucleus IDs sequentially starting from the current maximum.",
    "id": 16,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named generate_nucleus_report that accepts three input parameters: p_sample_id of type bigint, which specifies the sample identifier; p_circularity_threshold of type real, which defines the minimum circularity value for conditional logic; and p_texture of type text, which provides the texture value to be used when the condition is met. The procedure operates on the biological_sample_analysis_and_metrics database.\n\nThe procedure first declares a local variable v_max_nucleus_id of type bigint. It executes a SELECT statement to retrieve the maximum value of the nucleus_id column from the nucleus_metrics table, using the COALESCE function to default to 0 if no records exist, and stores this value in v_max_nucleus_id.\n\nNext, the procedure performs a loop over each row in the nucleus_metrics table where the sample_id column equals the p_sample_id parameter. For each nucleus record in this result set, it evaluates a conditional IF statement. The condition checks if the circularity column value from the current nucleus_metrics row is greater than the p_circularity_threshold parameter.\n\nIf the condition is true (circularity exceeds the threshold), the procedure executes an INSERT statement into the nucleus_metrics table. This INSERT statement populates the following columns: nucleus_id is set to v_max_nucleus_id incremented by 1; sample_id is set to the p_sample_id parameter; area is set to 50.0; perimeter is set to 30.0; circularity is set to 0.9; max_caliper is set to 10.0; min_caliper is set to 6.0; eccentricity is set to 0.5; nucleus_volume is set to 200.0; nucleus_shape is set to 'Spherical'; nucleus_texture is set to the p_texture parameter value; nucleus_intensity is set to 0.85; and nucleus_area_std_dev is set to 1.0. After the insertion, v_max_nucleus_id is incremented by 1.\n\nIf the condition is false (circularity does not exceed the threshold), the procedure executes an alternative INSERT statement into the nucleus_metrics table. This INSERT statement populates the columns as follows: nucleus_id is set to v_max_nucleus_id incremented by 1; sample_id is set to the p_sample_id parameter; area is set to 40.0; perimeter is set to 25.0; circularity is set to 0.8; max_caliper is set to 8.0; min_caliper is set to 5.0; eccentricity is set to 0.6; nucleus_volume is set to 150.0; nucleus_shape is set to 'Ellipsoidal'; nucleus_texture is set to 'Default'; nucleus_intensity is set to 0.75; and nucleus_area_std_dev is set to 1.5. After this insertion, v_max_nucleus_id is also incremented by 1.\n\nThe procedure continues this loop for all nucleus records in the nucleus_metrics table that match the given sample_id. The loop ensures that each new nucleus record inserted receives a unique, sequentially increasing nucleus_id starting from the initial maximum value plus one. The procedure does not return a value; it performs insertions based on the conditional logic.",
    "original_summary": "Create a stored procedure named `generate_nucleus_report` that accepts a sample ID, a circularity threshold, and a texture. For each nucleus in the specified sample, check its circularity. If it exceeds the threshold, insert a new record with the provided texture and predefined metrics like area 50.0. If not, insert a record with 'Default' texture and different predefined metrics like area 40.0. Ensure new nucleus IDs are generated sequentially from the current maximum.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure called `generate_nucleus_report` that takes a sample ID, a circularity threshold, and a texture as inputs? For every nucleus in the given sample, it should check if the circularity is above the threshold. If it is, how do I insert a new record using the provided texture and predefined metrics such as an area of 50.0? If it is not, how do I insert a record with a 'Default' texture and different predefined metrics like an area of 40.0? Also, how do I ensure that new nucleus IDs are generated sequentially starting from the current maximum?"
  },
  {
    "ir": "Write a PLpgSQL stored procedure named clean_access_logs that accepts a single parameter p_cutoff_date of type text, which represents a date threshold. The procedure iterates over each record in the access_logs table where the access_date column is earlier than the specified p_cutoff_date. For each record, it retrieves the status of the user associated with the access log by selecting the status column from the users table where the user_id matches the user_id in the current access_logs record. If the user's status is 'inactive', the procedure deletes the corresponding record from the access_logs table using the access_id column to identify the record. If the user's status is 'active', it updates the access_type column of the access_logs record to 'archived', again using the access_id to locate the record. If the user's status is neither 'inactive' nor 'active', the procedure deletes the access_logs record using the access_id. The procedure uses a FOR loop to iterate over the selected records and conditional statements to determine the appropriate action based on the user's status.",
    "plsql": "CREATE OR REPLACE PROCEDURE clean_access_logs(p_cutoff_date text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_access_record access_logs%ROWTYPE;\n    v_user_status text;\nBEGIN\n    FOR v_access_record IN SELECT * FROM access_logs WHERE access_date < p_cutoff_date LOOP\n        SELECT u.status INTO v_user_status\n        FROM users u\n        WHERE u.user_id = v_access_record.user_id;\n        \n        IF v_user_status = 'inactive' THEN\n            DELETE FROM access_logs WHERE access_id = v_access_record.access_id;\n        ELSIF v_user_status = 'active' THEN\n            UPDATE access_logs SET access_type = 'archived' WHERE access_id = v_access_record.access_id;\n        ELSE\n            DELETE FROM access_logs WHERE access_id = v_access_record.access_id;\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "weather_data_collection_and_analysis_704531",
    "tables": [
      "access_logs",
      "users",
      "weather_data",
      "weather_stations",
      "weather_types"
    ],
    "call_sqls": [
      "CALL clean_access_logs('2023-05-01');",
      "CALL clean_access_logs('2023-05-02');",
      "CALL clean_access_logs('2023-04-30');",
      "CALL clean_access_logs('2023-06-01');",
      "CALL clean_access_logs('2022-12-31');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named clean_access_logs that cleans old access logs from the access_logs table based on a provided cutoff date. For each log older than the cutoff date, check the associated user's status from the users table: if the user's status is 'inactive', delete the log; if the user's status is 'active', update the log's access_type to 'archived'; for any other user status, delete the log.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named clean_access_logs that, given a cutoff date, deletes logs from the access_logs table for users with 'inactive' status in the users table, archives logs by setting access_type to 'archived' for users with 'active' status, and deletes logs for any other user status.",
    "id": 17,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named clean_access_logs that accepts one input parameter: a cutoff_date of type text, representing the date before which access logs will be processed. The procedure does not return a value.\n\nThe procedure begins by performing a DELETE operation on the access_logs table. It deletes rows from access_logs where the access_date is less than the provided cutoff_date and the associated user in the users table has a status equal to the string 'inactive'. This is achieved by joining the access_logs table with the users table on the user_id column, using a subquery or a join in the WHERE clause to filter for users with status 'inactive'.\n\nNext, the procedure performs an UPDATE operation on the access_logs table. It updates rows by setting the access_type column to the string 'archived' where the access_date is less than the provided cutoff_date and the associated user in the users table has a status equal to the string 'active'. This is achieved by joining the access_logs table with the users table on the user_id column, using a subquery or a join in the WHERE clause to filter for users with status 'active'.\n\nFinally, the procedure performs another DELETE operation on the access_logs table. It deletes rows from access_logs where the access_date is less than the provided cutoff_date and the associated user in the users table has a status that is neither 'active' nor 'inactive'. This is achieved by joining the access_logs table with the users table on the user_id column, using a subquery or a join in the WHERE clause to filter for users where the status is NOT IN ('active', 'inactive'). This handles any other possible status values.\n\nAll operations are executed sequentially within a single procedure. The procedure assumes that the access_date column in the access_logs table is stored in a text format comparable to the cutoff_date parameter (e.g., 'YYYY-MM-DD'), and that the status column in the users table contains text values such as 'active', 'inactive', and possibly others. No explicit local variables are declared; the logic is implemented directly using SQL statements with joins and conditions.",
    "original_summary": "Create a stored procedure named clean_access_logs that cleans old access logs. It takes a cutoff date. For each log older than the cutoff: check the associated user's status. If the user is 'inactive', delete the log. If the user is 'active', update the log's access_type to 'archived'. For any other user status, delete the log.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create procedure clean_access_logs with cutoff date. Delete logs for inactive users, archive logs for active users, delete logs for any other status."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `log_feature_count_for_experiment` that accepts a single input parameter, `exp_id`, of type `bigint`. This procedure is designed to record configuration details for a specific experiment. Upon execution, the procedure first declares two local variables: `feat_count` of type `bigint` and `next_config_id` of type `bigint`. It then performs a `SELECT` operation to count all rows in the `dataset_features` table, storing the resulting total number of features into the `feat_count` variable. Subsequently, it executes another `SELECT` operation to determine the next available configuration identifier. This is achieved by querying the `experiment_configurations` table, finding the maximum value in the `config_id` column, and then adding `1` to it. If no records exist in the `experiment_configurations` table (i.e., `MAX(config_id)` returns `NULL`), the `COALESCE` function ensures that `0` is used instead, resulting in `next_config_id` being set to `1`. Finally, the procedure performs an `INSERT` operation into the `experiment_configurations` table. A new row is inserted with the following values: the calculated `next_config_id` is assigned to the `config_id` column, the input `exp_id` parameter is assigned to the `experiment_id` column, the previously calculated `feat_count` is assigned to the `batch_size` column, the literal integer value `10` is assigned to the `epochs` column, and the literal string value `'adam'` is assigned to the `optimizer` column.",
    "plsql": "CREATE OR REPLACE PROCEDURE log_feature_count_for_experiment(exp_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    feat_count bigint;\n    next_config_id bigint;\nBEGIN\n    SELECT COUNT(*) INTO feat_count FROM dataset_features;\n    SELECT COALESCE(MAX(config_id), 0) + 1 INTO next_config_id FROM experiment_configurations;\n    INSERT INTO experiment_configurations (config_id, experiment_id, batch_size, epochs, optimizer)\n    VALUES (next_config_id, exp_id, feat_count, 10, 'adam');\nEND;\n$$;",
    "database_name": "machine_learning_model_performance_tracking_and_analysis_455100",
    "tables": [
      "dataset_features",
      "experiment_configurations",
      "model_architectures"
    ],
    "call_sqls": [
      "CALL log_feature_count_for_experiment(1);",
      "CALL log_feature_count_for_experiment(2);",
      "CALL log_feature_count_for_experiment(3);",
      "CALL log_feature_count_for_experiment(4);",
      "CALL log_feature_count_for_experiment(5);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named log_feature_count_for_experiment that accepts an experiment ID, counts all rows in the dataset_features table, determines the next config_id from the experiment_configurations table, and inserts a new configuration record into experiment_configurations with that config_id, the provided experiment_id, the feature count as batch_size, 10 as epochs, and 'adam' as optimizer.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called log_feature_count_for_experiment that takes an experiment ID as input, counts all entries in the dataset_features table to get the total feature count, determines the next config_id from the experiment_configurations table, and inserts a new record into the experiment_configurations table with that config_id, the provided experiment_id, the feature count as batch_size, epochs set to 10, and optimizer as 'adam'.",
    "id": 18,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `log_feature_count_for_experiment` that accepts a single input parameter, `exp_id`, of type `bigint`. This procedure is designed to record configuration details for a specific experiment. Upon execution, the procedure first declares two local variables: `feat_count` of type `bigint` and `next_config_id` of type `bigint`. It then performs a `SELECT` operation to count all rows in the `dataset_features` table, storing the resulting total number of features into the `feat_count` variable. Subsequently, it executes another `SELECT` operation to determine the next available configuration identifier. This is achieved by querying the `experiment_configurations` table, finding the maximum value in the `config_id` column, and then adding `1` to it. If no records exist in the `experiment_configurations` table (i.e., `MAX(config_id)` returns `NULL`), the `COALESCE` function ensures that `0` is used instead, resulting in `next_config_id` being set to `1`. Finally, the procedure performs an `INSERT` operation into the `experiment_configurations` table. A new row is inserted with the following values: the calculated `next_config_id` is assigned to the `config_id` column, the input `exp_id` parameter is assigned to the `experiment_id` column, the previously calculated `feat_count` is assigned to the `batch_size` column, the literal integer value `10` is assigned to the `epochs` column, and the literal string value `'adam'` is assigned to the `optimizer` column.",
    "original_summary": "Create a stored procedure named log_feature_count_for_experiment that accepts an experiment ID (bigint). Count all rows in the dataset_features table. Determine the next config_id from the experiment_configurations table. Insert a new configuration record with the calculated config_id, the given experiment_id, the feature count as batch_size, 10 as epochs, and 'adam' as optimizer.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called log_feature_count_for_experiment that takes an experiment ID (as a bigint)? First, count up all the entries in the dataset_features table. Then, figure out what the next config_id should be from the experiment_configurations table. Finally, pop a new record into the configurations table using that new config_id, the experiment_id we got, the total feature count as the batch_size, set epochs to 10, and make the optimizer 'adam'."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named process_tournament_matches that accepts two input text parameters, p_event_name_param and p_surface_param, and processes tournament match data by first initializing a bit variable v_bit_mask to the binary value '11111111' and then using the set_bit function to set its first bit (position 0) to 0, resulting in the binary value '01111111'. The procedure then executes a loop over a result set obtained from a SELECT query that joins the matches table (aliased as m) with the match_results table (aliased as mr) via a LEFT JOIN on the match_id column, selecting the columns m.match_id, m.event_name, m.surface, and mr.winner_id for rows where the matches.event_name column contains the string from p_event_name_param as a substring (using the LIKE operator with wildcards '%' on both sides) and where the matches.surface column exactly equals the value of p_surface_param. For each record fetched into the v_match_record variable, the procedure checks if the winner_id field is NULL; if it is NULL, the procedure performs an INSERT into the match_results table, populating the columns result_id, match_id, playerA_id, playerB_id, winner_id, score, set_scores, match_duration, total_points, and total_games with specific values: the result_id is determined by a subquery that selects the maximum existing result_id from the match_results table, adds 1 to it, and uses 0 if the maximum is NULL via the COALESCE function; the match_id is set to v_match_record.match_id; playerA_id is set to 0; playerB_id is set to 1; winner_id is set to 0; score is set to the string '0-0'; set_scores is set to the string '0-0'; match_duration is set to 0; total_points is set to 0; and total_games is set to 0. If the winner_id is not NULL, the procedure instead executes an UPDATE on the players table, setting the career_winnings column for the row where player_id equals v_match_record.winner_id to the result of casting the current career_winnings value to numeric, adding 10000 to it, and then casting the sum back to text.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_tournament_matches(p_event_name_param text, p_surface_param text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_match_record RECORD;\n    v_bit_mask bit;\nBEGIN\n    v_bit_mask := set_bit(B'11111111'::bit, 0, 0);\n    \n    FOR v_match_record IN \n        SELECT m.match_id, m.event_name, m.surface, mr.winner_id\n        FROM matches m\n        LEFT JOIN match_results mr ON m.match_id = mr.match_id\n        WHERE m.event_name LIKE '%' || p_event_name_param || '%'\n          AND m.surface = p_surface_param\n    LOOP\n        IF v_match_record.winner_id IS NULL THEN\n            INSERT INTO match_results (result_id, match_id, playerA_id, playerB_id, winner_id, score, set_scores, match_duration, total_points, total_games)\n            VALUES ((SELECT COALESCE(MAX(result_id), 0) + 1 FROM match_results), \n                    v_match_record.match_id, 0, 1, 0, '0-0', '0-0', 0, 0, 0);\n        ELSE\n            UPDATE players \n            SET career_winnings = (CAST(career_winnings AS numeric) + 10000)::text\n            WHERE player_id = v_match_record.winner_id;\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "tennis_match_statistics_and_analytics",
    "tables": [
      "match_results",
      "matches",
      "players"
    ],
    "call_sqls": [
      "CALL process_tournament_matches('Australian Open', 'HARD');",
      "CALL process_tournament_matches('Wimbledon', 'GRASS');",
      "CALL process_tournament_matches('US Open', 'HARD');",
      "CALL process_tournament_matches('French Open', 'CLAY');",
      "CALL process_tournament_matches('ATP', 'HARD');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named process_tournament_matches that takes an event name and a surface type, retrieves matches from the MATCHES table where the event name contains the input string and the surface matches, and for each match: if no winner is recorded in the MATCH_RESULTS table, inserts a default match result with placeholder values; if a winner exists, updates that player's career winnings in the PLAYERS table by adding 10000.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called process_tournament_matches that accepts an event name and a surface type, processes matches from the matches table where the event name contains the provided event name and the surface matches the provided surface, inserts a default result into the match_results table for matches without a winner, and updates the career_winnings in the players table for existing winners by adding 10000.",
    "id": 19,
    "generated_ir": "Write a PostgreSQL PLpgSQL stored procedure named process_tournament_matches that accepts two input text parameters, p_event_name_param and p_surface_param, and processes tournament match data by first initializing a bit variable v_bit_mask to the binary value '11111111' and then using the set_bit function to set its first bit (position 0) to 0, resulting in the binary value '01111111'. The procedure then executes a loop over a result set obtained from a SELECT query that joins the matches table (aliased as m) with the match_results table (aliased as mr) via a LEFT JOIN on the match_id column, selecting the columns m.match_id, m.event_name, m.surface, and mr.winner_id for rows where the matches.event_name column contains the string from p_event_name_param as a substring (using the LIKE operator with wildcards '%' on both sides) and where the matches.surface column exactly equals the value of p_surface_param. For each record fetched into the v_match_record variable, the procedure checks if the winner_id field is NULL; if it is NULL, the procedure performs an INSERT into the match_results table, populating the columns result_id, match_id, playerA_id, playerB_id, winner_id, score, set_scores, match_duration, total_points, and total_games with specific values: the result_id is determined by a subquery that selects the maximum existing result_id from the match_results table, adds 1 to it, and uses 0 if the maximum is NULL via the COALESCE function; the match_id is set to v_match_record.match_id; playerA_id is set to 0; playerB_id is set to 1; winner_id is set to 0; score is set to the string '0-0'; set_scores is set to the string '0-0'; match_duration is set to 0; total_points is set to 0; and total_games is set to 0. If the winner_id is not NULL, the procedure instead executes an UPDATE on the players table, setting the career_winnings column for the row where player_id equals v_match_record.winner_id to the result of casting the current career_winnings value to numeric, adding 10000 to it, and then casting the sum back to text.",
    "original_summary": "Create a stored procedure named process_tournament_matches that takes an event name and a surface type. It processes matches where the event name contains the input string and the surface matches. For each match, if there is no winner recorded, it inserts a default match result. If a winner exists, it updates that player's career winnings by adding 10000.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure called process_tournament_matches that accepts an event name and a surface type, processes matches with a matching event name and surface, inserts a default result for matches without a winner, and updates the career winnings of existing winners by adding 10000?"
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `create_filtered_dataset` that accepts three input parameters: `p_source_dataset_id` of type `bigint`, `p_income_filter` of type `text`, and `p_education_threshold` of type `bigint`. The procedure begins by declaring two local variables: `v_new_dataset_id` of type `bigint` and `v_dataset_name` of type `text`. It then proceeds to determine a new unique identifier for a dataset by selecting the maximum value from the `dataset_id` column in the `datasets` table and adding 1 to it, storing this result in the `v_new_dataset_id` variable. Subsequently, it constructs a name for the new dataset by concatenating the literal string 'Filtered Dataset ' with the `v_new_dataset_id` converted to a text string using the `to_char` function with the format mask '999', and assigns this concatenated string to the `v_dataset_name` variable. Following this, the procedure inserts a new record into the `datasets` table. The `dataset_id` column of this new record is populated with the value from `v_new_dataset_id`. The `dataset_name` column is populated with the value from `v_dataset_name`. The `description` column is set to the literal string 'Filtered demographic data'. The `collection_date` column is set to the literal date '2024-01-01'. The `data_collection_method_id` column is populated by selecting the `data_collection_method_id` from the `datasets` table where the `dataset_id` matches the `p_source_dataset_id` parameter. After creating the new dataset entry, the procedure inserts filtered demographic data into the `demographic_data` table. For each new record, the `age`, `workclass`, `education`, `education_num`, `marital_status`, `occupation`, `relationship`, `race`, `sex`, `capital_gain`, `capital_loss`, `hours_per_week`, `native_country`, and `income` columns are populated with corresponding values selected from the `demographic_data` table. The `dataset_id` column for these new records is set to the value of `v_new_dataset_id`, and the `data_collection_method_id` column is populated with the `data_collection_method_id` selected from the source `demographic_data` table. The selection of source records from the `demographic_data` table is subject to three conditions: the `dataset_id` must match the `p_source_dataset_id` parameter, the `income` column must be equal to the `p_income_filter` parameter, and the `education_num` column must be greater than or equal to the `p_education_threshold` parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE create_filtered_dataset(\n    p_source_dataset_id bigint,\n    p_income_filter text,\n    p_education_threshold bigint\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_new_dataset_id bigint;\n    v_dataset_name text;\nBEGIN\n    SELECT MAX(dataset_id) + 1 INTO v_new_dataset_id FROM datasets;\n    \n    v_dataset_name := 'Filtered Dataset ' || to_char(v_new_dataset_id, '999');\n    \n    INSERT INTO datasets (dataset_id, dataset_name, description, collection_date, data_collection_method_id)\n    SELECT v_new_dataset_id, v_dataset_name, 'Filtered demographic data', '2024-01-01', data_collection_method_id\n    FROM datasets WHERE dataset_id = p_source_dataset_id;\n\n    INSERT INTO demographic_data (age, workclass, education, education_num, marital_status, \n                                 occupation, relationship, race, sex, capital_gain, capital_loss,\n                                 hours_per_week, native_country, income, dataset_id, data_collection_method_id)\n    SELECT age, workclass, education, education_num, marital_status, occupation, relationship,\n           race, sex, capital_gain, capital_loss, hours_per_week, native_country, income,\n           v_new_dataset_id, data_collection_method_id\n    FROM demographic_data\n    WHERE dataset_id = p_source_dataset_id\n    AND income = p_income_filter\n    AND education_num >= p_education_threshold;\nEND;\n$$;",
    "database_name": "demographic_and_socioeconomic_data_analysis_40195",
    "tables": [
      "data_collection_methods",
      "data_collections",
      "datasets",
      "demographic_data",
      "users"
    ],
    "call_sqls": [
      "CALL create_filtered_dataset(1, '>50K', 16);",
      "CALL create_filtered_dataset(2, '<=50K', 12);",
      "CALL create_filtered_dataset(3, '>50K', 14);",
      "CALL create_filtered_dataset(1, '<=50K', 10);",
      "CALL create_filtered_dataset(4, '>50K', 9);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `create_filtered_dataset` that creates a new filtered dataset from an existing source dataset. It takes a source dataset ID, an income filter text, and an education threshold. The procedure generates a new dataset ID and name, inserts a new record into the `datasets` table with a description and date based on the source dataset, and copies demographic records from the `demographic_data` table where the dataset ID matches the source, the income equals the provided filter, and the education number is at least the given threshold, associating these copied records with the new dataset ID.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `create_filtered_dataset` that accepts a source dataset ID, an income filter text, and an education threshold. It must generate a new dataset ID and name, insert a new record into the `datasets` table with a description and date, and copy filtered demographic records from the source dataset where the income matches the filter and the education number meets the threshold into the `demographic_data` table under the new dataset ID.",
    "id": 20,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named create_filtered_dataset that accepts three input parameters: a bigint parameter source_dataset_id representing the identifier of the source dataset to filter, a text parameter income_filter to specify the income value for filtering, and a bigint parameter education_threshold to define the minimum education number. The procedure begins by declaring two local variables: new_dataset_id of type bigint to store the generated identifier for the new dataset, and new_dataset_name of type text to store the constructed name for the new dataset. The procedure first generates a new dataset ID by obtaining the next value from the sequence associated with the dataset_id column in the datasets table, storing it in new_dataset_id. It then constructs the new dataset name by concatenating the string 'Filtered dataset from source ID ' with the source_dataset_id parameter, storing the result in new_dataset_name. Next, the procedure inserts a new record into the datasets table with the following values: dataset_id set to new_dataset_id, dataset_name set to new_dataset_name, description set to the string 'Filtered dataset based on income and education', collection_date set to the current date using the CURRENT_DATE function, and data_collection_method_id set to the data_collection_method_id from the source dataset by selecting it from the datasets table where dataset_id equals source_dataset_id. The procedure then copies filtered demographic records from the source dataset into the demographic_data table by executing an INSERT statement that selects all columns from the demographic_data table where the dataset_id matches source_dataset_id, the income column exactly matches the income_filter parameter, and the education_num column is greater than or equal to the education_threshold parameter; for each copied record, the dataset_id is set to new_dataset_id, while all other column values remain unchanged from the source.",
    "original_summary": "Create a stored procedure named `create_filtered_dataset` that takes a source dataset ID, an income filter text, and an education threshold. It generates a new dataset ID and name, inserts a new record into the `datasets` table with a description and date, and copies filtered demographic records from the source dataset where income matches the filter and education number meets the threshold into the `demographic_data` table under the new dataset ID.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure called `create_filtered_dataset` that accepts a source dataset ID, an income filter text, and an education threshold. It must generate a new dataset ID and name, insert a new record into the `datasets` table with a description and date, and copy filtered demographic records from the source dataset where the income matches the filter and the education number meets the threshold into the `demographic_data` table under the new dataset ID."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `migrate_user_data` that accepts three input parameters: `p_old_user_id` of type `TEXT`, representing the identifier of the user whose data is to be migrated; `p_new_user_id` of type `TEXT`, representing the identifier of the new user to whom the data will be migrated; and `p_migration_type` of type `TEXT`, which is declared but not utilized within the current implementation of the procedure.\n\nUpon execution, the procedure first declares two local variables: `activity_count` of type `BIGINT` and `status_count` of type `BIGINT`.\n\nThe procedure then proceeds to determine the number of existing records associated with the old user ID in the `user_activity` table. This is achieved by executing a `SELECT COUNT(*)` query on the `user_activity` table, filtering rows where the `user_id` column matches the value provided in `p_old_user_id`, and storing the resulting count in the `activity_count` variable.\n\nSubsequently, the procedure determines the number of existing records associated with the old user ID in the `user_status` table. This is achieved by executing a `SELECT COUNT(*)` query on the `user_status` table, filtering rows where the `user_id` column matches the value provided in `p_old_user_id`, and storing the resulting count in the `status_count` variable.\n\nFollowing these counts, the procedure enters a conditional block. If the `activity_count` variable holds a value greater than 0, indicating the presence of user activity records for the old user ID, the following operations are performed:\n\nFirst, new records are inserted into the `user_activity` table. The columns populated are `stream_id`, `user_id`, `state`, `last_active_ts`, `device_info`, and `currently_active`. The values for these columns are derived from a `SELECT` statement that queries the `user_activity` table for records where the `user_id` matches `p_old_user_id`.\n- For the `stream_id` column, the value is calculated by taking the maximum existing `stream_id` from the `user_activity` table (defaulting to 0 if no records exist, using `COALESCE(MAX(stream_id), 0)`) and adding the `ROW_NUMBER()` generated for each row in the subquery.\n- For the `user_id` column, the value is set to `p_new_user_id`.\n- For the `state` column, the value is taken directly from the `state` column of the corresponding old `user_activity` record.\n- For the `last_active_ts` column, the value is set to the current timestamp, converted to `BIGINT` representing seconds since the epoch using `EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)` and then cast to `TEXT`.\n- For the `device_info` column, the value is taken from the `device_info` column of the corresponding old `user_activity` record, with a fallback to the literal string 'Migrated Device' if the original `device_info` is `NULL` (using `COALESCE(device_info, 'Migrated Device')`).\n- For the `currently_active` column, the value is set to the integer `0`.\n\nAfter inserting these new records, all existing records in the `user_activity` table where the `user_id` column matches `p_old_user_id` are deleted.\n\nNext, the procedure enters another conditional block. If the `status_count` variable holds a value greater than 0, indicating the presence of user status records for the old user ID, the following operations are performed:\n\nFirst, new records are inserted into the `user_status` table. The columns populated are `status_id`, `user_id`, `status_text`, `status_type`, `created_at`, and `updated_at`. The values for these columns are derived from a `SELECT` statement that queries the `user_status` table for records where the `user_id` matches `p_old_user_id`.\n- For the `status_id` column, the value is calculated by taking the maximum existing `status_id` from the `user_status` table (defaulting to 0 if no records exist, using `COALESCE(MAX(status_id), 0)`) and adding the `ROW_NUMBER()` generated for each row in the subquery.\n- For the `user_id` column, the value is set to `p_new_user_id`.\n- For the `status_text` column, the value is taken directly from the `status_text` column of the corresponding old `user_status` record.\n- For the `status_type` column, the value is taken directly from the `status_type` column of the corresponding old `user_status` record.\n- For the `created_at` column, the value is taken directly from the `created_at` column of the corresponding old `user_status` record.\n- For the `updated_at` column, the value is set to the current timestamp, converted to `BIGINT` representing seconds since the epoch using `EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)` and then cast to `TEXT`.\n\nAfter inserting these new records, all existing records in the `user_status` table where the `user_id` column matches `p_old_user_id` are deleted.",
    "plsql": "CREATE OR REPLACE PROCEDURE migrate_user_data(p_old_user_id TEXT, p_new_user_id TEXT, p_migration_type TEXT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    activity_count BIGINT;\n    status_count BIGINT;\nBEGIN\n    SELECT COUNT(*) INTO activity_count FROM user_activity WHERE user_id = p_old_user_id;\n    SELECT COUNT(*) INTO status_count FROM user_status WHERE user_id = p_old_user_id;\n    \n    IF activity_count > 0 THEN\n        INSERT INTO user_activity (stream_id, user_id, state, last_active_ts, device_info, currently_active)\n        SELECT \n            (SELECT COALESCE(MAX(stream_id), 0) FROM user_activity) + ROW_NUMBER() OVER(),\n            p_new_user_id,\n            state,\n            EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)::BIGINT::TEXT,\n            COALESCE(device_info, 'Migrated Device'),\n            0\n        FROM user_activity WHERE user_id = p_old_user_id;\n        \n        DELETE FROM user_activity WHERE user_id = p_old_user_id;\n    END IF;\n    \n    IF status_count > 0 THEN\n        INSERT INTO user_status (status_id, user_id, status_text, status_type, created_at, updated_at)\n        SELECT \n            (SELECT COALESCE(MAX(status_id), 0) FROM user_status) + ROW_NUMBER() OVER(),\n            p_new_user_id,\n            status_text,\n            status_type,\n            created_at,\n            EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)::BIGINT::TEXT\n        FROM user_status WHERE user_id = p_old_user_id;\n        \n        DELETE FROM user_status WHERE user_id = p_old_user_id;\n    END IF;\nEND;\n$$;",
    "database_name": "user_activity_and_status_tracking",
    "tables": [
      "server_info",
      "user_activity",
      "user_server_sync",
      "user_status"
    ],
    "call_sqls": [
      "CALL migrate_user_data('@olduser:server.com', '@newuser:server.com', 'full');",
      "CALL migrate_user_data('@spyglass:localhost:8800', '@spyglass:migrated.com', 'partial');",
      "CALL migrate_user_data('@anon-20191002_181700-11:localhost', '@migrated_user:newserver.com', 'test');",
      "CALL migrate_user_data('user123', 'user456', 'merge');",
      "CALL migrate_user_data('@legacy:old.org', '@modern:new.org', 'upgrade');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_user_data that takes an old user ID, a new user ID, and an unused migration type, and migrates user data from the old user ID to the new user ID. For the user_activity table, if records exist for the old user ID, copy them to the new user ID with new stream IDs, updating the last_active_ts to the current timestamp and setting device_info to a fallback value if it is null, then delete the old records. For the user_status table, if records exist for the old user ID, copy them to the new user ID with new status IDs, updating the updated_at timestamp to the current timestamp, then delete the old records.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called migrate_user_data that takes an old user ID, a new user ID, and an unused migration type. For the old user, check if there are any records in the user_activity and user_status tables. If activity records exist, copy all of them to the new user ID with new stream IDs, set last_active_ts to the current timestamp, update device_info with a fallback value if needed, and then delete the old activity records. Similarly, if status records exist, copy them to the new user with new status IDs, update updated_at to the current timestamp, and then delete the old status entries.",
    "id": 21,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `migrate_user_data` that accepts three input parameters: `p_old_user_id` of type `TEXT`, representing the identifier of the user whose data is to be migrated; `p_new_user_id` of type `TEXT`, representing the identifier of the new user to whom the data will be migrated; and `p_migration_type` of type `TEXT`, which is declared but not utilized within the current implementation of the procedure.\n\nUpon execution, the procedure first declares two local variables: `activity_count` of type `BIGINT` and `status_count` of type `BIGINT`.\n\nThe procedure then proceeds to determine the number of existing records associated with the old user ID in the `user_activity` table. This is achieved by executing a `SELECT COUNT(*)` query on the `user_activity` table, filtering rows where the `user_id` column matches the value provided in `p_old_user_id`, and storing the resulting count in the `activity_count` variable.\n\nSubsequently, the procedure determines the number of existing records associated with the old user ID in the `user_status` table. This is achieved by executing a `SELECT COUNT(*)` query on the `user_status` table, filtering rows where the `user_id` column matches the value provided in `p_old_user_id`, and storing the resulting count in the `status_count` variable.\n\nFollowing these counts, the procedure enters a conditional block. If the `activity_count` variable holds a value greater than 0, indicating the presence of user activity records for the old user ID, the following operations are performed:\n\nFirst, new records are inserted into the `user_activity` table. The columns populated are `stream_id`, `user_id`, `state`, `last_active_ts`, `device_info`, and `currently_active`. The values for these columns are derived from a `SELECT` statement that queries the `user_activity` table for records where the `user_id` matches `p_old_user_id`.\n- For the `stream_id` column, the value is calculated by taking the maximum existing `stream_id` from the `user_activity` table (defaulting to 0 if no records exist, using `COALESCE(MAX(stream_id), 0)`) and adding the `ROW_NUMBER()` generated for each row in the subquery.\n- For the `user_id` column, the value is set to `p_new_user_id`.\n- For the `state` column, the value is taken directly from the `state` column of the corresponding old `user_activity` record.\n- For the `last_active_ts` column, the value is set to the current timestamp, converted to `BIGINT` representing seconds since the epoch using `EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)` and then cast to `TEXT`.\n- For the `device_info` column, the value is taken from the `device_info` column of the corresponding old `user_activity` record, with a fallback to the literal string 'Migrated Device' if the original `device_info` is `NULL` (using `COALESCE(device_info, 'Migrated Device')`).\n- For the `currently_active` column, the value is set to the integer `0`.\n\nAfter inserting these new records, all existing records in the `user_activity` table where the `user_id` column matches `p_old_user_id` are deleted.\n\nNext, the procedure enters another conditional block. If the `status_count` variable holds a value greater than 0, indicating the presence of user status records for the old user ID, the following operations are performed:\n\nFirst, new records are inserted into the `user_status` table. The columns populated are `status_id`, `user_id`, `status_text`, `status_type`, `created_at`, and `updated_at`. The values for these columns are derived from a `SELECT` statement that queries the `user_status` table for records where the `user_id` matches `p_old_user_id`.\n- For the `status_id` column, the value is calculated by taking the maximum existing `status_id` from the `user_status` table (defaulting to 0 if no records exist, using `COALESCE(MAX(status_id), 0)`) and adding the `ROW_NUMBER()` generated for each row in the subquery.\n- For the `user_id` column, the value is set to `p_new_user_id`.\n- For the `status_text` column, the value is taken directly from the `status_text` column of the corresponding old `user_status` record.\n- For the `status_type` column, the value is taken directly from the `status_type` column of the corresponding old `user_status` record.\n- For the `created_at` column, the value is taken directly from the `created_at` column of the corresponding old `user_status` record.\n- For the `updated_at` column, the value is set to the current timestamp, converted to `BIGINT` representing seconds since the epoch using `EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)` and then cast to `TEXT`.\n\nAfter inserting these new records, all existing records in the `user_status` table where the `user_id` column matches `p_old_user_id` are deleted.",
    "original_summary": "Create a stored procedure named migrate_user_data that takes an old user ID, a new user ID, and an unused migration type. Count the old user's records in the user_activity and user_status tables. If activity records exist, copy them to the new user ID with new stream IDs, updating the last_active_ts to now and device info with a fallback, then delete the old records. If status records exist, copy them to the new user ID with new status IDs, updating the updated_at timestamp to now, then delete the old records.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Alright, so we need a stored procedure called migrate_user_data. It's gotta take an old user ID, a new user ID, and some migration type we aren't even using. First, check how many records the old user has over in the user_activity and user_status tables. If there's any activity stuff, copy it all over to the new user ID, but give it fresh stream IDs. Oh, and set the last_active_ts to right now, plus update the device infouse a fallback if needed. After that, ditch the old activity records. Same deal for the status records: if they exist, copy 'em to the new user with brand new status IDs, bump the updated_at timestamp to now, and then clean up the old status entries."
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `evaluate_position_depth` that accepts two input parameters: `p_position` of type `TEXT`, representing a specific player position, and `p_team_id` of type `BIGINT`, representing a unique identifier for a team.\n\nThe procedure begins by declaring several local variables: `v_position_count` of type `BIGINT` to store the number of players at a given position on a team, `v_avg_draft_pick` of type `REAL` to store the average draft pick of players at a given position on a team, `v_total_experience` of type `BIGINT` to store the sum of years of experience for players at a given position on a team, `v_current_year` of type `BIGINT` to store the current calendar year, `v_existing_game_id` of type `BIGINT` to store a valid `game_id` from the `game_statistics` table, and `v_valid_player_id` of type `BIGINT` to store a valid `player_id` from the `players` table belonging to the specified team.\n\nFirst, the procedure initializes `v_current_year` by extracting the year component from the current date using the `EXTRACT(YEAR FROM CURRENT_DATE)` function.\n\nNext, it performs three `SELECT` statements to gather statistics about players:\n1. It counts the number of players (`COUNT(*)`) and stores the result in `v_position_count` from the `players` table where the `position` column matches the input parameter `p_position` and the `current_team_id` column matches the input parameter `p_team_id`.\n2. It calculates the average of the `draft_pick` column and stores the result in `v_avg_draft_pick` from the `players` table where the `position` column matches `p_position` and the `current_team_id` column matches `p_team_id`.\n3. It calculates the sum of the difference between `v_current_year` and the `draft_year` column for each player, storing the total in `v_total_experience` from the `players` table where the `position` column matches `p_position` and the `current_team_id` column matches `p_team_id`. This effectively calculates the total years of experience for players at that position on that team.\n\nFollowing these calculations, the procedure retrieves identifiers for subsequent `INSERT` operations:\n1. It selects a `game_id` into `v_existing_game_id` from the `game_statistics` table. It uses `COALESCE(MIN(game_id), 1)` to get the minimum `game_id` if any exist, otherwise it defaults to `1`. This is done to ensure a valid `game_id` is available for foreign key constraints.\n2. It selects a `player_id` into `v_valid_player_id` from the `players` table where the `current_team_id` column matches `p_team_id`. It uses `COALESCE(MIN(player_id), 0)` to get the minimum `player_id` for the team if any exist, otherwise it defaults to `0`. This is done to ensure a valid `player_id` is available for foreign key constraints.\n\nThe procedure then enters a series of conditional `IF-ELSIF-ELSE` statements to determine which type of game statistic record to insert into the `game_statistics` table, based on the previously calculated player statistics:\n\n*   **Condition 1:** If `v_position_count` is greater than `4`, it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated by finding the maximum existing `game_stat_id` and adding `1` to it (or `1` if no records exist, using `COALESCE(MAX(game_stat_id), 0) + 1`). The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `v_position_count * 5`, and the `assists` column is set to `v_position_count * 2`.\n\n*   **Condition 2:** Else if `v_position_count` is greater than `2` (and not greater than `4`), it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated using `COALESCE(MAX(game_stat_id), 0) + 1`. The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `v_position_count * 8`, and the `offensive_rebounds` column is set to `v_position_count * 3`.\n\n*   **Condition 3:** Else if `v_avg_draft_pick` is less than `15.0` (and the previous conditions are false), it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated using `COALESCE(MAX(game_stat_id), 0) + 1`. The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `25`, and the `blocks` column is set to `4`.\n\n*   **Condition 4:** Else if `v_total_experience` is greater than `20` (and the previous conditions are false), it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated using `COALESCE(MAX(game_stat_id), 0) + 1`. The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `18`, and the `steals` column is set to `3`.\n\n*   **Condition 5:** Else if `v_position_count` is greater than `0` (and the previous conditions are false), it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated using `COALESCE(MAX(game_stat_id), 0) + 1`. The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `v_position_count * 12`, and the `defensive_rebounds` column is set to `v_position_count * 4`.\n\n*   **Else Condition:** If none of the above conditions are met, it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated using `COALESCE(MAX(game_stat_id), 0) + 1`. The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `5`, and the `turnovers` column is set to `1`.",
    "plsql": "CREATE OR REPLACE PROCEDURE evaluate_position_depth(p_position TEXT, p_team_id BIGINT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_position_count BIGINT;\n    v_avg_draft_pick REAL;\n    v_total_experience BIGINT;\n    v_current_year BIGINT;\n    v_existing_game_id BIGINT;\n    v_valid_player_id BIGINT;\nBEGIN\n    v_current_year := EXTRACT(YEAR FROM CURRENT_DATE);\n    SELECT COUNT(*) INTO v_position_count FROM players WHERE position = p_position AND current_team_id = p_team_id;\n    SELECT AVG(draft_pick) INTO v_avg_draft_pick FROM players WHERE position = p_position AND current_team_id = p_team_id;\n    SELECT SUM(v_current_year - draft_year) INTO v_total_experience FROM players WHERE position = p_position AND current_team_id = p_team_id;\n    \n    -- Get an existing game_id to avoid foreign key violation\n    SELECT COALESCE(MIN(game_id), 1) INTO v_existing_game_id FROM game_statistics;\n    \n    -- Get a valid player_id from the team\n    SELECT COALESCE(MIN(player_id), 0) INTO v_valid_player_id FROM players WHERE current_team_id = p_team_id;\n    \n    IF v_position_count > 4 THEN\n        INSERT INTO game_statistics (game_stat_id, game_id, player_id, points, assists)\n        VALUES ((SELECT COALESCE(MAX(game_stat_id), 0) + 1 FROM game_statistics), v_existing_game_id, v_valid_player_id, v_position_count * 5, v_position_count * 2);\n    ELSIF v_position_count > 2 THEN\n        INSERT INTO game_statistics (game_stat_id, game_id, player_id, points, offensive_rebounds)\n        VALUES ((SELECT COALESCE(MAX(game_stat_id), 0) + 1 FROM game_statistics), v_existing_game_id, v_valid_player_id, v_position_count * 8, v_position_count * 3);\n    ELSIF v_avg_draft_pick < 15.0 THEN\n        INSERT INTO game_statistics (game_stat_id, game_id, player_id, points, blocks)\n        VALUES ((SELECT COALESCE(MAX(game_stat_id), 0) + 1 FROM game_statistics), v_existing_game_id, v_valid_player_id, 25, 4);\n    ELSIF v_total_experience > 20 THEN\n        INSERT INTO game_statistics (game_stat_id, game_id, player_id, points, steals)\n        VALUES ((SELECT COALESCE(MAX(game_stat_id), 0) + 1 FROM game_statistics), v_existing_game_id, v_valid_player_id, 18, 3);\n    ELSIF v_position_count > 0 THEN\n        INSERT INTO game_statistics (game_stat_id, game_id, player_id, points, defensive_rebounds)\n        VALUES ((SELECT COALESCE(MAX(game_stat_id), 0) + 1 FROM game_statistics), v_existing_game_id, v_valid_player_id, v_position_count * 12, v_position_count * 4);\n    ELSE\n        INSERT INTO game_statistics (game_stat_id, game_id, player_id, points, turnovers)\n        VALUES ((SELECT COALESCE(MAX(game_stat_id), 0) + 1 FROM game_statistics), v_existing_game_id, v_valid_player_id, 5, 1);\n    END IF;\nEND;\n$$;",
    "database_name": "basketball_player_performance_and_team_statistics_549881",
    "tables": [
      "game_statistics",
      "players"
    ],
    "call_sqls": [
      "CALL evaluate_position_depth('SF', 0);",
      "CALL evaluate_position_depth('PF', 1);",
      "CALL evaluate_position_depth('SG', 0);",
      "CALL evaluate_position_depth('PG', 1);",
      "CALL evaluate_position_depth('C', 0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named evaluate_position_depth that takes a player position and a team ID, calculates the count of players in that position for the team, their average draft pick, and their total experience, and then inserts a record into the game_statistics table with a generated game_stat_id, a valid existing game_id from game_statistics, a valid player_id from the players table for that team, and points and other statistics (assists, offensive_rebounds, blocks, steals, defensive_rebounds, or turnovers) determined by conditional logic: if the position count exceeds 4, use points as count times 5 and assists as count times 2; if count exceeds 2, use points as count times 8 and offensive_rebounds as count times 3; if average draft pick is below 15.0, use 25 points and 4 blocks; if total experience exceeds 20, use 18 points and 3 steals; if count is greater than 0, use points as count times 12 and defensive_rebounds as count times 4; otherwise, use 5 points and 1 turnover.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `evaluate_position_depth` that, given a player position (TEXT) and a team ID (BIGINT), calculates the count of players in that position for the specified team from the `players` table, their average draft pick, and their total experience, then inserts a record into the `game_statistics` table with a generated `game_stat_id`, a valid `game_id` from the `game_statistics` table, a valid `player_id` from the `players` table for that team, and calculated `points` and other statistics (such as `assists`, `offensive_rebounds`, `blocks`, `steals`, `defensive_rebounds`, or `turnovers`) based on conditional logic: if the position count exceeds 4, use `points` as count times 5 and `assists` as count times 2; if it exceeds 2, use `points` as count times 8 and `offensive_rebounds` as count times 3; if the average draft pick is below 15.0, use 25 `points` and 4 `blocks`; if total experience exceeds 20, use 18 `points` and 3 `steals`; if the position count is positive, use `points` as count times 12 and `defensive_rebounds` as count times 4; otherwise, use 5 `points` and 1 `turnovers`.",
    "id": 22,
    "generated_ir": "Write a PL/pgSQL stored procedure named `evaluate_position_depth` that accepts two input parameters: `p_position` of type `TEXT`, representing a specific player position, and `p_team_id` of type `BIGINT`, representing a unique identifier for a team.\n\nThe procedure begins by declaring several local variables: `v_position_count` of type `BIGINT` to store the number of players at a given position on a team, `v_avg_draft_pick` of type `REAL` to store the average draft pick of players at a given position on a team, `v_total_experience` of type `BIGINT` to store the sum of years of experience for players at a given position on a team, `v_current_year` of type `BIGINT` to store the current calendar year, `v_existing_game_id` of type `BIGINT` to store a valid `game_id` from the `game_statistics` table, and `v_valid_player_id` of type `BIGINT` to store a valid `player_id` from the `players` table belonging to the specified team.\n\nFirst, the procedure initializes `v_current_year` by extracting the year component from the current date using the `EXTRACT(YEAR FROM CURRENT_DATE)` function.\n\nNext, it performs three `SELECT` statements to gather statistics about players:\n1. It counts the number of players (`COUNT(*)`) and stores the result in `v_position_count` from the `players` table where the `position` column matches the input parameter `p_position` and the `current_team_id` column matches the input parameter `p_team_id`.\n2. It calculates the average of the `draft_pick` column and stores the result in `v_avg_draft_pick` from the `players` table where the `position` column matches `p_position` and the `current_team_id` column matches `p_team_id`.\n3. It calculates the sum of the difference between `v_current_year` and the `draft_year` column for each player, storing the total in `v_total_experience` from the `players` table where the `position` column matches `p_position` and the `current_team_id` column matches `p_team_id`. This effectively calculates the total years of experience for players at that position on that team.\n\nFollowing these calculations, the procedure retrieves identifiers for subsequent `INSERT` operations:\n1. It selects a `game_id` into `v_existing_game_id` from the `game_statistics` table. It uses `COALESCE(MIN(game_id), 1)` to get the minimum `game_id` if any exist, otherwise it defaults to `1`. This is done to ensure a valid `game_id` is available for foreign key constraints.\n2. It selects a `player_id` into `v_valid_player_id` from the `players` table where the `current_team_id` column matches `p_team_id`. It uses `COALESCE(MIN(player_id), 0)` to get the minimum `player_id` for the team if any exist, otherwise it defaults to `0`. This is done to ensure a valid `player_id` is available for foreign key constraints.\n\nThe procedure then enters a series of conditional `IF-ELSIF-ELSE` statements to determine which type of game statistic record to insert into the `game_statistics` table, based on the previously calculated player statistics:\n\n*   **Condition 1:** If `v_position_count` is greater than `4`, it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated by finding the maximum existing `game_stat_id` and adding `1` to it (or `1` if no records exist, using `COALESCE(MAX(game_stat_id), 0) + 1`). The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `v_position_count * 5`, and the `assists` column is set to `v_position_count * 2`.\n\n*   **Condition 2:** Else if `v_position_count` is greater than `2` (and not greater than `4`), it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated using `COALESCE(MAX(game_stat_id), 0) + 1`. The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `v_position_count * 8`, and the `offensive_rebounds` column is set to `v_position_count * 3`.\n\n*   **Condition 3:** Else if `v_avg_draft_pick` is less than `15.0` (and the previous conditions are false), it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated using `COALESCE(MAX(game_stat_id), 0) + 1`. The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `25`, and the `blocks` column is set to `4`.\n\n*   **Condition 4:** Else if `v_total_experience` is greater than `20` (and the previous conditions are false), it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated using `COALESCE(MAX(game_stat_id), 0) + 1`. The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `18`, and the `steals` column is set to `3`.\n\n*   **Condition 5:** Else if `v_position_count` is greater than `0` (and the previous conditions are false), it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated using `COALESCE(MAX(game_stat_id), 0) + 1`. The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `v_position_count * 12`, and the `defensive_rebounds` column is set to `v_position_count * 4`.\n\n*   **Else Condition:** If none of the above conditions are met, it inserts a new row into the `game_statistics` table. The `game_stat_id` is generated using `COALESCE(MAX(game_stat_id), 0) + 1`. The `game_id` is set to `v_existing_game_id`, the `player_id` is set to `v_valid_player_id`, the `points` column is set to `5`, and the `turnovers` column is set to `1`.",
    "original_summary": "Create a stored procedure named `evaluate_position_depth` that takes a player position (TEXT) and a team ID (BIGINT). Calculate the count, average draft pick, and total experience of players in that position for the team. Based on these values, insert a record into the `game_statistics` table with a generated ID, a valid game ID, a valid player ID, and calculated points and other statistics (like assists, rebounds, blocks, steals, or turnovers) according to conditional logic.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure called `evaluate_position_depth` that, given a player position (TEXT) and a team ID (BIGINT), calculates the count, average draft pick, and total experience of players in that position for the specified team, and then inserts a record into the `game_statistics` table with a generated ID, a valid game ID, a valid player ID, and calculated points and other statistics (such as assists, rebounds, blocks, steals, or turnovers) based on conditional logic?"
  },
  {
    "ir": "Write a PLpgSQL stored procedure that registers a new defect by first determining the next available defect_id by selecting the maximum defect_id from the defects table, defaulting to 0 if no defects exist, and incrementing it by 1. It then inserts a new row into the defects table with the following values: the calculated defect_id, the provided p_test_case_id, the trimmed version of the provided p_description, a status of 'Open', the provided p_reported_by, and the current date formatted as 'YYYY-MM-DD'. The procedure takes three parameters: p_test_case_id of type bigint, which specifies the identifier of the test case associated with the defect; p_description of type text, which provides a textual description of the defect; and p_reported_by of type text, which indicates the person who reported the defect.",
    "plsql": "CREATE OR REPLACE PROCEDURE register_new_defect(\n    p_test_case_id bigint,\n    p_description text,\n    p_reported_by text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_defect_id bigint;\nBEGIN\n    SELECT COALESCE(MAX(defect_id), 0) + 1 INTO v_defect_id FROM defects;\n    \n    INSERT INTO defects (\n        defect_id, \n        test_case_id, \n        description, \n        status, \n        reported_by, \n        reported_date\n    ) VALUES (\n        v_defect_id, \n        p_test_case_id, \n        TRIM(p_description), \n        'Open', \n        p_reported_by, \n        TO_CHAR(CURRENT_DATE, 'YYYY-MM-DD')\n    );\nEND;\n$$;",
    "database_name": "software_testing_and_quality_assurance_890020",
    "tables": [
      "test_case_execution",
      "test_cases",
      "defects",
      "test_plans"
    ],
    "call_sqls": [
      "CALL register_new_defect(0, 'Defect in application start', 'John Doe');",
      "CALL register_new_defect(1, 'Issue during knight move', 'Jane Doe');",
      "CALL register_new_defect(0, 'Unexpected error on main menu', 'John Doe');",
      "CALL register_new_defect(1, 'Failure in test case execution', 'Jane Doe');",
      "CALL register_new_defect(0, 'Application crash on startup', 'John Doe');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named register_new_defect that registers a new defect by inserting a row into the defects table, generating a new defect_id as one more than the highest existing defect_id (starting at 0 if none exist), using the provided test_case_id, trimming the provided description, setting the status to 'Open', using the provided reported_by, and setting the reported_date to the current date in 'YYYY-MM-DD' format.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named register_new_defect that meticulously registers a brand new defect entry by inserting a comprehensive record into the defects table. The procedure must compute the next sequential defect identifier by determining the maximum existing defect_id from the defects table, defaulting to 0 if none exist, and then adding 1 to that value. It should insert a new record with this generated defect_id, the provided test_case_id, a thoroughly trimmed version of the description, an initial status explicitly set to 'Open', the supplied reported_by information, and the exact current date formatted as 'YYYY-MM-DD'. The procedure requires input parameters for p_test_case_id, p_description, and p_reported_by.",
    "id": 23,
    "generated_ir": "Write a PLpgSQL stored procedure that registers a new defect by first determining the next available defect_id by selecting the maximum defect_id from the defects table, defaulting to 0 if no defects exist, and incrementing it by 1. It then inserts a new row into the defects table with the following values: the calculated defect_id, the provided p_test_case_id, the trimmed version of the provided p_description, a status of 'Open', the provided p_reported_by, and the current date formatted as 'YYYY-MM-DD'. The procedure takes three parameters: p_test_case_id of type bigint, which specifies the identifier of the test case associated with the defect; p_description of type text, which provides a textual description of the defect; and p_reported_by of type text, which indicates the person who reported the defect.",
    "original_summary": "Create a stored procedure to register a new defect. Calculate the next defect_id by taking the maximum existing defect_id (default to 0 if none) and adding 1. Insert a new row into the defects table with this defect_id, the provided test_case_id, the trimmed description, a status of 'Open', the reported_by value, and the current date in 'YYYY-MM-DD' format. Parameters: p_test_case_id (bigint), p_description (text), p_reported_by (text).",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Develop a stored procedure that meticulously registers a brand new defect entry. To achieve this, you must first carefully compute the next sequential defect identifier by dynamically determining the maximum existing defect_id value from the table, gracefully defaulting to 0 should no prior defects exist, and then precisely adding 1 to that value. Subsequently, you are to insert a comprehensive new record into the defects table, which should include the freshly generated defect_id, the supplied test_case_id parameter, a thoroughly trimmed version of the description, an initial status explicitly set to 'Open', the provided reported_by information, and the exact current date, meticulously formatted as 'YYYY-MM-DD'. The procedure requires the following input parameters: p_test_case_id of type bigint, p_description of type text, and p_reported_by of type text."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named `manage_project_status` that accepts one input parameter, `p_dept_id`, of type `BIGINT`, which represents the unique identifier for a department. The procedure first declares three local variables: `v_project_count` of type `INT` to store the number of projects, `v_total_budget` of type `REAL` to store the sum of budgets, and `v_avg_budget` of type `REAL` to store the calculated average budget. It then executes a `SELECT` statement to retrieve data from the `agile_projects` table. This `SELECT` statement counts all rows and calculates the sum of the `budget` column. The `COALESCE` function is used on `SUM(budget)` to ensure that if no projects are found (and thus `SUM(budget)` would return `NULL`), it defaults to `0` instead. The results of `COUNT(*)` and `COALESCE(SUM(budget), 0)` are assigned to the `v_project_count` and `v_total_budget` variables, respectively. This selection is filtered by a `WHERE` clause, ensuring that only records where the `dept_id` column matches the input parameter `p_dept_id` are considered.\n\nFollowing this, the procedure enters a conditional block. It checks if the `v_project_count` is greater than `0`. If it is, the `v_avg_budget` is calculated by dividing `v_total_budget` by `v_project_count`. If `v_project_count` is not greater than `0` (meaning no projects were found for the given department), `v_avg_budget` is set to `0`.\n\nSubsequently, the procedure enters another series of conditional statements to update the `departments` table based on the calculated `v_avg_budget`.\nThe first condition checks if `v_avg_budget` is greater than `75000`. If this condition is true, an `UPDATE` statement is executed on the `departments` table. This `UPDATE` statement sets the `contact_number` column to the string literal `'555-9999'` for the row where the `dept_id` column matches the input parameter `p_dept_id`.\nIf the first condition is false, the procedure proceeds to an `ELSIF` condition, which checks if `v_avg_budget` is greater than `50000`. If this condition is true, an `UPDATE` statement is executed on the `departments` table. This `UPDATE` statement sets the `contact_number` column to the string literal `'555-8888'` for the row where the `dept_id` column matches the input parameter `p_dept_id`.\nIf both the first and second conditions are false, the procedure executes the `ELSE` block. In this block, an `UPDATE` statement is executed on the `departments` table. This `UPDATE` statement sets the `contact_number` column to the string literal `'555-7777'` for the row where the `dept_id` column matches the input parameter `p_dept_id`.",
    "plsql": "CREATE OR REPLACE PROCEDURE manage_project_status(p_dept_id BIGINT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_project_count INT;\n    v_total_budget REAL;\n    v_avg_budget REAL;\nBEGIN\n    SELECT COUNT(*), COALESCE(SUM(budget), 0) INTO v_project_count, v_total_budget\n    FROM agile_projects\n    WHERE dept_id = p_dept_id;\n\n    IF v_project_count > 0 THEN\n        v_avg_budget := v_total_budget / v_project_count;\n    ELSE\n        v_avg_budget := 0;\n    END IF;\n\n    IF v_avg_budget > 75000 THEN\n        UPDATE departments\n        SET contact_number = '555-9999'\n        WHERE dept_id = p_dept_id;\n    ELSIF v_avg_budget > 50000 THEN\n        UPDATE departments\n        SET contact_number = '555-8888'\n        WHERE dept_id = p_dept_id;\n    ELSE\n        UPDATE departments\n        SET contact_number = '555-7777'\n        WHERE dept_id = p_dept_id;\n    END IF;\nEND;\n$$;",
    "database_name": "healthcare_departmental_agile_readiness_assessment",
    "tables": [
      "departments",
      "agile_projects",
      "agile_interventions",
      "agile_readiness"
    ],
    "call_sqls": [
      "CALL manage_project_status(1);",
      "CALL manage_project_status(2);",
      "CALL manage_project_status(0);",
      "CALL manage_project_status(10);",
      "CALL manage_project_status(15);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named manage_project_status that accepts a department ID. For the specified department, retrieve the count of projects and total budget from the agile_projects table, calculate the average budget, and update the contact_number in the departments table to '555-9999' if the average exceeds 75000, to '555-8888' if it exceeds 50000, or to '555-7777' otherwise.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called manage_project_status that takes a department ID. For the given department, calculate the number of projects and total budget from the agile_projects table, determine the average budget, and then update the contact_number in the departments table based on that average: set it to '555-9999' if the average is over 75000, to '555-8888' if it's over 50000, and to '555-7777' otherwise.",
    "id": 24,
    "generated_ir": "Write a PLpgSQL stored procedure named `manage_project_status` that accepts one input parameter, `p_dept_id`, of type `BIGINT`, which represents the unique identifier for a department. The procedure first declares three local variables: `v_project_count` of type `INT` to store the number of projects, `v_total_budget` of type `REAL` to store the sum of budgets, and `v_avg_budget` of type `REAL` to store the calculated average budget. It then executes a `SELECT` statement to retrieve data from the `agile_projects` table. This `SELECT` statement counts all rows and calculates the sum of the `budget` column. The `COALESCE` function is used on `SUM(budget)` to ensure that if no projects are found (and thus `SUM(budget)` would return `NULL`), it defaults to `0` instead. The results of `COUNT(*)` and `COALESCE(SUM(budget), 0)` are assigned to the `v_project_count` and `v_total_budget` variables, respectively. This selection is filtered by a `WHERE` clause, ensuring that only records where the `dept_id` column matches the input parameter `p_dept_id` are considered.\n\nFollowing this, the procedure enters a conditional block. It checks if the `v_project_count` is greater than `0`. If it is, the `v_avg_budget` is calculated by dividing `v_total_budget` by `v_project_count`. If `v_project_count` is not greater than `0` (meaning no projects were found for the given department), `v_avg_budget` is set to `0`.\n\nSubsequently, the procedure enters another series of conditional statements to update the `departments` table based on the calculated `v_avg_budget`.\nThe first condition checks if `v_avg_budget` is greater than `75000`. If this condition is true, an `UPDATE` statement is executed on the `departments` table. This `UPDATE` statement sets the `contact_number` column to the string literal `'555-9999'` for the row where the `dept_id` column matches the input parameter `p_dept_id`.\nIf the first condition is false, the procedure proceeds to an `ELSIF` condition, which checks if `v_avg_budget` is greater than `50000`. If this condition is true, an `UPDATE` statement is executed on the `departments` table. This `UPDATE` statement sets the `contact_number` column to the string literal `'555-8888'` for the row where the `dept_id` column matches the input parameter `p_dept_id`.\nIf both the first and second conditions are false, the procedure executes the `ELSE` block. In this block, an `UPDATE` statement is executed on the `departments` table. This `UPDATE` statement sets the `contact_number` column to the string literal `'555-7777'` for the row where the `dept_id` column matches the input parameter `p_dept_id`.",
    "original_summary": "Create a stored procedure named manage_project_status that accepts a department ID (BIGINT). For the given department, calculate the count and total budget of projects from the agile_projects table. Compute the average budget. Update the departments table's contact_number to '555-9999' if the average is >75000, to '555-8888' if >50000, or to '555-7777' otherwise.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a stored procedure called manage_project_status that takes a department ID. For that department, figure out roughly how many projects there are and what the total budget looks like from the agile_projects table. Work out the typical budget amount. Then, if that typical budget is sort of high, say over 75000, set the contact number in the departments table to '555-9999'. If it's more in the moderate range, above 50000, change it to '555-8888'. Otherwise, for the lower ones, just update it to '555-7777'."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `calculate_total_sales` that accepts three input parameters: `p_start_date` of type `text`, representing the inclusive beginning date for the sales calculation; `p_end_date` of type `text`, representing the inclusive ending date for the sales calculation; and `p_location_id` of type `bigint`, representing the unique identifier of the sales location for which the total sales are to be calculated. The procedure begins by declaring a local variable `v_total_sales` of type `real` to store the aggregated sales amount. It then executes a `SELECT` statement to calculate the sum of `total_amount` from the `sales` table. This sum is filtered by two conditions: `sale_date` must be `BETWEEN` the `p_start_date` and `p_end_date` (inclusive), and `location_id` must be equal to the provided `p_location_id`. The result of this sum is then assigned to the `v_total_sales` variable. Following this, the procedure performs an `INSERT` operation into the `inventory_logs` table. For the `log_id` column, it calculates a new identifier by selecting the maximum existing `log_id` from `inventory_logs`, using `COALESCE` to default to `0` if no `log_id` exists, and then adding `1` to that value. The `product_id` column is set to `NULL`. The `location_id` column is populated with the value of the `p_location_id` parameter. The `change_type` column is set to the literal string `'SALES_CALCULATION'`. The `change_amount` column is populated with the value stored in the `v_total_sales` variable. The `change_date` column is set to the current timestamp converted to `text` using `NOW()::text`. Similarly, the `created_at` column is also set to the current timestamp converted to `text` using `NOW()::text`.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_total_sales(p_start_date text, p_end_date text, p_location_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_total_sales real;\nBEGIN\n    SELECT SUM(total_amount) INTO v_total_sales\n    FROM sales\n    WHERE sale_date BETWEEN p_start_date AND p_end_date\n    AND location_id = p_location_id;\n    \n    INSERT INTO inventory_logs (log_id, product_id, location_id, change_type, change_amount, change_date, created_at)\n    VALUES ((SELECT COALESCE(MAX(log_id), 0) + 1 FROM inventory_logs), NULL, p_location_id, 'SALES_CALCULATION', v_total_sales, NOW()::text, NOW()::text);\nEND;\n$$;",
    "database_name": "apparel_sizing_and_inventory_management_730443",
    "tables": [
      "categories",
      "inventory_logs",
      "products",
      "sales",
      "sizes",
      "supplier_products",
      "suppliers"
    ],
    "call_sqls": [
      "CALL calculate_total_sales('2024-01-01', '2024-01-31', 100);",
      "CALL calculate_total_sales('2024-03-01', '2024-03-15', 5);",
      "CALL calculate_total_sales('2023-12-01', '2023-12-31', 42);",
      "CALL calculate_total_sales('2024-06-01', '2024-06-30', 17);",
      "CALL calculate_total_sales('2024-02-01', '2024-02-29', 88);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_total_sales that, given a start_date, end_date, and location_id, calculates the total sum of total_amount from the sales table for sales occurring between those dates at the specified location, then logs this total by inserting a new record into the inventory_logs table with an auto-incremented log_id (using the maximum existing log_id plus one), the provided location_id, a change_type of 'SALES_CALCULATION', the calculated total as change_amount, and the current timestamp for both change_date and created_at.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called calculate_total_sales that, given a start_date, an end_date, and a location_id, calculates the total sales amount from the sales table for sales occurring between those dates at that location, and then logs this total into the inventory_logs table with a new log_id, the provided location_id, 'SALES_CALCULATION' as the change_type, the calculated total as the change_amount, and the current timestamp.",
    "id": 25,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_total_sales that accepts three input parameters: a text parameter start_date to specify the beginning of the date range, a text parameter end_date to specify the end of the date range, and a bigint parameter location_id to identify a specific location; the procedure begins by declaring a local variable v_total_sales of type real to store the calculated total sales amount; it then executes a SELECT query using the SUM function on the total_amount column from the sales table, summing all rows where the sale_date column is greater than or equal to the start_date parameter and less than or equal to the end_date parameter, and the location_id column equals the provided location_id parameter, storing the result into the v_total_sales variable; if the v_total_sales value is NULL, it sets v_total_sales to 0; next, it performs an INSERT operation into the inventory_logs table, generating a new log_id using the next value from the sequence associated with the log_id primary key column (typically via nextval), setting the product_id column to NULL, the location_id column to the provided location_id parameter, the change_type column to the literal string 'SALES_CALCULATION', the change_amount column to the v_total_sales value cast to bigint, the change_date column to the current date and time formatted as 'YYYY-MM-DD HH24:MI:SS' using the TO_CHAR(NOW(), 'YYYY-MM-DD HH24:MI:SS') function call, and the created_at column to the same formatted current timestamp; the procedure does not return a value.",
    "original_summary": "Create a stored procedure named calculate_total_sales that accepts start_date (text), end_date (text), and location_id (bigint) parameters. Calculate the sum of total_amount from the sales table where the sale_date is between the provided dates and matches the location_id. Insert a record into the inventory_logs table with a new log_id (max+1), the provided location_id, change_type 'SALES_CALCULATION', the calculated total as change_amount, and the current timestamp for change_date and created_at.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure called calculate_total_sales that takes start_date (text), end_date (text), and location_id (bigint) as parameters to sum the total_amount from the sales table for sales between the given dates and at the specified location, and then insert a log into inventory_logs with a new log_id, the location_id, 'SALES_CALCULATION' as the change_type, the calculated total as change_amount, and the current timestamp?"
  },
  {
    "ir": "Write a PLpgSQL stored procedure that takes three parameters: p_patient_id of type bigint, p_test_date of type text, and p_test_location of type text. The procedure begins by declaring a local variable v_genetic_id of type bigint. It then executes a SELECT statement to determine the maximum value of the genetic_id column from the genetic_markers table, using the COALESCE function to handle cases where no rows exist by defaulting to 0, and increments this maximum value by 1 to generate a new unique genetic_id. This new genetic_id is stored in the v_genetic_id variable. Following this, the procedure performs an INSERT operation into the genetic_markers table, populating the genetic_id column with the value stored in v_genetic_id, the patient_id column with the value of the p_patient_id parameter, and the apoe4_0, apoe4_1, and apoe4_2 columns with the default value of 0. The test_date and test_location columns are set to the values of the p_test_date and p_test_location parameters, respectively. The test_conducted_by column is assigned the string 'Dr. System', and the notes column is filled with the string 'Auto-generated record'.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_genetic_test_record(p_patient_id bigint, p_test_date text, p_test_location text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_genetic_id bigint;\nBEGIN\n    SELECT COALESCE(MAX(genetic_id), 0) + 1 INTO v_genetic_id FROM genetic_markers;\n    \n    INSERT INTO genetic_markers (genetic_id, patient_id, apoe4_0, apoe4_1, apoe4_2, test_date, test_location, test_conducted_by, notes)\n    VALUES (v_genetic_id, p_patient_id, 0, 0, 0, p_test_date, p_test_location, 'Dr. System', 'Auto-generated record');\nEND;\n$$;",
    "database_name": "medical_research_and_patient_data_management",
    "tables": [
      "genetic_markers",
      "lifestyle_factors",
      "neuroimaging",
      "treatment_outcomes",
      "users"
    ],
    "call_sqls": [
      "CALL insert_genetic_test_record(1, '2024-05-15', 'Main Hospital');",
      "CALL insert_genetic_test_record(2, '2024-05-16', 'Downtown Clinic');",
      "CALL insert_genetic_test_record(3, '2024-05-17', 'Research Center');",
      "CALL insert_genetic_test_record(1, '2024-06-01', 'Main Hospital');",
      "CALL insert_genetic_test_record(5, '2024-06-10', 'Westside Medical');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named insert_genetic_test_record that takes a patient_id, test_date, and test_location, generates a new unique genetic_id for the genetic_markers table by incrementing the highest existing genetic_id, inserts a new record with this generated genetic_id, the provided patient_id, test_date, and test_location, sets all apoe4 columns (apoe4_0, apoe4_1, apoe4_2) to 0, sets test_conducted_by to 'Dr. System', and sets notes to 'Auto-generated record'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called insert_genetic_test_record that accepts a patient_id, test_date, and test_location, generates a new genetic_id for the genetic_markers table, inserts a new record with this generated genetic_id and the provided parameters, sets all apoe4 columns to 0, assigns 'Dr. System' to test_conducted_by, and populates the notes column with 'Auto-generated record'.",
    "id": 26,
    "generated_ir": "Write a PLpgSQL stored procedure that takes three parameters: p_patient_id of type bigint, p_test_date of type text, and p_test_location of type text. The procedure begins by declaring a local variable v_genetic_id of type bigint. It then executes a SELECT statement to determine the maximum value of the genetic_id column from the genetic_markers table, using the COALESCE function to handle cases where no rows exist by defaulting to 0, and increments this maximum value by 1 to generate a new unique genetic_id. This new genetic_id is stored in the v_genetic_id variable. Following this, the procedure performs an INSERT operation into the genetic_markers table, populating the genetic_id column with the value stored in v_genetic_id, the patient_id column with the value of the p_patient_id parameter, and the apoe4_0, apoe4_1, and apoe4_2 columns with the default value of 0. The test_date and test_location columns are set to the values of the p_test_date and p_test_location parameters, respectively. The test_conducted_by column is assigned the string 'Dr. System', and the notes column is filled with the string 'Auto-generated record'.",
    "original_summary": "Create a stored procedure that takes a patient_id, test_date, and test_location. It generates a new genetic_id for the genetic_markers table, inserts a new record with this ID, the provided patient_id, test_date, and test_location, sets apoe4 columns to 0, test_conducted_by to 'Dr. System', and notes to 'Auto-generated record'.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure that accepts the parameters patient_id, test_date, and test_location. The procedure must generate a new identifier for the genetic_id field within the genetic_markers table. Subsequently, it should insert a new entry utilizing this generated identifier, the supplied patient_id, test_date, and test_location parameters. The procedure must also initialize the apoe4 columns to a value of 0, assign the test_conducted_by column the value 'Dr. System', and populate the notes column with the text 'Auto-generated record'."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named update_financial_status_by_year that accepts three input parameters: p_fiscal_year_id of type bigint to identify the target fiscal year, p_new_status of type text to specify the new status value, and p_modified_by of type bigint to record the identifier of the user making the change. The procedure performs a single update operation on the financial_statements table. It sets the status column to the value of the p_new_status parameter, the modified_by column to the value of the p_modified_by parameter, and the modified_date column to the current system date formatted as a string in 'YYYY-MM-DD' format using the TO_CHAR function with the CURRENT_DATE argument. This update is applied to all rows in the financial_statements table where the fiscal_year_id column matches the value provided in the p_fiscal_year_id parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_financial_status_by_year(\n    p_fiscal_year_id bigint,\n    p_new_status text,\n    p_modified_by bigint\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE financial_statements\n    SET status = p_new_status, modified_by = p_modified_by, modified_date = TO_CHAR(CURRENT_DATE, 'YYYY-MM-DD')\n    WHERE fiscal_year_id = p_fiscal_year_id;\nEND;\n$$;",
    "database_name": "financial_statement_analysis_and_reporting_660831",
    "tables": [
      "financial_statements",
      "balance_sheets",
      "income_statements",
      "cash_flow_statements"
    ],
    "call_sqls": [
      "CALL update_financial_status_by_year(1, 'approved', 1);",
      "CALL update_financial_status_by_year(1, 'pending review', 2);",
      "CALL update_financial_status_by_year(1, 'rejected', 3);",
      "CALL update_financial_status_by_year(1, 'finalized', 4);",
      "CALL update_financial_status_by_year(1, 'draft', 5);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_financial_status_by_year that updates the status of all financial records in the financial_statements table for a specified fiscal year, identified by fiscal_year_id, to a new status value, while also recording who made the change in the modified_by column and setting the modified_date to the current date.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called update_financial_status_by_year that updates all records in the financial_statements table for a given fiscal_year_id, setting the status to a new_status, recording who modified it in modified_by, and updating the modified_date to the current date.",
    "id": 27,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named update_financial_status_by_year that accepts three input parameters: p_fiscal_year_id of type BIGINT to identify the fiscal year, p_new_status of type TEXT to specify the new status value, and p_modified_by of type BIGINT to record the user ID of the person making the modification. The procedure performs an UPDATE operation on the financial_statements table. It updates all rows in the financial_statements table where the fiscal_year_id column matches the input parameter p_fiscal_year_id. For each matching row, it sets the status column to the value of the input parameter p_new_status, sets the modified_by column to the value of the input parameter p_modified_by, and sets the modified_date column to the current system date using the CURRENT_DATE function cast to TEXT. The procedure does not return any value.",
    "original_summary": "Create a stored procedure named update_financial_status_by_year that takes fiscal_year_id, new_status, and modified_by as inputs. Update the financial_statements table for all rows matching the given fiscal_year_id, setting the status to the new value, modified_by to the provided user, and modified_date to the current date.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as 'update_financial_status_by_year'. This procedure shall accept three input parameters: fiscal_year_id, new_status, and modified_by. Its function is to modify all records within the financial_statements table that correspond to the specified fiscal_year_id. For each such record, the procedure must set the status column to the provided new_status value, assign the modified_by column to the supplied user identifier, and update the modified_date column to reflect the current system date."
  },
  {
    "ir": "Write a PostgreSQL stored procedure named add_treatment_outcome that accepts three input parameters: a bigint parameter p_patient_id representing the unique identifier of a patient, a text parameter p_treatment_type describing the type of treatment administered, and a text parameter p_response describing the patient's response to the treatment. The procedure first declares a local bigint variable v_outcome_id. It then performs a SELECT query on the treatment_outcomes table to calculate a new outcome identifier by using the COALESCE function to handle null values, which returns the maximum existing value from the outcome_id column or 0 if the column is null, and then adds 1 to that result, storing the computed value into the v_outcome_id variable. Following this, the procedure executes an INSERT operation into the treatment_outcomes table, specifying values for the following columns: outcome_id is set to the generated v_outcome_id, patient_id is set to the input parameter p_patient_id, treatment_type is set to the input parameter p_treatment_type, treatment_start_date is hardcoded to the date '2023-01-01', treatment_end_date is hardcoded to the date '2023-12-31', response is set to the input parameter p_response, progression is hardcoded to the text 'Stable', follow_up_dates is hardcoded to the date '2023-06-01', follow_up_notes is hardcoded to the text 'Regular follow-up', adverse_events is hardcoded to the text 'None', adverse_event_dates is explicitly set to NULL, treatment_dosage is hardcoded to the text 'Standard', and treatment_frequency is hardcoded to the text 'Daily'.",
    "plsql": "CREATE OR REPLACE PROCEDURE add_treatment_outcome(p_patient_id bigint, p_treatment_type text, p_response text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_outcome_id bigint;\nBEGIN\n    SELECT COALESCE(MAX(outcome_id), 0) + 1 INTO v_outcome_id FROM treatment_outcomes;\n    \n    INSERT INTO treatment_outcomes (outcome_id, patient_id, treatment_type, treatment_start_date, treatment_end_date, response, progression, follow_up_dates, follow_up_notes, adverse_events, adverse_event_dates, treatment_dosage, treatment_frequency)\n    VALUES (v_outcome_id, p_patient_id, p_treatment_type, '2023-01-01', '2023-12-31', p_response, 'Stable', '2023-06-01', 'Regular follow-up', 'None', NULL, 'Standard', 'Daily');\nEND;\n$$;",
    "database_name": "medical_research_and_patient_data_management",
    "tables": [
      "genetic_markers",
      "lifestyle_factors",
      "neuroimaging",
      "treatment_outcomes",
      "users"
    ],
    "call_sqls": [
      "CALL add_treatment_outcome(1, 'Medication A', 'Positive');",
      "CALL add_treatment_outcome(2, 'Cognitive Therapy', 'Stable');",
      "CALL add_treatment_outcome(3, 'Physical Therapy', 'Improved');",
      "CALL add_treatment_outcome(1, 'Medication B', 'Negative');",
      "CALL add_treatment_outcome(4, 'Combination Therapy', 'Partial Response');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `add_treatment_outcome` that creates a new record in the TREATMENT_OUTCOMES table for a specified PATIENT_ID, TREATMENT_TYPE, and RESPONSE, automatically generating a new OUTCOME_ID by incrementing the highest existing ID, and setting default values for TREATMENT_START_DATE to '2023-01-01', TREATMENT_END_DATE to '2023-12-31', PROGRESSION to 'Stable', FOLLOW_UP_DATES to '2023-06-01', FOLLOW_UP_NOTES to 'Regular follow-up', ADVERSE_EVENTS to 'None', ADVERSE_EVENT_DATES to NULL, TREATMENT_DOSAGE to 'Standard', and TREATMENT_FREQUENCY to 'Daily'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `add_treatment_outcome` that inserts a new record into the TREATMENT_OUTCOMES table by generating a new OUTCOME_ID based on the maximum existing one, using the provided patient ID, treatment type, and response, while setting fixed values for the other columns like treatment start date, end date, progression, follow-up details, adverse events, dosage, and frequency.",
    "id": 28,
    "generated_ir": "Write a PostgreSQL stored procedure named add_treatment_outcome that accepts three input parameters: a bigint parameter p_patient_id representing the unique identifier of a patient, a text parameter p_treatment_type describing the type of treatment administered, and a text parameter p_response describing the patient's response to the treatment. The procedure first declares a local bigint variable v_outcome_id. It then performs a SELECT query on the treatment_outcomes table to calculate a new outcome identifier by using the COALESCE function to handle null values, which returns the maximum existing value from the outcome_id column or 0 if the column is null, and then adds 1 to that result, storing the computed value into the v_outcome_id variable. Following this, the procedure executes an INSERT operation into the treatment_outcomes table, specifying values for the following columns: outcome_id is set to the generated v_outcome_id, patient_id is set to the input parameter p_patient_id, treatment_type is set to the input parameter p_treatment_type, treatment_start_date is hardcoded to the date '2023-01-01', treatment_end_date is hardcoded to the date '2023-12-31', response is set to the input parameter p_response, progression is hardcoded to the text 'Stable', follow_up_dates is hardcoded to the date '2023-06-01', follow_up_notes is hardcoded to the text 'Regular follow-up', adverse_events is hardcoded to the text 'None', adverse_event_dates is explicitly set to NULL, treatment_dosage is hardcoded to the text 'Standard', and treatment_frequency is hardcoded to the text 'Daily'.",
    "original_summary": "Create a stored procedure named `add_treatment_outcome` that inserts a new treatment outcome record. Generate a new `outcome_id` by incrementing the maximum existing ID. Insert into `treatment_outcomes` with provided `p_patient_id`, `p_treatment_type`, and `p_response`. Set hardcoded values for other columns: `treatment_start_date` to '2023-01-01', `treatment_end_date` to '2023-12-31', `progression` to 'Stable', `follow_up_dates` to '2023-06-01', `follow_up_notes` to 'Regular follow-up', `adverse_events` to 'None', `adverse_event_dates` to NULL, `treatment_dosage` to 'Standard', and `treatment_frequency` to 'Daily'.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure named `add_treatment_outcome` that inserts a new treatment outcome record by generating a new `outcome_id` from the maximum existing ID, using the provided `p_patient_id`, `p_treatment_type`, and `p_response`, and setting hardcoded values for the other columns?"
  },
  {
    "ir": "Write a PLpgSQL stored procedure named `delete_old_indicator_values` that accepts a single input parameter, `p_year`, which is of type `bigint`. The purpose of this procedure is to remove historical data from two related tables, `indicator_value_sources` and `indicator_values`, based on a specified year threshold. The procedure begins by executing a `DELETE` statement on the `indicator_value_sources` table. This deletion is conditional, targeting rows where the `indicator_value_id` column matches any `indicator_value_id` found in a subquery. The subquery selects `indicator_value_id` values from the `indicator_values` table where the `year` column is strictly less than the value provided in the `p_year` parameter. This initial deletion from `indicator_value_sources` is performed to maintain referential integrity and prevent foreign key violations, assuming `indicator_value_sources` is a child table of `indicator_values` and `indicator_value_id` is the foreign key. Following this, the procedure executes a second `DELETE` statement, this time on the `indicator_values` table. This deletion targets rows where the `year` column is strictly less than the value provided in the `p_year` parameter. The procedure includes an exception handling block that catches any `OTHERS` exception that might occur during its execution. If an exception is caught, it raises a new exception with a custom message \"Failed to delete old indicator values: \" concatenated with the standard SQL error message (`SQLERRM`).",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_old_indicator_values(p_year bigint)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    -- First delete from child table to avoid foreign key violation\n    DELETE FROM indicator_value_sources\n    WHERE indicator_value_id IN (\n        SELECT indicator_value_id \n        FROM indicator_values \n        WHERE year < p_year\n    );\n    \n    -- Then delete from parent table\n    DELETE FROM indicator_values\n    WHERE year < p_year;\n    \n    -- Commit the transaction\n    EXCEPTION\n        WHEN OTHERS THEN\n            RAISE EXCEPTION 'Failed to delete old indicator values: %', SQLERRM;\nEND;\n$$;",
    "database_name": "global_health_and_development_indicators",
    "tables": [
      "indicators",
      "indicator_values",
      "indicator_versions"
    ],
    "call_sqls": [
      "CALL delete_old_indicator_values(2020);",
      "CALL delete_old_indicator_values(2015);",
      "CALL delete_old_indicator_values(2023);",
      "CALL delete_old_indicator_values(1990);",
      "CALL delete_old_indicator_values(2000);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named delete_old_indicator_values that removes historical indicator data older than a specified year. It accepts a parameter p_year representing the cutoff year. The procedure deletes all records from the indicator_value_sources table that are linked to indicator_values records with a year less than p_year, then deletes those older records from the indicator_values table. If the operation fails, it should return an error message.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called delete_old_indicator_values that purges historical records by accepting a parameter for the year threshold. It must first delete related entries from the dependent table indicator_value_sources where the linked indicator_value_id corresponds to records in the indicator_values table with a year less than the provided parameter, then delete the records directly from the indicator_values table where the year is below that threshold. Include error handling to raise a descriptive error message if any failure occurs during execution.",
    "id": 29,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named delete_old_indicator_values that accepts one input parameter: p_year_threshold of type BIGINT representing the year boundary for deletion. The procedure performs a two-step deletion operation to purge historical records, first from a dependent table and then from the main table, with comprehensive error handling.\n\nThe procedure begins by declaring a variable v_error_message of type TEXT to capture any error details. It uses a BEGIN block with an EXCEPTION section for error handling.\n\nWithin the main execution block, the procedure first executes a DELETE operation on the table indicator_value_sources. This deletion targets rows where the indicator_value_id column in indicator_value_sources matches the indicator_value_id of rows in the indicator_values table that have a year column value strictly less than the p_year_threshold parameter. This is achieved via a subquery that selects indicator_value_id from indicator_values where year < p_year_threshold.\n\nAfter deleting from the dependent table, the procedure then executes a second DELETE operation directly on the indicator_values table. This deletion removes all rows where the year column is strictly less than the p_year_threshold parameter.\n\nThe procedure includes an EXCEPTION section to catch any SQL errors that occur during the DELETE operations. If an error is caught, it assigns a descriptive error message to the v_error_message variable, concatenating the SQL error state (SQLSTATE) and the error message (SQLERRM). It then uses the RAISE statement to raise a new exception with the custom error message, ensuring the procedure fails visibly and informatively.\n\nThe procedure does not return a value; it is a void procedure that performs deletions and raises an error on failure.",
    "original_summary": "Create a stored procedure named delete_old_indicator_values that deletes historical data. It accepts one BIGINT parameter: p_year. First, delete from the child table indicator_value_sources where the indicator_value_id references records in indicator_values with a year less than p_year. Then, delete from indicator_values where the year is less than p_year. Include an exception handler to raise an error with a descriptive message if the operation fails.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as 'delete_old_indicator_values' for the purpose of purging historical records. This procedure shall accept a single parameter of type BIGINT, named 'p_year'. The procedure must first execute a deletion from the dependent table 'indicator_value_sources', targeting rows where the associated 'indicator_value_id' corresponds to entries in the 'indicator_values' table having a 'year' value inferior to the provided parameter. Subsequently, it must delete records directly from the 'indicator_values' table where the 'year' is less than 'p_year'. It is imperative to incorporate an exception handling block to raise an error with a comprehensive descriptive message should the procedure encounter any failure during its execution."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named create_weather_type that accepts two input parameters: p_type_name of type TEXT, which is intended to be the name for a new weather type, and p_description of type TEXT, which is intended to be the descriptive text for that new weather type; the procedure's logic performs a single INSERT operation into a table named weather_types, targeting the columns type_id, type_name, and description; to generate the value for the type_id column, the procedure executes a subquery that selects from the weather_types table, applying the COALESCE function to the result of the MAX(type_id) aggregation, which returns the highest existing type_id value, and if this maximum value is NULL (indicating an empty table), COALESCE substitutes it with 0, and then adds 1 to this result to produce the next sequential identifier; for the type_name column value, the procedure takes the input parameter p_type_name, applies the TRIM function to remove any leading or trailing whitespace, and then applies the UPPER function to convert the trimmed string to uppercase before insertion; the value for the description column is inserted directly from the input parameter p_description without any transformation.",
    "plsql": "CREATE OR REPLACE PROCEDURE create_weather_type(\n    p_type_name TEXT,\n    p_description TEXT\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    INSERT INTO weather_types (type_id, type_name, description)\n    VALUES ((SELECT COALESCE(MAX(type_id), 0) + 1 FROM weather_types), UPPER(TRIM(p_type_name)), p_description);\nEND;\n$$;",
    "database_name": "weather_data_collection_and_analysis_704531",
    "tables": [
      "weather_data",
      "weather_stations",
      "weather_types"
    ],
    "call_sqls": [
      "CALL create_weather_type('Rain', 'Precipitation in the form of liquid water drops');",
      "CALL create_weather_type('Snow', 'Precipitation in the form of ice crystals');",
      "CALL create_weather_type('Fog', 'Low visibility due to condensed water vapor');",
      "CALL create_weather_type('Wind', 'Movement of air from high to low pressure areas');",
      "CALL create_weather_type('Storm', 'Severe weather with strong winds and rain');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named create_weather_type that accepts a type name and description, and inserts a new record into the weather_types table, generating a new type_id by incrementing the maximum existing type_id (starting from 1 if none exist), storing the type_name in uppercase and trimmed of whitespace along with the provided description.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called 'create_weather_type' that adds a new weather type by inserting a record into the weather_types table, using the next available type_id based on the current maximum, with the provided type name trimmed and converted to uppercase and the given description.",
    "id": 30,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named create_weather_type that accepts two input parameters: a parameter named p_type_name of type TEXT, which represents the name of the new weather type to be inserted, and a parameter named p_description of type TEXT, which provides the descriptive text for the new weather type. The procedure first declares a local variable v_next_type_id of type BIGINT to store the calculated identifier for the new record. The procedure executes a SELECT statement on the weather_types table to compute the next available type_id by retrieving the current maximum value from the type_id column and adding 1 to it; if the table is empty, the COALESCE function ensures the result defaults to 1. The procedure then performs an INSERT operation into the weather_types table, specifying values for three columns: the type_id column is set to the calculated v_next_type_id, the type_name column is set to the result of applying the UPPER function to the TRIM function on the input parameter p_type_name (which removes leading and trailing spaces and converts the string to uppercase), and the description column is set directly to the input parameter p_description. The procedure does not return a value, as it is designed to perform a data insertion operation.",
    "original_summary": "Create a stored procedure named create_weather_type that accepts a type name and description. Insert a new record into the weather_types table. Generate a new type ID by incrementing the maximum existing ID (starting at 1). Insert the type name in uppercase and trimmed of whitespace, along with the provided description.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure called 'create_weather_type' that takes a type name and description, then inserts a new record into the weather_types table by generating a new ID from the maximum existing one, inserting the trimmed and uppercase type name along with the given description?"
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named handle_role_based_operations that accepts two input parameters: target_role_id of type BIGINT, which identifies a specific role, and target_user_id of type BIGINT, which identifies a specific user. The procedure begins by declaring four local variables: role_name_var of type TEXT, user_superuser_status of type BIGINT, user_staff_status of type BIGINT, and failed_attempts of type BIGINT. It then performs four separate SELECT queries to retrieve data into these variables: first, it selects the role_name from the roles table where the role_id matches the target_role_id parameter and stores it in role_name_var; second, it selects the is_superuser value from the users table where the user_id matches the target_user_id parameter and stores it in user_superuser_status; third, it selects the is_staff value from the same users table for the target user and stores it in user_staff_status; fourth, it selects the failed_login_attempts value from the users table for the target user and stores it in failed_attempts. The procedure then executes a conditional logic block based on the retrieved role_name_var. If role_name_var equals the string 'Team Leader', it checks the user_superuser_status variable: if user_superuser_status equals 1, it updates the users table by setting the failed_login_attempts column to 0 for the row where user_id equals target_user_id; otherwise, if user_superuser_status is not 1, it updates the roles table by setting the updated_at column to the current timestamp cast to TEXT for the row where role_id equals target_role_id. If role_name_var equals the string 'Team Member', it checks the user_staff_status variable: if user_staff_status equals 1, it deletes rows from the team_invitations table where the user_id equals target_user_id and the status column equals the string 'expired'; otherwise, if user_staff_status is not 1, it inserts a new row into the team_invitations table, populating the columns invitation_id, team_id, user_id, invitation_time, invited_by, status, and message, where the invitation_id is calculated as the maximum existing invitation_id from the team_invitations table plus one (or 1 if the table is empty, using COALESCE), team_id is set to 1, user_id is set to target_user_id, invitation_time is set to the current timestamp cast to TEXT, invited_by is set to 0, status is set to 'role_based', and message is set to 'Role based invitation'. For any other role_name_var value not matching 'Team Leader' or 'Team Member', the procedure checks the failed_attempts variable: if failed_attempts is greater than 3, it updates the users table by setting the is_active column to 0 for the row where user_id equals target_user_id; otherwise, if failed_attempts is 3 or less, it updates the users table by setting the role_id column to the target_role_id parameter value for the row where user_id equals target_user_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE handle_role_based_operations(target_role_id BIGINT, target_user_id BIGINT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    role_name_var TEXT;\n    user_superuser_status BIGINT;\n    user_staff_status BIGINT;\n    failed_attempts BIGINT;\nBEGIN\n    SELECT role_name INTO role_name_var FROM roles WHERE role_id = target_role_id;\n    SELECT is_superuser INTO user_superuser_status FROM users WHERE user_id = target_user_id;\n    SELECT is_staff INTO user_staff_status FROM users WHERE user_id = target_user_id;\n    SELECT failed_login_attempts INTO failed_attempts FROM users WHERE user_id = target_user_id;\n    \n    IF role_name_var = 'Team Leader' THEN\n        IF user_superuser_status = 1 THEN\n            UPDATE users SET failed_login_attempts = 0 WHERE user_id = target_user_id;\n        ELSE\n            UPDATE roles SET updated_at = CURRENT_TIMESTAMP::TEXT WHERE role_id = target_role_id;\n        END IF;\n    ELSIF role_name_var = 'Team Member' THEN\n        IF user_staff_status = 1 THEN\n            DELETE FROM team_invitations WHERE user_id = target_user_id AND status = 'expired';\n        ELSE\n            INSERT INTO team_invitations (invitation_id, team_id, user_id, invitation_time, invited_by, status, message)\n            VALUES ((SELECT COALESCE(MAX(invitation_id), 0) + 1 FROM team_invitations), 1, target_user_id, CURRENT_TIMESTAMP::TEXT, 0, 'role_based', 'Role based invitation');\n        END IF;\n    ELSE\n        IF failed_attempts > 3 THEN\n            UPDATE users SET is_active = 0 WHERE user_id = target_user_id;\n        ELSE\n            UPDATE users SET role_id = target_role_id WHERE user_id = target_user_id;\n        END IF;\n    END IF;\nEND;\n$$;",
    "database_name": "user_management_and_authorization_system",
    "tables": [
      "users",
      "roles",
      "teams",
      "team_invitations"
    ],
    "call_sqls": [
      "CALL handle_role_based_operations(0, 0);",
      "CALL handle_role_based_operations(1, 1);",
      "CALL handle_role_based_operations(2, 0);",
      "CALL handle_role_based_operations(0, 1);",
      "CALL handle_role_based_operations(1, 0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named handle_role_based_operations that accepts a target role ID and a target user ID, retrieves the role name from the ROLES table and the user's superuser status, staff status, and failed login attempts from the USERS table, and performs role-based operations: if the role is 'Team Leader', check if the user is a superuserif true, reset the user's failed login attempts to zero in USERS; if false, update the role's timestamp in ROLES; if the role is 'Team Member', check if the user is staffif true, delete the user's 'expired' invitations from TEAM_INVITATIONS; if false, insert a new 'role_based' invitation into TEAM_INVITATIONS; for any other role, check the user's failed attemptsif more than 3, deactivate the user in USERS; otherwise, assign the new role ID to the user in USERS.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called handle_role_based_operations that takes a role ID and a user ID, and based on the role's name from the roles table, performs different operations. For the 'Team Leader' role, if the user is a superuser in the users table, reset their failed_login_attempts to zero; otherwise, update the updated_at timestamp for that role in the roles table. For the 'Team Member' role, if the user is staff, delete any expired invitations for them from the team_invitations table; if not staff, insert a new 'role_based' invitation into team_invitations. For any other role, check the user's failed_login_attempts: if more than 3, deactivate the user by setting is_active to 0 in users; otherwise, assign the new role to the user by updating their role_id.",
    "id": 31,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `handle_role_based_operations` that accepts two input parameters: `p_role_id` of type `bigint` and `p_user_id` of type `bigint`. The procedure performs role-specific operations on the `user_management_and_authorization_system` database based on the role name associated with the provided role ID and the user's attributes.\n\nThe procedure begins by declaring three local variables: `v_role_name` of type `text` to store the role name, `v_is_superuser` of type `bigint` to store the user's superuser status, `v_is_staff` of type `bigint` to store the user's staff status, and `v_failed_login_attempts` of type `bigint` to store the user's failed login attempts count.\n\nFirst, the procedure executes a `SELECT` statement to retrieve the `role_name` from the `roles` table where the `role_id` matches the input parameter `p_role_id`. The retrieved value is assigned to the variable `v_role_name`.\n\nNext, the procedure executes another `SELECT` statement to retrieve the `is_superuser`, `is_staff`, and `failed_login_attempts` columns from the `users` table where the `user_id` matches the input parameter `p_user_id`. These values are assigned to the variables `v_is_superuser`, `v_is_staff`, and `v_failed_login_attempts`, respectively.\n\nThe procedure then uses a conditional block (`IF-ELSIF-ELSE`) to branch based on the value of `v_role_name`.\n\nIf `v_role_name` is 'Team Leader', the procedure checks if `v_is_superuser` is equal to 1 (indicating the user is a superuser). If true, it executes an `UPDATE` statement on the `users` table, setting the `failed_login_attempts` column to 0 for the row where `user_id` equals `p_user_id`. If `v_is_superuser` is not 1, it executes an `UPDATE` statement on the `roles` table, setting the `updated_at` column to the current timestamp (using `CURRENT_TIMESTAMP`) for the row where `role_id` equals `p_role_id`.\n\nIf `v_role_name` is 'Team Member', the procedure checks if `v_is_staff` is equal to 1 (indicating the user is staff). If true, it executes a `DELETE` statement on the `team_invitations` table, removing rows where the `user_id` equals `p_user_id` and the `invitation_time` is older than 7 days (calculated by comparing `invitation_time` to `CURRENT_TIMESTAMP - INTERVAL '7 days'`). If `v_is_staff` is not 1, it executes an `INSERT` statement into the `team_invitations` table, adding a new row with the following values: `team_id` set to 1 (a default team ID), `user_id` set to `p_user_id`, `invitation_time` set to the current timestamp, `invited_by` set to 1 (a default inviter ID), `status` set to 'pending', and `message` set to 'Role-based invitation'.\n\nIf `v_role_name` is neither 'Team Leader' nor 'Team Member', the procedure checks if `v_failed_login_attempts` is greater than 3. If true, it executes an `UPDATE` statement on the `users` table, setting the `is_active` column to 0 for the row where `user_id` equals `p_user_id`. If `v_failed_login_attempts` is 3 or less, it executes an `UPDATE` statement on the `users` table, setting the `role_id` column to `p_role_id` for the row where `user_id` equals `p_user_id`.\n\nThe procedure then concludes.",
    "original_summary": "Create a stored procedure named handle_role_based_operations that accepts a role ID and a user ID. It retrieves the role name, the user's superuser status, staff status, and failed login attempts. If the role is 'Team Leader', check if the user is a superuser. If true, reset the user's failed login attempts to zero. If false, update the role's timestamp. If the role is 'Team Member', check if the user is staff. If true, delete the user's 'expired' invitations. If false, insert a new 'role_based' invitation. For any other role, check the user's failed attempts. If more than 3, deactivate the user. Otherwise, assign the new role to the user.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Alright, so we need a stored procedure called handle_role_based_operations that takes a role ID and a user ID. First, it's gotta grab the role's name, and check if the user's a superuser, on staff, and how many times they've messed up logging in. If the role is 'Team Leader', we see if the user's a superuser. If they are, cool, just reset their failed login count to zero. If they're not, then we need to update the timestamp for that role. Now, if the role is 'Team Member', we check if the user's on staff. If yes, then we delete any of their invitations that are marked as 'expired'. If they're not staff, then we pop in a new invitation of the 'role_based' type. For any other role, we look at the user's failed login attempts. If they've botched it more than 3 times, we have to deactivate their account. Otherwise, if they're under the limit, just go ahead and assign them this new role."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named transform_file_paths_with_overlay that accepts three input parameters: p_old_substring of type text, p_new_substring of type text, and p_target_region_id of type bigint, and processes records in the data_files table for a specific region by replacing a substring in file paths and re-inserting the modified records. The procedure declares a cursor named v_file_cursor that selects the file_id and file_path columns from the data_files table where the region_id column equals the input parameter p_target_region_id and the file_path column contains the substring specified by p_old_substring using a LIKE pattern with wildcards. It then opens this cursor and enters a loop, fetching each row into a record variable v_file_rec. For each fetched row, it constructs a new file path v_new_path by using the overlay function to replace the first occurrence of p_old_substring within v_file_rec.file_path with p_new_substring, where the starting position is determined by the position function to find p_old_substring in the original file path and the length to replace is the length of p_old_substring. After computing the new path, the procedure deletes the current record from the data_files table where the file_id matches v_file_rec.file_id. It then inserts a new row into the data_files table with the same file_id (v_file_rec.file_id), the region_id set to the input parameter p_target_region_id, the indicator_id hardcoded to 0, the file_path set to the newly computed v_new_path, the file_size hardcoded to 1.0, the upload_date hardcoded to '2024-01-01', the file_format hardcoded to 'CSV', and the file_type hardcoded to 'processed'. The loop continues until no more rows are found from the cursor, after which the cursor is closed.",
    "plsql": "CREATE OR REPLACE PROCEDURE transform_file_paths_with_overlay(p_old_substring text, p_new_substring text, p_target_region_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_file_cursor CURSOR FOR \n        SELECT file_id, file_path \n        FROM data_files \n        WHERE region_id = p_target_region_id \n        AND file_path LIKE '%' || p_old_substring || '%';\n    v_file_rec RECORD;\n    v_new_path text;\nBEGIN\n    OPEN v_file_cursor;\n    LOOP\n        FETCH v_file_cursor INTO v_file_rec;\n        EXIT WHEN NOT FOUND;\n        \n        v_new_path := overlay(v_file_rec.file_path placing p_new_substring from position(p_old_substring in v_file_rec.file_path) for length(p_old_substring));\n        \n        DELETE FROM data_files WHERE file_id = v_file_rec.file_id;\n        INSERT INTO data_files (file_id, region_id, indicator_id, file_path, file_size, upload_date, file_format, file_type)\n        SELECT v_file_rec.file_id, p_target_region_id, 0, v_new_path, 1.0, '2024-01-01', 'CSV', 'processed';\n    END LOOP;\n    CLOSE v_file_cursor;\nEND;\n$$;",
    "database_name": "economic_data_analysis_and_reporting_473112",
    "tables": [
      "data_points",
      "economic_indicators",
      "regions",
      "metadata",
      "data_versions",
      "data_files",
      "readme_files"
    ],
    "call_sqls": [
      "CALL transform_file_paths_with_overlay('region1', 'region_one', 0);",
      "CALL transform_file_paths_with_overlay('gdp', 'gross_domestic_product', 0);",
      "CALL transform_file_paths_with_overlay('2001-2011', '2000_2010', 0);",
      "CALL transform_file_paths_with_overlay('data/', 'archive/', 0);",
      "CALL transform_file_paths_with_overlay('csv', 'txt', 0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named transform_file_paths_with_overlay that takes an old substring, a new substring, and a target region ID to update file paths in the data_files table for records matching the target region_id and containing the old substring in file_path, replacing the first occurrence of the old substring with the new substring, then deleting each original record and inserting a new record with the updated file_path, the same file_id, the provided region_id, and fixed values for indicator_id (0), file_size (1.0), upload_date ('2024-01-01'), file_format ('CSV'), and file_type ('processed').",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called transform_file_paths_with_overlay that uses three inputs: p_old_substring (text), p_new_substring (text), and p_target_region_id (bigint). For records in the data_files table where the region_id matches the specified region and the file_path contains the old substring, replace that substring with the new one in the file_path. Then, remove each original record and insert a new record with the updated file_path, preserving the original file_id and using the given region_id, while setting indicator_id to 0, file_size to 1.0, upload_date to '2024-01-01', and file_format and file_type to 'CSV' and 'processed' respectively.",
    "id": 32,
    "generated_ir": "Write a PostgreSQL PLpgSQL stored procedure named transform_file_paths_with_overlay that accepts three input parameters: p_old_substring of type text, p_new_substring of type text, and p_target_region_id of type bigint, and processes records in the data_files table for a specific region by replacing a substring in file paths and re-inserting the modified records. The procedure declares a cursor named v_file_cursor that selects the file_id and file_path columns from the data_files table where the region_id column equals the input parameter p_target_region_id and the file_path column contains the substring specified by p_old_substring using a LIKE pattern with wildcards. It then opens this cursor and enters a loop, fetching each row into a record variable v_file_rec. For each fetched row, it constructs a new file path v_new_path by using the overlay function to replace the first occurrence of p_old_substring within v_file_rec.file_path with p_new_substring, where the starting position is determined by the position function to find p_old_substring in the original file path and the length to replace is the length of p_old_substring. After computing the new path, the procedure deletes the current record from the data_files table where the file_id matches v_file_rec.file_id. It then inserts a new row into the data_files table with the same file_id (v_file_rec.file_id), the region_id set to the input parameter p_target_region_id, the indicator_id hardcoded to 0, the file_path set to the newly computed v_new_path, the file_size hardcoded to 1.0, the upload_date hardcoded to '2024-01-01', the file_format hardcoded to 'CSV', and the file_type hardcoded to 'processed'. The loop continues until no more rows are found from the cursor, after which the cursor is closed.",
    "original_summary": "Create a stored procedure named transform_file_paths_with_overlay that takes three parameters: p_old_substring (text), p_new_substring (text), and p_target_region_id (bigint). For each record in the data_files table where region_id matches p_target_region_id and file_path contains p_old_substring, replace the first occurrence of p_old_substring in file_path with p_new_substring using the overlay function. Delete the original record and insert a new one with the updated file_path, the same file_id, the provided region_id, and hardcoded values for indicator_id (0), file_size (1.0), upload_date ('2024-01-01'), file_format ('CSV'), and file_type ('processed').",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Make a stored procedure called transform_file_paths_with_overlay that uses three inputs: p_old_substring (text), p_new_substring (text), and p_target_region_id (bigint). For data in the data_files table that's roughly from the specified region and where the file_path kind of has the old text bit, use overlay to swap that bit out for the new one. Get rid of the old entry and put in a fresh one with this adjusted path, keeping the original file_id and the given region. Just set indicator_id to 0, file_size to around 1.0, upload_date to something like '2024-01-01', and file_format and file_type to common values like 'CSV' and 'processed'."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named manage_access_logs_by_duration that accepts a single parameter p_min_duration of type bigint. This procedure manages records in the access_logs table based on the access_duration and data_size columns. It declares a cursor v_access_cursor to select records from access_logs where access_duration is greater than or equal to p_min_duration. For each record fetched into v_access_record, it performs conditional operations: if access_duration is greater than 300 and data_size is greater than 5000, it deletes the record; if access_duration is greater than 200 and data_size is greater than 3000, it updates the access_type to 'premium'; if access_duration is greater than 100 and data_size is greater than 2000, it updates the access_type to 'standard'; if access_duration is greater than 50, it updates the access_type to 'basic'; otherwise, it updates the access_type to 'minimal'. It then retrieves the team_name from the teams table where team_id matches the current record's team_id, pads this name to 25 characters with leading dashes, and stores it in v_team_name. It calculates the next access_id by selecting the maximum access_id from access_logs, defaulting to 0 if none exist, and increments it by 1, storing the result in v_next_access_id. Finally, it inserts a new record into access_logs with the calculated v_next_access_id, a fixed user_id of 1, a game_id of 0, the current record's team_id, the current date as a string, an access_type of 'audit', a fixed ip_address of '127.0.0.1', the padded v_team_name as user_agent, an access_duration of 60, and a data_size of 1024.",
    "plsql": "CREATE OR REPLACE PROCEDURE manage_access_logs_by_duration(p_min_duration bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_access_cursor CURSOR FOR SELECT access_id, access_duration, data_size, team_id FROM access_logs WHERE access_duration >= p_min_duration;\n    v_access_record RECORD;\n    v_team_name text;\n    v_next_access_id bigint;\nBEGIN\n    FOR v_access_record IN v_access_cursor LOOP\n        IF v_access_record.access_duration > 300 AND v_access_record.data_size > 5000 THEN\n            DELETE FROM access_logs WHERE access_id = v_access_record.access_id;\n        ELSIF v_access_record.access_duration > 200 AND v_access_record.data_size > 3000 THEN\n            UPDATE access_logs SET access_type = 'premium' WHERE access_id = v_access_record.access_id;\n        ELSIF v_access_record.access_duration > 100 AND v_access_record.data_size > 2000 THEN\n            UPDATE access_logs SET access_type = 'standard' WHERE access_id = v_access_record.access_id;\n        ELSIF v_access_record.access_duration > 50 THEN\n            UPDATE access_logs SET access_type = 'basic' WHERE access_id = v_access_record.access_id;\n        ELSE\n            UPDATE access_logs SET access_type = 'minimal' WHERE access_id = v_access_record.access_id;\n        END IF;\n        \n        SELECT t.team_name INTO v_team_name FROM teams t WHERE t.team_id = v_access_record.team_id;\n        v_team_name := lpad(v_team_name, 25, '-');\n        \n        SELECT COALESCE(MAX(access_id), 0) + 1 INTO v_next_access_id FROM access_logs;\n        \n        INSERT INTO access_logs (access_id, user_id, game_id, team_id, access_date, access_type, ip_address, user_agent, access_duration, data_size)\n        VALUES (v_next_access_id, 1, 0, v_access_record.team_id, CURRENT_DATE::text, 'audit', '127.0.0.1', v_team_name, 60, 1024);\n    END LOOP;\nEND;\n$$;",
    "database_name": "sports_team_performance_and_analytics",
    "tables": [
      "teams",
      "games",
      "opponents",
      "ratings",
      "events",
      "access_logs"
    ],
    "call_sqls": [
      "CALL manage_access_logs_by_duration(50);",
      "CALL manage_access_logs_by_duration(150);",
      "CALL manage_access_logs_by_duration(250);",
      "CALL manage_access_logs_by_duration(350);",
      "CALL manage_access_logs_by_duration(10);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `manage_access_logs_by_duration` that processes access logs from the `access_logs` table where the `access_duration` meets or exceeds a provided minimum duration parameter. For each qualifying log, based on the `access_duration` and `data_size`, either delete the log if both values are very high, or update its `access_type` in `access_logs` to 'premium', 'standard', 'basic', or 'minimal' according to specific thresholds. Then, for each processed log, retrieve the associated team name from the `teams` table, pad it to 25 characters with hyphens, generate a new `access_id`, and insert a new audit record into the `access_logs` table with fixed values including the padded team name as the `user_agent`, 'audit' as the `access_type`, and the current date.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `manage_access_logs_by_duration` that takes a minimum duration parameter. For each access log in the `access_logs` table where the `access_duration` is at least the provided minimum, either delete the record or update its `access_type` based on specific thresholds of `access_duration` and `data_size`: delete if both are very high, otherwise set `access_type` to 'premium', 'standard', 'basic', or 'minimal' depending on progressively lower thresholds. Then, for each processed record, retrieve the corresponding `team_name` from the `teams` table, pad it to 25 characters with dashes, generate a new `access_id`, and insert a new audit entry into the `access_logs` table with fixed values including the padded team name as the `user_agent`.",
    "id": 33,
    "generated_ir": "Write a PL/pgSQL stored procedure named `manage_access_logs_by_duration` that accepts one input parameter: `p_min_duration` of type `bigint` representing the minimum access duration threshold. The procedure operates on the `access_logs` table within the `sports_team_performance_and_analytics` database. It processes each access log record where the `access_duration` is greater than or equal to the provided `p_min_duration`. For each such record, it performs conditional logic to either delete the original record or update its `access_type`, and then it inserts a new audit entry into the `access_logs` table.\n\nThe procedure begins by declaring several local variables: `log_rec` of type `RECORD` to hold each row from the `access_logs` table during iteration; `v_team_name` of type `text` to store the team name fetched from the `teams` table; `v_padded_team_name` of type `text` to hold the team name padded to 25 characters; `v_new_access_id` of type `bigint` to store a newly generated unique identifier for the audit entry; and `v_current_timestamp` of type `text` to store the current date in 'YYYY-MM-DD' format.\n\nThe core logic is encapsulated within a `FOR` loop. This loop iterates over a result set obtained by selecting all columns from the `access_logs` table where the `access_duration` column is greater than or equal to the input parameter `p_min_duration`. The records are processed in a deterministic order based on `access_id`.\n\nInside the loop, for each `log_rec` (access log record) retrieved:\n1.  A series of nested conditional `IF` statements are executed to determine the action for the current record:\n    *   **Condition for Deletion:** If `log_rec.access_duration` is greater than or equal to `120` AND `log_rec.data_size` is greater than or equal to `5000`, then the original record is deleted from the `access_logs` table where `access_id` equals `log_rec.access_id`. The procedure then proceeds to generate and insert an audit entry (step 4).\n    *   **Condition for Update to 'premium':** If the deletion condition is not met, and `log_rec.access_duration` is greater than or equal to `90` AND `log_rec.data_size` is greater than or equal to `3000`, then the `access_type` of the original record is updated to the string `'premium'` where `access_id` equals `log_rec.access_id`.\n    *   **Condition for Update to 'standard':** If the previous conditions are not met, and `log_rec.access_duration` is greater than or equal to `60` AND `log_rec.data_size` is greater than or equal to `1000`, then the `access_type` of the original record is updated to the string `'standard'` where `access_id` equals `log_rec.access_id`.\n    *   **Condition for Update to 'basic':** If the previous conditions are not met, and `log_rec.access_duration` is greater than or equal to `30` AND `log_rec.data_size` is greater than or equal to `500`, then the `access_type` of the original record is updated to the string `'basic'` where `access_id` equals `log_rec.access_id`.\n    *   **Else Condition for Update to 'minimal':** If none of the above conditions are met, the `access_type` of the original record is updated to the string `'minimal'` where `access_id` equals `log_rec.access_id`.\n\n2.  After the conditional update or delete operation, the procedure retrieves the `team_name` from the `teams` table. It performs a `SELECT` query on the `teams` table to get the `team_name` where the `team_id` matches `log_rec.team_id`. The result is stored in the local variable `v_team_name`.\n\n3.  The `v_team_name` is then padded to a length of 25 characters using the `RPAD` function. The padding character is a dash (`'-'`). The result is stored in `v_padded_team_name`.\n\n4.  A new unique `access_id` for the audit entry is generated by finding the maximum existing `access_id` in the `access_logs` table and adding `1` to it. This value is stored in `v_new_access_id`. The current date is obtained using the `CURRENT_DATE` function and cast to `text`, stored in `v_current_timestamp`.\n\n5.  Finally, a new record is inserted into the `access_logs` table as an audit entry. The inserted values are:\n    *   `access_id`: Set to `v_new_access_id`.\n    *   `user_id`: Set to `log_rec.user_id`.\n    *   `game_id`: Set to `log_rec.game_id`.\n    *   `team_id`: Set to `log_rec.team_id`.\n    *   `access_date`: Set to `v_current_timestamp`.\n    *   `access_type`: Set to the fixed string `'audit'`.\n    *   `ip_address`: Set to the fixed string `'0.0.0.0'`.\n    *   `user_agent`: Set to `v_padded_team_name`.\n    *   `access_duration`: Set to `log_rec.access_duration`.\n    *   `data_size`: Set to `log_rec.data_size`.\n\nAfter the audit entry is inserted, the loop continues to the next qualifying `access_logs` record. The procedure concludes once the loop finishes processing all records.",
    "original_summary": "Create a stored procedure named `manage_access_logs_by_duration` with a parameter `p_min_duration`. Use a cursor to select access logs where the duration meets or exceeds the parameter. For each record, conditionally delete or update the `access_type` based on duration and data size. Then, fetch the associated team name, pad it, and insert a new audit record into the `access_logs` table.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a stored procedure called `manage_access_logs_by_duration` that takes a parameter for a minimum duration. Use a cursor to go through some access logs where the duration is around or above that parameter value. For each of those records, decide whether to delete or update the `access_type` depending on how long the duration was and the general size of the data. Afterwards, get the related team name, add some padding to it, and put a new audit entry into the `access_logs` table."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named compare_methods_performance that accepts four input parameters: method1_param, method2_param, year_range_start_param, and year_range_end_param, all of type BIGINT. The procedure begins by declaring four local variables: method1_avg and method2_avg of type REAL, and method1_count and method2_count of type BIGINT. It then performs two SELECT operations on the data_points table. The first SELECT calculates the average value and count of rows where the method_id matches method1_param and the year is within the range specified by year_range_start_param and year_range_end_param, storing the results in method1_avg and method1_count. The second SELECT performs a similar operation for method2_param, storing the results in method2_avg and method2_count. The procedure then uses an IF-ELSIF-ELSE conditional structure to compare method1_avg and method2_avg. If method1_avg is greater than method2_avg, it inserts a new row into the methods table with method1_param as the method_id, 'better_performing' as the method_name, and a description indicating that Method 1 performed better, along with the current timestamp for created_at and updated_at, 'comparison' as the algorithm, a JSON string containing both averages as parameters, method1_avg as the accuracy, and the current timestamp as last_used_date. If method2_avg is greater, it performs a similar insertion for method2_param. If the averages are equal, it inserts a row for method1_param with 'equal_performing' as the method_name and a description indicating equal performance. Each INSERT operation uses an ON CONFLICT clause to update the existing row if a conflict occurs on method_id, setting the method_name, description, updated_at, algorithm, parameters, accuracy, and last_used_date to the values from the EXCLUDED pseudo-table.",
    "plsql": "CREATE OR REPLACE PROCEDURE compare_methods_performance(\n    IN method1_param BIGINT,\n    IN method2_param BIGINT,\n    IN year_range_start_param BIGINT,\n    IN year_range_end_param BIGINT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    method1_avg REAL;\n    method2_avg REAL;\n    method1_count BIGINT;\n    method2_count BIGINT;\nBEGIN\n    SELECT AVG(value), COUNT(*)\n    INTO method1_avg, method1_count\n    FROM data_points\n    WHERE method_id = compare_methods_performance.method1_param\n    AND year BETWEEN compare_methods_performance.year_range_start_param AND compare_methods_performance.year_range_end_param;\n    \n    SELECT AVG(value), COUNT(*)\n    INTO method2_avg, method2_count\n    FROM data_points\n    WHERE method_id = compare_methods_performance.method2_param\n    AND year BETWEEN compare_methods_performance.year_range_start_param AND compare_methods_performance.year_range_end_param;\n    \n    IF method1_avg > method2_avg THEN\n        INSERT INTO methods (method_id, method_name, description, created_at, updated_at, algorithm, parameters, accuracy, last_used_date)\n        VALUES (compare_methods_performance.method1_param, 'better_performing', \n                'Method 1 performed better with avg: ' || method1_avg,\n                CURRENT_TIMESTAMP::text, CURRENT_TIMESTAMP::text, 'comparison',\n                '{\"method1_avg\": ' || method1_avg || ', \"method2_avg\": ' || method2_avg || '}',\n                method1_avg, CURRENT_TIMESTAMP::text)\n        ON CONFLICT (method_id) DO UPDATE SET\n            method_name = EXCLUDED.method_name,\n            description = EXCLUDED.description,\n            updated_at = EXCLUDED.updated_at,\n            algorithm = EXCLUDED.algorithm,\n            parameters = EXCLUDED.parameters,\n            accuracy = EXCLUDED.accuracy,\n            last_used_date = EXCLUDED.last_used_date;\n    ELSIF method2_avg > method1_avg THEN\n        INSERT INTO methods (method_id, method_name, description, created_at, updated_at, algorithm, parameters, accuracy, last_used_date)\n        VALUES (compare_methods_performance.method2_param, 'better_performing', \n                'Method 2 performed better with avg: ' || method2_avg,\n                CURRENT_TIMESTAMP::text, CURRENT_TIMESTAMP::text, 'comparison',\n                '{\"method1_avg\": ' || method1_avg || ', \"method2_avg\": ' || method2_avg || '}',\n                method2_avg, CURRENT_TIMESTAMP::text)\n        ON CONFLICT (method_id) DO UPDATE SET\n            method_name = EXCLUDED.method_name,\n            description = EXCLUDED.description,\n            updated_at = EXCLUDED.updated_at,\n            algorithm = EXCLUDED.algorithm,\n            parameters = EXCLUDED.parameters,\n            accuracy = EXCLUDED.accuracy,\n            last_used_date = EXCLUDED.last_used_date;\n    ELSE\n        INSERT INTO methods (method_id, method_name, description, created_at, updated_at, algorithm, parameters, accuracy, last_used_date)\n        VALUES (compare_methods_performance.method1_param, 'equal_performing', \n                'Both methods performed equally with avg: ' || method1_avg,\n                CURRENT_TIMESTAMP::text, CURRENT_TIMESTAMP::text, 'comparison',\n                '{\"method1_avg\": ' || method1_avg || ', \"method2_avg\": ' || method2_avg || '}',\n                method1_avg, CURRENT_TIMESTAMP::text)\n        ON CONFLICT (method_id) DO UPDATE SET\n            method_name = EXCLUDED.method_name,\n            description = EXCLUDED.description,\n            updated_at = EXCLUDED.updated_at,\n            algorithm = EXCLUDED.algorithm,\n            parameters = EXCLUDED.parameters,\n            accuracy = EXCLUDED.accuracy,\n            last_used_date = EXCLUDED.last_used_date;\n    END IF;\nEND;\n$$;",
    "database_name": "marine_ecosystem_monitoring_and_analysis",
    "tables": [
      "data_points",
      "methods"
    ],
    "call_sqls": [
      "CALL compare_methods_performance(0, 1, 2000, 2005);",
      "CALL compare_methods_performance(1, 2, 2010, 2015);",
      "CALL compare_methods_performance(0, 2, 2005, 2010);",
      "CALL compare_methods_performance(3, 4, 2015, 2020);",
      "CALL compare_methods_performance(1, 3, 2000, 2020);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named compare_methods_performance that takes two method IDs and a start and end year as inputs. For each provided method ID, calculate the average value and the number of records from the data_points table where the year falls within the specified range. Compare the two calculated average values to determine which method performed better. Insert or update a record in the methods table for the method with the higher average, using a descriptive method_name and description, storing both averages as a JSON in the parameters column, setting the accuracy to the higher average, and recording current timestamps; if the averages are equal, perform this operation for the first method.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named `compare_methods_performance` that accepts two method identifiers and a year range, calculates the average value and total number of rows from the `data_points` table for each method within that year range, compares the two averages, and then inserts or updates a record in the `methods` table for the method with the higher averageor the first method if they are equalincluding a descriptive name, a JSON object with both averages, the higher average as the accuracy, and appropriate timestamps.",
    "id": 34,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named compare_methods_performance that accepts three parameters: p_method_id_1 of type bigint, p_method_id_2 of type bigint, and p_year_range of type text, which is expected to be a string representing a range, such as '2000-2005'. The procedure begins by declaring several variables: avg_value_1 of type real to store the average value for the first method, avg_value_2 of type real for the second method, total_rows_1 of type bigint for the total number of rows for the first method, total_rows_2 of type bigint for the second method, higher_method_id of type bigint to store the method identifier with the higher average value, higher_avg of type real to store the higher average value, current_timestamp_str of type text to capture the current timestamp, and method_name of type text to store a descriptive name for the method with the higher average.\n\nThe procedure first parses the p_year_range parameter to extract the start year and end year as integers. It then calculates the average value and total number of rows from the data_points table for p_method_id_1 within the specified year range by selecting the AVG of the value column and the COUNT of rows where the method_id column equals p_method_id_1 and the year column is between the extracted start year and end year, inclusive. These results are stored into avg_value_1 and total_rows_1, respectively. Similarly, it calculates the average value and total number of rows for p_method_id_2 under the same year conditions and stores them into avg_value_2 and total_rows_2.\n\nNext, the procedure compares avg_value_1 and avg_value_2. If avg_value_1 is greater than avg_value_2, it sets higher_method_id to p_method_id_1 and higher_avg to avg_value_1. If avg_value_2 is greater than avg_value_1, it sets higher_method_id to p_method_id_2 and higher_avg to avg_value_2. If the averages are equal, it sets higher_method_id to p_method_id_1 (the first method) and higher_avg to avg_value_1.\n\nThe procedure then constructs a descriptive method name by concatenating the string 'Comparison Winner ' with the higher_method_id and the year range, storing it in the method_name variable. It also constructs a JSON object containing both averages and total rows, formatted as a JSON string with keys 'method1_avg', 'method2_avg', 'method1_total_rows', and 'method2_total_rows', and their corresponding values. The current timestamp is captured and formatted as a text string for the created_at and updated_at fields.\n\nFinally, the procedure performs an upsert operation on the methods table. It attempts to insert a new record with the following values: higher_method_id for the method_id column, method_name for the method_name column, a description text that includes the comparison details, current_timestamp_str for both created_at and updated_at columns, a placeholder algorithm text such as 'comparison_based', the constructed JSON object for the parameters column, and higher_avg for the accuracy column. If a record with the same method_id already exists, the procedure updates the existing record with the new method_name, description, updated_at timestamp, algorithm, parameters, and accuracy values. The procedure does not return any value; it completes after the insert or update operation.",
    "original_summary": "Create a stored procedure named compare_methods_performance that takes two method IDs and a year range as BIGINT inputs. For each method, calculate the average value and row count from the data_points table within the year range. Compare the two averages. Insert or update a record in the methods table for the better-performing method (or the first method if equal) with a descriptive name, a JSON of the averages, the higher average as accuracy, and timestamps.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Develop a stored procedure, which should be named `compare_methods_performance`, that is designed to accept three distinct BIGINT input parameters: two specific method identifiers and a year range. For each of the provided method IDs, meticulously compute both the average value and the total number of rows sourced from the `data_points` table, strictly considering only those records that fall within the specified year range. Subsequently, perform a detailed comparison between the two calculated averages. Based on this comparison, you must then either insert a new record or update an existing one within the `methods` table specifically for the method that demonstrates superior performance; in the event that the averages are precisely equal, the first method should be selected. This record must include a richly descriptive name, a comprehensive JSON object encapsulating both averages, the higher average value recorded as the accuracy metric, and the appropriate creation and update timestamps."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named categorize_events_by_team_count that accepts one input parameter p_sport of type text, which is used to filter events by a specific sport. The procedure declares a cursor named v_event_cursor to select the event_id, event_name, number_of_teams, and event_organizer columns from the events table for all rows where the sport column matches the provided p_sport parameter. It then iterates through each record from this cursor using a FOR loop, storing each row in a record variable v_event_record. For each event, the procedure evaluates the number_of_teams value using a series of conditional IF-ELSIF-ELSE statements. If number_of_teams is greater than 20, it formats the event_organizer string by left-padding it to a total length of 40 characters using the LPAD function with the padding character 'L', stores this in variable v_formatted_organizer, and updates the events table for that specific event_id, setting the event_type column to 'Major Championship' and the event_organizer column to the padded v_formatted_organizer value. If number_of_teams is greater than 15 but not greater than 20, it left-pads the event_organizer to 35 characters with the character 'M', updates the events table for that event_id, setting event_type to 'Regional Tournament' and event_organizer to the new padded string. If number_of_teams is greater than 10 but not greater than 15, it left-pads the event_organizer to 30 characters with the character 'S', updates the events table for that event_id, setting event_type to 'Local Tournament' and event_organizer to the padded string. If number_of_teams is greater than 5 but not greater than 10, it deletes the entire row from the events table where the event_id matches the current v_event_record.event_id. For all other cases where number_of_teams is 5 or less, it performs an INSERT into the events table, generating a new event_id using the nextval function on the sequence events_event_id_seq, constructing a new event_name by prepending 'Archived_' to the original v_event_record.event_name, setting the event_date to the current date cast to text, setting location to 'Archive', sport to the input parameter p_sport, event_type to 'Archived', number_of_teams to the original v_event_record.number_of_teams, event_organizer to 'System', event_website to 'N/A', and event_description to 'Archived event'.",
    "plsql": "CREATE OR REPLACE PROCEDURE categorize_events_by_team_count(p_sport text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_event_cursor CURSOR FOR SELECT event_id, event_name, number_of_teams, event_organizer FROM events WHERE sport = p_sport;\n    v_event_record RECORD;\n    v_formatted_organizer text;\nBEGIN\n    FOR v_event_record IN v_event_cursor LOOP\n        IF v_event_record.number_of_teams > 20 THEN\n            v_formatted_organizer := lpad(v_event_record.event_organizer, 40, 'L');\n            UPDATE events SET event_type = 'Major Championship', event_organizer = v_formatted_organizer WHERE event_id = v_event_record.event_id;\n        ELSIF v_event_record.number_of_teams > 15 THEN\n            v_formatted_organizer := lpad(v_event_record.event_organizer, 35, 'M');\n            UPDATE events SET event_type = 'Regional Tournament', event_organizer = v_formatted_organizer WHERE event_id = v_event_record.event_id;\n        ELSIF v_event_record.number_of_teams > 10 THEN\n            v_formatted_organizer := lpad(v_event_record.event_organizer, 30, 'S');\n            UPDATE events SET event_type = 'Local Tournament', event_organizer = v_formatted_organizer WHERE event_id = v_event_record.event_id;\n        ELSIF v_event_record.number_of_teams > 5 THEN\n            DELETE FROM events WHERE event_id = v_event_record.event_id;\n        ELSE\n            INSERT INTO events (event_id, event_name, event_date, location, sport, event_type, number_of_teams, event_organizer, event_website, event_description)\n            VALUES (nextval('events_event_id_seq'), 'Archived_' || v_event_record.event_name, CURRENT_DATE::text, 'Archive', p_sport, 'Archived', v_event_record.number_of_teams, 'System', 'N/A', 'Archived event');\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "sports_team_performance_and_analytics",
    "tables": [
      "teams",
      "games",
      "opponents",
      "ratings",
      "events",
      "access_logs"
    ],
    "call_sqls": [
      "CALL categorize_events_by_team_count('Basketball');",
      "CALL categorize_events_by_team_count('Soccer');",
      "CALL categorize_events_by_team_count('Volleyball');",
      "CALL categorize_events_by_team_count('Tennis');",
      "CALL categorize_events_by_team_count('Football');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named categorize_events_by_team_count that accepts a sport name as input, processes each event in the EVENTS table for that sport, and categorizes it based on its number_of_teams: for events with more than 20 teams, update the event_type to 'Major Championship' and pad the event_organizer to 40 characters with 'L'; for more than 15 teams, update to 'Regional Tournament' and pad the organizer to 35 characters with 'M'; for more than 10 teams, update to 'Local Tournament' and pad the organizer to 30 characters with 'S'; for more than 5 teams, delete the event from EVENTS; otherwise, archive the event by inserting a new record into EVENTS with event_name prefixed by 'Archived_', event_type as 'Archived', location as 'Archive', event_organizer as 'System', event_website as 'N/A', and event_description as 'Archived event', while preserving other details.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called categorize_events_by_team_count that takes a sport name as input and processes each event in the events table for that sport based on its number_of_teams: if an event has more than 20 teams, update it to set event_type to 'Major Championship' and pad its event_organizer to 40 characters with 'L'; if it has more than 15 teams, update it to set event_type to 'Regional Tournament' and pad event_organizer to 35 characters with 'M'; if it has more than 10 teams, update it to set event_type to 'Local Tournament' and pad event_organizer to 30 characters with 'S'; if it has more than 5 teams, delete the event; otherwise, archive it by inserting a new record into events with 'Archived_' prefixed to the event_name, event_type as 'Archived', location as 'Archive', event_organizer as 'System', and other details set accordingly.",
    "id": 35,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named categorize_events_by_team_count that accepts one input parameter: a text parameter p_sport representing the name of a sport. The procedure processes each event in the events table where the sport column matches the p_sport parameter, categorizing them based on the value of the number_of_teams column. For each matching event, the procedure evaluates the number_of_teams value and performs specific actions accordingly.\n\nIf the number_of_teams is greater than 20, the procedure updates the events table for that event by setting the event_type column to the literal string 'Major Championship' and the event_organizer column to the result of padding the existing event_organizer value to a length of 40 characters by appending the character 'L' to the right until the desired length is reached.\n\nIf the number_of_teams is greater than 15 but less than or equal to 20, the procedure updates the events table for that event by setting the event_type column to the literal string 'Regional Tournament' and the event_organizer column to the result of padding the existing event_organizer value to a length of 35 characters by appending the character 'M' to the right until the desired length is reached.\n\nIf the number_of_teams is greater than 10 but less than or equal to 15, the procedure updates the events table for that event by setting the event_type column to the literal string 'Local Tournament' and the event_organizer column to the result of padding the existing event_organizer value to a length of 30 characters by appending the character 'S' to the right until the desired length is reached.\n\nIf the number_of_teams is greater than 5 but less than or equal to 10, the procedure deletes the event from the events table entirely.\n\nIf the number_of_teams is 5 or less, the procedure archives the event by inserting a new record into the events table with the following column values: event_name set to the concatenation of the literal string 'Archived_' and the original event_name value, event_type set to the literal string 'Archived', location set to the literal string 'Archive', event_organizer set to the literal string 'System', event_date set to the original event_date value, sport set to the original sport value, number_of_teams set to the original number_of_teams value, event_website set to the original event_website value, and event_description set to the original event_description value. After inserting this archived record, the procedure deletes the original event from the events table.\n\nThe procedure processes all events for the given sport in a single execution, applying the appropriate action based on the number_of_teams value for each event.",
    "original_summary": "Create a stored procedure named categorize_events_by_team_count that accepts a sport name as input. For each event in that sport, categorize it based on team count: update the event as a 'Major Championship', 'Regional Tournament', or 'Local Tournament' with a padded organizer name for high team counts; delete the event for medium counts; or archive it as a new 'Archived' record for low counts.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Alright, so we need a stored procedure, let's call it categorize_events_by_team_count. It's gonna take a sport name as its input. For every event under that sport, we gotta sort it based on how many teams are in it. Here's the deal: if there's a ton of teams, we'll update the event, tag it as something like a 'Major Championship', 'Regional Tournament', or 'Local Tournament', and also pad out the organizer's name. If the team count's just so-so, we're gonna delete that event altogether. And if there's only a few teams, we'll archive itbasically, make a new 'Archived' record for it. Got it?"
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named insert_regional_summaries that accepts three input parameters: p_min_population of type bigint, p_vaccination_status of type text, and p_severity_level of type text. The procedure begins by calculating a new update identifier by selecting the maximum value from the update_id column in the case_updates table, using the COALESCE function to default to 0 if the table is empty, and then incrementing this value by one, storing the result in the local variable v_next_update_id. It then enters a loop that iterates over each row returned from a query on the regions table, selecting the region_id, region_name, and population columns for every region where the population is greater than or equal to the provided p_min_population parameter, storing each row's data in the record variable v_region_record. For each region in this loop, the procedure executes a SELECT statement on the cases table to compute aggregated totals, using the COALESCE function to return 0 for any NULL sums, for the confirmed, recovered, deceased, and total columns, but only for cases where the region_id matches the current v_region_record.region_id, the vaccination_status column equals the input parameter p_vaccination_status, and the symptoms_severity column equals the input parameter p_severity_level; these four aggregated sums are stored in the record variable v_case_totals as sum_confirmed, sum_recovered, sum_deceased, and sum_total. The procedure then performs an INSERT operation into the case_updates table, providing values for the following columns: the update_id is set to the current v_next_update_id, the case_id is set to the current region's v_region_record.region_id, the update_date is set to the current date formatted as 'YYYY-MM-DD' using the TO_CHAR function with CURRENT_DATE, the confirmed, recovered, deceased, and total columns are populated from the corresponding v_case_totals fields, the age_group column is hardcoded to the string 'summary', the gender column is hardcoded to 'all', the vaccination_status and symptoms_severity columns are set to the input parameters p_vaccination_status and p_severity_level respectively, and the is_travel_related and is_cluster_related columns are both set to the integer 0. After each insert, the v_next_update_id variable is incremented by one before the loop proceeds to the next region.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_regional_summaries(p_min_population bigint, p_vaccination_status text, p_severity_level text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_region_record RECORD;\n    v_next_update_id bigint;\n    v_case_totals RECORD;\nBEGIN\n    SELECT COALESCE(MAX(update_id), 0) + 1 INTO v_next_update_id FROM case_updates;\n    \n    FOR v_region_record IN \n        SELECT region_id, region_name, population\n        FROM regions \n        WHERE population >= p_min_population\n    LOOP\n        SELECT COALESCE(SUM(confirmed), 0) as sum_confirmed,\n               COALESCE(SUM(recovered), 0) as sum_recovered,\n               COALESCE(SUM(deceased), 0) as sum_deceased,\n               COALESCE(SUM(total), 0) as sum_total\n        INTO v_case_totals\n        FROM cases \n        WHERE region_id = v_region_record.region_id \n          AND vaccination_status = p_vaccination_status\n          AND symptoms_severity = p_severity_level;\n        \n        INSERT INTO case_updates (\n            update_id, case_id, update_date, confirmed, recovered, deceased, total,\n            age_group, gender, vaccination_status, symptoms_severity,\n            is_travel_related, is_cluster_related\n        ) VALUES (\n            v_next_update_id,\n            v_region_record.region_id,\n            TO_CHAR(CURRENT_DATE, 'YYYY-MM-DD'),\n            v_case_totals.sum_confirmed,\n            v_case_totals.sum_recovered,\n            v_case_totals.sum_deceased,\n            v_case_totals.sum_total,\n            'summary',\n            'all',\n            p_vaccination_status,\n            p_severity_level,\n            0,\n            0\n        );\n        \n        v_next_update_id := v_next_update_id + 1;\n    END LOOP;\nEND;\n$$;",
    "database_name": "covid_19_case_tracking_and_statistics",
    "tables": [
      "cases",
      "case_updates",
      "case_fractions",
      "regions"
    ],
    "call_sqls": [
      "CALL insert_regional_summaries(1000000, 'fully vaccinated', 'mild');",
      "CALL insert_regional_summaries(500000, 'partially vaccinated', 'moderate');",
      "CALL insert_regional_summaries(2000000, 'fully vaccinated', 'severe');",
      "CALL insert_regional_summaries(100000, 'not vaccinated', 'mild');",
      "CALL insert_regional_summaries(3000000, 'partially vaccinated', 'mild');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named insert_regional_summaries that takes a minimum population, a vaccination status, and a severity level as input. For each region in the REGIONS table with a population greater than or equal to the provided minimum, calculate the total confirmed, recovered, deceased, and total cases from the CASES table where the vaccination status and symptoms severity match the input parameters. Insert a summary record into the CASE_UPDATES table for each qualifying region, using a new update ID generated by incrementing the maximum existing update ID from CASE_UPDATES, the region's ID, today's date, the calculated totals, 'summary' for age group, 'all' for gender, the input vaccination status and severity level, and setting both travel-related and cluster-related flags to 0. Increment the update ID for each subsequent region.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called 'insert_regional_summaries' that takes a minimum population, a vaccination status, and a severity level as input. It should generate a new update identifier by incrementing the highest existing ID from the 'case_updates' table. For each region in the 'regions' table with a population at or above the given minimum, calculate the total sums of confirmed, recovered, deceased, and total cases from the 'cases' table, filtered by the specified vaccination status and severity level. Then, insert a summary record into the 'case_updates' table for each such region, including the generated update ID, the region ID, the current date, the calculated sums, 'summary' for age group, 'all' for gender, the input parameters, and flags set to 0, incrementing the update ID after each insertion.",
    "id": 36,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named insert_regional_summaries that accepts three input parameters: p_min_population of type bigint to specify the minimum population threshold for regions, p_vaccination_status of type text to filter cases by vaccination status, and p_symptoms_severity of type text to filter cases by symptom severity level. The procedure declares a variable v_update_id of type bigint to hold the generated update identifier, and a record variable v_region_summary to store aggregated case data for each qualifying region.\n\nThe procedure begins by generating a new update identifier: it selects the maximum existing update_id from the case_updates table, adds 1 to it, and assigns this value to v_update_id. If the case_updates table is empty, the maximum update_id will be NULL, so the COALESCE function is used to default v_update_id to 1.\n\nNext, the procedure iterates over each region in the regions table where the population is greater than or equal to p_min_population. For each qualifying region, it calculates the total sums of confirmed, recovered, deceased, and total cases from the cases table, but only for cases that match the specified p_vaccination_status and p_symptoms_severity, and where the region_id matches the current region's region_id. These aggregated sums are stored in v_region_summary.\n\nFor each region that meets the population threshold, the procedure inserts a new record into the case_updates table with the following values: v_update_id as update_id, the current region's region_id as case_id, the current date (obtained via the CURRENT_DATE function cast to text) as update_date, the summed confirmed cases as confirmed, the summed recovered cases as recovered, the summed deceased cases as deceased, the summed total cases as total, the string 'summary' for age_group, the string 'all' for gender, the input parameter p_vaccination_status for vaccination_status, the input parameter p_symptoms_severity for symptoms_severity, 0 for is_travel_related, and 0 for is_cluster_related.\n\nAfter each insertion, the procedure increments v_update_id by 1 to ensure a unique identifier for the next summary record. This process repeats for all regions with sufficient population, resulting in multiple summary records inserted into the case_updates table, each representing aggregated case data for a specific region filtered by the given vaccination status and symptom severity.",
    "original_summary": "Create a stored procedure named insert_regional_summaries with parameters for minimum population, vaccination status, and severity level. Generate a new update ID by incrementing the maximum ID from the case_updates table. For each region with a population greater than or equal to the provided minimum, calculate the sum of confirmed, recovered, deceased, and total cases where vaccination status and severity level match the parameters. Insert a summary record into the case_updates table for each region with the generated update ID, region ID, current date, calculated sums, hardcoded 'summary' and 'all' for age and gender, the input parameters, and flags set to 0. Increment the update ID after each insert.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure entitled 'insert_regional_summaries' that accepts parameters for minimum population, vaccination status, and severity level. The procedure shall generate a new update identifier by incrementing the maximum existing ID from the 'case_updates' table. For every region whose population meets or exceeds the specified minimum, compute the aggregate sums of confirmed, recovered, deceased, and total cases, filtered by the provided vaccination status and severity level. Subsequently, for each such region, insert a summary record into the 'case_updates' table. This record shall include the generated update ID, the region ID, the current date, the calculated sums, the hardcoded values 'summary' for age and 'all' for gender, the input parameters, and flags initialized to 0. The update ID is to be incremented following each insertion."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named update_station_maintenance that accepts three input parameters: p_station_id of type bigint, which identifies a specific weather station; p_new_date of type text, which provides a new date value for the last maintenance; and p_frequency of type text, which provides a new value for the data collection frequency. The procedure first declares a local boolean variable v_station_exists. It then executes a SELECT query on the weather_stations table to check for the existence of a row where the station_id column matches the input parameter p_station_id, storing the result of the EXISTS condition into the variable v_station_exists. If the value of v_station_exists is true, indicating the station exists, the procedure performs an UPDATE operation on the weather_stations table, setting the last_maintenance_date column to the value of p_new_date and the data_collection_frequency column to the value of p_frequency, specifically for the row where the station_id column equals the input parameter p_station_id. If the v_station_exists condition evaluates to false, no update operation is performed.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_station_maintenance(p_station_id bigint, p_new_date text, p_frequency text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_station_exists boolean;\nBEGIN\n    SELECT EXISTS(SELECT 1 FROM weather_stations WHERE station_id = p_station_id) INTO v_station_exists;\n    \n    IF v_station_exists THEN\n        UPDATE weather_stations \n        SET last_maintenance_date = p_new_date,\n            data_collection_frequency = p_frequency\n        WHERE station_id = p_station_id;\n    END IF;\nEND;\n$$;",
    "database_name": "weather_data_collection_and_analysis_874430",
    "tables": [
      "data_requests",
      "roles",
      "user_roles",
      "users",
      "weather_data_versions",
      "weather_stations"
    ],
    "call_sqls": [
      "CALL update_station_maintenance(1, '2024-01-15', 'hourly');",
      "CALL update_station_maintenance(2, '2024-01-20', 'daily');",
      "CALL update_station_maintenance(3, '2024-02-01', 'weekly');",
      "CALL update_station_maintenance(0, '2024-02-10', 'monthly');",
      "CALL update_station_maintenance(1, '2024-02-15', 'hourly');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_station_maintenance that updates the maintenance details for a weather station, taking as input a station ID, a new maintenance date, and a new data collection frequency; it first checks if the station exists in the weather_stations table, and if it does, updates the last_maintenance_date and data_collection_frequency columns for that station.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `update_station_maintenance` that takes a station ID, a new maintenance date, and a new frequency as parameters, verifies if the station exists in the `weather_stations` table, and if it does, updates its `last_maintenance_date` and `data_collection_frequency` columns accordingly.",
    "id": 37,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named update_station_maintenance that accepts three input parameters: p_station_id of type bigint, p_new_maintenance_date of type text, and p_new_frequency of type text. The procedure's purpose is to update the maintenance information for a specific weather station, but only if that station exists in the database.\n\nThe procedure begins by declaring a local variable v_station_exists of type boolean, initialized to false.\n\nThe procedure then performs a SELECT EXISTS query on the weather_stations table to check for the existence of a row where the station_id column matches the value provided by the p_station_id input parameter. The result of this existence check is stored in the v_station_exists variable.\n\nNext, the procedure enters a conditional block. If the v_station_exists variable is true, meaning a station with the given p_station_id is found, the procedure executes an UPDATE operation on the weather_stations table. The update targets the row where the station_id column equals the p_station_id parameter. It sets the last_maintenance_date column to the value of the p_new_maintenance_date parameter and the data_collection_frequency column to the value of the p_new_frequency parameter. Additionally, the updated_at column is set to the current timestamp, obtained using the CURRENT_TIMESTAMP function.\n\nIf the v_station_exists variable is false, meaning no station with the given p_station_id is found in the weather_stations table, the conditional block is skipped, and no update is performed. The procedure is designed to handle non-existent station IDs gracefully without raising an error.",
    "original_summary": "Create a stored procedure named `update_station_maintenance` with parameters for station ID, a new maintenance date, and a new frequency. Check if the station exists. If it does, update its `last_maintenance_date` and `data_collection_frequency` columns.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure called `update_station_maintenance` that takes a station ID, a new maintenance date, and a new frequency as parameters, checks for the station's existence, and then updates its `last_maintenance_date` and `data_collection_frequency` columns if it is found?"
  },
  {
    "ir": "Write a PLpgSQL stored procedure named remove_old_access_logs that accepts two parameters: p_user_id of type bigint, which specifies the user identifier, and p_days_old of type bigint, which indicates the number of days to consider for log removal. The procedure performs a delete operation on the access_logs table, targeting rows where the user_id column matches the value of p_user_id and the access_date column is earlier than the current date minus the number of days specified by p_days_old. The calculation for determining the cutoff date involves subtracting an interval of '1 day' multiplied by p_days_old from the current date, and the result is cast to text to ensure proper comparison with the access_date column.",
    "plsql": "CREATE OR REPLACE PROCEDURE remove_old_access_logs(p_user_id bigint, p_days_old bigint)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM access_logs \n    WHERE user_id = p_user_id \n    AND access_date < (CURRENT_DATE - INTERVAL '1 day' * p_days_old)::text;\nEND;\n$$;",
    "database_name": "demographic_and_economic_data_for_us_counties_159057",
    "tables": [
      "access_logs",
      "counties",
      "data_validations",
      "users"
    ],
    "call_sqls": [
      "CALL remove_old_access_logs(0, 30);",
      "CALL remove_old_access_logs(1, 60);",
      "CALL remove_old_access_logs(0, 90);",
      "CALL remove_old_access_logs(1, 180);",
      "CALL remove_old_access_logs(0, 365);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named remove_old_access_logs that accepts a user ID and a number of days, and deletes records from the access_logs table for that specific user where the access_date is older than the current date minus the given number of days.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called remove_old_access_logs that takes a user's identification number and a count of days as parameters, and deletes all entries from the access_logs table for that user where the access_date timestamp is older than the current date minus the specified number of days.",
    "id": 38,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `remove_old_access_logs`. This procedure accepts two input parameters: `p_user_id` of type `BIGINT`, which represents the unique identifier of a user, and `p_days` of type `INTEGER`, which specifies the number of days to look back from the current date. The procedure does not declare any local variables. Its purpose is to delete historical access log entries for a specific user that are older than a calculated cutoff date. The procedure performs a single `DELETE` operation on the `access_logs` table. The deletion is conditional, targeting rows where two criteria are met: first, the `user_id` column in the `access_logs` table must exactly match the input parameter `p_user_id`; second, the `access_date` column, which is stored as `TEXT`, must be converted to a date type and compared to a calculated cutoff. The cutoff date is determined by subtracting the integer value of `p_days` from the current date (obtained using the `CURRENT_DATE` function). The condition checks if the converted `access_date` is less than this cutoff date (`access_date::DATE < CURRENT_DATE - p_days`), meaning the log entry is older than the specified number of days. The procedure does not return a value; it executes the deletion and then completes.",
    "original_summary": "Create a stored procedure named remove_old_access_logs that accepts a bigint user ID and a bigint number of days. It should delete records from the access_logs table for the specified user where the access_date is older than the current date minus the specified number of days.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Develop a stored procedure called remove_old_access_logs that takes a bigint parameter for a user's identification number and another bigint parameter representing a count of days. This procedure must meticulously delete all entries from the access_logs table which are associated with the provided user, specifically targeting those records where the timestamp in the access_date column is definitively older than the current date, precisely reduced by the specified number of days."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named generate_tournament_report that accepts four input parameters: p_event_name of type text for a partial event name pattern, p_round of type text for a specific match round, p_min_games of type bigint for a minimum number of games threshold, and p_weather of type text for specific weather conditions. The procedure begins by declaring a record variable v_match_record to hold rows from a cursor loop and a bigint variable v_new_stat_id to store a new identifier. It then opens a loop that iterates over a result set from a SELECT query joining the matches, match_results, and players tables. The query selects the match_id, winner_id, total_points, and total_games from the match_results table, the player_name from the players table, and the attendance from the matches table. The join condition links matches to match_results on match_id and match_results to players on winner_id equaling player_id. The WHERE clause filters the matches table rows where the event_name contains the p_event_name string (using a pattern match with LIKE and concatenated wildcards), the round column exactly equals p_round, the total_games from match_results is greater than or equal to p_min_games, and the weather_conditions column from matches exactly equals p_weather. For each row fetched into v_match_record, the procedure executes a SELECT statement to compute a new statistic identifier by taking the maximum existing stat_id value from the player_statistics table, using COALESCE to substitute 0 if the table is empty, and adding 1, storing the result in v_new_stat_id. It then performs an INSERT operation into the player_statistics table, specifying columns stat_id, match_id, player_id, duration_minutes, aces, double_faults, first_serve_hits, first_serve_total, first_serve_won, second_serve_won, return_points_won, return_points_total, break_points_faced, break_points_converted, net_points_won, net_points_total, unforced_errors, forced_errors, and winning_shots. The inserted values use v_new_stat_id for stat_id, v_match_record.match_id for match_id, v_match_record.winner_id for player_id, the value 0 for all statistical columns except return_points_total which is set to v_match_record.total_points and winning_shots which is set to v_match_record.total_games. The loop continues until all rows from the SELECT query are processed.",
    "plsql": "CREATE OR REPLACE PROCEDURE generate_tournament_report(p_event_name text, p_round text, p_min_games bigint, p_weather text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_match_record RECORD;\n    v_new_stat_id bigint;\nBEGIN\n    FOR v_match_record IN\n        SELECT m.match_id, mr.winner_id, mr.total_points, mr.total_games,\n               p.player_name, m.attendance\n        FROM matches m\n        JOIN match_results mr ON m.match_id = mr.match_id\n        JOIN players p ON mr.winner_id = p.player_id\n        WHERE m.event_name LIKE '%' || p_event_name || '%'\n          AND m.round = p_round\n          AND mr.total_games >= p_min_games\n          AND m.weather_conditions = p_weather\n    LOOP\n        SELECT COALESCE(MAX(stat_id), 0) + 1 INTO v_new_stat_id FROM player_statistics;\n        \n        INSERT INTO player_statistics (stat_id, match_id, player_id, duration_minutes, aces, double_faults, first_serve_hits, first_serve_total, first_serve_won, second_serve_won, return_points_won, return_points_total, break_points_faced, break_points_converted, net_points_won, net_points_total, unforced_errors, forced_errors, winning_shots)\n        VALUES (v_new_stat_id, v_match_record.match_id, v_match_record.winner_id, 0, 0, 0, 0, 0, 0, 0, 0, v_match_record.total_points, 0, 0, 0, 0, 0, 0, v_match_record.total_games);\n    END LOOP;\nEND;\n$$;",
    "database_name": "tennis_match_statistics_and_analytics",
    "tables": [
      "match_results",
      "matches",
      "player_statistics",
      "players",
      "service_statistics",
      "users"
    ],
    "call_sqls": [
      "CALL generate_tournament_report('Adelaide Australia ATP World T', 'R32', 20, 'Sunny');",
      "CALL generate_tournament_report('Adelaide Australia ATP World T', 'R32', 30, 'Sunny');",
      "CALL generate_tournament_report('Adelaide Australia ATP World T', 'R32', 25, 'Sunny');",
      "CALL generate_tournament_report('Adelaide Australia ATP World T', 'R32', 15, 'Sunny');",
      "CALL generate_tournament_report('Adelaide Australia ATP World T', 'R32', 10, 'Sunny');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named generate_tournament_report that takes an event name pattern, a match round, a minimum games threshold, and a weather condition, and for each match in the matches table that matches the event name pattern, has the specified round, has total games from match_results at least equal to the minimum threshold, and matches the given weather condition, generates a new stat ID and inserts a summary record into the player_statistics table with the match ID, winner ID, total points as return_points_total, and total games as winning_shots, setting all other statistical columns to zero.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called generate_tournament_report that takes a pattern for the event name, a match round, a minimum number of games, and a weather condition, and for each match in the matches table that matches the event name pattern, has the specified round, has at least the minimum number of games in match_results, and matches the weather condition, generates a new stat ID and inserts a summary into the player_statistics table including the match ID from matches, the winner's ID from match_results, the total points as return_points_total, and the total games as winning_shots, while setting all other stat columns to zero.",
    "id": 39,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named generate_tournament_report that accepts four input parameters: p_event_name of type text for a partial event name pattern, p_round of type text for a specific match round, p_min_games of type bigint for a minimum number of games threshold, and p_weather of type text for specific weather conditions. The procedure begins by declaring a record variable v_match_record to hold rows from a cursor loop and a bigint variable v_new_stat_id to store a new identifier. It then opens a loop that iterates over a result set from a SELECT query joining the matches, match_results, and players tables. The query selects the match_id, winner_id, total_points, and total_games from the match_results table, the player_name from the players table, and the attendance from the matches table. The join condition links matches to match_results on match_id and match_results to players on winner_id equaling player_id. The WHERE clause filters the matches table rows where the event_name contains the p_event_name string (using a pattern match with LIKE and concatenated wildcards), the round column exactly equals p_round, the total_games from match_results is greater than or equal to p_min_games, and the weather_conditions column from matches exactly equals p_weather. For each row fetched into v_match_record, the procedure executes a SELECT statement to compute a new statistic identifier by taking the maximum existing stat_id value from the player_statistics table, using COALESCE to substitute 0 if the table is empty, and adding 1, storing the result in v_new_stat_id. It then performs an INSERT operation into the player_statistics table, specifying columns stat_id, match_id, player_id, duration_minutes, aces, double_faults, first_serve_hits, first_serve_total, first_serve_won, second_serve_won, return_points_won, return_points_total, break_points_faced, break_points_converted, net_points_won, net_points_total, unforced_errors, forced_errors, and winning_shots. The inserted values use v_new_stat_id for stat_id, v_match_record.match_id for match_id, v_match_record.winner_id for player_id, the value 0 for all statistical columns except return_points_total which is set to v_match_record.total_points and winning_shots which is set to v_match_record.total_games. The loop continues until all rows from the SELECT query are processed.",
    "original_summary": "Create a stored procedure named generate_tournament_report that takes an event name pattern, a match round, a minimum games threshold, and a weather condition. For each match that meets these criteria, generate a new stat ID and insert a summary record into player_statistics with the match ID, winner ID, total points as return_points_total, and total games as winning_shots. Set all other statistical columns to zero.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called generate_tournament_report? It needs to take in a pattern for the event name, a match round, a minimum number of games, and a weather condition. For every match that fits the bill, we gotta make a new stat ID and pop a summary into the player_statistics table. That summary should include the match ID, the winner's ID, the total points as return_points_total, and the total games as winning_shots. Just zero out all the other stat columns."
  },
  {
    "ir": "Write a PLpgSQL stored procedure that takes a single parameter p_taxon_id of type BIGINT, which represents the identifier of a taxon. The procedure begins by declaring three local variables: recent_publication_date and previous_publication_date, both of type TEXT, to store the most recent and the previous publication dates for the specified taxon, and trend, also of type TEXT, to store the trend of publication dates. The procedure first executes a SELECT statement to retrieve the maximum publication_date from the publications table where the taxon_id matches the provided p_taxon_id, storing the result in recent_publication_date. It then performs another SELECT statement to obtain the maximum publication_date from the same table, with the additional condition that publication_date must be less than the value stored in recent_publication_date, storing this result in previous_publication_date. The procedure then evaluates the relationship between recent_publication_date and previous_publication_date using an IF-ELSIF-ELSE conditional structure. If recent_publication_date is greater than previous_publication_date, it assigns the value 'upward' to the trend variable. If recent_publication_date is less than previous_publication_date, it assigns 'downward' to trend. If neither condition is met, it assigns 'stable' to trend. Finally, the procedure updates the taxons table by appending the string ' [Trend: ' followed by the value of trend and a closing bracket to the description column for the row where taxon_id matches the provided p_taxon_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_publication_trend(p_taxon_id BIGINT)\nAS $$\nDECLARE\n    recent_publication_date TEXT;\n    previous_publication_date TEXT;\n    trend TEXT;\nBEGIN\n    SELECT MAX(publication_date) INTO recent_publication_date\n    FROM publications\n    WHERE taxon_id = p_taxon_id;\n    \n    SELECT MAX(publication_date) INTO previous_publication_date\n    FROM publications\n    WHERE taxon_id = p_taxon_id AND publication_date < recent_publication_date;\n    \n    IF recent_publication_date > previous_publication_date THEN\n        trend := 'upward';\n    ELSIF recent_publication_date < previous_publication_date THEN\n        trend := 'downward';\n    ELSE\n        trend := 'stable';\n    END IF;\n    \n    UPDATE taxons \n    SET description = description || ' [Trend: ' || trend || ']'\n    WHERE taxon_id = p_taxon_id;\nEND;\n$$ LANGUAGE plpgsql;",
    "database_name": "genomic_data_management_and_analysis_867750",
    "tables": [
      "taxons",
      "citations",
      "publications"
    ],
    "call_sqls": [
      "CALL update_publication_trend(0);",
      "CALL update_publication_trend(1);",
      "CALL update_publication_trend(100);",
      "CALL update_publication_trend(NULL);",
      "CALL update_publication_trend(99999);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_publication_trend that accepts a taxon_id parameter. For the given taxon_id, retrieve the most recent and the previous publication dates from the publications table. Determine a trend based on these dates: 'upward' if the recent date is later than the previous date, 'downward' if it is earlier, otherwise 'stable'. Then, update the description in the taxons table for that taxon_id by appending the trend in the format ' [Trend: <trend>]'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called update_publication_trend that takes a taxon_id as input, retrieves the two most recent publication dates for that taxon from the publications table, determines whether the trend is 'upward' if the most recent date is later than the previous one, 'downward' if it is earlier, or 'stable' if they are the same, and then updates the taxon's description in the taxons table by appending this trend.",
    "id": 40,
    "generated_ir": "Write a PLpgSQL stored procedure that takes a single parameter p_taxon_id of type BIGINT, which represents the identifier of a taxon. The procedure begins by declaring three local variables: recent_publication_date and previous_publication_date, both of type TEXT, to store the most recent and the previous publication dates for the specified taxon, and trend, also of type TEXT, to store the trend of publication dates. The procedure first executes a SELECT statement to retrieve the maximum publication_date from the publications table where the taxon_id matches the provided p_taxon_id, storing the result in recent_publication_date. It then performs another SELECT statement to obtain the maximum publication_date from the same table, with the additional condition that publication_date must be less than the value stored in recent_publication_date, storing this result in previous_publication_date. The procedure then evaluates the relationship between recent_publication_date and previous_publication_date using an IF-ELSIF-ELSE conditional structure. If recent_publication_date is greater than previous_publication_date, it assigns the value 'upward' to the trend variable. If recent_publication_date is less than previous_publication_date, it assigns 'downward' to trend. If neither condition is met, it assigns 'stable' to trend. Finally, the procedure updates the taxons table by appending the string ' [Trend: ' followed by the value of trend and a closing bracket to the description column for the row where taxon_id matches the provided p_taxon_id.",
    "original_summary": "Create a PL/pgSQL stored procedure that accepts a taxon_id (BIGINT) parameter. Find the most recent and the previous publication dates for the taxon. Determine a trend: 'upward' if recent date > previous date, 'downward' if recent date < previous date, else 'stable'. Update the taxon's description by appending this trend.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Construct a comprehensive PL/pgSQL stored procedure that takes a single input parameter, specifically a taxon_id of type BIGINT. This procedure should meticulously locate the two most recent publication dates associated with the given taxon, clearly identifying the most recent one and the one immediately preceding it. Subsequently, it must perform a detailed analysis to ascertain a trend: meticulously classifying it as an 'upward' trend if the most recent publication date is demonstrably later than the previous one, a 'downward' trend if it is conclusively earlier, or a 'stable' trend if the two dates are identical. Finally, the procedure must persistently update the taxon's existing description by thoughtfully appending a textual representation of this calculated trend."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named generate_rental_summary_report that accepts three parameters: p_report_date of type text, p_station_filter of type bigint, and p_payment_method of type text. The procedure begins by declaring three local variables: v_total_rentals of type bigint, v_total_revenue of type numeric, and v_method_ascii of type integer. It then executes a SELECT statement to count the total number of rentals and sum the payment amounts from the rentals table, joining it with the bikes table on the bike_id column. The SELECT statement filters records where the rental_date in the rentals table starts with the value of p_report_date, the start_station_id matches p_station_filter unless p_station_filter is zero, and the payment_method matches p_payment_method. The results are stored in v_total_rentals and v_total_revenue. Next, the procedure calculates the ASCII value of the p_payment_method string using the ascii function and stores it in v_method_ascii. The procedure then performs an INSERT operation into the rentals table, creating a new row with the rental_id set to one more than the current maximum rental_id or zero if no rentals exist, bike_id and user_id both set to 1, rental_date and return_date set to p_report_date, start_station_id and end_station_id set to p_station_filter, payment_amount set to the text representation of v_total_revenue, and payment_method set to p_payment_method.",
    "plsql": "CREATE OR REPLACE PROCEDURE generate_rental_summary_report(\n    p_report_date text,\n    p_station_filter bigint,\n    p_payment_method text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_total_rentals bigint;\n    v_total_revenue numeric;\n    v_method_ascii integer;\nBEGIN\n    SELECT COUNT(*), SUM(CAST(payment_amount AS numeric)) INTO v_total_rentals, v_total_revenue\n    FROM rentals r\n    JOIN bikes b ON r.bike_id = b.bike_id\n    WHERE r.rental_date LIKE p_report_date || '%'\n    AND (p_station_filter = 0 OR r.start_station_id = p_station_filter)\n    AND r.payment_method = p_payment_method;\n    \n    SELECT ascii(p_payment_method) INTO v_method_ascii;\n    \n    INSERT INTO rentals (rental_id, bike_id, user_id, rental_date, return_date, start_station_id, end_station_id, payment_amount, payment_method)\n    SELECT COALESCE(MAX(rental_id), 0) + 1, 1, 1, p_report_date, p_report_date, p_station_filter, p_station_filter, CAST(v_total_revenue AS text), p_payment_method\n    FROM rentals;\nEND;\n$$;",
    "database_name": "bike_sharing_service_and_user_trip_data_management",
    "tables": [
      "bikes",
      "rentals",
      "stations",
      "trips",
      "users"
    ],
    "call_sqls": [
      "CALL generate_rental_summary_report('2013-08-29', 1, 'Credit Card');",
      "CALL generate_rental_summary_report('2013-08-29', 0, 'PayPal');",
      "CALL generate_rental_summary_report('2023-01-01', 1, 'Credit Card');",
      "CALL generate_rental_summary_report('2023-07-15', 0, 'PayPal');",
      "CALL generate_rental_summary_report('2023-08-01', 1, 'Credit Card');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `generate_rental_summary_report` that, given a report date, a station ID filter, and a payment method, calculates the total number of rentals and total revenue from the `rentals` and `bikes` tables for rentals matching the specified date, payment method, and station (if the station filter is not zero). It then computes the ASCII value of the payment method and inserts a new summary record into the `rentals` table with a new rental ID, the calculated totals, and the provided parameters.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `generate_rental_summary_report` that, given a report date, a station ID filter (where zero means no filter), and a payment method, calculates the total number of rentals and total revenue from the `rentals` and `bikes` tables matching those criteria, determines the ASCII code of the payment method, and inserts a new summary record into the `rentals` table with a new rental ID, the calculated totals, and the input parameters.",
    "id": 41,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named generate_rental_summary_report that takes three parameters: p_report_date of type text representing the date for which the report is generated, p_station_id_filter of type bigint representing a station ID to filter by (where a value of 0 indicates no filtering), and p_payment_method of type text representing the payment method to filter by. The procedure begins by declaring several local variables: v_total_rentals of type bigint to store the total number of rentals, v_total_revenue of type numeric to store the total revenue, v_ascii_code of type integer to store the ASCII code of the payment method, v_new_rental_id of type bigint to store a new rental ID for the summary record, and v_bike_id of type bigint to store a bike ID for the summary record. The procedure first calculates the ASCII code of the p_payment_method parameter using the ASCII function and stores it in v_ascii_code. Next, it queries the rentals table to compute the total number of rentals and total revenue. The query joins the rentals table with the bikes table on bike_id to access bike information. It filters the rentals where the rental_date matches the p_report_date (using a date comparison by casting rental_date to date) and the payment_method matches p_payment_method. If p_station_id_filter is not zero, it adds an additional filter to include only rentals where the bike's station_id (from the bikes table) equals p_station_id_filter. The query aggregates the results to count the number of rentals as v_total_rentals and sum the payment_amount (cast to numeric) as v_total_revenue. The procedure then generates a new rental ID by selecting the maximum rental_id from the rentals table, using COALESCE to handle cases where no rentals exist (returning 0), and adding 1 to this value, storing it in v_new_rental_id. It also selects a bike_id from the bikes table where availability is 1, ordering by bike_id in ascending order and limiting to 1, storing the result in v_bike_id; if no such bike is found, it sets v_bike_id to NULL. Finally, the procedure inserts a new record into the rentals table with the following values: rental_id set to v_new_rental_id, bike_id set to v_bike_id, user_id set to 0 (as a placeholder since no specific user is associated with the summary), rental_date set to p_report_date, return_date set to p_report_date (since it's a summary record with no actual return), start_station_id set to p_station_id_filter (or NULL if p_station_id_filter is 0), end_station_id set to p_station_id_filter (or NULL if p_station_id_filter is 0), payment_amount set to v_total_revenue (cast to text), and payment_method set to p_payment_method. The procedure does not return a value; it performs the insertion as its output.",
    "original_summary": "Create a stored procedure named `generate_rental_summary_report` that takes a report date, a station ID filter, and a payment method as input. It calculates the total number of rentals and total revenue for rentals matching the date, station (if not zero), and payment method from the `rentals` and `bikes` tables. It then calculates the ASCII value of the payment method and inserts a new summary record into the `rentals` table with a new rental ID, the calculated totals, and the provided parameters.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called `generate_rental_summary_report`? It needs to take in a date for the report, a station ID to filter by (or skip if it's zero), and how the customer paid. Basically, it's gotta figure out the total number of rentals and all the money made from rentals that match that date, the station (if we gave one), and the payment type, pulling from the `rentals` and `bikes` tables. Then, it should get the ASCII code for that payment method. Finally, it slaps a new summary record into the `rentals` table with a fresh rental ID, the totals we just worked out, and the original stuff we put in."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named insert_employment_category that inserts a new record into the employment_categories table using the provided parameters. The procedure accepts five parameters: p_employment_category_id of type bigint, which specifies the unique identifier for the employment category; p_category_name of type text with a default value of 'Tech Industry', which represents the name of the employment category; p_description of type text with a default value of 'Employment in technology sector', which provides a textual description of the employment category; p_percentage_of_population of type real with a default value of 0.15, indicating the percentage of the population associated with this employment category; and p_year of type bigint with a default value of 2023, denoting the year for which the employment category data is relevant. The procedure performs an INSERT operation into the employment_categories table, populating the columns employment_category_id, category_name, description, percentage_of_population, and year with the values provided by the respective parameters. The procedure does not include any conditional logic or function calls, and it directly inserts the data into the table without any additional processing or checks.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_employment_category(\n    p_employment_category_id bigint,\n    p_category_name text DEFAULT 'Tech Industry',\n    p_description text DEFAULT 'Employment in technology sector',\n    p_percentage_of_population real DEFAULT 0.15,\n    p_year bigint DEFAULT 2023\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    INSERT INTO employment_categories (employment_category_id, category_name, description, percentage_of_population, year)\n    VALUES (p_employment_category_id, p_category_name, p_description, p_percentage_of_population, p_year);\nEND;\n$$;",
    "database_name": "demographic_and_socioeconomic_data_analysis_462657",
    "tables": [
      "census_data",
      "employment_data",
      "employment_categories",
      "income_data",
      "income_categories"
    ],
    "call_sqls": [
      "CALL insert_employment_category(1, 'Healthcare', 'Employment in healthcare sector', 0.10, 2023);",
      "CALL insert_employment_category(2, 'Education', 'Employment in education sector', 0.08);",
      "CALL insert_employment_category(3, 'Retail', 'Employment in retail sector');",
      "CALL insert_employment_category(4, 'Manufacturing');",
      "CALL insert_employment_category(5);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named insert_employment_category that adds a new record to the employment_categories table, taking an ID, a category name (defaulting to 'Tech Industry'), a description (defaulting to 'Employment in technology sector'), a population percentage (defaulting to 0.15), and a year (defaulting to 2023).",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `insert_employment_category` that adds a new entry into the `employment_categories` table using provided inputs for the ID, category name, description, approximate workforce share, and an optional year.",
    "id": 42,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `insert_employment_category` that accepts five input parameters: `p_employment_category_id` of type `BIGINT`, `p_category_name` of type `TEXT`, `p_description` of type `TEXT`, `p_percentage_of_population` of type `REAL`, and `p_year` of type `BIGINT`. The `p_year` parameter is optional and defaults to `NULL`. The purpose of this procedure is to insert a new record into the `employment_categories` table using the provided parameter values.\n\nThe procedure does not declare any local variables. It directly performs a single `INSERT` operation into the `employment_categories` table. The `INSERT` statement specifies the target columns: `employment_category_id`, `category_name`, `description`, `percentage_of_population`, and `year`. The values for these columns are supplied directly from the corresponding input parameters: `p_employment_category_id`, `p_category_name`, `p_description`, `p_percentage_of_population`, and `p_year`.\n\nThe procedure executes this `INSERT` statement and then completes. It does not return any value.",
    "original_summary": "Create a stored procedure named `insert_employment_category` that takes parameters for ID, category name, description, population percentage, and year (with defaults). It inserts a record with these values into the `employment_categories` table.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Make a stored procedure called `insert_employment_category` that uses inputs for the ID, what to call the category, some details about it, a rough share of the workforce it covers, and a year if you have one. It should add a new entry with this info into the `employment_categories` table."
  },
  {
    "ir": "Write a PostgreSQL stored procedure named migrate_user_sessions that accepts five parameters: p_old_server_id of type bigint, p_new_server_id of type bigint, p_threshold_ts of type text, p_user_pattern of type text, and p_session_prefix of type text. The procedure begins by declaring two local variables: v_count of type bigint and v_server_name of type text. It first queries the server_info table to select the server_name column where the server_id column equals the input parameter p_new_server_id, storing the result into the variable v_server_name. If v_server_name is not null, the procedure performs an insert operation into the user_server_sync table, selecting columns sync_id, user_id, server_id, and sync_ts. The sync_id value is generated by applying the ROW_NUMBER window function over the result set and adding its sequential number to the current maximum sync_id value from the user_server_sync table, using COALESCE to handle null by starting from zero. The data for this insert is sourced from the user_activity table, specifically selecting the user_id and last_active_ts columns for rows where the user_id contains the p_user_pattern string (using the pattern '%' concatenated with p_user_pattern concatenated with '%'), the session_id column starts with the p_session_prefix string (using the pattern p_session_prefix concatenated with '%'), and the last_active_ts column is greater than the p_threshold_ts parameter. Additionally, a subquery condition ensures the row is only selected if no corresponding entry already exists in the user_server_sync table for the same user_id and the new server_id p_new_server_id. If the initial query returns a null v_server_name, the procedure instead executes a delete operation on the user_server_sync table, removing rows where the server_id column equals the input parameter p_old_server_id and the sync_ts column is less than the p_threshold_ts parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE migrate_user_sessions(p_old_server_id bigint, p_new_server_id bigint, p_threshold_ts text, p_user_pattern text, p_session_prefix text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_count bigint;\n    v_server_name text;\nBEGIN\n    SELECT server_name INTO v_server_name \n    FROM server_info \n    WHERE server_id = p_new_server_id;\n    \n    IF v_server_name IS NOT NULL THEN\n        INSERT INTO user_server_sync (sync_id, user_id, server_id, sync_ts)\n        SELECT \n            ROW_NUMBER() OVER() + COALESCE((SELECT MAX(sync_id) FROM user_server_sync), 0),\n            ua.user_id,\n            p_new_server_id,\n            ua.last_active_ts\n        FROM user_activity ua\n        WHERE ua.user_id LIKE '%' || p_user_pattern || '%'\n        AND ua.session_id LIKE p_session_prefix || '%'\n        AND ua.last_active_ts > p_threshold_ts\n        AND NOT EXISTS (\n            SELECT 1 FROM user_server_sync uss2 \n            WHERE uss2.user_id = ua.user_id \n            AND uss2.server_id = p_new_server_id\n        );\n    ELSE\n        DELETE FROM user_server_sync \n        WHERE server_id = p_old_server_id \n        AND sync_ts < p_threshold_ts;\n    END IF;\nEND;\n$$;",
    "database_name": "user_activity_and_status_tracking",
    "tables": [
      "user_activity",
      "user_server_sync",
      "server_info"
    ],
    "call_sqls": [
      "CALL migrate_user_sessions(1, 2, '1570040270000', 'spyglass', 'session');",
      "CALL migrate_user_sessions(0, 1, '1570040280000', 'anon', 'sess');",
      "CALL migrate_user_sessions(2, 3, '1570040300000', 'user', 'id_');",
      "CALL migrate_user_sessions(1, 0, '1570040250000', 'test', 'prefix');",
      "CALL migrate_user_sessions(3, 4, '1570040200000', 'john', 'web_session');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `migrate_user_sessions` that, given an old server ID, a new server ID, a threshold timestamp, a user ID pattern, and a session ID prefix, either inserts new synchronization records or deletes old ones. If the new server ID exists in the `server_info` table, insert into `user_server_sync` for users from `user_activity` where the user ID contains the pattern, session ID starts with the prefix, last active timestamp is after the threshold, and no existing sync exists for the new server. If the new server ID is not found, delete from `user_server_sync` where the server ID matches the old server and sync timestamp is before the threshold.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `migrate_user_sessions` that transfers user session data based on server availability. If the new server identifier corresponds to a valid server name in the `server_info` table, insert new synchronization records into the `user_server_sync` table for users from the `user_activity` table where the user identifier contains a specified pattern, the session identifier starts with a given prefix, the last active timestamp is after a provided threshold, and no existing synchronization entry for the new server exists for that user. If the server name is not found, delete old synchronization records from the `user_server_sync` table where the server identifier matches a specified old server and the synchronization timestamp is before the threshold.",
    "id": 43,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_user_sessions that accepts five input parameters: a bigint parameter p_new_server_id representing the identifier of the new server, a text parameter p_server_name representing the name of the new server to validate, a text parameter p_user_pattern representing a substring pattern to match within user identifiers, a text parameter p_session_prefix representing a prefix that session identifiers must start with, and a text parameter p_timestamp_threshold representing a cutoff timestamp in text format. The procedure operates on the user_activity_and_status_tracking database.\n\nThe procedure begins by declaring a local variable v_server_exists of type boolean to store the result of a validation check.\n\nFirst, the procedure performs a SELECT operation with an EXISTS subquery to check if there is at least one row in the server_info table where the server_name column exactly matches the p_server_name input parameter. The result of this check, a boolean value, is assigned to the v_server_exists variable.\n\nNext, the procedure executes a conditional block based on the value of v_server_exists.\n\nIf v_server_exists is true, indicating the new server name is valid, the procedure performs an INSERT operation into the user_server_sync table. The data for this insert is selected from the user_activity table. The SELECT statement for the insert includes the following conditions: the user_id column must contain the p_user_pattern substring (using a LIKE operator with '%' wildcards), the session_id column must start with the p_session_prefix string (using a LIKE operator with the prefix followed by a '%' wildcard), the last_active_ts column value must be greater than the p_timestamp_threshold parameter value (compared as text strings), and there must not exist a corresponding row in the user_server_sync table for the same user_id and the specified p_new_server_id (using a NOT EXISTS subquery). The INSERT statement will populate the user_server_sync columns as follows: a new unique value for sync_id must be generated (the description implies the need for a sequence or method to generate a unique bigint, though not explicitly stated, it is a requirement for the primary key), the user_id is taken directly from the user_activity table, the server_id is set to the p_new_server_id input parameter, and the sync_ts is set to the current system timestamp converted to a text string representing milliseconds since the epoch (the description implies using the current time for the new sync record, though the exact method is not specified, it is a logical requirement).\n\nIf v_server_exists is false, indicating the server name is invalid, the procedure performs a DELETE operation on the user_server_sync table. The DELETE targets rows where the server_id column matches the p_new_server_id input parameter (this parameter is interpreted as representing the 'old' server identifier in this branch) and where the sync_ts column value is less than the p_timestamp_threshold parameter value (compared as text strings).\n\nThe procedure does not return a value; it is a void procedure that performs data migration or cleanup based on server validation.",
    "original_summary": "Create a stored procedure named `migrate_user_sessions` to transfer or clean up user session data. First, get the server name for a new server ID. If found, insert new sync records into `user_server_sync` for users from `user_activity` where the user ID contains a pattern, session ID starts with a prefix, last active timestamp is after a threshold, and no existing sync exists for the new server. If the server name is not found, delete old sync records where the server ID matches an old server and sync timestamp is before the threshold.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as `migrate_user_sessions` for the purpose of transferring or purging user session data. The procedure should initially retrieve the server name corresponding to a specified new server identifier. Should this server name be located, the procedure must then insert new synchronization records into the `user_server_sync` table. These records are to be generated for users derived from the `user_activity` table, subject to the following conditions: the user identifier must contain a specified pattern, the session identifier must commence with a defined prefix, the last active timestamp must be subsequent to a provided threshold, and no pre-existing synchronization entry for the new server may exist for the respective user. Conversely, if the server name is not found, the procedure should proceed to delete obsolete synchronization records from the `user_server_sync` table where the server identifier matches a specified old server and the synchronization timestamp predates the established threshold."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named analyze_spatial_distribution that accepts four parameters: p_min_latitude, p_max_latitude, p_min_longitude, and p_max_longitude, all of type REAL, which define a geographical bounding box. The procedure begins by declaring three integer variables, v_region_count, v_neighborhood_count, and v_incident_count, and a text variable v_total_severity. It first performs a SELECT operation to count distinct region_id values from the regions table where the latitude and longitude fall within the specified bounds, storing the result in v_region_count. Next, it counts distinct neighborhood_id values from the neighborhoods table, joining with the regions table on region_id, again constrained by the latitude and longitude bounds, and stores the result in v_neighborhood_count. Then, it counts all rows from the crime_incidents table, joining with the crimes table on crime_id and the regions table on region_id, within the same geographical constraints, storing the count in v_incident_count and aggregating distinct severity_level values from the crimes table into v_total_severity using STRING_AGG. The procedure proceeds to delete rows from the crime_subcategories table where subcategory_id matches those in a subquery selecting subcategory_id from crime_subcategories joined with crimes on crime_id, where severity_level is 'Low' and description contains the word 'obsolete'. Finally, it inserts a new row into the regions table with a calculated region_id as the maximum existing region_id plus one, a region_name of 'Analysis Region', a description summarizing the counts of regions, neighborhoods, and incidents, and latitude and longitude set to the average of the provided bounds, along with fixed values for city, state, and country as 'Analyzed', 'Spatial', and 'Data', respectively.",
    "plsql": "CREATE OR REPLACE PROCEDURE analyze_spatial_distribution(\n    p_min_latitude REAL,\n    p_max_latitude REAL,\n    p_min_longitude REAL,\n    p_max_longitude REAL\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_region_count INT;\n    v_neighborhood_count INT;\n    v_incident_count INT;\n    v_total_severity TEXT;\nBEGIN\n    SELECT COUNT(DISTINCT r.region_id) INTO v_region_count\n    FROM regions r\n    WHERE r.latitude BETWEEN p_min_latitude AND p_max_latitude\n    AND r.longitude BETWEEN p_min_longitude AND p_max_longitude;\n\n    SELECT COUNT(DISTINCT n.neighborhood_id) INTO v_neighborhood_count\n    FROM neighborhoods n\n    JOIN regions r ON n.region_id = r.region_id\n    WHERE r.latitude BETWEEN p_min_latitude AND p_max_latitude\n    AND r.longitude BETWEEN p_min_longitude AND p_max_longitude;\n\n    SELECT COUNT(*), STRING_AGG(DISTINCT c.severity_level, ', ') INTO v_incident_count, v_total_severity\n    FROM crime_incidents ci\n    JOIN crimes c ON ci.crime_id = c.crime_id\n    JOIN regions r ON ci.region_id = r.region_id\n    WHERE r.latitude BETWEEN p_min_latitude AND p_max_latitude\n    AND r.longitude BETWEEN p_min_longitude AND p_max_longitude;\n\n    DELETE FROM crime_subcategories\n    WHERE subcategory_id IN (\n        SELECT cs.subcategory_id\n        FROM crime_subcategories cs\n        JOIN crimes c ON cs.crime_id = c.crime_id\n        WHERE c.severity_level = 'Low'\n        AND cs.description LIKE '%obsolete%'\n    );\n\n    INSERT INTO regions (region_id, region_name, description, latitude, longitude, city, state, country)\n    VALUES ((SELECT MAX(region_id) + 1 FROM regions), 'Analysis Region', \n            'Regions: ' || v_region_count || ', Neighborhoods: ' || v_neighborhood_count || ', Incidents: ' || v_incident_count,\n            (p_min_latitude + p_max_latitude) / 2, (p_min_longitude + p_max_longitude) / 2,\n            'Analyzed', 'Spatial', 'Data');\nEND;\n$$;",
    "database_name": "crime_statistics_and_reporting_791805",
    "tables": [
      "crimes",
      "crime_incidents",
      "crime_subcategories",
      "neighborhoods",
      "regions"
    ],
    "call_sqls": [
      "CALL analyze_spatial_distribution(30.0, 45.0, -120.0, -70.0);",
      "CALL analyze_spatial_distribution(33.0, 35.0, -119.0, -117.0);",
      "CALL analyze_spatial_distribution(40.0, 41.0, -75.0, -73.0);",
      "CALL analyze_spatial_distribution(25.0, 50.0, -130.0, -60.0);",
      "CALL analyze_spatial_distribution(38.0, 42.0, -100.0, -90.0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_spatial_distribution that accepts four parameters defining a bounding box by minimum and maximum latitude and longitude values. It should count distinct regions from the REGIONS table and distinct neighborhoods from the NEIGHBORHOODS table within the bounds, count all crime incidents from the CRIME_INCIDENTS table within the bounds while aggregating distinct severity levels from the CRIMES table into a comma-separated string, delete obsolete low-severity crime subcategories from the CRIME_SUBCATEGORIES table where the description contains 'obsolete', and insert a new summary region record into the REGIONS table with a calculated ID (maximum existing region_id plus one), average coordinates from the bounds, and a description containing the region, neighborhood, and incident counts.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_spatial_distribution that accepts four REAL parameters defining a geographical bounding box: minimum latitude, maximum latitude, minimum longitude, and maximum longitude. The procedure should count the distinct regions from the REGIONS table and distinct neighborhoods from the NEIGHBORHOODS table that are entirely within these bounds. It must also count all crime incidents from the CRIME_INCIDENTS table within the area and aggregate the distinct severity levels from the CRIMES table into a comma-separated string. Then, delete any obsolete crime subcategories from the CRIME_SUBCATEGORIES table that are marked with low severity. Finally, insert a new summary region record into the REGIONS table with a unique identifier, average coordinates from the bounding box, and a textual description incorporating the gathered counts.",
    "id": 44,
    "generated_ir": "Write a PLpgSQL stored procedure named analyze_spatial_distribution that accepts four parameters: p_min_latitude, p_max_latitude, p_min_longitude, and p_max_longitude, all of type REAL, which define a geographical bounding box. The procedure begins by declaring three integer variables, v_region_count, v_neighborhood_count, and v_incident_count, and a text variable v_total_severity. It first performs a SELECT operation to count distinct region_id values from the regions table where the latitude and longitude fall within the specified bounds, storing the result in v_region_count. Next, it counts distinct neighborhood_id values from the neighborhoods table, joining with the regions table on region_id, again constrained by the latitude and longitude bounds, and stores the result in v_neighborhood_count. Then, it counts all rows from the crime_incidents table, joining with the crimes table on crime_id and the regions table on region_id, within the same geographical constraints, storing the count in v_incident_count and aggregating distinct severity_level values from the crimes table into v_total_severity using STRING_AGG. The procedure proceeds to delete rows from the crime_subcategories table where subcategory_id matches those in a subquery selecting subcategory_id from crime_subcategories joined with crimes on crime_id, where severity_level is 'Low' and description contains the word 'obsolete'. Finally, it inserts a new row into the regions table with a calculated region_id as the maximum existing region_id plus one, a region_name of 'Analysis Region', a description summarizing the counts of regions, neighborhoods, and incidents, and latitude and longitude set to the average of the provided bounds, along with fixed values for city, state, and country as 'Analyzed', 'Spatial', and 'Data', respectively.",
    "original_summary": "Create a stored procedure named analyze_spatial_distribution that accepts four REAL parameters defining a bounding box (min/max latitude and longitude). It should count distinct regions and neighborhoods within the bounds, count all crime incidents within the bounds while aggregating distinct severity levels into a comma-separated string, delete obsolete low-severity crime subcategories, and insert a new summary region record with calculated ID, average coordinates, and a description containing the counts.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a stored procedure named analyze_spatial_distribution that accepts four REAL parameters, specifically the minimum latitude, the maximum latitude, the minimum longitude, and the maximum longitude, which together define a precise geographical bounding box. This procedure should meticulously count the distinct regions and neighborhoods located entirely within these specified bounds. Furthermore, it must comprehensively count all crime incidents occurring within the area, while also aggregating the distinct severity levels found into a single, neatly formatted comma-separated string. As part of its operations, the procedure should then proceed to delete any obsolete crime subcategories that are marked with low severity. Finally, it must insert a brand new summary region record, which will include a carefully calculated unique identifier, the average coordinates derived from the bounded area, and a detailed textual description that incorporates all the previously gathered counts."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named delete_user_workclass that accepts a single parameter p_user_id of type bigint. This procedure performs a delete operation on the workclasses table, specifically targeting rows where the workclass_id column matches the value provided in the p_user_id parameter. Additionally, it applies a condition on the workclass_name column, ensuring that only rows where the workclass_name begins with the string 'State' are considered for deletion. The procedure does not involve any other operations, such as updates, inserts, or selects, and does not utilize any function calls or special operations like UPPER() or LOWER(). The logic flow is straightforward, with the procedure executing the delete operation based on the specified conditions without any conditional branching or additional logic.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_user_workclass(p_user_id bigint)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM workclasses\n    WHERE workclass_id = p_user_id\n    AND workclass_name LIKE 'State%';\nEND;\n$$;",
    "database_name": "demographic_and_socioeconomic_data_analysis_40195",
    "tables": [
      "users",
      "roles",
      "user_roles",
      "permissions",
      "data_access",
      "data_collections",
      "education_levels",
      "occupations",
      "workclasses"
    ],
    "call_sqls": [
      "CALL delete_user_workclass(0);",
      "CALL delete_user_workclass(1);",
      "CALL delete_user_workclass(2);",
      "CALL delete_user_workclass(3);",
      "CALL delete_user_workclass(4);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named delete_user_workclass that accepts a user ID and deletes all records from the workclasses table where the workclass_id matches the provided user ID and the workclass_name begins with 'State'.",
    "natural_language": "Hey, can you whip up a PostgreSQL PL/pgSQL stored procedure called delete_user_workclass that takes a user ID? It should clean out any records from the workclasses table where the workclass_id matches the given user ID, but only for those entries where the workclass_name starts with 'State'.",
    "id": 45,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named delete_user_workclass that takes a single input parameter named user_id of type bigint. The procedure performs a delete operation on the workclasses table. Specifically, it deletes rows from the workclasses table where the workclass_id column value equals the provided user_id parameter, but only for those rows where the workclass_name column value begins with the string 'State'. This condition is implemented using the LIKE operator with the pattern 'State%' to match any workclass_name that starts with 'State'. The procedure does not return any value; it is a void procedure that executes the deletion directly.",
    "original_summary": "Create a stored procedure named delete_user_workclass that accepts a user ID. Delete rows from the workclasses table where the workclass_id matches the provided user ID and the workclass_name starts with 'State'.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called delete_user_workclass that takes a user ID? It should clean out any records from the workclasses table where the workclass_id is the same as the user ID we give it, but only for those entries where the workclass_name kicks off with 'State'."
  },
  {
    "ir": "Write a PostgreSQL stored procedure named calculate_average_file_size that accepts four input parameters: p_dataset_id of type text to identify a specific dataset, p_start_date of type text to define the beginning of a date range, p_end_date of type text to define the end of a date range, and p_min_file_size of type real to set a minimum file size threshold. The procedure declares a local variable v_avg_file_size of type real. It begins by calculating the average file size from the data_files table, specifically from the file_size column, for all rows where the dataset_id column matches the input parameter p_dataset_id, the upload_date column falls within the inclusive range specified by p_start_date and p_end_date, and the file_size column is greater than the input parameter p_min_file_size; this calculated average is stored into the local variable v_avg_file_size. The procedure then performs an insertion into the data_analysis table, populating the following columns: analysis_id is set to the result of a subquery that finds the maximum existing value in the analysis_id column of the data_analysis table, adds 1 to it, and uses 0 as a default if the maximum is null via the COALESCE function; dataset_id is set to the input parameter p_dataset_id; analysis_name is set to the literal string 'Average File Size Analysis'; analysis_type is set to the literal string 'File Metrics'; analysis_date is set to the current date cast to text; analysis_file_path is constructed by concatenating the literal string 'analysis/avg_file_size_' with the value of p_dataset_id; analysis_result is constructed by concatenating the literal string 'Average file size: ' with the value stored in v_avg_file_size; and analysis_description is set to the literal string 'Analysis of average file size for specified dataset'.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_average_file_size(\n    p_dataset_id text,\n    p_start_date text,\n    p_end_date text,\n    p_min_file_size real\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_avg_file_size real;\nBEGIN\n    SELECT AVG(file_size)\n    INTO v_avg_file_size\n    FROM data_files\n    WHERE dataset_id = p_dataset_id\n    AND upload_date BETWEEN p_start_date AND p_end_date\n    AND file_size > p_min_file_size;\n    \n    INSERT INTO data_analysis (analysis_id, dataset_id, analysis_name, analysis_type, analysis_date, analysis_file_path, analysis_result, analysis_description)\n    VALUES (\n        (SELECT COALESCE(MAX(analysis_id), 0) + 1 FROM data_analysis),\n        p_dataset_id,\n        'Average File Size Analysis',\n        'File Metrics',\n        CURRENT_DATE::text,\n        'analysis/avg_file_size_' || p_dataset_id,\n        'Average file size: ' || v_avg_file_size,\n        'Analysis of average file size for specified dataset'\n    );\nEND;\n$$;",
    "database_name": "biomedical_research_and_data_management",
    "tables": [
      "datasets",
      "data_files",
      "dataset_details",
      "data_analysis",
      "access_logs",
      "dataset_shares"
    ],
    "call_sqls": [
      "CALL calculate_average_file_size('0', '2023-01-01', '2023-02-01', 1.0);",
      "CALL calculate_average_file_size('1', '2023-01-01', '2023-02-01', 1.0);",
      "CALL calculate_average_file_size('0', '2023-01-01', '2023-03-01', 1.2);",
      "CALL calculate_average_file_size('1', '2023-02-01', '2023-03-01', 1.5);",
      "CALL calculate_average_file_size('0', '2023-01-01', '2023-02-01', 1.5);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_average_file_size that takes a dataset ID, a start date, an end date, and a minimum file size to compute the average file_size from the data_files table for the given dataset within the specified date range where file_size exceeds the minimum threshold, and then inserts a new record into the data_analysis table with a generated analysis_id, the provided dataset_id, an analysis_name of 'Average File Size Analysis', an analysis_type of 'File Metrics', the current date as analysis_date, an analysis_file_path formatted as 'analysis/avg_file_size_[dataset_id]', an analysis_result string showing the calculated average, and an analysis_description of 'Analysis of average file size for specified dataset'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `calculate_average_file_size` that takes a dataset ID, a start date, an end date, and a minimum file size, calculates the average `file_size` from the `data_files` table for that dataset where the `upload_date` falls between the given dates and the file size exceeds the minimum, then inserts a new record into the `data_analysis` table with a generated analysis ID, the provided dataset ID, the analysis name as 'Average File Size Analysis', the type as 'File Metrics', today's date, a file path formatted as 'analysis/avg_file_size_[dataset ID]', a result stating the calculated average, and a description as 'Analysis of average file size for specified dataset'.",
    "id": 46,
    "generated_ir": "Write a PostgreSQL stored procedure named calculate_average_file_size that accepts four input parameters: p_dataset_id of type text to identify a specific dataset, p_start_date of type text to define the beginning of a date range, p_end_date of type text to define the end of a date range, and p_min_file_size of type real to set a minimum file size threshold. The procedure declares a local variable v_avg_file_size of type real. It begins by calculating the average file size from the data_files table, specifically from the file_size column, for all rows where the dataset_id column matches the input parameter p_dataset_id, the upload_date column falls within the inclusive range specified by p_start_date and p_end_date, and the file_size column is greater than the input parameter p_min_file_size; this calculated average is stored into the local variable v_avg_file_size. The procedure then performs an insertion into the data_analysis table, populating the following columns: analysis_id is set to the result of a subquery that finds the maximum existing value in the analysis_id column of the data_analysis table, adds 1 to it, and uses 0 as a default if the maximum is null via the COALESCE function; dataset_id is set to the input parameter p_dataset_id; analysis_name is set to the literal string 'Average File Size Analysis'; analysis_type is set to the literal string 'File Metrics'; analysis_date is set to the current date cast to text; analysis_file_path is constructed by concatenating the literal string 'analysis/avg_file_size_' with the value of p_dataset_id; analysis_result is constructed by concatenating the literal string 'Average file size: ' with the value stored in v_avg_file_size; and analysis_description is set to the literal string 'Analysis of average file size for specified dataset'.",
    "original_summary": "Create a stored procedure named `calculate_average_file_size` that takes a dataset ID (TEXT), a start date (TEXT), an end date (TEXT), and a minimum file size (REAL). Calculate the average `file_size` from the `data_files` table for the specified dataset, date range, and minimum size threshold. Insert a record into the `data_analysis` table with a generated analysis ID, the input dataset ID, analysis name 'Average File Size Analysis', type 'File Metrics', the current date, a file path like 'analysis/avg_file_size_[dataset_id]', a result string like 'Average file size: [calculated_value]', and a description 'Analysis of average file size for specified dataset'.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called `calculate_average_file_size`? It needs to take a dataset ID (as TEXT), a start date and an end date (both as TEXT), and a minimum file size (as a REAL number). Basically, it should figure out the average `file_size` from the `data_files` table, but only for that specific dataset, for files between those dates, and only if they're bigger than that minimum size you give it. Then, it's gotta pop a new record into the `data_analysis` table. For that record, generate a new analysis ID, use the dataset ID you provided, set the analysis name to 'Average File Size Analysis', the type to 'File Metrics', use today's date, make a file path like 'analysis/avg_file_size_[put the dataset ID here]', a result that says something like 'Average file size: [the average you just calculated]', and a description that reads 'Analysis of average file size for specified dataset'."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_station_data that accepts three input parameters: p_source_station_id of type bigint representing the unique identifier of the station to be decommissioned, p_target_station_id of type bigint representing the unique identifier of the station that will absorb the data, and p_migration_date of type text which provides a date string used for timestamping updates. The procedure first ensures the target station exists in the stations table by checking if a row with a station_id equal to p_target_station_id is present; if no such row exists, it inserts a new row into the stations table with the specified p_target_station_id, a placeholder station_name of 'New Station', a capacity of 0, a location of 'Unknown', latitude and longitude values of '0', a current_capacity of 0, and sets the last_updated column to the value of the p_migration_date parameter. The procedure then updates the bikes table, setting the station_id column to p_target_station_id and the last_maintenance_date column to p_migration_date for every row where the current station_id equals p_source_station_id. Next, it updates the trips table in two separate operations: the first operation sets the start_station_id column to p_target_station_id for all rows where start_station_id equals p_source_station_id, and the second operation sets the end_station_id column to p_target_station_id for all rows where end_station_id equals p_source_station_id. It performs identical dual updates on the rentals table, first setting start_station_id to p_target_station_id for rows where start_station_id equals p_source_station_id, and then setting end_station_id to p_target_station_id for rows where end_station_id equals p_source_station_id. Finally, the procedure deletes the row from the stations table where the station_id column matches the p_source_station_id parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE migrate_station_data(\n    p_source_station_id bigint,\n    p_target_station_id bigint,\n    p_migration_date text\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    -- Ensure the target station exists in the stations table\n    IF NOT EXISTS (SELECT 1 FROM stations WHERE station_id = p_target_station_id) THEN\n        -- Insert a new station entry for the target station\n        INSERT INTO stations (station_id, station_name, capacity, location, latitude, longitude, current_capacity, last_updated)\n        VALUES (p_target_station_id, 'New Station', 0, 'Unknown', '0', '0', 0, p_migration_date);\n    END IF;\n\n    -- 1. Update bikes to reflect the new station_id\n    UPDATE bikes\n    SET\n        station_id = p_target_station_id,\n        last_maintenance_date = p_migration_date\n    WHERE\n        station_id = p_source_station_id;\n\n    -- 2. Update historical trip records that started or ended at the source station\n    UPDATE trips\n    SET\n        start_station_id = p_target_station_id\n    WHERE\n        start_station_id = p_source_station_id;\n\n    UPDATE trips\n    SET\n        end_station_id = p_target_station_id\n    WHERE\n        end_station_id = p_source_station_id;\n\n    -- 3. Update historical rental records that started or ended at the source station\n    UPDATE rentals\n    SET\n        start_station_id = p_target_station_id\n    WHERE\n        start_station_id = p_source_station_id;\n\n    UPDATE rentals\n    SET\n        end_station_id = p_target_station_id\n    WHERE\n        end_station_id = p_source_station_id;\n\n    -- 4. Delete the source station entry from the stations table\n    DELETE FROM stations\n    WHERE station_id = p_source_station_id;\n\nEND;\n$$;",
    "database_name": "bike_sharing_service_and_user_trip_data_management",
    "tables": [
      "bikes",
      "rentals",
      "stations",
      "trips",
      "users"
    ],
    "call_sqls": [
      "CALL migrate_station_data(0, 2, '2023-09-01');",
      "CALL migrate_station_data(1, 3, '2023-09-02');",
      "CALL migrate_station_data(0, 4, '2023-09-03');",
      "CALL migrate_station_data(1, 5, '2023-09-04');",
      "CALL migrate_station_data(0, 6, '2023-09-05');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_station_data that takes a source station ID, a target station ID, and a migration date as input to consolidate station data by ensuring the target station exists in the stations table (creating a placeholder record with default values if it does not), updating all references to the source station in the bikes, trips, and rentals tables to point to the target station while setting relevant timestamps to the migration date, and finally removing the source station record from the stations table.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `migrate_station_data` that migrates data from a source station to a target station on a specified date. It should first check if the target station exists in the `stations` table and, if not, insert a placeholder record with default values. Then, update all references in the `bikes`, `trips`, and `rentals` tables: change the `station_id` in `bikes` from the source to the target and set `last_maintenance_date` to the migration date; update `start_station_id` and `end_station_id` in both `trips` and `rentals` from the source to the target where applicable. Finally, delete the source station record from the `stations` table.",
    "id": 47,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_station_data that accepts three input parameters: p_source_station_id of type bigint representing the unique identifier of the station to be decommissioned, p_target_station_id of type bigint representing the unique identifier of the station that will absorb the data, and p_migration_date of type text which provides a date string used for timestamping updates. The procedure first ensures the target station exists in the stations table by checking if a row with a station_id equal to p_target_station_id is present; if no such row exists, it inserts a new row into the stations table with the specified p_target_station_id, a placeholder station_name of 'New Station', a capacity of 0, a location of 'Unknown', latitude and longitude values of '0', a current_capacity of 0, and sets the last_updated column to the value of the p_migration_date parameter. The procedure then updates the bikes table, setting the station_id column to p_target_station_id and the last_maintenance_date column to p_migration_date for every row where the current station_id equals p_source_station_id. Next, it updates the trips table in two separate operations: the first operation sets the start_station_id column to p_target_station_id for all rows where start_station_id equals p_source_station_id, and the second operation sets the end_station_id column to p_target_station_id for all rows where end_station_id equals p_source_station_id. It performs identical dual updates on the rentals table, first setting start_station_id to p_target_station_id for rows where start_station_id equals p_source_station_id, and then setting end_station_id to p_target_station_id for rows where end_station_id equals p_source_station_id. Finally, the procedure deletes the row from the stations table where the station_id column matches the p_source_station_id parameter.",
    "original_summary": "Create a stored procedure named `migrate_station_data` that takes a source station ID, a target station ID, and a migration date as input. It ensures the target station exists in the `stations` table, creating a placeholder record if needed. It then updates all references to the source station in the `bikes`, `trips`, and `rentals` tables to point to the target station, using the migration date for timestamps. Finally, it deletes the source station record from the `stations` table.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Alright, so we need a stored procedure called `migrate_station_data`. It's gonna take three things: a source station ID, a target station ID, and the date we're doing this migration. First off, it's gotta check if the target station is already in the `stations` table. If it's not there, just slap in a basic placeholder record for it. Then, we need to go through the `bikes`, `trips`, and `rentals` tables and switch any references from the old source station ID over to the new target station ID, using that migration date for the timestamps. Once all that's done, just get rid of the original source station record from the `stations` table."
  },
  {
    "ir": "Write a PLpgSQL stored procedure that takes two parameters: p_year of type bigint and p_threshold of type real. The procedure first calculates the number of records in the poverty_data table where the year column matches the p_year parameter and the poverty_rate column exceeds the p_threshold parameter, storing this count in a variable named high_poverty_count. It then determines the next available poverty_id by selecting the maximum value of the poverty_id column from the poverty_data table, defaulting to 0 if no records exist, and increments this value by 1, storing the result in a variable named next_id. Finally, the procedure inserts a new row into the poverty_data table with the following values: next_id for the poverty_id column, NULL for the census_id, poverty_rate, and child_poverty_rate columns, the value of p_year for the year column, NULL for the poverty_threshold column, and the value of high_poverty_count for the household_size column.",
    "plsql": "CREATE OR REPLACE PROCEDURE count_high_poverty_areas(p_year bigint, p_threshold real)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    high_poverty_count bigint;\n    next_id bigint;\nBEGIN\n    SELECT COUNT(*)\n    INTO high_poverty_count\n    FROM poverty_data\n    WHERE year = p_year AND poverty_rate > p_threshold;\n\n    SELECT COALESCE(MAX(poverty_id), 0) + 1\n    INTO next_id\n    FROM poverty_data;\n\n    INSERT INTO poverty_data (poverty_id, census_id, poverty_rate, child_poverty_rate, year, poverty_threshold, household_size)\n    VALUES (next_id, NULL, NULL, NULL, p_year, NULL, high_poverty_count);\nEND;\n$$;",
    "database_name": "demographic_and_socioeconomic_data_analysis_462657",
    "tables": [
      "census_data",
      "employment_data",
      "employment_categories",
      "income_data",
      "income_categories",
      "poverty_data",
      "transportation_data"
    ],
    "call_sqls": [
      "CALL count_high_poverty_areas(2020, 15.0);",
      "CALL count_high_poverty_areas(2021, 20.5);",
      "CALL count_high_poverty_areas(2019, 10.0);",
      "CALL count_high_poverty_areas(2022, 25.0);",
      "CALL count_high_poverty_areas(2023, 18.7);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named count_high_poverty_areas that takes a target year and a poverty rate threshold as inputs, counts how many records in the poverty_data table have that year and a poverty_rate exceeding the threshold, generates a new unique poverty_id, and inserts a new row into the poverty_data table with the count stored in the household_size column, the provided year, and NULL values for the census_id, poverty_rate, child_poverty_rate, poverty_threshold, and other specified columns.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called count_high_poverty_areas that, given a specific year and a poverty rate threshold, counts how many records in the poverty_data table have that year and a poverty_rate exceeding the threshold, then inserts a new record into poverty_data with a new poverty_id, the given year, the count as household_size, and NULL values for the other columns.",
    "id": 48,
    "generated_ir": "Write a PL/pgSQL stored procedure named `count_high_poverty_areas` that accepts two input parameters: `p_year` of type `bigint` and `p_poverty_threshold` of type `real`. The purpose of this procedure is to analyze records in the `poverty_data` table for a specified year, count how many of those records have a poverty rate exceeding a given threshold, and then insert a new summary record back into the `poverty_data` table.\n\nThe procedure begins by declaring a local variable named `v_count` of type `bigint`. This variable will store the result of the count operation.\n\nNext, the procedure executes a `SELECT` statement with a `COUNT(*)` aggregate function to calculate the number of qualifying records. This query targets the `poverty_data` table. The `WHERE` clause filters the rows to include only those where the `year` column exactly matches the value provided in the `p_year` input parameter AND where the `poverty_rate` column is greater than the value provided in the `p_poverty_threshold` input parameter. The result of this count operation is assigned to the `v_count` local variable.\n\nFollowing the count, the procedure performs an `INSERT` operation into the `poverty_data` table. The `INSERT` statement specifies values for the following columns: `poverty_id`, `census_id`, `poverty_rate`, `child_poverty_rate`, `year`, `poverty_threshold`, and `household_size`.\n\nThe values provided for these columns are determined as follows:\n- For `poverty_id`: A new unique identifier is generated by querying the `poverty_data` table to find the maximum existing value in the `poverty_id` column using the `MAX()` aggregate function. The `COALESCE()` function is applied to this result; if `MAX(poverty_id)` returns `NULL` (indicating an empty table), `COALESCE()` returns `0`. The final value for `poverty_id` is this result plus `1`.\n- For `census_id`: A `NULL` value is inserted.\n- For `poverty_rate`: A `NULL` value is inserted.\n- For `child_poverty_rate`: A `NULL` value is inserted.\n- For `year`: The value passed in the `p_year` input parameter.\n- For `poverty_threshold`: A `NULL` value is inserted.\n- For `household_size`: The value stored in the `v_count` local variable, which represents the count of high-poverty areas for the given year and threshold.\n\nThis `INSERT` statement creates a new record that serves as a summary, capturing the year and the computed count of high-poverty areas, while leaving other demographic and census-specific columns as `NULL`.",
    "original_summary": "Create a stored procedure with parameters p_year and p_threshold. Count records in poverty_data where the year matches p_year and the poverty_rate exceeds p_threshold. Generate a new ID. Insert a new row into poverty_data with the count stored in the household_size column, the provided year, and NULL for other specified columns.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create procedure with p_year, p_threshold. Count poverty_data rows where year = p_year and poverty_rate > p_threshold. Generate new ID. Insert count as household_size, given year, NULL for other columns."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named manage_clothing_catalog that accepts two input parameters: p_category of type text, which specifies a clothing category, and p_price_limit of type real, which defines a price threshold. The procedure first calculates the average price of all items in the clothing_items table for the specified p_category, storing the result in a local variable v_avg_price; if no items exist for that category, the COALESCE function returns 0. It then determines the next available item_id by selecting the maximum existing item_id from the clothing_items table, incrementing it by one, and storing it in v_max_item_id, with COALESCE ensuring a default of 0 if the table is empty. Based on a comparison between v_avg_price and p_price_limit, the procedure executes one of three conditional branches: if the average price is less than the price limit, it inserts a new row into the clothing_items table with the generated v_max_item_id, a predefined item_name of 'Affordable Item', a description of 'Budget-friendly', the input p_price_limit as the price, the input p_category as the category, and fixed placeholder values for sub_category, brand, color, and material; if the average price exceeds 1.5 times the price limit, it deletes all rows from the clothing_items table where the category matches p_category and the price is greater than 1.5 times p_price_limit; otherwise, for the case where the average price is between the price limit and 1.5 times the price limit, it updates all rows in the clothing_items table for the specified p_category by reducing each item's price by 5.",
    "plsql": "CREATE OR REPLACE PROCEDURE manage_clothing_catalog(p_category text, p_price_limit real)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_avg_price real;\n    v_max_item_id bigint;\nBEGIN\n    SELECT COALESCE(AVG(price), 0)\n    INTO v_avg_price\n    FROM clothing_items\n    WHERE category = p_category;\n\n    SELECT COALESCE(MAX(item_id), 0) + 1\n    INTO v_max_item_id\n    FROM clothing_items;\n\n    IF v_avg_price < p_price_limit THEN\n        INSERT INTO clothing_items (item_id, item_name, description, price, category, sub_category, brand, color, material)\n        VALUES (v_max_item_id, 'Affordable Item', 'Budget-friendly', p_price_limit, p_category, 'sub_category', 'brand', 'color', 'material');\n    ELSIF v_avg_price > p_price_limit * 1.5 THEN\n        DELETE FROM clothing_items\n        WHERE category = p_category AND price > p_price_limit * 1.5;\n    ELSE\n        UPDATE clothing_items\n        SET price = price - 5\n        WHERE category = p_category;\n    END IF;\nEND;\n$$;",
    "database_name": "fashion_and_apparel_sizing_guide",
    "tables": [
      "clothing_items",
      "inventory",
      "sizes"
    ],
    "call_sqls": [
      "CALL manage_clothing_catalog('women', 25.0);",
      "CALL manage_clothing_catalog('women', 30.0);",
      "CALL manage_clothing_catalog('women', 20.0);",
      "CALL manage_clothing_catalog('women', 35.0);",
      "CALL manage_clothing_catalog('women', 40.0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named manage_clothing_catalog that accepts a category and a price limit, calculates the average price for that category from the clothing_items table, and then: if the average price is below the limit, inserts a new affordable item into clothing_items with the price limit; if the average price exceeds 1.5 times the limit, deletes all items in the category priced above that higher limit; otherwise, reduces the price of all items in the category by 5.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called manage_clothing_catalog that takes a clothing type and a rough price cap. It calculates the typical price for that clothing type from the clothing_items table. If the typical price is below the cap, it adds a new reasonably-priced item to clothing_items using the cap as the price. If the typical price exceeds the cap by a good margin, specifically by 50%, it removes any items in that clothing type that cost more than that higher amount. Otherwise, it slightly lowers the cost of all items in that clothing type by a fixed amount.",
    "id": 49,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named manage_clothing_catalog that accepts two input parameters: clothing_type of type TEXT, representing the specific clothing category to process, and price_cap of type REAL, representing the maximum price threshold for the operation. The procedure declares three local variables: avg_price of type REAL to store the calculated average price for the specified clothing type, price_threshold of type REAL to store a computed threshold value, and fixed_discount of type REAL set to 5.0, representing the amount by which prices are reduced in the default scenario.\n\nThe procedure begins by executing a SELECT statement with an aggregate AVG function to calculate the average price from the price column of the clothing_items table. This calculation is performed only for rows where the category column matches the input clothing_type parameter. The result is stored in the avg_price variable.\n\nFollowing this, an IF conditional statement checks if avg_price is less than the price_cap parameter. If this condition is true, the procedure executes an INSERT INTO statement to add a new record to the clothing_items table. The values inserted are:\n1. For the item_id column, the next value from the sequence associated with the clothing_items.item_id primary key is used (assumed to be clothing_items_item_id_seq).\n2. For the item_name column, a concatenated string is formed by combining the input clothing_type parameter and the literal string ' Item'.\n3. For the description column, a concatenated string is formed by combining the input clothing_type parameter and the literal string ' description'.\n4. For the price column, the price_cap parameter value is inserted.\n5. For the category column, the input clothing_type parameter value is inserted.\n6. For the sub_category, brand, color, and material columns, the literal string 'Unknown' is inserted for each.\n\nIf the first condition is false, the procedure proceeds to an ELSIF conditional statement. This statement checks if avg_price is greater than the price_cap parameter multiplied by 1.5 (representing a 50% margin). If this condition is true, the procedure calculates a price_threshold by multiplying price_cap by 1.5. It then executes a DELETE statement on the clothing_items table to remove all rows where the category column matches the input clothing_type parameter and the price column is greater than the computed price_threshold.\n\nIf neither the IF nor the ELSIF condition is true, the procedure executes an ELSE block. In this block, it performs an UPDATE statement on the clothing_items table. For all rows where the category column matches the input clothing_type parameter, the price column is decreased by the fixed_discount value (5.0). This ensures the new price is the old price minus the discount.\n\nAfter the conditional logic completes, the procedure finishes its execution.",
    "original_summary": "Create a stored procedure named manage_clothing_catalog that accepts a category and a price limit. It calculates the average price for the category. If the average is below the limit, insert a new affordable item with the price limit. If the average exceeds 1.5 times the limit, delete all items in the category priced above that higher limit. Otherwise, reduce the price of all items in the category by 5.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a stored procedure called manage_clothing_catalog that takes a clothing type and a rough price cap. It figures out the typical price for that type. If the typical price is kind of low compared to the cap, add a new reasonably-priced item using that cap. If the typical price goes noticeably over the cap, say by a good margin, then remove any items in that type that cost more than that higher amount. Otherwise, just lower the cost of everything in that type by a little bit."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named manage_intervention_assignments that accepts five input parameters: a bigint parameter p_dept_id representing a department identifier, a text parameter p_intervention_type describing the type of intervention, a real parameter p_budget for the intervention's budget, a text parameter p_start_date for the intervention's start date, and a text parameter p_end_date for the intervention's end date. The procedure begins by declaring local variables v_coach_count as integer, v_dept_exists as boolean, v_coach_id as bigint, and v_intervention_id as bigint. It first executes a SELECT statement to count the number of rows in the agile_coaches table where the dept_id column equals the input p_dept_id, storing the result into v_coach_count. It then executes another SELECT statement using the EXISTS operator to check if a row exists in the departments table where the dept_id column equals p_dept_id, storing the boolean result into v_dept_exists. The procedure uses a conditional IF-ELSIF-ELSIF-ELSIF-ELSE block to control logic flow. If v_dept_exists is false, it performs an INSERT into the departments table, creating a new department row with dept_id set to p_dept_id, dept_name set to 'New Department', location set to 'TBD Location', contact_number set to '555-0000', and both created_date and updated_date set to the current date converted to text. If the department exists and v_coach_count equals 0, it performs an INSERT into the agile_coaches table, creating a new coach row with a coach_id calculated as p_dept_id multiplied by 100, coach_name set to 'Auto Assigned Coach', email set to 'auto@coach.com', dept_id set to p_dept_id, contact_number set to '555-9999', and both created_date and updated_date set to the current date as text. If the department exists and v_coach_count equals 1, it first executes a SELECT statement to retrieve the coach_id from the agile_coaches table for the given p_dept_id, limiting the result to one row, and stores the value into v_coach_id. It then executes another SELECT statement using the COALESCE and MAX functions to calculate the next intervention_id by finding the maximum existing intervention_id in the agile_interventions table, defaulting to 0 if none exist, and adding 1, storing the result into v_intervention_id. It then performs an INSERT into the agile_interventions table, creating a new intervention row with the calculated v_intervention_id, dept_id set to p_dept_id, intervention_type set to the input p_intervention_type, start_date set to p_start_date, end_date set to p_end_date, outcome set to 'Pending', budget set to p_budget, responsible_person set to the string 'Coach ID: ' concatenated with the v_coach_id value, and both created_date and updated_date set to the current date as text. If the department exists and v_coach_count is greater than 1 and the input p_budget is greater than 7500, it calculates the next v_intervention_id using the same COALESCE(MAX(intervention_id), 0) + 1 logic from the agile_interventions table. It then performs an INSERT into the agile_interventions table, creating a new intervention row with the calculated v_intervention_id, dept_id set to p_dept_id, intervention_type set to the input p_intervention_type concatenated with the string ' - Multi Coach', start_date set to p_start_date, end_date set to p_end_date, outcome set to 'High Priority', budget set to p_budget, responsible_person set to 'Multiple Coaches', and both created_date and updated_date set to the current date as text. For any other condition where the department exists, the coach count is not 0 or 1, and the budget condition is not met, the procedure executes a DELETE statement on the agile_interventions table, removing any rows where the dept_id equals p_dept_id and the budget column value is less than 3000.",
    "plsql": "CREATE OR REPLACE PROCEDURE manage_intervention_assignments(\n    p_dept_id bigint,\n    p_intervention_type text,\n    p_budget real,\n    p_start_date text,\n    p_end_date text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_coach_count integer;\n    v_dept_exists boolean;\n    v_coach_id bigint;\n    v_intervention_id bigint;\nBEGIN\n    SELECT COUNT(*) INTO v_coach_count FROM agile_coaches WHERE dept_id = p_dept_id;\n    SELECT EXISTS(SELECT 1 FROM departments WHERE dept_id = p_dept_id) INTO v_dept_exists;\n    \n    IF v_dept_exists = false THEN\n        INSERT INTO departments (dept_id, dept_name, location, contact_number, created_date, updated_date)\n        VALUES (p_dept_id, 'New Department', 'TBD Location', '555-0000', CURRENT_DATE::text, CURRENT_DATE::text);\n    ELSIF v_coach_count = 0 THEN\n        INSERT INTO agile_coaches (coach_id, coach_name, email, dept_id, contact_number, created_date, updated_date)\n        VALUES (p_dept_id * 100, 'Auto Assigned Coach', 'auto@coach.com', p_dept_id, '555-9999', CURRENT_DATE::text, CURRENT_DATE::text);\n    ELSIF v_coach_count = 1 THEN\n        SELECT coach_id INTO v_coach_id FROM agile_coaches WHERE dept_id = p_dept_id LIMIT 1;\n        SELECT COALESCE(MAX(intervention_id), 0) + 1 INTO v_intervention_id FROM agile_interventions;\n        INSERT INTO agile_interventions (intervention_id, dept_id, intervention_type, start_date, end_date, outcome, budget, responsible_person, created_date, updated_date)\n        VALUES (v_intervention_id, p_dept_id, p_intervention_type, p_start_date, p_end_date, 'Pending', p_budget, 'Coach ID: ' || v_coach_id, CURRENT_DATE::text, CURRENT_DATE::text);\n    ELSIF v_coach_count > 1 AND p_budget > 7500 THEN\n        SELECT COALESCE(MAX(intervention_id), 0) + 1 INTO v_intervention_id FROM agile_interventions;\n        INSERT INTO agile_interventions (intervention_id, dept_id, intervention_type, start_date, end_date, outcome, budget, responsible_person, created_date, updated_date)\n        VALUES (v_intervention_id, p_dept_id, p_intervention_type || ' - Multi Coach', p_start_date, p_end_date, 'High Priority', p_budget, 'Multiple Coaches', CURRENT_DATE::text, CURRENT_DATE::text);\n    ELSE\n        DELETE FROM agile_interventions WHERE dept_id = p_dept_id AND budget < 3000;\n    END IF;\nEND;\n$$;",
    "database_name": "healthcare_departmental_agile_readiness_assessment",
    "tables": [
      "agile_coaches",
      "agile_interventions",
      "departments"
    ],
    "call_sqls": [
      "CALL manage_intervention_assignments(100, 'Agile Training Workshop', 5000.0, '2024-01-15', '2024-01-20');",
      "CALL manage_intervention_assignments(200, 'Technical System Upgrade', 8000.0, '2024-02-01', '2024-03-01');",
      "CALL manage_intervention_assignments(300, 'Process Optimization', 2500.0, '2024-03-10', '2024-03-15');",
      "CALL manage_intervention_assignments(400, 'Team Coaching', 10000.0, '2024-04-01', '2024-06-01');",
      "CALL manage_intervention_assignments(500, 'Leadership Training', 6000.0, '2024-05-01', '2024-05-05');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named manage_intervention_assignments that accepts a department ID, an intervention type, a budget, a start date, and an end date as parameters to manage intervention assignments for a department. The procedure must check if the department exists in the departments table and count its coaches in the agile_coaches table. If the department does not exist, create it with default values. If it exists but has no coaches, create a default coach for it. If it has exactly one coach, create a new intervention in the agile_interventions table for that coach with a pending outcome. If it has multiple coaches and the budget exceeds 7500, create a high-priority multi-coach intervention. Otherwise, delete low-budget interventions for that department where the budget is less than 3000.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named manage_intervention_assignments that accepts a department identifier, an intervention type, a budget allocation, a commencement date, and a conclusion date. The procedure must check if the specified department exists in the departments table and count its associated coaches in the agile_coaches table. If the department does not exist, create it with default details. If it exists but has no coaches, insert a default coach record. If it has exactly one coach, create a new intervention in the agile_interventions table for that coach. If it has multiple coaches and the provided budget exceeds 7500, create a high-priority multi-coach intervention. Otherwise, delete any low-budget interventions for that department where the budget is below 3000.",
    "id": 50,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named manage_intervention_assignments that accepts five input parameters: a bigint parameter p_dept_id representing a department identifier, a text parameter p_intervention_type describing the type of intervention, a real parameter p_budget for the intervention's budget, a text parameter p_start_date for the intervention's start date, and a text parameter p_end_date for the intervention's end date. The procedure begins by declaring local variables v_coach_count as integer, v_dept_exists as boolean, v_coach_id as bigint, and v_intervention_id as bigint. It first executes a SELECT statement to count the number of rows in the agile_coaches table where the dept_id column equals the input p_dept_id, storing the result into v_coach_count. It then executes another SELECT statement using the EXISTS operator to check if a row exists in the departments table where the dept_id column equals p_dept_id, storing the boolean result into v_dept_exists. The procedure uses a conditional IF-ELSIF-ELSIF-ELSIF-ELSE block to control logic flow. If v_dept_exists is false, it performs an INSERT into the departments table, creating a new department row with dept_id set to p_dept_id, dept_name set to 'New Department', location set to 'TBD Location', contact_number set to '555-0000', and both created_date and updated_date set to the current date converted to text. If the department exists and v_coach_count equals 0, it performs an INSERT into the agile_coaches table, creating a new coach row with a coach_id calculated as p_dept_id multiplied by 100, coach_name set to 'Auto Assigned Coach', email set to 'auto@coach.com', dept_id set to p_dept_id, contact_number set to '555-9999', and both created_date and updated_date set to the current date as text. If the department exists and v_coach_count equals 1, it first executes a SELECT statement to retrieve the coach_id from the agile_coaches table for the given p_dept_id, limiting the result to one row, and stores the value into v_coach_id. It then executes another SELECT statement using the COALESCE and MAX functions to calculate the next intervention_id by finding the maximum existing intervention_id in the agile_interventions table, defaulting to 0 if none exist, and adding 1, storing the result into v_intervention_id. It then performs an INSERT into the agile_interventions table, creating a new intervention row with the calculated v_intervention_id, dept_id set to p_dept_id, intervention_type set to the input p_intervention_type, start_date set to p_start_date, end_date set to p_end_date, outcome set to 'Pending', budget set to p_budget, responsible_person set to the string 'Coach ID: ' concatenated with the v_coach_id value, and both created_date and updated_date set to the current date as text. If the department exists and v_coach_count is greater than 1 and the input p_budget is greater than 7500, it calculates the next v_intervention_id using the same COALESCE(MAX(intervention_id), 0) + 1 logic from the agile_interventions table. It then performs an INSERT into the agile_interventions table, creating a new intervention row with the calculated v_intervention_id, dept_id set to p_dept_id, intervention_type set to the input p_intervention_type concatenated with the string ' - Multi Coach', start_date set to p_start_date, end_date set to p_end_date, outcome set to 'High Priority', budget set to p_budget, responsible_person set to 'Multiple Coaches', and both created_date and updated_date set to the current date as text. For any other condition where the department exists, the coach count is not 0 or 1, and the budget condition is not met, the procedure executes a DELETE statement on the agile_interventions table, removing any rows where the dept_id equals p_dept_id and the budget column value is less than 3000.",
    "original_summary": "Create a stored procedure named manage_intervention_assignments that accepts department ID, intervention type, budget, start date, and end date as parameters. It checks if the department exists and counts its coaches. If the department doesn't exist, create it. If it exists but has no coaches, create a default coach. If it has exactly one coach, create a new intervention for that coach. If it has multiple coaches and the budget exceeds 7500, create a high-priority multi-coach intervention. Otherwise, delete low-budget interventions for that department.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Formulate a stored procedure designated as 'manage_intervention_assignments' which shall accept the following parameters: department identifier, intervention type, budget allocation, commencement date, and conclusion date. The procedure must first verify the existence of the specified department and enumerate its associated coaches. Should the department not exist, it is to be created. If the department exists yet possesses no assigned coaches, a default coach record must be established. In the event the department has precisely one coach, a new intervention is to be created for that coach. For departments with multiple coaches, if the provided budget exceeds 7500, a high-priority intervention involving multiple coaches must be created. Otherwise, any low-budget interventions associated with that department are to be deleted."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named aggregate_crime_statistics that accepts four input parameters: a BIGINT parameter p_region_id to identify a specific geographical region, a TEXT parameter p_start_date to define the beginning of a date range, a TEXT parameter p_end_date to define the end of a date range, and a TEXT parameter p_severity_filter to specify a crime severity level. The procedure first declares four local variables: v_total_incidents as an INT, v_avg_latitude and v_avg_longitude as REAL, and v_most_common_crime as TEXT. It then executes a SELECT statement that joins the crime_incidents table (aliased as ci) with the crimes table (aliased as c) on the crime_id column, and from this joined dataset, it calculates the total count of rows, the average value of the latitude column, and the average value of the longitude column, storing these results into the variables v_total_incidents, v_avg_latitude, and v_avg_longitude respectively, but only for rows where the region_id column from the crime_incidents table equals the p_region_id parameter, the incident_date column from crime_incidents falls between the p_start_date and p_end_date parameters inclusive, and the severity_level column from the crimes table matches the p_severity_filter parameter. Next, the procedure executes a second SELECT statement that joins the crimes table (c) with the crime_incidents table (ci) again on crime_id, groups the results by the crime_name column from the crimes table, orders the groups in descending order based on the count of rows per group, and selects the single crime_name value from the top group, storing it into the v_most_common_crime variable, but only for rows filtered by the same conditions on region_id and incident_date matching p_region_id and the date range. Following this, the procedure performs an INSERT operation on the regions table, attempting to insert a new row with the following column values: region_id is set to the p_region_id parameter, region_name is set to the concatenation of the literal string 'Aggregated Stats ' and the p_region_id value, description is set to a concatenated string starting with 'Total: ', followed by the v_total_incidents value, then ', Common: ', followed by the v_most_common_crime value (or the string 'None' if that value is null via the COALESCE function), latitude is set to the v_avg_latitude variable, longitude is set to the v_avg_longitude variable, city is set to the literal 'Aggregated', state is set to the literal 'Stats', and country is set to the literal 'USA'. This INSERT command includes an ON CONFLICT clause that triggers when a conflict arises on the region_id column (which is presumably a primary key or unique constraint); in case of such a conflict, instead of inserting, it performs an UPDATE on the existing row, setting the region_name column to the value that would have been inserted (referenced as EXCLUDED.region_name), the description column to EXCLUDED.description, the latitude column to EXCLUDED.latitude, the longitude column to EXCLUDED.longitude, the city column to EXCLUDED.city, the state column to EXCLUDED.state, and the country column to EXCLUDED.country.",
    "plsql": "CREATE OR REPLACE PROCEDURE aggregate_crime_statistics(\n    p_region_id BIGINT,\n    p_start_date TEXT,\n    p_end_date TEXT,\n    p_severity_filter TEXT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_total_incidents INT;\n    v_avg_latitude REAL;\n    v_avg_longitude REAL;\n    v_most_common_crime TEXT;\nBEGIN\n    SELECT COUNT(*), AVG(latitude), AVG(longitude)\n    INTO v_total_incidents, v_avg_latitude, v_avg_longitude\n    FROM crime_incidents ci\n    JOIN crimes c ON ci.crime_id = c.crime_id\n    WHERE ci.region_id = p_region_id\n    AND ci.incident_date BETWEEN p_start_date AND p_end_date\n    AND c.severity_level = p_severity_filter;\n\n    SELECT crime_name INTO v_most_common_crime\n    FROM crimes c\n    JOIN crime_incidents ci ON c.crime_id = ci.crime_id\n    WHERE ci.region_id = p_region_id\n    AND ci.incident_date BETWEEN p_start_date AND p_end_date\n    GROUP BY c.crime_name\n    ORDER BY COUNT(*) DESC\n    LIMIT 1;\n\n    INSERT INTO regions (region_id, region_name, description, latitude, longitude, city, state, country)\n    VALUES (p_region_id, 'Aggregated Stats ' || p_region_id, \n            'Total: ' || v_total_incidents || ', Common: ' || COALESCE(v_most_common_crime, 'None'),\n            v_avg_latitude, v_avg_longitude, 'Aggregated', 'Stats', 'USA')\n    ON CONFLICT (region_id) DO UPDATE SET\n        region_name = EXCLUDED.region_name,\n        description = EXCLUDED.description,\n        latitude = EXCLUDED.latitude,\n        longitude = EXCLUDED.longitude,\n        city = EXCLUDED.city,\n        state = EXCLUDED.state,\n        country = EXCLUDED.country;\nEND;\n$$;",
    "database_name": "crime_statistics_and_reporting_791805",
    "tables": [
      "crimes",
      "crime_incidents",
      "crime_subcategories",
      "neighborhoods",
      "regions"
    ],
    "call_sqls": [
      "CALL aggregate_crime_statistics(1, '2023-01-01', '2023-12-31', 'Medium');",
      "CALL aggregate_crime_statistics(2, '2023-06-01', '2023-08-31', 'High');",
      "CALL aggregate_crime_statistics(3, '2023-03-01', '2023-03-31', 'Low');",
      "CALL aggregate_crime_statistics(1, '2024-01-01', '2024-05-31', 'Medium');",
      "CALL aggregate_crime_statistics(5, '2023-01-01', '2023-12-31', 'All');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named aggregate_crime_statistics that takes a region_id, a start_date, an end_date, and a severity_filter to calculate aggregated crime statistics for the specified region and date range, including the total number of incidents from the crime_incidents table joined with the crimes table, the average latitude and longitude, and the most common crime_name from the crimes table; then insert or update a row in the regions table with these statistics, setting region_name, description, latitude, longitude, city, state, and country accordingly.",
    "natural_language": "Hey, can you whip up a PostgreSQL PL/pgSQL stored procedure called aggregate_crime_statistics? It needs to take a region_id, a start date, an end date, and a severity filter. Basically, we wanna crunch the numbers for that area and time from the crime_incidents and crimes tables: get the total number of incidents, the average latitude and longitude, and figure out the crime_name that pops up the most. Then, take those stats and either put in a new row or update the existing one in the regions table for that region_id.",
    "id": 51,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named aggregate_crime_statistics that accepts four input parameters: a BIGINT parameter p_region_id to identify a specific geographical region, a TEXT parameter p_start_date to define the beginning of a date range, a TEXT parameter p_end_date to define the end of a date range, and a TEXT parameter p_severity_filter to specify a crime severity level. The procedure first declares four local variables: v_total_incidents as an INT, v_avg_latitude and v_avg_longitude as REAL, and v_most_common_crime as TEXT. It then executes a SELECT statement that joins the crime_incidents table (aliased as ci) with the crimes table (aliased as c) on the crime_id column, and from this joined dataset, it calculates the total count of rows, the average value of the latitude column, and the average value of the longitude column, storing these results into the variables v_total_incidents, v_avg_latitude, and v_avg_longitude respectively, but only for rows where the region_id column from the crime_incidents table equals the p_region_id parameter, the incident_date column from crime_incidents falls between the p_start_date and p_end_date parameters inclusive, and the severity_level column from the crimes table matches the p_severity_filter parameter. Next, the procedure executes a second SELECT statement that joins the crimes table (c) with the crime_incidents table (ci) again on crime_id, groups the results by the crime_name column from the crimes table, orders the groups in descending order based on the count of rows per group, and selects the single crime_name value from the top group, storing it into the v_most_common_crime variable, but only for rows filtered by the same conditions on region_id and incident_date matching p_region_id and the date range. Following this, the procedure performs an INSERT operation on the regions table, attempting to insert a new row with the following column values: region_id is set to the p_region_id parameter, region_name is set to the concatenation of the literal string 'Aggregated Stats ' and the p_region_id value, description is set to a concatenated string starting with 'Total: ', followed by the v_total_incidents value, then ', Common: ', followed by the v_most_common_crime value (or the string 'None' if that value is null via the COALESCE function), latitude is set to the v_avg_latitude variable, longitude is set to the v_avg_longitude variable, city is set to the literal 'Aggregated', state is set to the literal 'Stats', and country is set to the literal 'USA'. This INSERT command includes an ON CONFLICT clause that triggers when a conflict arises on the region_id column (which is presumably a primary key or unique constraint); in case of such a conflict, instead of inserting, it performs an UPDATE on the existing row, setting the region_name column to the value that would have been inserted (referenced as EXCLUDED.region_name), the description column to EXCLUDED.description, the latitude column to EXCLUDED.latitude, the longitude column to EXCLUDED.longitude, the city column to EXCLUDED.city, the state column to EXCLUDED.state, and the country column to EXCLUDED.country.",
    "original_summary": "Create a stored procedure named aggregate_crime_statistics that takes a region_id, start_date, end_date, and severity_filter. Calculate total incidents, average latitude/longitude, and the most common crime name for the filtered data. Insert or update a row in the regions table with these aggregated statistics.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called aggregate_crime_statistics? It needs to take a region_id, a start date, an end date, and a severity filter. Basically, we wanna crunch the numbers for that area and time: get the total number of incidents, the average lat and long, and figure out the crime that pops up the most. Then, take those stats and either put in a new row or update the existing one in the regions table."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `migrate_weather_data_by_temperature` that accepts a single input parameter, `p_threshold_temp`, which is of type `real` and represents a temperature threshold used for conditional logic. The procedure declares four local variables: `v_data_id` of type `bigint` to store the `data_id` from the `weather_data` table, `v_station_id` of type `bigint` to store the `station_id` from the `weather_data` table, `v_temp` of type `real` to store the `mean_temperature_f` from the `weather_data` table, and `v_new_station_id` of type `bigint` to temporarily hold a new station ID value before an update. It then defines a cursor named `data_cursor` that selects the `data_id`, `station_id`, and `mean_temperature_f` columns from the `weather_data` table, specifically filtering for rows where the `mean_temperature_f` column is not `NULL`. The procedure then iterates through each record returned by the `data_cursor`. For each `data_rec` in the cursor loop, it assigns the value of `data_rec.data_id` to `v_data_id`, the value of `data_rec.station_id` to `v_station_id`, and the value of `data_rec.mean_temperature_f` to `v_temp`. Inside the loop, it evaluates a series of conditional statements. If `v_temp` is greater than `p_threshold_temp` AND `v_station_id` is equal to `0`, it sets `v_new_station_id` to `1` and then updates the `weather_data` table by setting the `station_id` column to the value of `v_new_station_id` for the row where `data_id` matches `v_data_id`. Otherwise, if `v_temp` is greater than `p_threshold_temp` AND `v_station_id` is equal to `1`, it sets `v_new_station_id` to `0` and then updates the `weather_data` table by setting the `station_id` column to the value of `v_new_station_id` for the row where `data_id` matches `v_data_id`. Otherwise, if `v_temp` is less than or equal to `p_threshold_temp` AND `v_station_id` is equal to `0`, it updates the `weather_data` table by setting the `station_id` column to `1` for the row where `data_id` matches `v_data_id`. Otherwise, if `v_temp` is less than or equal to `p_threshold_temp` AND `v_station_id` is equal to `1`, it updates the `weather_data` table by setting the `station_id` column to `0` for the row where `data_id` matches `v_data_id`. In all other cases (the `ELSE` block), it updates the `weather_data` table by setting the `station_id` column to `0` for the row where `data_id` matches `v_data_id`. The loop continues until all records from the `data_cursor` have been processed.",
    "plsql": "CREATE OR REPLACE PROCEDURE migrate_weather_data_by_temperature(p_threshold_temp real)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_data_id bigint;\n    v_station_id bigint;\n    v_temp real;\n    v_new_station_id bigint;\n    data_cursor CURSOR FOR SELECT data_id, station_id, mean_temperature_f FROM weather_data WHERE mean_temperature_f IS NOT NULL;\nBEGIN\n    FOR data_rec IN data_cursor LOOP\n        v_data_id := data_rec.data_id;\n        v_station_id := data_rec.station_id;\n        v_temp := data_rec.mean_temperature_f;\n        \n        IF v_temp > p_threshold_temp AND v_station_id = 0 THEN\n            v_new_station_id := 1;\n            UPDATE weather_data SET station_id = v_new_station_id WHERE data_id = v_data_id;\n        ELSIF v_temp > p_threshold_temp AND v_station_id = 1 THEN\n            v_new_station_id := 0;\n            UPDATE weather_data SET station_id = v_new_station_id WHERE data_id = v_data_id;\n        ELSIF v_temp <= p_threshold_temp AND v_station_id = 0 THEN\n            UPDATE weather_data SET station_id = 1 WHERE data_id = v_data_id;\n        ELSIF v_temp <= p_threshold_temp AND v_station_id = 1 THEN\n            UPDATE weather_data SET station_id = 0 WHERE data_id = v_data_id;\n        ELSE\n            UPDATE weather_data SET station_id = 0 WHERE data_id = v_data_id;\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "weather_observation_and_forecasting_92747",
    "tables": [
      "predictions",
      "prediction_models",
      "weather_conditions",
      "weather_stations",
      "weather_data"
    ],
    "call_sqls": [
      "CALL migrate_weather_data_by_temperature(25.0);",
      "CALL migrate_weather_data_by_temperature(30.0);",
      "CALL migrate_weather_data_by_temperature(20.0);",
      "CALL migrate_weather_data_by_temperature(15.5);",
      "CALL migrate_weather_data_by_temperature(35.0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_weather_data_by_temperature that accepts a temperature threshold parameter p_threshold_temp and updates the station_id in the weather_data table for all records where mean_temperature_f is not null, swapping the station_id between 0 and 1 if the temperature exceeds the threshold, or setting it to the opposite value if the temperature is at or below the threshold.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_weather_data_by_temperature that takes a real parameter p_threshold_temp to update the station_id in the weather_data table for all records where mean_temperature_f is not null: if the temperature is greater than the threshold, swap the station_id between 0 and 1; if the temperature is less than or equal to the threshold, set the station_id to the opposite value (0 becomes 1, 1 becomes 0).",
    "id": 52,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `migrate_weather_data_by_temperature` that accepts a single input parameter, `p_threshold_temp`, which is of type `real` and represents a temperature threshold used for conditional logic. The procedure declares four local variables: `v_data_id` of type `bigint` to store the `data_id` from the `weather_data` table, `v_station_id` of type `bigint` to store the `station_id` from the `weather_data` table, `v_temp` of type `real` to store the `mean_temperature_f` from the `weather_data` table, and `v_new_station_id` of type `bigint` to temporarily hold a new station ID value before an update. It then defines a cursor named `data_cursor` that selects the `data_id`, `station_id`, and `mean_temperature_f` columns from the `weather_data` table, specifically filtering for rows where the `mean_temperature_f` column is not `NULL`. The procedure then iterates through each record returned by the `data_cursor`. For each `data_rec` in the cursor loop, it assigns the value of `data_rec.data_id` to `v_data_id`, the value of `data_rec.station_id` to `v_station_id`, and the value of `data_rec.mean_temperature_f` to `v_temp`. Inside the loop, it evaluates a series of conditional statements. If `v_temp` is greater than `p_threshold_temp` AND `v_station_id` is equal to `0`, it sets `v_new_station_id` to `1` and then updates the `weather_data` table by setting the `station_id` column to the value of `v_new_station_id` for the row where `data_id` matches `v_data_id`. Otherwise, if `v_temp` is greater than `p_threshold_temp` AND `v_station_id` is equal to `1`, it sets `v_new_station_id` to `0` and then updates the `weather_data` table by setting the `station_id` column to the value of `v_new_station_id` for the row where `data_id` matches `v_data_id`. Otherwise, if `v_temp` is less than or equal to `p_threshold_temp` AND `v_station_id` is equal to `0`, it updates the `weather_data` table by setting the `station_id` column to `1` for the row where `data_id` matches `v_data_id`. Otherwise, if `v_temp` is less than or equal to `p_threshold_temp` AND `v_station_id` is equal to `1`, it updates the `weather_data` table by setting the `station_id` column to `0` for the row where `data_id` matches `v_data_id`. In all other cases (the `ELSE` block), it updates the `weather_data` table by setting the `station_id` column to `0` for the row where `data_id` matches `v_data_id`. The loop continues until all records from the `data_cursor` have been processed.",
    "original_summary": "Create a stored procedure named migrate_weather_data_by_temperature that accepts a real parameter p_threshold_temp. For each weather data record with a temperature value, swap the station_id between 0 and 1 if the temperature exceeds the threshold, or set it to the opposite value if temperature is at or below the threshold.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create procedure migrate_weather_data_by_temperature with real param p_threshold_temp. For each record, swap station_id 0/1 if temp > threshold; set to opposite if temp <= threshold."
  },
  {
    "ir": "Write a PostgreSQL stored procedure named calculate_metric_statistics that accepts three input parameters: p_metric_category of type TEXT, threshold_multiplier of type REAL, and frequency_limit of type BIGINT, and begins by performing a SELECT query that calculates the average of the metric_threshold column from the performance_metrics table, joining it with the system_metrics table on the metric_id column, filtering for rows where the performance_metrics.metric_category matches the input parameter p_metric_category and the system_metrics.metric_frequency is less than or equal to the input parameter frequency_limit, then multiplies this computed average by the input parameter threshold_multiplier and stores the result into a local variable named avg_threshold_product; then, using an IF conditional statement, it checks if avg_threshold_product is not NULL and is greater than or equal to 1.0, and if true, it computes the inverse hyperbolic cosine of avg_threshold_product using the acosh function and assigns the result to a local variable named computed_value, but if the condition is false (meaning avg_threshold_product is NULL or less than 1.0), it assigns NULL to the computed_value variable; finally, the procedure executes an INSERT statement into the performance_metrics table, specifying values for the columns metric_id, metric_name, description, unit, metric_category, metric_threshold, and metric_criticality, where the metric_id value is determined by a subquery that selects the maximum existing metric_id from the performance_metrics table, uses the COALESCE function to return 0 if the maximum is NULL, and adds 1 to this result, the metric_name is set to the literal string 'Computed Metric', the description is set to 'Statistical analysis result', the unit is set to 'computed', the metric_category is set to the input parameter p_metric_category, the metric_threshold is set to the computed_value variable, and the metric_criticality is set to the literal string 'medium'.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_metric_statistics(IN p_metric_category TEXT, IN threshold_multiplier REAL, IN frequency_limit BIGINT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    computed_value REAL;\n    avg_threshold_product REAL;\nBEGIN\n    SELECT AVG(pm.metric_threshold) * threshold_multiplier INTO avg_threshold_product\n    FROM performance_metrics pm\n    JOIN system_metrics sm ON pm.metric_id = sm.metric_id\n    WHERE pm.metric_category = p_metric_category\n    AND sm.metric_frequency <= frequency_limit;\n\n    IF avg_threshold_product IS NOT NULL AND avg_threshold_product >= 1.0 THEN\n        computed_value := acosh(avg_threshold_product);\n    ELSE\n        -- Handle cases where acosh argument is less than 1 or NULL\n        -- For this problem, we'll set it to NULL if it's invalid for acosh\n        computed_value := NULL;\n    END IF;\n    \n    INSERT INTO performance_metrics (metric_id, metric_name, description, unit, metric_category, metric_threshold, metric_criticality)\n    VALUES (\n        (SELECT COALESCE(MAX(metric_id), 0) + 1 FROM performance_metrics),\n        'Computed Metric',\n        'Statistical analysis result',\n        'computed',\n        p_metric_category,\n        computed_value,\n        'medium'\n    );\nEND;\n$$;",
    "database_name": "system_performance_monitoring_and_analysis_481541",
    "tables": [
      "systems",
      "access_logs",
      "users",
      "system_metrics",
      "performance_metrics"
    ],
    "call_sqls": [
      "CALL calculate_metric_statistics('CPU', 1.5, 120);",
      "CALL calculate_metric_statistics('Memory', 2.0, 300);",
      "CALL calculate_metric_statistics('CPU', 1.2, 60);",
      "CALL calculate_metric_statistics('Network', 1.8, 180);",
      "CALL calculate_metric_statistics('Storage', 1.0, 600);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_metric_statistics that, for a given metric_category and frequency_limit, calculates the average metric_threshold from the performance_metrics table joined with system_metrics where metric_frequency does not exceed the limit, multiplies this average by a threshold_multiplier, and if the result is at least 1.0, computes its inverse hyperbolic cosine; otherwise, sets the computed value to NULL. It then inserts a new row into the performance_metrics table with a generated metric_id (as the next sequential integer), the computed threshold (or NULL), and sets metric_name to 'Computed Metric', description to 'Statistical analysis result', unit to 'computed', metric_category to the input category, and metric_criticality to 'medium'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called calculate_metric_statistics that calculates the average metric_threshold from the performance_metrics table for a given metric_category and frequency_limit, multiplies it by a threshold_multiplier, and if the result is at least 1.0, computes its inverse hyperbolic cosine; otherwise, sets the value to NULL. Then, insert a new row into the performance_metrics table with a unique metric_id, the computed value (or NULL), the provided metric_category, and predefined values for metric_name, description, unit, and metric_criticality.",
    "id": 53,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_metric_statistics that accepts three input parameters: p_metric_category of type text which specifies the metric category for which statistics are to be calculated, p_frequency_limit of type bigint which sets a limit on the metric_frequency for filtering related system_metrics records, and p_threshold_multiplier of type real which is a multiplier applied to the computed average threshold. The procedure declares a local variable v_avg_threshold of type real to store the calculated average metric_threshold, a local variable v_computed_value of type real to hold the final computed value after processing, and a local variable v_new_metric_id of type bigint to generate a unique identifier for the new performance_metrics row.\n\nThe procedure first calculates the average metric_threshold from the performance_metrics table by performing a SELECT statement that joins the performance_metrics table with the system_metrics table on the metric_id column, where the metric_category column in performance_metrics matches the p_metric_category parameter and the metric_frequency column in system_metrics is less than or equal to the p_frequency_limit parameter. This average is stored into v_avg_threshold.\n\nNext, the procedure multiplies v_avg_threshold by the p_threshold_multiplier parameter. It then checks if the resulting product is greater than or equal to 1.0 using an IF condition. If true, it computes the inverse hyperbolic cosine of the product using the ACOSH function and assigns this result to v_computed_value. If false, it sets v_computed_value to NULL.\n\nThen, the procedure generates a unique metric_id for the new row by selecting the maximum existing metric_id from the performance_metrics table, adding 1 to it, and using 0 as a default if the maximum is null via the COALESCE function; this is stored in v_new_metric_id.\n\nFinally, the procedure inserts a new row into the performance_metrics table with the following column values: metric_id set to v_new_metric_id, metric_name set to the string 'Computed Statistic', description set to the string 'Derived from average threshold calculations', unit set to the string 'unitless', metric_category set to the p_metric_category parameter, metric_threshold set to v_computed_value (which may be NULL), and metric_criticality set to the string 'medium'. The procedure does not return a value; it performs the insertion as its final operation.",
    "original_summary": "Create a stored procedure named calculate_metric_statistics that calculates the average metric_threshold for a given metric_category and frequency_limit, multiplies it by a threshold_multiplier, and if the result is >=1.0, computes its inverse hyperbolic cosine. It then inserts a new row into performance_metrics with a calculated ID, the computed threshold (or NULL), and sets category, name, description, unit, and criticality.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a comprehensive stored procedure, which shall be named calculate_metric_statistics, that meticulously calculates the average value of the metric_threshold specifically for a provided metric_category and a defined frequency_limit. This average is then carefully multiplied by a specified threshold_multiplier. Subsequently, a conditional check is performed: if the resulting product is greater than or equal to 1.0, the procedure must compute its intricate inverse hyperbolic cosine. Following these calculations, the procedure dutifully inserts a brand new row into the performance_metrics table. This new entry includes a uniquely calculated identifier, the computed final threshold valueor a NULL placeholder if the condition was not metand also thoughtfully populates the fields for category, name, a detailed description, unit of measurement, and the criticality level."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `insert_user_occupation` that accepts a single input parameter, `p_user_id`, of type `bigint`. This procedure is designed to conditionally insert a new record into the `occupations` table. The insertion operation proceeds only if a record with the `occupation_id` matching the provided `p_user_id` does not already exist in the `occupations` table. If such a record does not exist, a new row is inserted into the `occupations` table with the following column values: the `occupation_id` column is set to the value of the `p_user_id` parameter, the `occupation_name` column is set to the literal string 'Generated', the `description` column is set to the literal string 'Auto-generated occupation', the `category` column is set to the literal string 'System', and the `subcategory` column is set to the literal string 'User'. The condition for this insertion is evaluated by a subquery that selects the literal value `1` from the `occupations` table, filtering for rows where the `occupation_id` column is equal to the value of the `p_user_id` parameter. The `NOT EXISTS` clause ensures that the `INSERT` statement is executed only if this subquery returns no rows, indicating the absence of an existing occupation record for the given `p_user_id`.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_user_occupation(p_user_id bigint)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    INSERT INTO occupations (occupation_id, occupation_name, description, category, subcategory)\n    SELECT p_user_id, 'Generated', 'Auto-generated occupation', 'System', 'User'\n    WHERE NOT EXISTS (SELECT 1 FROM occupations WHERE occupation_id = p_user_id);\nEND;\n$$;",
    "database_name": "demographic_and_socioeconomic_data_analysis_40195",
    "tables": [
      "users",
      "roles",
      "user_roles",
      "permissions",
      "data_access",
      "data_collections",
      "education_levels",
      "occupations",
      "workclasses"
    ],
    "call_sqls": [
      "CALL insert_user_occupation(0);",
      "CALL insert_user_occupation(1);",
      "CALL insert_user_occupation(100);",
      "CALL insert_user_occupation(2);",
      "CALL insert_user_occupation(999);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named insert_user_occupation that accepts a user ID and, only if an occupation with that ID does not already exist in the occupations table, inserts a new record with that user ID as the occupation_id, setting the occupation_name to 'Generated', the description to 'Auto-generated occupation', the category to 'System', and the subcategory to 'User'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called insert_user_occupation that takes a user ID and, if no occupation with that ID already exists in the occupations table, inserts a new row using the user ID as the occupation_id, with preset values for occupation_name, description, category, and subcategory.",
    "id": 54,
    "generated_ir": "Write a PL/pgSQL stored procedure named `insert_user_occupation` that accepts one input parameter: `p_user_id` of type `bigint`. The purpose of this procedure is to conditionally insert a new record into the `occupations` table. The procedure begins by checking for the existence of a record in the `occupations` table where the `occupation_id` column matches the value provided in the `p_user_id` parameter. This is done using a `SELECT INTO` statement to attempt to fetch the `occupation_id` from the `occupations` table where `occupation_id = p_user_id`. The result is stored in a local variable, for example `v_existing_id`.\n\nFollowing this existence check, a conditional block is executed. If the `v_existing_id` variable is found to be `NULL` (indicating no occupation with that ID currently exists), then an `INSERT` operation is performed into the `occupations` table. The `INSERT` statement specifies values for all columns of the `occupations` table. The `occupation_id` column is set to the value of the input parameter `p_user_id`. The `occupation_name` column is set to a preset string literal, for example 'User-Defined Occupation'. The `description` column is set to a preset string literal, for example 'Occupation entry created from user ID'. The `category` column is set to a preset string literal, for example 'Custom'. The `subcategory` column is set to a preset string literal, for example 'User-Generated'.\n\nIf, however, the `v_existing_id` variable is not `NULL` (meaning an occupation with that ID already exists), then no `INSERT` operation is performed, and the procedure simply ends without taking any action. The procedure does not return a value; its effect is the potential insertion of a single row into the `occupations` table based on the conditional logic.",
    "original_summary": "Create a stored procedure named insert_user_occupation that accepts a user ID. Insert a new record into the occupations table only if an occupation with the given ID does not already exist. The new record should have the user ID as the occupation_id, with predefined values for name, description, category, and subcategory.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called insert_user_occupation that takes a user ID? Basically, it should add a new row to the occupations table, but only if there isn't already an occupation with that ID hanging around. For the new entry, just use the user ID as the occupation_id, and plug in some preset values for the name, description, category, and subcategory fields."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_dataset_statistics that accepts three input parameters: p_territory_level_id of type bigint to filter by a specific territory level identifier, p_start_year of type bigint to define the inclusive start year for a range, and p_end_year of type bigint to define the inclusive end year for a range; the procedure begins by declaring four local variables: v_avg_value and v_max_value and v_min_value of type real, and v_count of type bigint; it then executes a SELECT query on the datasets table, aliased as d, to calculate the average, maximum, minimum, and total count of the value column for all rows where the territory_level_id column equals the input parameter p_territory_level_id, and the year column is between the input parameters p_start_year and p_end_year inclusive, and the value column is not null; the results of these aggregate functions are stored into the corresponding local variables v_avg_value, v_max_value, v_min_value, and v_count; subsequently, the procedure performs an INSERT operation into the same datasets table, specifying the columns dataset_id, territory_level_id, year, value, and created_at; the value for the dataset_id column is determined by a scalar subquery that selects the maximum existing dataset_id from the datasets table, uses the COALESCE function to return 0 if the maximum is null, and adds 1 to this result; the territory_level_id column is populated with the input parameter p_territory_level_id; the year column is set to the input parameter p_end_year incremented by 1; the value column is set to the calculated average stored in v_avg_value; and the created_at column is populated by calling the NOW() function to get the current timestamp and formatting it to a string in 'YYYY-MM-DD HH24:MI:SS' format using the TO_CHAR function.",
    "plsql": "CREATE OR REPLACE PROCEDURE analyze_dataset_statistics(p_territory_level_id bigint, p_start_year bigint, p_end_year bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_avg_value real;\n    v_max_value real;\n    v_min_value real;\n    v_count bigint;\nBEGIN\n    SELECT AVG(value), MAX(value), MIN(value), COUNT(*)\n    INTO v_avg_value, v_max_value, v_min_value, v_count\n    FROM datasets d\n    WHERE d.territory_level_id = p_territory_level_id\n    AND d.year BETWEEN p_start_year AND p_end_year\n    AND d.value IS NOT NULL;\n\n    INSERT INTO datasets (dataset_id, territory_level_id, year, value, created_at)\n    VALUES (\n        (SELECT COALESCE(MAX(dataset_id), 0) + 1 FROM datasets),\n        p_territory_level_id,\n        p_end_year + 1,\n        v_avg_value,\n        TO_CHAR(NOW(), 'YYYY-MM-DD HH24:MI:SS')\n    );\nEND;\n$$;",
    "database_name": "demographic_and_health_statistics_652164",
    "tables": [
      "datasets",
      "territory_levels",
      "positions",
      "sex"
    ],
    "call_sqls": [
      "CALL analyze_dataset_statistics(1, 2010, 2020);",
      "CALL analyze_dataset_statistics(2, 2015, 2021);",
      "CALL analyze_dataset_statistics(3, 2000, 2010);",
      "CALL analyze_dataset_statistics(4, 1990, 2000);",
      "CALL analyze_dataset_statistics(5, 2020, 2023);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_dataset_statistics that accepts a territory level ID, a start year, and an end year, and for the specified territory and year range from the datasets table, calculates the average, maximum, minimum, and count of non-null values, then inserts a new summary record into the datasets table with a new dataset ID, using the input territory level ID, the year after the end year, the calculated average value, and the current timestamp.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called analyze_dataset_statistics that takes a territory ID, a start year, and an end year as inputs. For the specified territory ID and year range, compute the average, maximum, minimum, and count of non-null values from the datasets table. Then, insert a summary record into the datasets table with a new dataset ID, the given territory ID, the year following the end year, the computed average value, and the current timestamp.",
    "id": 55,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_dataset_statistics that accepts three input parameters: p_territory_id of type BIGINT representing the territory_level_id to filter datasets, p_start_year of type BIGINT representing the starting year for the range, and p_end_year of type BIGINT representing the ending year for the range. The procedure begins by declaring several variables: v_avg_value of type REAL to store the computed average value, v_max_value of type REAL to store the maximum value, v_min_value of type REAL to store the minimum value, v_count_values of type BIGINT to store the count of non-null values, v_new_dataset_id of type BIGINT to store the new dataset identifier for insertion, and v_current_timestamp of type TEXT to store the current timestamp as a string.\n\nThe procedure first computes the statistical summary from the datasets table. It performs a SELECT query that uses the AVG, MAX, MIN, and COUNT aggregate functions on the value column, filtering rows where territory_level_id equals p_territory_id, year is between p_start_year and p_end_year inclusive, and value is not null. The results are stored into the variables v_avg_value, v_max_value, v_min_value, and v_count_values respectively.\n\nNext, the procedure calculates v_new_dataset_id by selecting the maximum dataset_id from the datasets table, adding 1 to it, and using COALESCE to default to 1 if the table is empty (i.e., if max(dataset_id) returns null). It also sets v_current_timestamp by casting the current timestamp to TEXT.\n\nThe procedure then inserts a new record into the datasets table. The inserted values include: dataset_id as v_new_dataset_id, territory_level_id as p_territory_id, region_id as null, indicator_id as null, unit_id as null, position_id as null, sex_id as null, year as p_end_year + 1 (i.e., the year following the end year), time_period as null, value as v_avg_value, flag_codes as null, flags as null, data_collection_method as 'Statistical Summary', data_collection_frequency as 'One-time', version as 1, created_at as v_current_timestamp, and updated_at as v_current_timestamp. All other columns not explicitly set are inserted as null.\n\nThe procedure does not include any explicit control flow such as conditionals or loops beyond the basic aggregation and insertion. It returns void, as it is a procedure that performs data modification without returning a result set.",
    "original_summary": "Create a stored procedure named analyze_dataset_statistics that accepts a territory level ID, a start year, and an end year. Calculate the average, maximum, minimum, and count of non-null values for the specified territory and year range. Insert a new summary record into the datasets table with a new ID, using the input territory ID, the year after the end year, the calculated average value, and the current timestamp.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create procedure analyze_dataset_statistics with territory ID, start year, end year. Compute average, max, min, count for that range. Insert summary into datasets: new ID, given territory ID, next year, average, current time."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named migrate_crime_categories that accepts four parameters: p_old_category of type TEXT, p_new_category of type TEXT, p_severity_level of type TEXT, and p_subcategory_pattern of type TEXT. The procedure iterates over records in the crimes table where the crime_category matches p_old_category, the severity_level matches p_severity_level, and the crime_subcategory contains the pattern specified by p_subcategory_pattern. For each matching record, it updates the crime_category to p_new_category and modifies the crime_subcategory by prefixing it with 'Migrated '. The procedure maintains a count of updated records using the variable v_updated_count. If no records are updated, it inserts a new record into the crimes table with a unique crime_id, determined by selecting the maximum existing crime_id and adding one, a crime_name prefixed with 'Placeholder ' followed by p_new_category, a description indicating no crimes were migrated for the specified p_old_category, the new crime_category as p_new_category, a crime_subcategory set to 'Migration', and the specified severity_level as p_severity_level.",
    "plsql": "CREATE OR REPLACE PROCEDURE migrate_crime_categories(\n    p_old_category TEXT,\n    p_new_category TEXT,\n    p_severity_level TEXT,\n    p_subcategory_pattern TEXT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_crime_record RECORD;\n    v_updated_count INT := 0;\nBEGIN\n    FOR v_crime_record IN\n        SELECT crime_id, crime_name, crime_subcategory\n        FROM crimes\n        WHERE crime_category = p_old_category\n        AND severity_level = p_severity_level\n        AND crime_subcategory LIKE '%' || p_subcategory_pattern || '%'\n    LOOP\n        -- Instead of deleting and potentially re-inserting, update the existing crime record\n        -- to avoid foreign key violations.\n        UPDATE crimes\n        SET\n            crime_category = p_new_category,\n            crime_subcategory = 'Migrated ' || v_crime_record.crime_subcategory -- Update subcategory as well if needed\n        WHERE crime_id = v_crime_record.crime_id;\n\n        -- If the intention was to create a new entry in crime_subcategories for the migrated crime,\n        -- this part would be re-added, but it's not directly related to the FK violation on 'crimes'.\n        -- For now, we assume the primary goal is to update the main crime record.\n        -- INSERT INTO crime_subcategories (subcategory_id, crime_id, subcategory_name, description)\n        -- VALUES ((SELECT COALESCE(MAX(subcategory_id), 0) + 1 FROM crime_subcategories),\n        --         v_crime_record.crime_id,\n        --         'Migrated ' || v_crime_record.crime_subcategory,\n        --         'Migrated from ' || p_old_category || ' to ' || p_new_category);\n\n        v_updated_count := v_updated_count + 1;\n    END LOOP;\n\n    IF v_updated_count = 0 THEN\n        -- Ensure crime_id is unique. Using COALESCE for MAX(crime_id) + 1 to handle empty table.\n        INSERT INTO crimes (crime_id, crime_name, description, crime_category, crime_subcategory, severity_level)\n        VALUES ((SELECT COALESCE(MAX(crime_id), 0) + 1 FROM crimes), 'Placeholder ' || p_new_category,\n                'No crimes migrated for ' || p_old_category, p_new_category, 'Migration', p_severity_level);\n    END IF;\nEND;\n$$;",
    "database_name": "crime_statistics_and_reporting_791805",
    "tables": [
      "crimes",
      "crime_incidents",
      "crime_subcategories",
      "neighborhoods",
      "regions"
    ],
    "call_sqls": [
      "CALL migrate_crime_categories('Environmental', 'Public Order', 'Low', 'Waste');",
      "CALL migrate_crime_categories('Public Disturbance', 'Social Disorder', 'Medium', 'Alcohol');",
      "CALL migrate_crime_categories('Theft', 'Property Crime', 'High', 'Shoplifting');",
      "CALL migrate_crime_categories('Environmental', 'Public Order', 'Medium', 'Litter');",
      "CALL migrate_crime_categories('NonExistentCategory', 'NewCategory', 'Low', 'Pattern');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_crime_categories that takes an old_category, new_category, severity_level, and subcategory_pattern to update matching crime records in the crimes table. For crimes where the crime_category matches old_category, the severity_level matches the given severity_level, and the crime_subcategory contains the subcategory_pattern, update the crime_category to new_category and prefix the crime_subcategory with 'Migrated '. If no such crimes are found, insert a placeholder crime record into crimes with a unique crime_id, a crime_name indicating the new category, a description stating no migration occurred, the new_category as crime_category, 'Migration' as crime_subcategory, and the provided severity_level.",
    "natural_language": "Hey, can you whip up a PostgreSQL PL/pgSQL stored procedure called migrate_crime_categories? It needs to take in the old_category, new_category, severity_level, and a subcategory_pattern. Basically, go through the crimes table and update any crimes that match the old_category and severity_level and have a crime_subcategory containing the subcategory_pattern, switching their crime_category to the new_category and slapping 'Migrated ' in front of the crime_subcategory. Oh, and if nothing gets updated, just toss in a placeholder crime record into crimes to say no migration happened, with a crime_name like 'Placeholder ' plus the new_category, a description indicating no migration, a crime_category set to the new_category, a crime_subcategory as 'Migration', and the given severity_level.",
    "id": 56,
    "generated_ir": "Write a PLpgSQL stored procedure named migrate_crime_categories that accepts four parameters: p_old_category of type TEXT, p_new_category of type TEXT, p_severity_level of type TEXT, and p_subcategory_pattern of type TEXT. The procedure iterates over records in the crimes table where the crime_category matches p_old_category, the severity_level matches p_severity_level, and the crime_subcategory contains the pattern specified by p_subcategory_pattern. For each matching record, it updates the crime_category to p_new_category and modifies the crime_subcategory by prefixing it with 'Migrated '. The procedure maintains a count of updated records using the variable v_updated_count. If no records are updated, it inserts a new record into the crimes table with a unique crime_id, determined by selecting the maximum existing crime_id and adding one, a crime_name prefixed with 'Placeholder ' followed by p_new_category, a description indicating no crimes were migrated for the specified p_old_category, the new crime_category as p_new_category, a crime_subcategory set to 'Migration', and the specified severity_level as p_severity_level.",
    "original_summary": "Create a stored procedure named migrate_crime_categories that takes old_category, new_category, severity_level, and subcategory_pattern. Update matching crimes in the crimes table, changing the category and prefixing the subcategory with 'Migrated '. If no rows were updated, insert a placeholder crime record indicating no migration occurred.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called migrate_crime_categories? It needs to take in the old_category, new_category, severity_level, and a subcategory_pattern. Basically, go through the crimes table and update any crimes that match, switching their category and slapping 'Migrated ' in front of the subcategory. Oh, and if nothing gets updated, just toss in a placeholder crime record to say no migration happened."
  },
  {
    "ir": "Write a PostgreSQL stored procedure named `remove_patient_data` that accepts three input parameters: `p_patient_id` of type `bigint`, `p_data_type` of type `text`, and `p_confirmation_code` of type `text`. The purpose of this procedure is to conditionally delete specific types of patient-related data from various tables based on the provided data type and a confirmation code. The procedure's logic flow is as follows: it first evaluates a conditional statement. If the value of the `p_data_type` parameter is exactly equal to the string literal 'genetic' AND the value of the `p_confirmation_code` parameter is exactly equal to the string literal 'CONFIRM', then it proceeds to execute a `DELETE` operation. This `DELETE` operation targets the `genetic_markers` table, removing all rows where the `patient_id` column matches the value provided in the `p_patient_id` parameter. If the first condition is not met, the procedure then evaluates an alternative conditional statement. If the value of the `p_data_type` parameter is exactly equal to the string literal 'lifestyle' AND the value of the `p_confirmation_code` parameter is exactly equal to the string literal 'CONFIRM', then it executes a `DELETE` operation. This `DELETE` operation targets the `lifestyle_factors` table, removing all rows where the `patient_id` column matches the value provided in the `p_patient_id` parameter. If neither of the preceding conditions is met, the procedure evaluates a final alternative conditional statement. If the value of the `p_data_type` parameter is exactly equal to the string literal 'imaging' AND the value of the `p_confirmation_code` parameter is exactly equal to the string literal 'CONFIRM', then it executes a `DELETE` operation. This `DELETE` operation targets the `neuroimaging` table, removing all rows where the `patient_id` column matches the value provided in the `p_patient_id` parameter. If none of these conditions are met, no data modification operations are performed by the procedure.",
    "plsql": "CREATE OR REPLACE PROCEDURE remove_patient_data(p_patient_id bigint, p_data_type text, p_confirmation_code text)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    IF p_data_type = 'genetic' AND p_confirmation_code = 'CONFIRM' THEN\n        DELETE FROM genetic_markers WHERE patient_id = p_patient_id;\n    ELSIF p_data_type = 'lifestyle' AND p_confirmation_code = 'CONFIRM' THEN\n        DELETE FROM lifestyle_factors WHERE patient_id = p_patient_id;\n    ELSIF p_data_type = 'imaging' AND p_confirmation_code = 'CONFIRM' THEN\n        DELETE FROM neuroimaging WHERE patient_id = p_patient_id;\n    END IF;\nEND;\n$$;",
    "database_name": "medical_research_and_patient_data_management",
    "tables": [
      "genetic_markers",
      "lifestyle_factors",
      "neuroimaging",
      "treatment_outcomes",
      "users"
    ],
    "call_sqls": [
      "CALL remove_patient_data(1, 'genetic', 'CONFIRM');",
      "CALL remove_patient_data(2, 'lifestyle', 'CONFIRM');",
      "CALL remove_patient_data(1, 'imaging', 'CONFIRM');",
      "CALL remove_patient_data(2, 'genetic', 'CONFIRM');",
      "CALL remove_patient_data(1, 'lifestyle', 'CONFIRM');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `remove_patient_data` that deletes patient data from specific tables based on the provided data type and a confirmation code. The procedure takes a patient ID, a data type (which can be 'genetic', 'lifestyle', or 'imaging'), and a confirmation code. If the data type is 'genetic' and the confirmation code is 'CONFIRM', it deletes all records for that patient from the `genetic_markers` table. If the data type is 'lifestyle' and the confirmation code is 'CONFIRM', it deletes from the `lifestyle_factors` table. If the data type is 'imaging' and the confirmation code is 'CONFIRM', it deletes from the `neuroimaging` table. If the conditions are not met, no action is taken.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `remove_patient_data` that deletes patient data from the system only when a confirmation code is 'CONFIRM'. For the 'genetic' data type, delete the patient's records from the `genetic_markers` table. For 'lifestyle', delete from the `lifestyle_factors` table. For 'imaging', delete from the `neuroimaging` table. If the data type or confirmation code does not match, do not perform any deletion.",
    "id": 57,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `remove_patient_data` that accepts two input parameters: `data_type` of type `text` and `confirmation_code` of type `text`. The procedure's purpose is to conditionally delete patient data from specific tables in the medical_research_and_patient_data_management database based on the provided data type, but only if a confirmation code is exactly 'CONFIRM'. The procedure does not return a value; it performs a deletion operation.\n\nThe procedure begins by checking the value of the `confirmation_code` parameter. If `confirmation_code` is not equal to the string literal 'CONFIRM', the procedure immediately exits without performing any database operations.\n\nIf the `confirmation_code` is 'CONFIRM', the procedure proceeds to evaluate the `data_type` parameter. It uses a conditional control flow structure (an IF-ELSIF-ELSE or CASE statement) to determine which table to delete from.\n\nIf the `data_type` parameter is equal to the string 'genetic', the procedure executes a `DELETE` statement on the `genetic_markers` table. This `DELETE` statement has no `WHERE` clause, meaning it will delete all rows from the `genetic_markers` table.\n\nIf the `data_type` parameter is equal to the string 'lifestyle', the procedure executes a `DELETE` statement on the `lifestyle_factors` table. This `DELETE` statement also has no `WHERE` clause, meaning it will delete all rows from the `lifestyle_factors` table.\n\nIf the `data_type` parameter is equal to the string 'imaging', the procedure executes a `DELETE` statement on the `neuroimaging` table. This `DELETE` statement also has no `WHERE` clause, meaning it will delete all rows from the `neuroimaging` table.\n\nIf the `data_type` parameter does not match any of the specified strings ('genetic', 'lifestyle', or 'imaging'), the procedure does not execute any `DELETE` statement, even though the confirmation code was correct. The procedure then concludes.\n\nNo local variables are declared within this procedure. The logic is driven entirely by the input parameters and the conditional checks. The procedure interacts with three tables: `genetic_markers`, `lifestyle_factors`, and `neuroimaging`. The deletions are unconditional and will remove all records from the targeted table. The procedure does not involve the `treatment_outcomes` or `users` tables.",
    "original_summary": "Create a stored procedure named `remove_patient_data` that conditionally deletes patient data based on data type and confirmation code. If `p_data_type` is 'genetic' and `p_confirmation_code` is 'CONFIRM', delete from `genetic_markers` where `patient_id` matches. If 'lifestyle' and 'CONFIRM', delete from `lifestyle_factors`. If 'imaging' and 'CONFIRM', delete from `neuroimaging`. Otherwise, perform no action.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure called `remove_patient_data` that deletes patient data only when a confirmation code is 'CONFIRM'. For 'genetic' data type, delete from the `genetic_markers` table. For 'lifestyle', delete from `lifestyle_factors`. For 'imaging', delete from `neuroimaging`. If the data type or code doesn't match, do nothing."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named create_validation_record that accepts two parameters: p_county_id of type bigint, representing the identifier of a county, and p_score of type real, representing a score related to data quality. The procedure begins by declaring two local variables, v_status and v_message, both of type text, which will be used to store the status and message of the validation process. The procedure then evaluates the value of p_score using an IF conditional statement. If p_score is greater than or equal to 90.0, it assigns the value 'passed' to v_status and 'Excellent data quality' to v_message. Otherwise, it assigns 'failed' to v_status and 'Data quality needs improvement' to v_message. Following this conditional logic, the procedure performs an INSERT operation into the data_validations table, which consists of six columns: validation_id, county_id, validation_date, validation_status, validation_message, and validation_score. The validation_id is determined by selecting the maximum existing validation_id from the data_validations table, using the COALESCE function to handle null values, and incrementing it by one to ensure a unique identifier for the new record. The county_id column is populated with the value of the p_county_id parameter. The validation_date column is set to the current date, converted to text format using the ::text cast operation. The validation_status and validation_message columns are populated with the values of v_status and v_message, respectively, which were determined based on the p_score evaluation. Finally, the validation_score column is populated with the value of the p_score parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE create_validation_record(p_county_id bigint, p_score real)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_status text;\n    v_message text;\nBEGIN\n    IF p_score >= 90.0 THEN\n        v_status := 'passed';\n        v_message := 'Excellent data quality';\n    ELSE\n        v_status := 'failed';\n        v_message := 'Data quality needs improvement';\n    END IF;\n    \n    INSERT INTO data_validations (validation_id, county_id, validation_date, validation_status, validation_message, validation_score)\n    VALUES (\n        (SELECT COALESCE(MAX(validation_id), 0) + 1 FROM data_validations),\n        p_county_id,\n        CURRENT_DATE::text,\n        v_status,\n        v_message,\n        p_score\n    );\nEND;\n$$;",
    "database_name": "demographic_and_economic_data_for_us_counties_159057",
    "tables": [
      "access_logs",
      "counties",
      "data_validations",
      "users"
    ],
    "call_sqls": [
      "CALL create_validation_record(0, 95.5);",
      "CALL create_validation_record(1, 88.2);",
      "CALL create_validation_record(0, 70.0);",
      "CALL create_validation_record(1, 90.0);",
      "CALL create_validation_record(0, 99.9);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named create_validation_record that accepts a county ID and a score, determines a status of 'passed' with the message 'Excellent data quality' if the score is at least 90 or 'failed' with the message 'Data quality needs improvement' otherwise, and inserts a new record into the data_validations table with a new validation ID (the maximum existing validation_id plus one, starting from 1 if none exist), the provided county_id and score, today's date as text, and the determined status and message.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called 'create_validation_record' that takes a county ID and a score, determines a 'passed' status and message if the score is 90 or higher or 'failed' otherwise, and inserts a new record into the 'data_validations' table with an auto-incremented validation ID, the provided county ID and score, today's date as text, and the determined status and message.",
    "id": 58,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named create_validation_record that accepts two input parameters: county_id_input of type BIGINT, representing the county identifier, and score_input of type REAL, representing the validation score. The procedure performs an INSERT operation into the data_validations table. It first determines the validation_status and validation_message based on the score_input parameter: if score_input is greater than or equal to 90.0, set validation_status to the string 'passed' and validation_message to the string 'Validation passed with high score'; otherwise, set validation_status to the string 'failed' and validation_message to the string 'Validation failed due to low score'. The INSERT statement includes values for all columns: validation_id is generated automatically using the next value from the sequence associated with the validation_id column (assuming it is a SERIAL or BIGSERIAL type, typically via nextval('data_validations_validation_id_seq') or DEFAULT), county_id is set to county_id_input, validation_date is set to the current date converted to text format using CURRENT_DATE::TEXT, validation_status and validation_message are set to the determined values as described, and validation_score is set to score_input. The procedure does not return any value and operates solely to insert a new validation record with the computed status and message based on the provided score.",
    "original_summary": "Create a stored procedure named create_validation_record that accepts a bigint county ID and a real score. It should determine a status ('passed'/'failed') and message based on whether the score is >= 90. Then, insert a record into the data_validations table with a new validation ID (max existing + 1), the provided county ID and score, today's date as text, and the determined status and message.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called 'create_validation_record'? It needs to take in a county ID (as a bigint) and a score (as a real number). Basically, check if the score is 90 or more to figure out if it 'passed' or 'failed' and set a message. Then, toss a new record into the 'data_validations' table. For the validation ID, just grab the highest existing one and add 1 to it. Pop in the county ID and score we got, use today's date as text, and slap on the status and message we figured out."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `delete_old_updates` that accepts a single input parameter. This parameter, named `p_cutoff_date`, is of data type `text` and represents a specific date or timestamp. The purpose of this procedure is to perform a data manipulation operation, specifically a `DELETE` statement, on the `size_updates` table. The `DELETE` operation targets rows within the `size_updates` table where the value in the `update_date` column is strictly less than the value provided by the `p_cutoff_date` parameter. The `update_date` column is implicitly assumed to be of a date or timestamp compatible data type, allowing for direct comparison with the `text` input parameter `p_cutoff_date`. The procedure does not return any value.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_old_updates(\n    p_cutoff_date text\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM size_updates \n    WHERE update_date < p_cutoff_date;\nEND;\n$$;",
    "database_name": "apparel_sizing_and_measurement_standards_543314",
    "tables": [
      "measurements",
      "size_updates",
      "users"
    ],
    "call_sqls": [
      "CALL delete_old_updates('2023-06-01');",
      "CALL delete_old_updates('2023-01-01');",
      "CALL delete_old_updates('2022-12-31');",
      "CALL delete_old_updates('2024-01-01');",
      "CALL delete_old_updates('2020-01-01');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named delete_old_updates that accepts a cutoff date as a text parameter and deletes all records from the size_updates table where the update_date is earlier than the provided cutoff date.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called delete_old_updates that takes a text parameter p_cutoff_date to delete all records from the size_updates table where the update_date is older than the given cutoff date.",
    "id": 59,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `delete_old_updates` that accepts one input parameter: `p_cutoff_date` of type `text`, representing a date string used as a threshold for deletion. The procedure does not declare any local variables. The sole operation is a `DELETE` statement executed on the `size_updates` table. This `DELETE` statement removes all rows from the `size_updates` table where the `update_date` column, which is of type `text`, is less than the input `p_cutoff_date` parameter. The comparison is performed directly as a string comparison because both operands are of type `text`. The procedure does not include any conditional logic, loops, or return values; it simply performs the deletion and then completes.",
    "original_summary": "Create a stored procedure named delete_old_updates that accepts a text parameter p_cutoff_date. Delete all records from the size_updates table where the update_date is earlier than the provided cutoff date.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure called delete_old_updates that takes a text parameter p_cutoff_date to delete all records from the size_updates table where the update_date is older than the given cutoff date?"
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named generate_author_performance_report that accepts a single input parameter p_author_id of type BIGINT, which identifies the author for whom a performance report is generated. The procedure begins by declaring local variables: v_total_submissions, v_accepted_papers, v_rejected_papers, and v_under_review as INTEGER; v_total_citations as INTEGER; v_avg_rating and v_success_rate as REAL; v_author_name and v_institution as TEXT; journal_rec as a RECORD; and v_journal_count as INTEGER. It first retrieves the author's name and institution from the authors table where the author_id matches p_author_id, storing them into v_author_name and v_institution. It then calculates the total number of submissions by counting all rows in the manuscripts table for the given author_id, storing the result in v_total_submissions. Next, it computes the number of accepted papers by counting manuscripts for the author where a corresponding entry in the editor_decisions table has a decision column value of 'accept', storing the count in v_accepted_papers. Similarly, it calculates the number of rejected papers by counting manuscripts for the author where the editor_decisions decision is 'reject', storing the count in v_rejected_papers. It determines the number of manuscripts currently under review by counting rows in the manuscripts table for the author where the status column equals 'under review', storing the result in v_under_review. The total citation count is computed by summing the citation_count from the publications table for all publications linked to the author's manuscripts, using COALESCE to return 0 if the sum is NULL, and storing it in v_total_citations. The average rating is calculated by averaging the rating column from the reviews table for reviews linked to the author's manuscripts, converting rating to REAL and using COALESCE to return 0 if the average is NULL, storing it in v_avg_rating. The success rate is then derived: if v_total_submissions is greater than 0, v_success_rate is set to v_accepted_papers divided by v_total_submissions (both cast to REAL); otherwise, it is set to 0. The procedure also counts the distinct journal_id values from the manuscripts table for the author, storing the result in v_journal_count. It then updates the authors table for the specific author_id by appending a performance summary string to the biography column, using COALESCE to handle NULL biography values, with the appended text containing the accepted paper count and total citation count. Following this, if the calculated v_success_rate is greater than 0.7 and v_avg_rating is greater than 4.0, the procedure enters a conditional loop: for each distinct journal (journal_id and journal_name) from the journals table that the author has submitted to (via manuscripts), it performs an INSERT into the referee_invitations table. For each such journal, it inserts a single row (LIMIT 1) where the invitation_id is generated as the sum of the current epoch timestamp (converted to BIGINT) and the manuscript's manuscript_id, the manuscript_id is from manuscripts belonging to that journal but authored by a different author (author_id != p_author_id) and with status 'under review', the referee_id is set to the input p_author_id, the invitation_date is the current date as TEXT, and the status is 'pending', but only if no existing invitation for that manuscript and referee combination exists (checked via a NOT EXISTS subquery against the referee_invitations table).",
    "plsql": "CREATE OR REPLACE PROCEDURE generate_author_performance_report(p_author_id BIGINT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_total_submissions INTEGER;\n    v_accepted_papers INTEGER;\n    v_rejected_papers INTEGER;\n    v_under_review INTEGER;\n    v_total_citations INTEGER;\n    v_avg_rating REAL;\n    v_success_rate REAL;\n    v_author_name TEXT;\n    v_institution TEXT;\n    journal_rec RECORD;\n    v_journal_count INTEGER;\nBEGIN\n    SELECT author_name, institution INTO v_author_name, v_institution\n    FROM authors WHERE author_id = p_author_id;\n    \n    SELECT COUNT(*) INTO v_total_submissions\n    FROM manuscripts WHERE author_id = p_author_id;\n    \n    SELECT COUNT(*) INTO v_accepted_papers\n    FROM manuscripts m\n    JOIN editor_decisions ed ON m.manuscript_id = ed.manuscript_id\n    WHERE m.author_id = p_author_id AND ed.decision = 'accept';\n    \n    SELECT COUNT(*) INTO v_rejected_papers\n    FROM manuscripts m\n    JOIN editor_decisions ed ON m.manuscript_id = ed.manuscript_id\n    WHERE m.author_id = p_author_id AND ed.decision = 'reject';\n    \n    SELECT COUNT(*) INTO v_under_review\n    FROM manuscripts WHERE author_id = p_author_id AND status = 'under review';\n    \n    SELECT COALESCE(SUM(p.citation_count), 0) INTO v_total_citations\n    FROM publications p\n    JOIN manuscripts m ON p.manuscript_id = m.manuscript_id\n    WHERE m.author_id = p_author_id;\n    \n    SELECT COALESCE(AVG(r.rating::REAL), 0) INTO v_avg_rating\n    FROM reviews r\n    JOIN manuscripts m ON r.manuscript_id = m.manuscript_id\n    WHERE m.author_id = p_author_id;\n    \n    IF v_total_submissions > 0 THEN\n        v_success_rate := v_accepted_papers::REAL / v_total_submissions::REAL;\n    ELSE\n        v_success_rate := 0;\n    END IF;\n    \n    SELECT COUNT(DISTINCT m.journal_id) INTO v_journal_count\n    FROM manuscripts m WHERE m.author_id = p_author_id;\n    \n    UPDATE authors \n    SET biography = COALESCE(biography, '') || ' Performance: ' || v_accepted_papers || ' accepted papers, ' || v_total_citations || ' total citations.'\n    WHERE author_id = p_author_id;\n    \n    IF v_success_rate > 0.7 AND v_avg_rating > 4.0 THEN\n        FOR journal_rec IN \n            SELECT DISTINCT j.journal_id, j.journal_name\n            FROM journals j\n            JOIN manuscripts m ON j.journal_id = m.journal_id\n            WHERE m.author_id = p_author_id\n        LOOP\n            INSERT INTO referee_invitations (invitation_id, manuscript_id, referee_id, invitation_date, status)\n            SELECT \n                EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)::BIGINT + m.manuscript_id,\n                m.manuscript_id,\n                p_author_id,\n                CURRENT_DATE::TEXT,\n                'pending'\n            FROM manuscripts m\n            WHERE m.journal_id = journal_rec.journal_id \n            AND m.author_id != p_author_id \n            AND m.status = 'under review'\n            AND NOT EXISTS (\n                SELECT 1 FROM referee_invitations ri \n                WHERE ri.manuscript_id = m.manuscript_id AND ri.referee_id = p_author_id\n            )\n            LIMIT 1;\n        END LOOP;\n    END IF;\nEND;\n$$;",
    "database_name": "academic_journal_management_and_publication",
    "tables": [
      "authors",
      "manuscripts",
      "journals",
      "editor_decisions",
      "reviews",
      "referee_invitations",
      "publications",
      "invoice"
    ],
    "call_sqls": [
      "CALL generate_author_performance_report(1);",
      "CALL generate_author_performance_report(0);",
      "CALL generate_author_performance_report(100);",
      "CALL generate_author_performance_report(25);",
      "CALL generate_author_performance_report(42);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named generate_author_performance_report that takes an author_id to generate a performance report for the author. Retrieve the author's name and institution from the AUTHORS table, then calculate the total number of submissions, accepted papers, rejected papers, and papers under review from the MANUSCRIPTS and EDITOR_DECISIONS tables, total citations from the PUBLICATIONS table, and average rating from the REVIEWS table. Compute the success rate as accepted papers divided by total submissions. Update the author's biography in the AUTHORS table by appending a performance summary with the accepted paper count and total citations. If the success rate exceeds 0.7 and the average rating exceeds 4.0, insert referee invitations into the REFEREE_INVITATIONS table for the author to review one manuscript per distinct journal they have submitted to, ensuring no duplicate invitations for the same manuscript and author, and only for manuscripts from other authors that are under review.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called generate_author_performance_report that takes an author_id and retrieves the author's details from the AUTHORS table, then calculates their total submissions, accepted papers, rejected papers, and papers under review from the MANUSCRIPTS and EDITOR_DECISIONS tables, along with total citations from PUBLICATIONS, average rating from REVIEWS, and success rate. Update the author's biography in the AUTHORS table with a performance summary. If the success rate exceeds 0.7 and the average rating is above 4.0, insert invitations for the author as a referee into the REFEREE_INVITATIONS table for one manuscript per distinct journal from JOURNALS where the author has previously submitted, ensuring no duplicate invitations are created.",
    "id": 60,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named generate_author_performance_report that accepts a single input parameter p_author_id of type BIGINT, which identifies the author for whom a performance report is generated. The procedure begins by declaring local variables: v_total_submissions, v_accepted_papers, v_rejected_papers, and v_under_review as INTEGER; v_total_citations as INTEGER; v_avg_rating and v_success_rate as REAL; v_author_name and v_institution as TEXT; journal_rec as a RECORD; and v_journal_count as INTEGER. It first retrieves the author's name and institution from the authors table where the author_id matches p_author_id, storing them into v_author_name and v_institution. It then calculates the total number of submissions by counting all rows in the manuscripts table for the given author_id, storing the result in v_total_submissions. Next, it computes the number of accepted papers by counting manuscripts for the author where a corresponding entry in the editor_decisions table has a decision column value of 'accept', storing the count in v_accepted_papers. Similarly, it calculates the number of rejected papers by counting manuscripts for the author where the editor_decisions decision is 'reject', storing the count in v_rejected_papers. It determines the number of manuscripts currently under review by counting rows in the manuscripts table for the author where the status column equals 'under review', storing the result in v_under_review. The total citation count is computed by summing the citation_count from the publications table for all publications linked to the author's manuscripts, using COALESCE to return 0 if the sum is NULL, and storing it in v_total_citations. The average rating is calculated by averaging the rating column from the reviews table for reviews linked to the author's manuscripts, converting rating to REAL and using COALESCE to return 0 if the average is NULL, storing it in v_avg_rating. The success rate is then derived: if v_total_submissions is greater than 0, v_success_rate is set to v_accepted_papers divided by v_total_submissions (both cast to REAL); otherwise, it is set to 0. The procedure also counts the distinct journal_id values from the manuscripts table for the author, storing the result in v_journal_count. It then updates the authors table for the specific author_id by appending a performance summary string to the biography column, using COALESCE to handle NULL biography values, with the appended text containing the accepted paper count and total citation count. Following this, if the calculated v_success_rate is greater than 0.7 and v_avg_rating is greater than 4.0, the procedure enters a conditional loop: for each distinct journal (journal_id and journal_name) from the journals table that the author has submitted to (via manuscripts), it performs an INSERT into the referee_invitations table. For each such journal, it inserts a single row (LIMIT 1) where the invitation_id is generated as the sum of the current epoch timestamp (converted to BIGINT) and the manuscript's manuscript_id, the manuscript_id is from manuscripts belonging to that journal but authored by a different author (author_id != p_author_id) and with status 'under review', the referee_id is set to the input p_author_id, the invitation_date is the current date as TEXT, and the status is 'pending', but only if no existing invitation for that manuscript and referee combination exists (checked via a NOT EXISTS subquery against the referee_invitations table).",
    "original_summary": "Create a stored procedure named generate_author_performance_report that takes an author_id. Retrieve author details, calculate submission counts (total, accepted, rejected, under review), total citations, average rating, and success rate. Update the author's biography with a performance summary. If success rate > 0.7 and average rating > 4.0, insert referee invitations for the author to review manuscripts from distinct journals they have submitted to, ensuring no duplicate invitations.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Compose a stored procedure designated as 'generate_author_performance_report' which accepts an author_id parameter. The procedure shall retrieve the author's details, compute the counts of their submissionscategorized as total, accepted, rejected, and under reviewalong with the total citation count, average rating, and success rate. Subsequently, update the author's biography with a synthesized performance summary. In the event that the calculated success rate exceeds 0.7 and the average rating surpasses 4.0, insert invitations for the author to serve as a referee. These invitations should pertain to manuscripts from distinct journals to which the author has previously submitted, with care taken to preclude duplicate entries."
  },
  {
    "ir": "Write a PLpgSQL stored procedure that inserts a new record into the units_of_measure table with a unique unit_id, which is determined by selecting the maximum existing unit_id from the table and adding one to it, or using 1 if the table is empty. The procedure takes two parameters: p_unit_name of type text, which specifies the name of the unit of measure to be inserted, and p_unit_symbol of type text, which specifies the symbol associated with the unit of measure. The procedure constructs the unit_description by concatenating the string 'Description for ' with the provided p_unit_name. The new record is inserted with the calculated unit_id, the provided p_unit_name, the constructed unit_description, and the provided p_unit_symbol.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_new_unit_of_measure(\n    p_unit_name text,\n    p_unit_symbol text\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    INSERT INTO units_of_measure (unit_id, unit_name, unit_description, unit_symbol)\n    VALUES (\n        (SELECT COALESCE(MAX(unit_id), 0) + 1 FROM units_of_measure),\n        p_unit_name,\n        'Description for ' || p_unit_name,\n        p_unit_symbol\n    );\nEND;\n$$;",
    "database_name": "demographic_data_collection_and_analysis_801780",
    "tables": [
      "calculated_percentages",
      "data_sources",
      "definitions",
      "error_margins",
      "labels",
      "unit_levels",
      "units_of_measure"
    ],
    "call_sqls": [
      "CALL insert_new_unit_of_measure('Kilograms', 'kg');",
      "CALL insert_new_unit_of_measure('Meters', 'm');",
      "CALL insert_new_unit_of_measure('Liters', 'L');",
      "CALL insert_new_unit_of_measure('Hours', 'hr');",
      "CALL insert_new_unit_of_measure('Dollars', '$');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named insert_new_unit_of_measure that adds a new record to the units_of_measure table, taking the unit_name and unit_symbol as input text. It generates a unique unit_id by incrementing the highest existing unit_id from the table (or starts at 1 if the table is empty), creates a unit_description by prepending 'Description for ' to the provided unit_name, and inserts all values into the table.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named insert_new_unit_of_measure that adds a new entry to the units_of_measure table, taking the unit_name and unit_symbol as inputs. It should generate a new unit_id by incrementing the highest existing unit_id by one, or start at 1 if the table is empty, and create a unit_description by prefixing the given unit_name with 'Description for '.",
    "id": 61,
    "generated_ir": "Write a PLpgSQL stored procedure that inserts a new record into the units_of_measure table with a unique unit_id, which is determined by selecting the maximum existing unit_id from the table and adding one to it, or using 1 if the table is empty. The procedure takes two parameters: p_unit_name of type text, which specifies the name of the unit of measure to be inserted, and p_unit_symbol of type text, which specifies the symbol associated with the unit of measure. The procedure constructs the unit_description by concatenating the string 'Description for ' with the provided p_unit_name. The new record is inserted with the calculated unit_id, the provided p_unit_name, the constructed unit_description, and the provided p_unit_symbol.",
    "original_summary": "Create a stored procedure to insert a new record into the units_of_measure table. Generate a unique unit_id by incrementing the maximum existing ID (or start at 1 if empty). Use provided text parameters for unit_name and unit_symbol. Construct unit_description by concatenating 'Description for ' with the unit_name.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Make a stored procedure that adds a new entry to the units_of_measure table. Figure out a new unit_id by taking the highest current one and adding a bit to it, or just use a small number if the table is pretty much empty. It should take the given text for the unit_name and unit_symbol. For the unit_description, just put together something like 'Description for ' with the provided unit_name."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named archive_old_allocations that accepts four input parameters: an integer p_days_threshold representing a number of days, a text p_status representing a status value, a bigint p_company_id representing a company identifier, and a bigint p_usage_type_id representing a usage type identifier. The procedure begins by calculating a cutoff date by subtracting p_days_threshold days from the current date and casting the result to text, storing it in a local variable v_cutoff_date. It then attempts to create a table named archived_allocations if it does not already exist, with columns allocation_id (bigint, primary key), prefix_id (bigint), company_id (bigint), allocation_date (text), effective_date (text), expiration_date (text), status (text), notes (text), and last_updated (text); if this table creation fails for any reason, the procedure raises a notice with the error message and exits without performing further operations. If the table creation is successful or the table already exists, the procedure inserts rows into the archived_allocations table by selecting all columns from the number_allocations table where the allocation_date column is less than the v_cutoff_date, the status column equals the p_status parameter, the company_id column equals the p_company_id parameter, and the prefix_id column matches any prefix_id value found in the number_prefixes table where the usage_type_id column equals the p_usage_type_id parameter. Following this insertion, the procedure deletes from the number_allocations table all rows that satisfy the exact same set of conditions: allocation_date less than v_cutoff_date, status equal to p_status, company_id equal to p_company_id, and prefix_id existing in the subquery selecting prefix_id from number_prefixes where usage_type_id equals p_usage_type_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE archive_old_allocations(\n    p_days_threshold INTEGER,\n    p_status TEXT,\n    p_company_id BIGINT,\n    p_usage_type_id BIGINT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_cutoff_date TEXT;\nBEGIN\n    v_cutoff_date := (CURRENT_DATE - INTERVAL '1 day' * p_days_threshold)::TEXT;\n    \n    -- Create archived_allocations table if it doesn't exist\n    BEGIN\n        EXECUTE 'CREATE TABLE IF NOT EXISTS archived_allocations (\n            allocation_id bigint PRIMARY KEY,\n            prefix_id bigint,\n            company_id bigint,\n            allocation_date text,\n            effective_date text,\n            expiration_date text,\n            status text,\n            notes text,\n            last_updated text\n        )';\n    EXCEPTION\n        WHEN OTHERS THEN\n            -- Table creation failed, continue without archiving\n            RAISE NOTICE 'Could not create archived_allocations table: %', SQLERRM;\n            RETURN;\n    END;\n    \n    INSERT INTO archived_allocations\n    SELECT * FROM number_allocations\n    WHERE allocation_date < v_cutoff_date\n    AND status = p_status\n    AND company_id = p_company_id\n    AND prefix_id IN (\n        SELECT prefix_id FROM number_prefixes WHERE usage_type_id = p_usage_type_id\n    );\n    \n    DELETE FROM number_allocations\n    WHERE allocation_date < v_cutoff_date\n    AND status = p_status\n    AND company_id = p_company_id\n    AND prefix_id IN (\n        SELECT prefix_id FROM number_prefixes WHERE usage_type_id = p_usage_type_id\n    );\nEND;\n$$;",
    "database_name": "telecommunication_number_allocation_and_usage",
    "tables": [
      "cities",
      "counties",
      "companies",
      "number_allocations",
      "number_prefixes",
      "usage_types",
      "users"
    ],
    "call_sqls": [
      "CALL archive_old_allocations(365, 'active', 0, 0);",
      "CALL archive_old_allocations(180, 'active', 1, 1);",
      "CALL archive_old_allocations(90, 'active', 0, 1);",
      "CALL archive_old_allocations(30, 'active', 1, 0);",
      "CALL archive_old_allocations(60, 'active', 0, 0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named archive_old_allocations that accepts a days threshold, a status, a company ID, and a usage type ID to archive and remove old allocations from the NUMBER_ALLOCATIONS table. The procedure should create the ARCHIVED_ALLOCATIONS table if it does not exist, then copy all allocations from NUMBER_ALLOCATIONS into ARCHIVED_ALLOCATIONS where the allocation date is older than the specified number of days, the status matches the provided status, the company ID matches the provided company ID, and the prefix ID corresponds to the given usage type ID via the NUMBER_PREFIXES table. After copying, it should delete those same allocations from the NUMBER_ALLOCATIONS table.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called archive_old_allocations that takes p_days_threshold, p_status, p_company_id, and p_usage_type_id as parameters. Ensure the archived_allocations table exists, then move old allocations from the number_allocations table into archived_allocations and remove them from number_allocations, where the allocation_date is older than the specified days threshold, the status matches p_status, the company_id matches p_company_id, and the prefix_id corresponds to the given p_usage_type_id via the number_prefixes table.",
    "id": 62,
    "generated_ir": "Write a PostgreSQL PLpgSQL stored procedure named archive_old_allocations that accepts four input parameters: an integer p_days_threshold representing a number of days, a text p_status representing a status value, a bigint p_company_id representing a company identifier, and a bigint p_usage_type_id representing a usage type identifier. The procedure begins by calculating a cutoff date by subtracting p_days_threshold days from the current date and casting the result to text, storing it in a local variable v_cutoff_date. It then attempts to create a table named archived_allocations if it does not already exist, with columns allocation_id (bigint, primary key), prefix_id (bigint), company_id (bigint), allocation_date (text), effective_date (text), expiration_date (text), status (text), notes (text), and last_updated (text); if this table creation fails for any reason, the procedure raises a notice with the error message and exits without performing further operations. If the table creation is successful or the table already exists, the procedure inserts rows into the archived_allocations table by selecting all columns from the number_allocations table where the allocation_date column is less than the v_cutoff_date, the status column equals the p_status parameter, the company_id column equals the p_company_id parameter, and the prefix_id column matches any prefix_id value found in the number_prefixes table where the usage_type_id column equals the p_usage_type_id parameter. Following this insertion, the procedure deletes from the number_allocations table all rows that satisfy the exact same set of conditions: allocation_date less than v_cutoff_date, status equal to p_status, company_id equal to p_company_id, and prefix_id existing in the subquery selecting prefix_id from number_prefixes where usage_type_id equals p_usage_type_id.",
    "original_summary": "Create a stored procedure named archive_old_allocations that accepts p_days_threshold (INTEGER), p_status (TEXT), p_company_id (BIGINT), and p_usage_type_id (BIGINT). Create an archive table if it doesn't exist. Copy old allocations matching the criteria (date, status, company, and usage type) into the archive table, then delete them from the original table.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure called archive_old_allocations that takes p_days_threshold (INTEGER), p_status (TEXT), p_company_id (BIGINT), and p_usage_type_id (BIGINT) as parameters. Ensure the archive table exists. Move old allocations that match the given date, status, company, and usage type criteria into the archive table and remove them from the source table."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named create_user_account that accepts four parameters: p_user_name of type text, p_email of type text, p_role of type text, and p_department of type text. This procedure first checks if a sequence named users_user_id_seq exists by querying the pg_class system catalog. If the sequence does not exist, it creates the sequence using the EXECUTE command. It then calculates the maximum value of the user_id column from the users table, defaults to 0 if no users exist, and sets the sequence to start from the next integer after this maximum value using the ALTER SEQUENCE command. The procedure then inserts a new row into the users table with columns user_id, user_name, email, role, and department. The user_id is generated using the nextval function on the users_user_id_seq sequence, while the other columns are populated with the values of the respective parameters p_user_name, p_email, p_role, and p_department. If an insertion conflict occurs on the user_id column, the procedure does nothing, effectively ignoring the conflict.",
    "plsql": "CREATE OR REPLACE PROCEDURE create_user_account(\n    p_user_name text,\n    p_email text,\n    p_role text,\n    p_department text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    max_user_id bigint;\nBEGIN\n    -- Create the sequence if it does not exist\n    IF NOT EXISTS (SELECT 1 FROM pg_class WHERE relname = 'users_user_id_seq') THEN\n        EXECUTE 'CREATE SEQUENCE users_user_id_seq';\n        \n        -- Set sequence to start after the maximum existing user_id\n        SELECT COALESCE(MAX(user_id), 0) + 1 INTO max_user_id FROM users;\n        EXECUTE 'ALTER SEQUENCE users_user_id_seq RESTART WITH ' || max_user_id;\n    END IF;\n\n    -- Insert the new user using the sequence for user_id with conflict handling\n    INSERT INTO users (user_id, user_name, email, role, department)\n    VALUES (nextval('users_user_id_seq'), p_user_name, p_email, p_role, p_department)\n    ON CONFLICT (user_id) DO NOTHING;\nEND;\n$$;",
    "database_name": "apparel_sizing_and_measurement_standards_543314",
    "tables": [
      "measurements",
      "size_updates",
      "users"
    ],
    "call_sqls": [
      "CALL create_user_account('John Smith', 'john.smith@appareltask.com', 'designer', 'design');",
      "CALL create_user_account('Sarah Chen', 'sarah.chen@appareltask.com', 'manufacturer', 'production');",
      "CALL create_user_account('Michael Brown', 'michael.brown@appareltask.com', 'manager', 'quality');",
      "CALL create_user_account('Emma Wilson', 'emma.wilson@appareltask.com', 'analyst', 'data');",
      "CALL create_user_account('David Lee', 'david.lee@appareltask.com', 'technician', 'production');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named create_user_account that creates a new user account in the users table by accepting the user's name as p_user_name, email as p_email, role as p_role, and department as p_department. It ensures the users_user_id_seq sequence exists, setting its starting value to one more than the highest current user_id in the users table if it needs to be created. The procedure then inserts a new record with a unique user_id generated from the sequence and the provided user details, avoiding insertion if a user with the same user_id already exists.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named create_user_account that sets up a user account by taking basic details including a name, email address, role type, and department. It should first ensure a sequence for user IDs exists, creating it if necessary and setting its starting point to one more than the highest existing user ID in the users table. Then, it adds the new user to the users table with the next value from that sequence for the user_id, along with the provided details, and should skip insertion if a user with that ID already exists.",
    "id": 63,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named create_user_account that takes four input parameters: p_user_name of type text, which represents the full name of the user; p_email of type text, which represents the email address of the user; p_role of type text, which represents the role type of the user; and p_department of type text, which represents the department of the user. The procedure does not have a return type; it performs operations to set up a user account.\n\nThe procedure first checks for the existence of a sequence named user_id_seq in the database. If the sequence does not exist, the procedure creates it. After ensuring the sequence exists, the procedure sets the starting value of the sequence to one more than the maximum existing user_id value in the users table. This is done by executing a SELECT query to find the maximum user_id from the users table, adding 1 to that value, and then using the SETVAL function on the user_id_seq sequence to set its next value accordingly.\n\nNext, the procedure attempts to insert a new record into the users table. The insertion uses the next value from the user_id_seq sequence for the user_id column, and assigns the input parameters p_user_name, p_email, p_role, and p_department to the corresponding columns user_name, email, role, and department. The job_title column is left as NULL. The insertion is performed with an ON CONFLICT clause that specifies the conflict target as the user_id column. If a user with the same user_id (generated from the sequence) already exists in the users table, the insertion is skipped, and no error is raised. The procedure completes after the insertion attempt.",
    "original_summary": "Create a stored procedure named create_user_account that accepts p_user_name, p_email, p_role, and p_department as text parameters. It ensures the users_user_id_seq sequence exists, creating it if necessary. It sets the sequence's start value to one greater than the current maximum user_id in the users table. The procedure then inserts a new user with a generated ID from the sequence and the provided parameter values, ignoring any conflict on the user_id column.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure to set up a user account. It should take in some basic details like a name, email address, role type, and department. First, it needs to check for and maybe create a sequence for user IDs, making sure it starts from a suitable point just after the highest existing ID. Then, it adds the new user with the next number from that sequence, using the given details, and should just skip over if there's any issue with the ID already being there."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named insert_property_with_image that accepts four input parameters: p_property_id of type BIGINT representing the unique identifier for a property, p_address of type TEXT representing the property's location, p_beds of type BIGINT representing the number of bedrooms, and p_image_path of type TEXT representing the file system path for an associated image. The procedure first performs an INSERT operation into the properties table, populating the property_id column with the value from p_property_id, the address column with the value from p_address, the beds column with the value from p_beds, and the co_date column with the current system date formatted as a string in 'YYYY-MM-DD' format using the TO_CHAR function with the CURRENT_DATE argument. The procedure then performs a second INSERT operation into the property_images table, populating the image_id column with a calculated value derived by multiplying the p_property_id parameter by 1000, the property_id column with the value from p_property_id, the image_path column with the value from p_image_path, and the upload_date column with the current system timestamp formatted as a string in 'YYYY-MM-DD HH24:MI:SS' format using the TO_CHAR function with the CURRENT_TIMESTAMP argument.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_property_with_image(\n    IN p_property_id BIGINT,\n    IN p_address TEXT,\n    IN p_beds BIGINT,\n    IN p_image_path TEXT\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    INSERT INTO properties (property_id, address, beds, co_date)\n    VALUES (p_property_id, p_address, p_beds, TO_CHAR(CURRENT_DATE, 'YYYY-MM-DD'));\n    \n    INSERT INTO property_images (image_id, property_id, image_path, upload_date)\n    VALUES (p_property_id * 1000, p_property_id, p_image_path, TO_CHAR(CURRENT_TIMESTAMP, 'YYYY-MM-DD HH24:MI:SS'));\nEND;\n$$;",
    "database_name": "real_estate_sales_and_market_analysis_221588",
    "tables": [
      "properties",
      "property_images"
    ],
    "call_sqls": [
      "CALL insert_property_with_image(1, '123 Main St', 3, '/images/property1.jpg');",
      "CALL insert_property_with_image(2, '456 Elm St', 4, '/images/property2.jpg');",
      "CALL insert_property_with_image(3, '789 Oak St', 2, '/images/property3.jpg');",
      "CALL insert_property_with_image(4, '101 Pine St', 5, '/images/property4.jpg');",
      "CALL insert_property_with_image(5, '202 Maple St', 3, '/images/property5.jpg');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named insert_property_with_image that inserts a new property record into the properties table with a given property ID, address, number of beds, and the current date, and then inserts a corresponding image record into the property_images table with an image ID calculated as the property ID multiplied by 1000, the provided image path, and the current timestamp.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called insert_property_with_image that inserts a new property record into the properties table using the provided property ID, address, and number of beds, with the current date as the co_date, and then inserts a corresponding image record into the property_images table, generating the image ID by multiplying the property ID by 1000, using the provided image path, and setting the upload_date to the current timestamp.",
    "id": 64,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named insert_property_with_image that accepts three input parameters: p_property_id of type BIGINT, p_address of type TEXT, p_beds of type BIGINT, and p_image_path of type TEXT. The procedure performs two INSERT operations into two related tables within a single transaction. First, it inserts a new record into the properties table. The values inserted are: the property_id column is set to the p_property_id parameter, the address column is set to the p_address parameter, the beds column is set to the p_beds parameter, and the co_date column is set to the current system date obtained via the CURRENT_DATE function. All other columns in the properties table (region_id, total_sqft, baths, year_built, property_type_id, last_sale_id, parking_type, parking_spaces, lot_size, views, amenities, description) are left as NULL. Second, it inserts a new record into the property_images table. The values inserted are: the image_id column is calculated by multiplying the provided p_property_id parameter by 1000, the property_id column is set to the same p_property_id parameter to establish the foreign key relationship, the image_path column is set to the p_image_path parameter, and the upload_date column is set to the current system date and time obtained via the CURRENT_TIMESTAMP function. The image_description and image_type columns are left as NULL. The procedure ensures both inserts are executed sequentially, linking the new image record to the newly created property record via the shared property_id.",
    "original_summary": "Create a stored procedure named insert_property_with_image that inserts a property record with given ID, address, beds, and current date, then inserts a corresponding image record with generated image ID (property_id * 1000), image path, and current timestamp.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure called insert_property_with_image to insert a property record using the provided ID, address, beds, and the current date, and then insert a matching image record with an image ID generated as property_id multiplied by 1000, an image path, and the current timestamp."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named update_player_performance that accepts five parameters: p_player_id of type bigint, p_season_id of type bigint, p_performance_multiplier of type numeric, p_contract_date of type text, and p_salary_cap of type bigint. The procedure begins by declaring two local variables: v_team_id of type bigint and v_points_calculation of type numeric. It then executes a SELECT statement to retrieve the team_id from the players table where the player_id matches p_player_id and the season_id matches p_season_id, storing the result in v_team_id. Next, it calculates v_points_calculation by applying the tangent function to half of p_performance_multiplier, multiplying the result by 100. The procedure then updates the players table, setting the contract_expiration column to p_contract_date and the performance_trend column to a JSON string that includes an \"updated\" flag set to true and a \"calculation\" field set to the string representation of v_points_calculation, for the row where player_id matches p_player_id and season_id matches p_season_id. Finally, it deletes rows from the schedules table where the team_id matches v_team_id, the game_status is 'Cancelled', and the schedule_id is less than p_salary_cap.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_player_performance(\n    p_player_id bigint,\n    p_season_id bigint,\n    p_performance_multiplier numeric,\n    p_contract_date text,\n    p_salary_cap bigint\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_team_id bigint;\n    v_points_calculation numeric;\nBEGIN\n    SELECT team_id INTO v_team_id\n    FROM players\n    WHERE player_id = p_player_id AND season_id = p_season_id;\n    \n    v_points_calculation := tan(p_performance_multiplier * 0.5) * 100;\n    \n    UPDATE players\n    SET contract_expiration = p_contract_date,\n        performance_trend = '{\"updated\": true, \"calculation\": ' || v_points_calculation::text || '}'\n    WHERE player_id = p_player_id AND season_id = p_season_id;\n    \n    DELETE FROM schedules\n    WHERE team_id = v_team_id \n    AND game_status = 'Cancelled'\n    AND schedule_id < p_salary_cap;\nEND;\n$$;",
    "database_name": "sports_team_performance_tracking_659887",
    "tables": [
      "games",
      "players",
      "schedules",
      "standings",
      "teams"
    ],
    "call_sqls": [
      "CALL update_player_performance(1, 1, 1.25, '2025-12-31', 10000);",
      "CALL update_player_performance(0, 0, 0.85, '2024-06-30', 5000);",
      "CALL update_player_performance(15, 1, 2.10, '2026-07-15', 15000);",
      "CALL update_player_performance(7, 0, 1.50, '2025-08-20', 7500);",
      "CALL update_player_performance(22, 1, 0.95, '2024-12-01', 12000);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_player_performance that, for a given player identified by p_player_id and p_season_id, updates the player's contract_expiration to the provided p_contract_date and sets the performance_trend based on a calculated points value derived from the p_performance_multiplier, then removes any cancelled schedules for that player's team where the schedule_id is below the provided p_salary_cap threshold.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named update_player_performance that updates the contract expiration date and performance trend for a specific player in the players table based on a provided contract date and a calculated points value derived from a performance multiplier, and then removes any cancelled schedules for that player's team from the schedules table where the schedule ID is below a given salary cap threshold.",
    "id": 65,
    "generated_ir": "Write a PLpgSQL stored procedure named update_player_performance that accepts five parameters: p_player_id of type bigint, p_season_id of type bigint, p_performance_multiplier of type numeric, p_contract_date of type text, and p_salary_cap of type bigint. The procedure begins by declaring two local variables: v_team_id of type bigint and v_points_calculation of type numeric. It then executes a SELECT statement to retrieve the team_id from the players table where the player_id matches p_player_id and the season_id matches p_season_id, storing the result in v_team_id. Next, it calculates v_points_calculation by applying the tangent function to half of p_performance_multiplier, multiplying the result by 100. The procedure then updates the players table, setting the contract_expiration column to p_contract_date and the performance_trend column to a JSON string that includes an \"updated\" flag set to true and a \"calculation\" field set to the string representation of v_points_calculation, for the row where player_id matches p_player_id and season_id matches p_season_id. Finally, it deletes rows from the schedules table where the team_id matches v_team_id, the game_status is 'Cancelled', and the schedule_id is less than p_salary_cap.",
    "original_summary": "Create a stored procedure named update_player_performance that updates a player's contract expiration and performance trend based on a calculated points value, then removes cancelled schedules for that player's team below a salary cap threshold.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Develop a stored procedure, to be named update_player_performance, which meticulously updates both the contract expiration date and the detailed performance trend for a specified player, based on a carefully calculated points value; subsequently, it proceeds to systematically remove any cancelled schedules associated with that player's team, but only for those schedules which fall below a predefined salary cap threshold."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named `synchronize_user_roles` that accepts three input parameters: `p_email_domain` of type `text`, representing a specific email domain to filter users; `p_default_description` of type `text`, providing a default description to be used for new team member entries; and `p_min_team_size` of type `integer`, specifying the minimum number of distinct teams a user must be part of to be considered active for certain operations. The procedure begins by defining a Common Table Expression (CTE) named `active_users`. This CTE selects `user_id` and `user_name` from the `users` table, aliased as `u`, and calculates the count of distinct `team_id` values from the `team_members` table, aliased as `tm`, for each user, naming this count `team_count`. It joins `users` and `team_members` on `u.user_id = tm.user_id`. The selection is filtered to include only users whose `email` column, from the `users` table, ends with the value provided in `p_email_domain` (using the `LIKE` operator with a wildcard prefix `'%`' concatenated with `p_email_domain`). The results are grouped by `u.user_id` and `u.user_name`. Furthermore, only those groups (users) are included where the calculated `team_count` is greater than or equal to the value specified in `p_min_team_size`.\n\nFollowing the CTE definition, the procedure executes a `DELETE` statement. This statement removes rows from the `team_members` table. The deletion is conditional: a row is deleted if its `user_id` is present in the set of `user_id`s returned by the `active_users` CTE, AND its `team_id` is present in a subquery's result. This subquery selects `team_id` from the `research_teams` table, aliased as `rt`, where the `LENGTH` of the `description` column in `research_teams` is less than 50.\n\nAfter the deletion, the procedure performs an `INSERT` operation into the `team_members` table, populating the columns `member_id`, `team_id`, `user_id`, `role`, and `description`. The values for these columns are derived from a `SELECT` statement. For `member_id`, it calculates a new unique identifier by taking the `MAX` value of `member_id` from the `team_members` table, using `COALESCE` to default to 0 if no `member_id` exists, and then adding the `ROW_NUMBER()` over an empty partition, effectively generating a sequential number for each row being inserted. For `team_id`, it uses `rt.team_id` from the `research_teams` table. For `user_id`, it uses `u.user_id` from the `users` table. For `role`, it uses `u.role` from the `users` table. For `description`, it uses the value provided in the `p_default_description` parameter. The `SELECT` statement retrieves data from the `users` table, aliased as `u`, and performs a `CROSS JOIN` with the `research_teams` table, aliased as `rt`. The selection is filtered by several conditions: first, `u.email` must end with the value of `p_email_domain` (using `LIKE '%' || p_email_domain`). Second, `rt.team_id` must NOT be present in a subquery that selects `team_id` from `team_members` where `user_id` matches `u.user_id`, ensuring that a user is not added to a team they are already a member of. Third, there must `EXISTS` at least one row in the `team_access` table, aliased as `ta`, where `ta.team_id` matches `rt.team_id`, AND the `EXTRACT`ed `MONTH` from the `access_date` column (after converting it to a `DATE` type using `TO_DATE` with format 'YYYY-MM-DD') is equal to the `EXTRACT`ed `MONTH` from the `CURRENT_DATE`.",
    "plsql": "CREATE OR REPLACE PROCEDURE synchronize_user_roles(p_email_domain text, p_default_description text, p_min_team_size integer)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    WITH active_users AS (\n        SELECT u.user_id, u.user_name, COUNT(DISTINCT tm.team_id) as team_count\n        FROM users u\n        JOIN team_members tm ON u.user_id = tm.user_id\n        WHERE u.email LIKE '%' || p_email_domain\n        GROUP BY u.user_id, u.user_name\n        HAVING COUNT(DISTINCT tm.team_id) >= p_min_team_size\n    )\n    DELETE FROM team_members\n    WHERE user_id IN (SELECT user_id FROM active_users)\n    AND team_id IN (\n        SELECT rt.team_id FROM research_teams rt\n        WHERE LENGTH(rt.description) < 50\n    );\n    \n    INSERT INTO team_members (member_id, team_id, user_id, role, description)\n    SELECT \n        (SELECT COALESCE(MAX(member_id), 0) + ROW_NUMBER() OVER () FROM team_members),\n        rt.team_id,\n        u.user_id,\n        u.role,\n        p_default_description\n    FROM users u\n    CROSS JOIN research_teams rt\n    WHERE u.email LIKE '%' || p_email_domain\n    AND rt.team_id NOT IN (SELECT team_id FROM team_members WHERE user_id = u.user_id)\n    AND EXISTS (\n        SELECT 1 FROM team_access ta\n        WHERE ta.team_id = rt.team_id\n        AND EXTRACT(MONTH FROM TO_DATE(ta.access_date, 'YYYY-MM-DD')) = EXTRACT(MONTH FROM CURRENT_DATE)\n    );\nEND;\n$$;",
    "database_name": "global_happiness_and_well_being_index_549073",
    "tables": [
      "research_teams",
      "team_members",
      "users",
      "team_access"
    ],
    "call_sqls": [
      "CALL synchronize_user_roles('example.com', 'Default description', 2);",
      "CALL synchronize_user_roles('example.com', 'Default description', 3);",
      "CALL synchronize_user_roles('example.com', 'Default description', 4);",
      "CALL synchronize_user_roles('example.com', 'Default description', 5);",
      "CALL synchronize_user_roles('example.com', 'Default description', 6);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named synchronize_user_roles that manages team memberships for active users from a specified email domain. It accepts three parameters: p_email_domain to filter users by email domain, p_default_description to provide a default description for new memberships, and p_min_team_size to set a minimum number of existing team memberships. The procedure first removes memberships for active users (those in at least the minimum number of teams from the specified email domain) from teams with short descriptions (less than 50 characters in the RESEARCH_TEAMS table). Then, it adds new memberships for these users into teams they are not already part of, but only for teams that had access recorded in the current month in the TEAM_ACCESS table, assigning the provided default description.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named synchronize_user_roles that manages team memberships by taking p_email_domain as text, p_default_description as text, and p_min_team_size as integer parameters. The procedure should first identify active users from the users table whose email ends with the given domain and who are members of at least the minimum number of teams from the team_members table. Then, it removes these users' memberships from teams in the research_teams table that have descriptions shorter than 50 characters. Finally, it adds new memberships for these users into teams from the research_teams table they are not already part of, but only for teams that have an access record in the team_access table for the current month, assigning the provided default description.",
    "id": 66,
    "generated_ir": "Write a PLpgSQL stored procedure named `synchronize_user_roles` that accepts three input parameters: `p_email_domain` of type `text`, representing a specific email domain to filter users; `p_default_description` of type `text`, providing a default description to be used for new team member entries; and `p_min_team_size` of type `integer`, specifying the minimum number of distinct teams a user must be part of to be considered active for certain operations. The procedure begins by defining a Common Table Expression (CTE) named `active_users`. This CTE selects `user_id` and `user_name` from the `users` table, aliased as `u`, and calculates the count of distinct `team_id` values from the `team_members` table, aliased as `tm`, for each user, naming this count `team_count`. It joins `users` and `team_members` on `u.user_id = tm.user_id`. The selection is filtered to include only users whose `email` column, from the `users` table, ends with the value provided in `p_email_domain` (using the `LIKE` operator with a wildcard prefix `'%`' concatenated with `p_email_domain`). The results are grouped by `u.user_id` and `u.user_name`. Furthermore, only those groups (users) are included where the calculated `team_count` is greater than or equal to the value specified in `p_min_team_size`.\n\nFollowing the CTE definition, the procedure executes a `DELETE` statement. This statement removes rows from the `team_members` table. The deletion is conditional: a row is deleted if its `user_id` is present in the set of `user_id`s returned by the `active_users` CTE, AND its `team_id` is present in a subquery's result. This subquery selects `team_id` from the `research_teams` table, aliased as `rt`, where the `LENGTH` of the `description` column in `research_teams` is less than 50.\n\nAfter the deletion, the procedure performs an `INSERT` operation into the `team_members` table, populating the columns `member_id`, `team_id`, `user_id`, `role`, and `description`. The values for these columns are derived from a `SELECT` statement. For `member_id`, it calculates a new unique identifier by taking the `MAX` value of `member_id` from the `team_members` table, using `COALESCE` to default to 0 if no `member_id` exists, and then adding the `ROW_NUMBER()` over an empty partition, effectively generating a sequential number for each row being inserted. For `team_id`, it uses `rt.team_id` from the `research_teams` table. For `user_id`, it uses `u.user_id` from the `users` table. For `role`, it uses `u.role` from the `users` table. For `description`, it uses the value provided in the `p_default_description` parameter. The `SELECT` statement retrieves data from the `users` table, aliased as `u`, and performs a `CROSS JOIN` with the `research_teams` table, aliased as `rt`. The selection is filtered by several conditions: first, `u.email` must end with the value of `p_email_domain` (using `LIKE '%' || p_email_domain`). Second, `rt.team_id` must NOT be present in a subquery that selects `team_id` from `team_members` where `user_id` matches `u.user_id`, ensuring that a user is not added to a team they are already a member of. Third, there must `EXISTS` at least one row in the `team_access` table, aliased as `ta`, where `ta.team_id` matches `rt.team_id`, AND the `EXTRACT`ed `MONTH` from the `access_date` column (after converting it to a `DATE` type using `TO_DATE` with format 'YYYY-MM-DD') is equal to the `EXTRACT`ed `MONTH` from the `CURRENT_DATE`.",
    "original_summary": "Create a stored procedure named synchronize_user_roles that manages team memberships. It accepts three parameters: p_email_domain (text), p_default_description (text), and p_min_team_size (integer). First, identify active users from the specified email domain who are in at least the minimum number of teams. Delete their memberships from teams with short descriptions. Then, insert new memberships for these users into teams they are not already in, where the team had access in the current month. Use the provided default description.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure named synchronize_user_roles to manage team memberships, which takes p_email_domain as text, p_default_description as text, and p_min_team_size as integer parameters? The procedure should first find active users from the given email domain who are in at least the minimum number of teams, then remove their memberships from teams with short descriptions, and finally add new memberships for these users into teams they are not already part of, but only for teams that had access in the current month, using the provided default description."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named update_cytoplasm_texture that accepts three parameters: p_cell_id of type bigint, p_texture_threshold of type real, and p_new_texture of type text. The procedure begins by declaring a local variable v_current_texture of type text to store the current texture value, a bit pattern v_bit_pattern of type bit(18) initialized to the binary value '110011001100110011', and an integer variable v_bit_value. It then retrieves the current cytoplasm_texture from the cytoplasm_metrics table for the row where the cell_id matches the provided p_cell_id and stores it in v_current_texture. The procedure extracts the value of the fifth bit from v_bit_pattern using the get_bit function and assigns it to v_bit_value. If v_bit_value equals 1, the procedure updates the cytoplasm_texture column in the cytoplasm_metrics table to the value of p_new_texture for the row where the cell_id matches p_cell_id and the cytoplasm_intensity is greater than p_texture_threshold. If v_bit_value is not equal to 1, it updates the cytoplasm_texture column to 'Default' for the row where the cell_id matches p_cell_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_cytoplasm_texture(\n    p_cell_id bigint,\n    p_texture_threshold real,\n    p_new_texture text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_current_texture text;\n    v_bit_pattern bit(18) := B'110011001100110011';\n    v_bit_value integer;\nBEGIN\n    SELECT cytoplasm_texture INTO v_current_texture\n    FROM cytoplasm_metrics\n    WHERE cell_id = p_cell_id;\n    \n    v_bit_value := get_bit(v_bit_pattern, 5);\n    \n    IF v_bit_value = 1 THEN\n        UPDATE cytoplasm_metrics\n        SET cytoplasm_texture = p_new_texture\n        WHERE cell_id = p_cell_id AND cytoplasm_intensity > p_texture_threshold;\n    ELSE\n        UPDATE cytoplasm_metrics\n        SET cytoplasm_texture = 'Default'\n        WHERE cell_id = p_cell_id;\n    END IF;\nEND;\n$$;",
    "database_name": "biological_sample_analysis_and_metrics",
    "tables": [
      "cell_metrics",
      "cytoplasm_metrics",
      "nucleus_metrics",
      "nucleus_OD_metrics"
    ],
    "call_sqls": [
      "CALL update_cytoplasm_texture(1, 0.14, 'Fibrous');",
      "CALL update_cytoplasm_texture(0, 0.15, 'Reticular');",
      "CALL update_cytoplasm_texture(1, 0.13, 'Smooth');",
      "CALL update_cytoplasm_texture(0, 0.16, 'Granular');",
      "CALL update_cytoplasm_texture(1, 0.12, 'Spongy');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_cytoplasm_texture that, for a given cell_id (p_cell_id), retrieves the current cytoplasm_texture from the cytoplasm_metrics table, checks a specific bit in a fixed pattern, and updates the cytoplasm_texture: if the bit equals 1, it sets the texture to the provided new value (p_new_texture) only where the cytoplasm_intensity exceeds a given threshold (p_texture_threshold); otherwise, it sets the texture to 'Default' for that cell_id.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called update_cytoplasm_texture that updates the cytoplasm_texture in the cytoplasm_metrics table for a specified cell_id, using a texture threshold and a new texture value: if a specific bit condition is met, set the texture to the provided new texture only when the cytoplasm_intensity exceeds the given threshold; otherwise, set it to 'Default'.",
    "id": 67,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named update_cytoplasm_texture that takes three input parameters: p_cell_id of type bigint to identify the target cell, p_threshold of type real to serve as the intensity threshold, and p_new_texture of type text to provide the new texture value. The procedure does not return a value.\n\nThe procedure begins by declaring a local variable v_cytoplasm_intensity of type real to temporarily store the cytoplasm_intensity value from the cytoplasm_metrics table.\n\nIt then performs a SELECT operation on the cytoplasm_metrics table to retrieve the cytoplasm_intensity column for the row where the cell_id column matches the provided p_cell_id parameter, storing this value into the v_cytoplasm_intensity variable.\n\nNext, the procedure checks if the retrieved v_cytoplasm_intensity is not NULL, indicating a matching record exists. If a record is found, it evaluates a specific bit condition: it checks if the bitwise AND operation between the p_cell_id parameter and the integer 1 equals 1 (i.e., p_cell_id & 1 = 1). This condition tests whether the cell_id is an odd number.\n\nIf this bit condition is true, the procedure then compares the v_cytoplasm_intensity with the provided p_threshold. If v_cytoplasm_intensity is greater than p_threshold, it executes an UPDATE operation on the cytoplasm_metrics table, setting the cytoplasm_texture column to the value of the p_new_texture parameter for the row where cell_id equals p_cell_id.\n\nIf the bit condition is true but v_cytoplasm_intensity is not greater than p_threshold, or if the bit condition is false (i.e., p_cell_id & 1 != 1), the procedure executes an UPDATE operation on the cytoplasm_metrics table, setting the cytoplasm_texture column to the literal string 'Default' for the row where cell_id equals p_cell_id.\n\nThe procedure performs no action if the initial SELECT query finds no matching row (i.e., v_cytoplasm_intensity is NULL).",
    "original_summary": "Create a stored procedure named update_cytoplasm_texture with parameters: p_cell_id (bigint), p_texture_threshold (real), p_new_texture (text). Declare variables: v_current_texture (text), v_bit_pattern (bit(18)), v_bit_value (integer). It should: 1) Get the current texture for the given cell_id. 2) Extract the 5th bit from a fixed bit pattern. 3) If the extracted bit equals 1, update the texture to p_new_texture where cytoplasm_intensity > threshold. Otherwise, update the texture to 'Default'.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create procedure update_cytoplasm_texture(p_cell_id bigint, p_texture_threshold real, p_new_texture text). Variables: v_current_texture text, v_bit_pattern bit(18), v_bit_value integer. Steps: 1. Fetch current texture for p_cell_id. 2. Get the 5th bit from a fixed bit pattern. 3. If bit is 1, update texture to p_new_texture where cytoplasm_intensity > p_texture_threshold. Else, update to 'Default'."
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `reassign_user_issues` that accepts three input parameters: `p_source_user_id` of type `BIGINT`, representing the unique identifier of the user whose issue assignments are to be potentially reassigned; `p_target_user_id` of type `BIGINT`, representing the unique identifier of the user to whom the issues will be reassigned; and `p_min_issues` of type `BIGINT`, representing the minimum number of issues the source user must have for the reassignment process to proceed. The procedure declares two local variables: `v_issue_count` of type `BIGINT`, intended to store the total number of issues assigned to the source user, and `v_assignment_id` of type `BIGINT`, intended to temporarily hold the `assignment_id` of each issue assignment being processed.\n\nThe procedure begins by executing a `SELECT` statement to count the total number of rows in the `issue_assignments` table where the `user_id` column matches the value provided in the `p_source_user_id` parameter. The result of this count is then stored into the `v_issue_count` local variable.\n\nFollowing this, a conditional `IF` statement evaluates whether the value stored in `v_issue_count` is greater than or equal to the value provided in the `p_min_issues` parameter.\n\nIf the condition `v_issue_count >= p_min_issues` evaluates to `TRUE`, the procedure enters a `FOR` loop. This loop iterates over a result set obtained by a `SELECT` statement that retrieves all `assignment_id` values from the `issue_assignments` table where the `user_id` column matches the `p_source_user_id` parameter. For each `assignment_id` retrieved in this loop, the value is assigned to the `v_assignment_id` local variable.\n\nInside the `FOR` loop, for each `v_assignment_id`, an `INSERT` statement is executed to add a new row into the `issue_assignments` table. The values for the columns of this new row are determined by a nested `SELECT` statement.\nThe `assignment_id` for the new row is generated by a subquery `(SELECT COALESCE(MAX(assignment_id), 0) + 1 FROM issue_assignments)`. This subquery first finds the maximum existing `assignment_id` in the `issue_assignments` table. If no `assignment_id` exists (i.e., `MAX(assignment_id)` returns `NULL`), `COALESCE` replaces `NULL` with `0`, and then `1` is added to this value to ensure a unique, incrementing `assignment_id`.\nThe `issue_id` for the new row is selected from the `issue_assignments` table where the `assignment_id` matches the current `v_assignment_id` from the outer loop.\nThe `user_id` for the new row is set to the value provided in the `p_target_user_id` parameter.\nThe `assigned_at` column for the new row is set to the current timestamp using the `CURRENT_TIMESTAMP` function.\nThe `assigned_by` column for the new row is set to the value provided in the `p_source_user_id` parameter.\nThis `INSERT` operation effectively creates a new assignment record for the target user, duplicating the issue details from an existing assignment of the source user, but assigning it to the target user and marking the source user as the one who initiated this new assignment.\n\nThe `FOR` loop continues until all `assignment_id`s for the `p_source_user_id` have been processed.\n\nIf the initial `IF` condition `v_issue_count >= p_min_issues` evaluates to `FALSE`, the `FOR` loop is skipped, and no issue reassignments occur.\n\nThe procedure concludes after the `IF` statement, whether the loop was executed or not.",
    "plsql": "CREATE OR REPLACE PROCEDURE reassign_user_issues(\n    IN p_source_user_id BIGINT,\n    IN p_target_user_id BIGINT,\n    IN p_min_issues BIGINT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_issue_count BIGINT;\n    v_assignment_id BIGINT;\nBEGIN\n    SELECT COUNT(*) INTO v_issue_count FROM issue_assignments WHERE user_id = p_source_user_id;\n    IF v_issue_count >= p_min_issues THEN\n        FOR v_assignment_id IN SELECT assignment_id FROM issue_assignments WHERE user_id = p_source_user_id\n        LOOP\n            INSERT INTO issue_assignments (assignment_id, issue_id, user_id, assigned_at, assigned_by)\n            SELECT (SELECT COALESCE(MAX(assignment_id), 0) + 1 FROM issue_assignments),\n                   issue_id,\n                   p_target_user_id,\n                   CURRENT_TIMESTAMP,\n                   p_source_user_id\n            FROM issue_assignments\n            WHERE assignment_id = v_assignment_id;\n        END LOOP;\n    END IF;\nEND;\n$$;",
    "database_name": "project_management_and_issue_tracking_for_software_development",
    "tables": [
      "issues",
      "comments",
      "issue_assignments",
      "users",
      "issue_priorities",
      "priority_levels",
      "dependencies"
    ],
    "call_sqls": [
      "CALL reassign_user_issues(0, 1, 1);",
      "CALL reassign_user_issues(1, 0, 2);",
      "CALL reassign_user_issues(0, 1, 100);",
      "CALL reassign_user_issues(1, 0, 0);",
      "CALL reassign_user_issues(99, 100, 1);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `reassign_user_issues` that, given a source user ID, a target user ID, and a minimum issue count, checks if the source user has at least that many issue assignments in the `issue_assignments` table; if so, it duplicates all the source user's issue assignments to the target user by creating new records in `issue_assignments` with new unique assignment IDs, copying the original issue IDs, setting the user ID to the target user, setting the assigned timestamp to the current time, and recording the source user as the assigner.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `reassign_user_issues` that takes a source user ID, a target user ID, and a minimum issue count. If the source user has at least the specified minimum number of issues in the issue_assignments table, copy all their issue assignments to the target user. For each copy, generate a new unique assignment_id, keep the same issue_id, set the user_id to the target user, set the assigned_at timestamp to the current time, and set the assigned_by to the source user.",
    "id": 68,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named reassign_user_issues that accepts three input parameters: p_source_user_id of type bigint representing the identifier of the user from whom issue assignments are to be copied, p_target_user_id of type bigint representing the identifier of the user to whom the issue assignments are to be assigned, and p_min_issue_count of type bigint representing the minimum number of issue assignments the source user must have for the reassignment to proceed. The procedure first declares a local variable v_issue_count of type bigint to store the count of issue assignments belonging to the source user. The procedure then executes a SELECT COUNT(*) query on the issue_assignments table to count all records where the user_id column matches the p_source_user_id parameter value, storing this count in the v_issue_count variable. Next, the procedure uses an IF statement to check if v_issue_count is greater than or equal to p_min_issue_count. If this condition is true, the procedure performs an INSERT operation into the issue_assignments table. The INSERT statement selects data from the issue_assignments table where the user_id column matches p_source_user_id. For each selected row, it generates a new unique assignment_id using the nextval function on the sequence associated with the assignment_id column (assuming a sequence exists, typically named issue_assignments_assignment_id_seq), keeps the original issue_id column value unchanged, sets the user_id column to the p_target_user_id parameter value, sets the assigned_at column to the current timestamp using the CURRENT_TIMESTAMP function, and sets the assigned_by column to the p_source_user_id parameter value. This effectively copies all issue assignments from the source user to the target user with new identifiers and updated timestamps, while recording the source user as the assigner. If the condition in the IF statement is false (i.e., the source user has fewer issue assignments than the minimum specified), the procedure takes no action and exits without performing the INSERT. The procedure does not return any value; it is a void procedure that modifies data conditionally based on the count of existing assignments.",
    "original_summary": "Create a stored procedure named `reassign_user_issues` that accepts a source user ID, a target user ID, and a minimum issue count. If the source user has at least the minimum number of issues, duplicate all their issue assignments to the target user. For each duplicated assignment, generate a new unique assignment ID, copy the issue ID, set the new user ID to the target user, set the assigned timestamp to now, and set the assigner to the source user.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure called `reassign_user_issues` that takes a source user ID, a target user ID, and a minimum issue count. For the source user, check if they have at least the specified minimum number of issues. If they do, copy all their issue assignments to the target user. For each copy, create a new unique assignment ID, keep the same issue ID, set the user ID to the target, set the assigned timestamp to the current time, and set the assigner to be the source user."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `archive_completed_test_plan` that accepts three input parameters: `p_test_plan_id` of type `bigint`, `p_archive_location` of type `text`, and `p_archived_by` of type `text`. The procedure's primary purpose is to perform data deletion operations related to a specific test plan. Upon execution, the procedure first deletes records from the `test_case_execution` table. This deletion is conditional, targeting rows where the `test_plan_id` column matches the value provided by the `p_test_plan_id` input parameter AND the `execution_status` column's value is either 'Passed' or 'Failed'. Following this initial deletion, the procedure proceeds to delete records from the `test_plans` table. This second deletion is also conditional, specifically targeting rows where the `test_plan_id` column matches the value supplied by the `p_test_plan_id` input parameter. The parameters `p_archive_location` and `p_archived_by` are declared but are not utilized within the current implementation of the procedure's body.",
    "plsql": "CREATE OR REPLACE PROCEDURE archive_completed_test_plan(\n    p_test_plan_id bigint,\n    p_archive_location text,\n    p_archived_by text\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM test_case_execution \n    WHERE test_plan_id = p_test_plan_id \n    AND execution_status IN ('Passed', 'Failed');\n    \n    DELETE FROM test_plans \n    WHERE test_plan_id = p_test_plan_id;\nEND;\n$$;",
    "database_name": "software_testing_and_quality_assurance_890020",
    "tables": [
      "test_case_execution",
      "test_cases",
      "defects",
      "test_plans"
    ],
    "call_sqls": [
      "CALL archive_completed_test_plan(1, '/archive/2024/test_plans', 'john.doe@example.com');",
      "CALL archive_completed_test_plan(5, '/backups/test_plans', 'jane.smith');",
      "CALL archive_completed_test_plan(10, 's3://archive-bucket/test-plans', 'system');",
      "CALL archive_completed_test_plan(15, '/var/lib/postgresql/archives', 'admin');",
      "CALL archive_completed_test_plan(20, 'nas://archive/test_plans', 'automation_bot');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named archive_completed_test_plan that accepts a test plan ID, an archive location, and the name of the person performing the archiving, and archives a completed test plan by first removing all records from the TEST_CASE_EXECUTION table where the TEST_PLAN_ID matches and the EXECUTION_STATUS is either 'Passed' or 'Failed', and then deleting the corresponding record from the TEST_PLANS table for that TEST_PLAN_ID.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named archive_completed_test_plan that archives a completed test plan by first deleting all test_case_execution records with execution_status of 'Passed' or 'Failed' for the given p_test_plan_id, and then deleting the corresponding record from the test_plans table, using the provided p_archive_location and p_archived_by inputs.",
    "id": 69,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `archive_completed_test_plan` that accepts three input parameters: `p_test_plan_id` of type `bigint`, `p_archive_location` of type `text`, and `p_archived_by` of type `text`. The procedure's primary purpose is to perform data deletion operations related to a specific test plan. Upon execution, the procedure first deletes records from the `test_case_execution` table. This deletion is conditional, targeting rows where the `test_plan_id` column matches the value provided by the `p_test_plan_id` input parameter AND the `execution_status` column's value is either 'Passed' or 'Failed'. Following this initial deletion, the procedure proceeds to delete records from the `test_plans` table. This second deletion is also conditional, specifically targeting rows where the `test_plan_id` column matches the value supplied by the `p_test_plan_id` input parameter. The parameters `p_archive_location` and `p_archived_by` are declared but are not utilized within the current implementation of the procedure's body.",
    "original_summary": "Create a stored procedure named archive_completed_test_plan that accepts p_test_plan_id (bigint), p_archive_location (text), and p_archived_by (text). Delete records from test_case_execution where the test_plan_id matches and the status is 'Passed' or 'Failed'. Then, delete the record from the test_plans table for the matching test_plan_id.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Archive completed test plan. Inputs: p_test_plan_id (bigint), p_archive_location (text), p_archived_by (text). Delete passed/failed test_case_execution records for the ID. Then delete the test_plans record."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named remove_company_data that accepts four input parameters: p_company_name of type TEXT to specify the name of the company, p_status of type TEXT to specify the status of the company, p_cutoff_date of type TEXT to specify a date threshold, and p_confirmation of type TEXT to provide a confirmation string. The procedure begins by checking if the p_confirmation parameter is exactly equal to the string 'CONFIRM'. If this condition is true, it proceeds to query the companies table, selecting the company_id column value into a local variable v_company_id where the company_name column matches the p_company_name parameter and the status column matches the p_status parameter. Using the retrieved v_company_id, the procedure then performs a series of deletions: first, it deletes all rows from the number_allocations table where the company_id column equals v_company_id and the allocation_date column is less than the p_cutoff_date parameter; second, it deletes all rows from the number_prefixes table where the company_id column equals v_company_id; and finally, it deletes the row from the companies table where the company_id column equals v_company_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE remove_company_data(\n    p_company_name TEXT,\n    p_status TEXT,\n    p_cutoff_date TEXT,\n    p_confirmation TEXT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_company_id BIGINT;\nBEGIN\n    IF p_confirmation = 'CONFIRM' THEN\n        SELECT company_id INTO v_company_id FROM companies WHERE company_name = p_company_name AND status = p_status;\n        \n        DELETE FROM number_allocations WHERE company_id = v_company_id AND allocation_date < p_cutoff_date;\n        DELETE FROM number_prefixes WHERE company_id = v_company_id;\n        DELETE FROM companies WHERE company_id = v_company_id;\n    END IF;\nEND;\n$$;",
    "database_name": "telecommunication_number_allocation_and_usage",
    "tables": [
      "number_prefixes",
      "number_allocations",
      "companies"
    ],
    "call_sqls": [
      "CALL remove_company_data('Ast Telecom', 'active', '2023-01-01', 'CONFIRM');",
      "CALL remove_company_data('American Samoa License', 'active', '2023-06-01', 'CONFIRM');",
      "CALL remove_company_data('Ast Telecom', 'active', '2024-01-01', 'TEST');",
      "CALL remove_company_data('Ast Telecom', 'inactive', '2023-01-01', 'CONFIRM');",
      "CALL remove_company_data('Non Existent Company', 'active', '2023-01-01', 'CONFIRM');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `remove_company_data` that, after confirming the action with a 'CONFIRM' parameter, deletes all data for a specific company by first retrieving the company ID from the `companies` table based on the provided company name and status, then removing related records from the `number_allocations` table where the allocation date is before a specified cutoff date, followed by deleting associated records from the `number_prefixes` table, and finally deleting the company record itself from the `companies` table.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called remove_company_data that deletes a company's data after confirmation. It takes the company's name and status to find its ID from the companies table, then removes older allocations from number_allocations before the specified cutoff date, deletes its number prefixes from number_prefixes, and finally deletes the company record from companies, but only if the confirmation parameter is exactly 'CONFIRM'.",
    "id": 70,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named remove_company_data that takes three input parameters: a text parameter for the company's name, a text parameter for the company's status, and a text parameter for confirmation. The procedure declares a local variable of type BIGINT to store the company_id retrieved from the companies table.\n\nThe procedure first validates the confirmation parameter: it checks if the provided confirmation string is exactly equal to the literal string 'CONFIRM'. If it is not, the procedure raises an exception with a message stating that deletion is not confirmed and exits without performing any deletions.\n\nIf the confirmation is valid, the procedure proceeds to query the companies table to find the company_id. It performs a SELECT statement on the companies table, selecting the company_id column where the company_name column matches the input company name parameter and the status column matches the input status parameter. The result of this query is stored into the local company_id variable.\n\nIf no company is found (i.e., the SELECT query returns no rows), the procedure raises an exception with a message indicating that no company was found with the given name and status, and then exits.\n\nIf a company is found, the procedure performs a series of deletion operations. First, it deletes records from the number_allocations table. It deletes all rows where the company_id column matches the retrieved company_id variable and the allocation_date column is older than a specified cutoff date. The cutoff date is provided as a hardcoded literal date string '2010-01-01' within the DELETE statement's WHERE clause.\n\nSecond, the procedure deletes records from the number_prefixes table. It deletes all rows where the company_id column matches the retrieved company_id variable.\n\nFinally, the procedure deletes the company record from the companies table. It deletes the row where the company_id column matches the retrieved company_id variable.\n\nAfter all deletions are completed, the procedure raises a NOTICE message stating that the company data has been successfully removed, including the company name and company_id in the message for reference.",
    "original_summary": "Create a stored procedure named `remove_company_data` that deletes all data for a specific company. First, check if the confirmation parameter equals 'CONFIRM'. If true, find the company ID from the `companies` table using the provided name and status. Then, delete related records from `number_allocations` (where allocation date is before the cutoff), `number_prefixes`, and finally the company itself from the `companies` table.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a stored procedure to get rid of a bunch of company information. First, you need to make sure a certain confirmation parameter is set to the right value. If that checks out, look up the company's ID from the main companies list based on the name and its general status. Then, clean up related entries from the number allocations table for older allocations, remove its number prefixes, and finally delete the company's main record."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `calculate_semester_gpa` that accepts one input parameter: `semester_input` of type `text`, which represents the identifier for a specific academic semester. This procedure is designed to calculate and update the Grade Point Average (GPA) for all students who have completed courses in the specified semester.\n\nThe procedure begins by declaring two local variables: `student_record` of type `RECORD`, which will be used to hold individual student data retrieved during iteration, and `gpa_calc` of type `real`, which is intended for storing a calculated GPA value (though it is not explicitly used in the current implementation as the calculation is directly assigned within the loop).\n\nThe core logic of the procedure involves an iterative process. It initiates a `FOR` loop that iterates over the results of a `SELECT` statement. This `SELECT` statement retrieves data from two tables: `student_courses` (aliased as `sc`) and `courses` (aliased as `c`). These tables are joined using an `INNER JOIN` condition where `sc.course_id` matches `c.course_id`.\n\nThe `SELECT` statement filters the records based on two conditions in its `WHERE` clause: `sc.semester_id` must be equal to the value provided by the `semester_input` parameter, and `sc.status` must be equal to the string literal 'Completed'. This ensures that only courses completed in the specified semester are considered for GPA calculation.\n\nFor the filtered records, the `SELECT` statement groups the results by `sc.student_id`. For each `student_id` group, it calculates a `calculated_gpa`. This `calculated_gpa` is determined by summing the grade points earned for each course and dividing by the sum of credits for those courses. The grade points for each course are calculated using a `CASE` statement:\n- If `sc.grade` is 'A', it contributes `4.0 * c.credits` to the sum of grade points.\n- If `sc.grade` is 'B', it contributes `3.0 * c.credits` to the sum of grade points.\n- If `sc.grade` is 'C', it contributes `2.0 * c.credits` to the sum of grade points.\n- If `sc.grade` is 'D', it contributes `1.0 * c.credits` to the sum of grade points.\n- For any other grade, it contributes `0.0` to the sum of grade points.\nThe sum of these grade points is then divided by the `SUM(c.credits)` for all courses within that student's group to yield the `calculated_gpa`.\n\nFor each `student_record` obtained from this `SELECT` statement (which contains `student_id` and `calculated_gpa`), the procedure executes an `UPDATE` statement. This `UPDATE` statement modifies the `students` table. It sets the `gpa` column to the `calculated_gpa` value obtained from the current `student_record`. The `UPDATE` operation is applied only to the row where the `student_id` in the `students` table matches the `student_id` from the current `student_record`.\n\nThe `FOR` loop continues until all student records satisfying the initial `SELECT` query have been processed, ensuring that the GPA for every eligible student in the specified semester is updated in the `students` table.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_semester_gpa(semester_input text) LANGUAGE plpgsql AS $$\nDECLARE\n    student_record RECORD;\n    gpa_calc real;\nBEGIN\n    FOR student_record IN \n        SELECT sc.student_id, \n               SUM(CASE \n                    WHEN sc.grade = 'A' THEN 4.0 * c.credits\n                    WHEN sc.grade = 'B' THEN 3.0 * c.credits\n                    WHEN sc.grade = 'C' THEN 2.0 * c.credits\n                    WHEN sc.grade = 'D' THEN 1.0 * c.credits\n                    ELSE 0.0\n                   END) / SUM(c.credits) as calculated_gpa\n        FROM student_courses sc\n        JOIN courses c ON sc.course_id = c.course_id\n        WHERE sc.semester_id = semester_input AND sc.status = 'Completed'\n        GROUP BY sc.student_id\n    LOOP\n        UPDATE students \n        SET gpa = student_record.calculated_gpa\n        WHERE student_id = student_record.student_id;\n    END LOOP;\nEND;\n$$;",
    "database_name": "student_academic_performance_tracking",
    "tables": [
      "students",
      "student_courses",
      "courses",
      "instructors",
      "attendance",
      "semesters"
    ],
    "call_sqls": [
      "CALL calculate_semester_gpa('0');",
      "CALL calculate_semester_gpa('1');",
      "CALL calculate_semester_gpa('Fall 2023');",
      "CALL calculate_semester_gpa('Spring 2024');",
      "CALL calculate_semester_gpa('2');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_semester_gpa that, for a given semester specified by semester_input, updates the GPA in the students table for each student who has completed courses in that semester. The GPA is calculated by summing (grade points multiplied by course credits) and dividing by the total credits, using the grade points: A=4.0, B=3.0, C=2.0, D=1.0, and 0.0 for any other grade, based on data from the student_courses and courses tables.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called calculate_semester_gpa that updates the GPA in the students table for each student who has completed courses in a specified semester. For every such student, compute the semester GPA by summing the product of grade points and course credits for each completed course, then dividing by the total credits, using the grade points: A=4.0, B=3.0, C=2.0, D=1.0, and 0.0 for all other grades.",
    "id": 71,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `calculate_semester_gpa` that accepts one input parameter: a `semester_id` of type `text`. The procedure's primary purpose is to update the `gpa` column in the `students` table for each student who has completed courses in the specified semester, calculating a new semester-specific GPA based on their grades and the associated course credits.\n\nThe procedure begins by performing a query to gather the necessary data for the GPA calculation. It selects from the `students` table, joining with the `student_courses` table on `students.student_id = student_courses.student_id`, and then joining with the `courses` table on `student_courses.course_id = courses.course_id`. The join conditions ensure that only relevant course and enrollment data are considered. The selection is filtered with a `WHERE` clause that specifies two conditions: `student_courses.semester_id` must equal the input `semester_id` parameter, and `student_courses.status` must be exactly the string `'Completed'`. This ensures the calculation only includes courses the student has finished in that specific semester.\n\nFor each student meeting these criteria, the procedure calculates two aggregate values from their completed courses. First, it computes a weighted sum: for each course, it converts the letter grade from the `student_courses.grade` column to a numeric grade point using a `CASE` expression, multiplies that grade point by the number of `credits` from the `courses` table for that course, and then sums all these products. The `CASE` expression maps grades as follows: `'A'` maps to `4.0`, `'B'` maps to `3.0`, `'C'` maps to `2.0`, `'D'` maps to `1.0`, and any other grade value (including `NULL` or grades like `'F'`) maps to `0.0`. Second, it computes the total sum of all `credits` from the `courses` table for the student's completed courses in that semester.\n\nUsing these aggregates, the procedure then calculates the semester GPA for each student. The calculation is performed by dividing the computed weighted sum (the sum of grade points multiplied by credits) by the total sum of credits. To handle the edge case where a student has no completed credits (resulting in a division by zero), the procedure uses a `NULLIF` function to make the divisor `NULL` if the total credits sum is zero, which causes the division to return `NULL`. This `NULL` result is then handled by the `COALESCE` function, which converts it to `0.0`, ensuring the GPA defaults to zero when no credits are present.\n\nFinally, the procedure executes an `UPDATE` operation on the `students` table. It sets the `gpa` column for each student to their newly calculated semester GPA value. The `UPDATE` uses a `FROM` clause with the result of the previously described query, correlating the update by matching `students.student_id` with the `student_id` from the query results. This ensures only students who had completed courses in the specified semester receive an updated GPA. The procedure concludes after performing this update.",
    "original_summary": "Create a stored procedure named calculate_semester_gpa that updates the GPA in the students table for all students who have completed courses in a specified semester. The GPA is calculated by summing (grade points * course credits) and dividing by the total credits, where grade points are: A=4.0, B=3.0, C=2.0, D=1.0, else 0.0.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure called calculate_semester_gpa to update the GPA in the students table for every student who has finished courses in a given semester. Compute the GPA by summing (grade points multiplied by course credits) and then dividing by the total credits. Use these grade points: A=4.0, B=3.0, C=2.0, D=1.0, and 0.0 for all other grades."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named update_dataset_version that accepts four input parameters: p_dataset_id of type text, which identifies the target dataset; p_new_version of type text, which specifies the new version string to assign; p_citation of type text, which provides the new citation text; and p_publication_status of type text, which defines the new publication status. The procedure performs an UPDATE operation on the table named datasets. It modifies the row where the column dataset_id matches the value of the input parameter p_dataset_id. For that matching row, it sets the column version to the value of p_new_version, sets the column citation to the value of p_citation, sets the column publication_status to the value of p_publication_status, and sets the column last_updated_date to the current date, which is obtained by calling the CURRENT_DATE function and explicitly casting its result to text using the ::text cast operator.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_dataset_version(\n    p_dataset_id text,\n    p_new_version text,\n    p_citation text,\n    p_publication_status text\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE datasets\n    SET version = p_new_version,\n        citation = p_citation,\n        publication_status = p_publication_status,\n        last_updated_date = CURRENT_DATE::text\n    WHERE dataset_id = p_dataset_id;\nEND;\n$$;",
    "database_name": "biomedical_research_and_data_management",
    "tables": [
      "datasets",
      "data_files",
      "dataset_details",
      "data_analysis",
      "access_logs",
      "dataset_shares"
    ],
    "call_sqls": [
      "CALL update_dataset_version('0', '2.0', 'PMID: 98765432', 'published');",
      "CALL update_dataset_version('1', '1.1', 'DOI: 10.1000/xyz123', 'published');",
      "CALL update_dataset_version('2', '3.5', 'Smith et al., Nature, 2024', 'accepted');",
      "CALL update_dataset_version('0', '2.1', 'PMID: 98765432; Updated analysis', 'revised');",
      "CALL update_dataset_version('1', '1.2', 'DOI: 10.1000/xyz123; Supplementary data added', 'published');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_dataset_version that updates a dataset's version, citation, publication_status, and last_updated_date in the datasets table for a given dataset_id, using the provided new version, citation, and publication status, and automatically setting the last_updated_date to the current date.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called update_dataset_version that, for a given dataset identified by its dataset_id, updates its version number to a new version, sets how it should be cited, changes its publication standing, and records the current date as when it was last updated.",
    "id": 72,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `update_dataset_version` that accepts four input parameters: `p_dataset_id` of type `text` to identify the target dataset, `p_new_version` of type `text` to specify the new version number, `p_new_citation` of type `text` to set the updated citation, and `p_new_publication_status` of type `text` to change the publication standing. The procedure returns no values. The core operation is an `UPDATE` statement targeting the `datasets` table. The `UPDATE` statement modifies three columns: `version`, `citation`, and `publication_status`. The `version` column is set to the value of the input parameter `p_new_version`. The `citation` column is set to the value of the input parameter `p_new_citation`. The `publication_status` column is set to the value of the input parameter `p_new_publication_status`. Additionally, the `last_updated_date` column is updated to reflect the current date. This is achieved by setting the `last_updated_date` column to the result of the `CURRENT_DATE` function, which returns the current date as a `date` type. The `UPDATE` operation is conditionally applied only to the row in the `datasets` table where the `dataset_id` column matches the input parameter `p_dataset_id`. This is enforced by a `WHERE` clause that filters the update to rows where `dataset_id = p_dataset_id`. The procedure executes this single `UPDATE` statement and then completes.",
    "original_summary": "Create a stored procedure named update_dataset_version that updates a dataset's version, citation, publication_status, and last_updated_date based on a provided dataset_id.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Make a stored procedure called update_dataset_version that, for a given dataset, adjusts its version number, how it should be cited, its publication standing, and when it was last touched up."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named calculate_total_findings that accepts a single input parameter p_commit_id of type bigint, which represents the identifier for a specific commit record. The procedure first declares two local bigint variables: total_findings to hold a sum and next_change_id to hold a sequence number. It begins execution by performing a SELECT query on the code_reviews table, calculating the sum of the number_of_findings column for all rows where the commit_id column matches the provided p_commit_id parameter, and stores the result into the total_findings variable. Next, it executes another SELECT query on the repository_changes table to determine the next available change_id by taking the maximum existing value from the change_id column, using the COALESCE function to return 0 if no maximum is found (i.e., the table is empty), and then adding 1 to that value, storing the result into the next_change_id variable. Finally, the procedure performs an INSERT operation into the repository_changes table, specifying values for the columns change_id, repository_id, developer_id, change_date, and change_type. The value for change_id is the calculated next_change_id. The value for repository_id is obtained via a scalar subquery that selects the repository_id from the commits table where the commit_id column equals the input p_commit_id. The developer_id is hardcoded as 0. The change_date is set to the current date converted to text using CURRENT_DATE::text. The change_type is set to the literal string 'total_findings_calculated'.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_total_findings(p_commit_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    total_findings bigint;\n    next_change_id bigint;\nBEGIN\n    SELECT SUM(number_of_findings)\n    INTO total_findings\n    FROM code_reviews\n    WHERE commit_id = p_commit_id;\n    \n    SELECT COALESCE(MAX(change_id), 0) + 1\n    INTO next_change_id\n    FROM repository_changes;\n    \n    INSERT INTO repository_changes (change_id, repository_id, developer_id, change_date, change_type)\n    VALUES (next_change_id, (SELECT repository_id FROM commits WHERE commit_id = p_commit_id), 0, CURRENT_DATE::text, 'total_findings_calculated');\nEND;\n$$;",
    "database_name": "software_development_and_collaboration_metrics",
    "tables": [
      "code_reviews",
      "commits",
      "repositories",
      "repository_changes"
    ],
    "call_sqls": [
      "CALL calculate_total_findings(1);",
      "CALL calculate_total_findings(2);",
      "CALL calculate_total_findings(3);",
      "CALL calculate_total_findings(4);",
      "CALL calculate_total_findings(5);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_total_findings that accepts a commit ID, calculates the total number_of_findings from the code_reviews table for that commit, determines the next available change_id from the repository_changes table, and inserts a new record into repository_changes with that change_id, the corresponding repository_id from the commits table, a developer_id of 0, the current date, and a change_type of 'total_findings_calculated'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_total_findings that takes a commit ID as input, calculates the total number of findings from the code_reviews table for that commit, determines the next available change_id from the repository_changes table, and inserts a new record into repository_changes with that change_id, the corresponding repository_id from the commits table, a developer_id of 0, today's date, and a change_type of 'total_findings_calculated'.",
    "id": 73,
    "generated_ir": "Write a PostgreSQL PLpgSQL stored procedure named calculate_total_findings that accepts a single input parameter p_commit_id of type bigint, which represents the identifier for a specific commit record. The procedure first declares two local bigint variables: total_findings to hold a sum and next_change_id to hold a sequence number. It begins execution by performing a SELECT query on the code_reviews table, calculating the sum of the number_of_findings column for all rows where the commit_id column matches the provided p_commit_id parameter, and stores the result into the total_findings variable. Next, it executes another SELECT query on the repository_changes table to determine the next available change_id by taking the maximum existing value from the change_id column, using the COALESCE function to return 0 if no maximum is found (i.e., the table is empty), and then adding 1 to that value, storing the result into the next_change_id variable. Finally, the procedure performs an INSERT operation into the repository_changes table, specifying values for the columns change_id, repository_id, developer_id, change_date, and change_type. The value for change_id is the calculated next_change_id. The value for repository_id is obtained via a scalar subquery that selects the repository_id from the commits table where the commit_id column equals the input p_commit_id. The developer_id is hardcoded as 0. The change_date is set to the current date converted to text using CURRENT_DATE::text. The change_type is set to the literal string 'total_findings_calculated'.",
    "original_summary": "Create a stored procedure named calculate_total_findings that accepts a commit ID (bigint). It calculates the sum of number_of_findings from code_reviews for that commit, determines the next change_id from repository_changes, and inserts a new record into repository_changes with the calculated ID, the associated repository_id, a developer_id of 0, the current date as text, and a change_type of 'total_findings_calculated'.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Make a stored procedure, maybe call it something like calculate_total_findings, that takes a commit ID. It should figure out roughly the total number of findings from code_reviews for that commit, find what seems like the next available change_id from the repository_changes table, and then put a new entry into repository_changes. This new entry would use that calculated ID, grab the related repository_id, set developer_id to 0, use today's date, and mark the change_type as something like 'total_findings_calculated'."
  },
  {
    "ir": "Write a PLpgSQL stored procedure that deletes a row from the order_items table where the order_id column matches the provided parameter p_order_id of type bigint and the item_id column matches the provided parameter p_item_id of type bigint.",
    "plsql": "CREATE OR REPLACE PROCEDURE remove_order_item(p_order_id bigint, p_item_id bigint)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM order_items\n    WHERE order_id = p_order_id AND item_id = p_item_id;\nEND;\n$$;",
    "database_name": "clothing_size_specifications_and_inventory_management_736487",
    "tables": [
      "clothing_items",
      "inventory",
      "order_items",
      "orders",
      "customers",
      "sizes"
    ],
    "call_sqls": [
      "CALL remove_order_item(0, 0);",
      "CALL remove_order_item(0, 1);",
      "CALL remove_order_item(1, 0);",
      "CALL remove_order_item(1, 1);",
      "CALL remove_order_item(2, 3);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named remove_order_item that deletes a record from the order_items table where the order_id matches the provided order identifier and the item_id matches the provided item identifier.",
    "natural_language": "Hey, can you whip up a PostgreSQL PL/pgSQL stored procedure named remove_order_item that zaps a record from the `order_items` table? It just needs to find the row where the `order_id` and `item_id` match the numbers we give it as input parameters.",
    "id": 74,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named remove_order_item that accepts two input parameters: p_order_id of type bigint and p_item_id of type bigint. The procedure's purpose is to delete a specific record from the order_items table. It performs a DELETE operation on the order_items table. The deletion is conditional, targeting only the row or rows where the order_id column value exactly matches the input parameter p_order_id and simultaneously the item_id column value exactly matches the input parameter p_item_id. The procedure does not return a value.",
    "original_summary": "Create a stored procedure that deletes a record from the `order_items` table where the `order_id` and `item_id` match the provided input parameters.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure that zaps a record from the `order_items` table? It just needs to find the row where the `order_id` and `item_id` match the numbers we give it."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named calculate_average_cell_intensity that accepts three parameters: p_sample_id of type bigint, p_intensity_threshold of type real, and p_multiplier of type real. The procedure begins by declaring several local variables: v_avg_intensity of type real to store the average intensity, v_bit_pattern of type bit(18) initialized to the binary pattern '101010101010101010', v_bit_value of type integer to hold a specific bit value, and v_new_cell_id of type bigint to store a new cell identifier. The procedure first calculates the average cell intensity from the cell_metrics table for rows where the sample_id matches the provided p_sample_id, storing the result in v_avg_intensity. It then retrieves the value of the fourth bit from v_bit_pattern using the get_bit function, storing this value in v_bit_value. Next, it determines the next available cell_id by selecting the maximum cell_id from the cell_metrics table, defaulting to 0 if no rows exist, and incrementing this value by 1, storing the result in v_new_cell_id. The procedure then evaluates whether v_avg_intensity exceeds the p_intensity_threshold. If true, it inserts a new row into the cell_metrics table with the following values: v_new_cell_id for cell_id, p_sample_id for sample_id, fixed values for cell_area, cell_perimeter, cell_circularity, cell_max_caliper, cell_min_caliper, cell_eosin_mean, cell_volume, cell_shape, cell_texture, and cell_area_std_dev, and a calculated cell_intensity using the formula v_avg_intensity multiplied by p_multiplier and v_bit_value. If the condition is false, it inserts a new row with similar fixed values but different values for cell_area, cell_perimeter, cell_circularity, cell_max_caliper, cell_min_caliper, cell_eosin_mean, cell_volume, cell_shape, cell_texture, and cell_area_std_dev, and sets cell_intensity directly to v_avg_intensity.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_average_cell_intensity(\n    p_sample_id bigint,\n    p_intensity_threshold real,\n    p_multiplier real\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_avg_intensity real;\n    v_bit_pattern bit(18) := B'101010101010101010';\n    v_bit_value integer;\n    v_new_cell_id bigint;\nBEGIN\n    SELECT AVG(cell_intensity) INTO v_avg_intensity\n    FROM cell_metrics\n    WHERE sample_id = p_sample_id;\n    \n    v_bit_value := get_bit(v_bit_pattern, 4);\n    \n    SELECT COALESCE(MAX(cell_id), 0) + 1 INTO v_new_cell_id FROM cell_metrics;\n    \n    IF v_avg_intensity > p_intensity_threshold THEN\n        INSERT INTO cell_metrics (cell_id, sample_id, cell_area, cell_perimeter, cell_circularity, cell_max_caliper, cell_min_caliper, cell_eosin_mean, cell_volume, cell_shape, cell_texture, cell_intensity, cell_area_std_dev)\n        VALUES (v_new_cell_id, p_sample_id, 100.0, 50.0, 0.9, 10.0, 8.0, 0.2, 1000.0, 'Spherical', 'Smooth', v_avg_intensity * p_multiplier * v_bit_value, 1.0);\n    ELSE\n        INSERT INTO cell_metrics (cell_id, sample_id, cell_area, cell_perimeter, cell_circularity, cell_max_caliper, cell_min_caliper, cell_eosin_mean, cell_volume, cell_shape, cell_texture, cell_intensity, cell_area_std_dev)\n        VALUES (v_new_cell_id, p_sample_id, 80.0, 40.0, 0.8, 9.0, 7.0, 0.15, 900.0, 'Ellipsoidal', 'Granular', v_avg_intensity, 1.5);\n    END IF;\nEND;\n$$;",
    "database_name": "biological_sample_analysis_and_metrics",
    "tables": [
      "cell_metrics",
      "cytoplasm_metrics",
      "nucleus_metrics",
      "nucleus_OD_metrics"
    ],
    "call_sqls": [
      "CALL calculate_average_cell_intensity(1, 0.2, 1.5);",
      "CALL calculate_average_cell_intensity(0, 0.25, 2.0);",
      "CALL calculate_average_cell_intensity(1, 0.15, 1.2);",
      "CALL calculate_average_cell_intensity(0, 0.3, 1.8);",
      "CALL calculate_average_cell_intensity(1, 0.22, 1.0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_average_cell_intensity that takes a sample ID (p_sample_id), an intensity threshold (p_intensity_threshold), and a multiplier (p_multiplier) as inputs, calculates the average cell_intensity from the cell_metrics table for the given sample_id, extracts a specific bit value from a fixed bit pattern, generates a new cell_id by incrementing the maximum existing cell_id in cell_metrics, and then, if the average intensity exceeds the threshold, inserts a new row into cell_metrics with the calculated intensity (average multiplied by the multiplier and the bit value) along with predefined metric values for cell_area, cell_perimeter, cell_circularity, cell_max_caliper, cell_min_caliper, cell_eosin_mean, cell_volume, cell_shape, cell_texture, and cell_area_std_dev; otherwise, inserts a row with the raw average intensity and different predefined metric values.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called 'calculate_average_cell_intensity' that takes a sample ID, an intensity threshold, and a multiplier as parameters. The procedure should calculate the average cell_intensity from the cell_metrics table for the given sample ID, extract the 4th bit from a fixed bit pattern, and generate a new cell_id by incrementing the maximum existing one. If the calculated average exceeds the provided intensity threshold, insert a new row into cell_metrics with the average multiplied by the multiplier and the extracted bit value, along with predefined metrics for cell_area, cell_perimeter, cell_circularity, cell_max_caliper, cell_min_caliper, cell_eosin_mean, cell_volume, cell_shape, cell_texture, and cell_area_std_dev. Otherwise, insert a row with just the raw average and a different set of predefined metrics.",
    "id": 75,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `calculate_average_cell_intensity` that accepts three input parameters: a `sample_id` of type `bigint`, an `intensity_threshold` of type `real`, and a `multiplier` of type `real`. The procedure operates on the `biological_sample_analysis_and_metrics` database and manipulates the `cell_metrics` table.\n\nThe procedure begins by declaring a local variable `avg_intensity` of type `real` to store the computed average. It executes a `SELECT` statement with an `AVG` aggregation on the `cell_intensity` column from the `cell_metrics` table, specifically for rows where the `sample_id` column matches the input `sample_id` parameter. The result of this calculation is stored in the `avg_intensity` variable.\n\nNext, the procedure declares a local variable `bit_value` of type `integer`. It extracts the 4th bit (bit position 3, counting from 0) from a fixed 8-bit binary pattern represented by the integer value `42` (binary `00101010`). This extraction is performed using the `GET_BIT` function, and the resulting bit value (either `0` or `1`) is stored in the `bit_value` variable.\n\nThe procedure then declares a local variable `new_cell_id` of type `bigint`. It executes a `SELECT` statement to find the maximum existing value in the `cell_id` column of the `cell_metrics` table. The `COALESCE` function is used to handle cases where the table is empty, substituting `0` if `MAX(cell_id)` returns `NULL`. This maximum value is incremented by `1` to generate a new, unique `cell_id`, which is stored in the `new_cell_id` variable.\n\nFollowing this, the procedure uses an `IF` statement to evaluate a condition: it checks whether the `avg_intensity` variable is greater than the input `intensity_threshold` parameter.\n\nIf the condition is true (i.e., `avg_intensity > intensity_threshold`), the procedure performs an `INSERT` operation into the `cell_metrics` table. It inserts a new row with the following column values:\n- `cell_id` is set to the value from the `new_cell_id` variable.\n- `sample_id` is set to the input `sample_id` parameter.\n- `cell_intensity` is set to the result of multiplying the `avg_intensity` variable by the input `multiplier` parameter.\n- `cell_area` is set to a predefined constant value of `100.0`.\n- `cell_perimeter` is set to a predefined constant value of `35.0`.\n- `cell_circularity` is set to a predefined constant value of `0.9`.\n- `cell_max_caliper` is set to a predefined constant value of `10.0`.\n- `cell_min_caliper` is set to a predefined constant value of `8.0`.\n- `cell_eosin_mean` is set to the value from the `bit_value` variable (cast to `real`).\n- `cell_volume` is set to a predefined constant value of `500.0`.\n- `cell_shape` is set to a predefined constant string `'Regular'`.\n- `cell_texture` is set to a predefined constant string `'Uniform'`.\n- `cell_area_std_dev` is set to a predefined constant value of `1.0`.\n\nIf the condition is false (i.e., `avg_intensity <= intensity_threshold`), the procedure performs a different `INSERT` operation into the `cell_metrics` table. It inserts a new row with the following column values:\n- `cell_id` is set to the value from the `new_cell_id` variable.\n- `sample_id` is set to the input `sample_id` parameter.\n- `cell_intensity` is set to the raw `avg_intensity` variable value (without multiplication).\n- `cell_area` is set to a predefined constant value of `50.0`.\n- `cell_perimeter` is set to a predefined constant value of `25.0`.\n- `cell_circularity` is set to a predefined constant value of `0.8`.\n- `cell_max_caliper` is set to a predefined constant value of `7.0`.\n- `cell_min_caliper` is set to a predefined constant value of `5.0`.\n- `cell_eosin_mean` is set to a predefined constant value of `0.0`.\n- `cell_volume` is set to a predefined constant value of `300.0`.\n- `cell_shape` is set to a predefined constant string `'Irregular'`.\n- `cell_texture` is set to a predefined constant string `'Variable'`.\n- `cell_area_std_dev` is set to a predefined constant value of `2.0`.\n\nThe procedure does not return a value; it is a `PROCEDURE` that performs data manipulation via `INSERT` operations based on the calculated average and the threshold comparison.",
    "original_summary": "Create a stored procedure named calculate_average_cell_intensity with parameters: p_sample_id (bigint), p_intensity_threshold (real), p_multiplier (real). Declare variables: v_avg_intensity (real), v_bit_pattern (bit(18)), v_bit_value (integer), v_new_cell_id (bigint). It should: 1) Calculate average intensity for the given sample_id. 2) Extract the 4th bit from a fixed bit pattern. 3) Generate a new cell_id by incrementing the maximum existing ID. 4) If the average intensity exceeds the threshold, insert a new row with calculated intensity (avg * multiplier * bit_value) and predefined metrics. Otherwise, insert a row with the raw average intensity and different predefined metrics.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure called 'calculate_average_cell_intensity' that takes parameters for sample ID, intensity threshold, and a multiplier? The procedure should calculate the average intensity for the specified sample, extract the 4th bit from a fixed bit pattern, and generate a new cell ID by incrementing the maximum existing one. If the calculated average exceeds the given threshold, how should it insert a new row using the average multiplied by the multiplier and the extracted bit value, along with some predefined metrics? Otherwise, how should it insert a row with just the raw average and a different set of predefined metrics?"
  },
  {
    "ir": "Write a PLpgSQL stored procedure named `generate_model_experiment_summary` that accepts two input parameters: `p_min_experiment_count` of type `integer`, which specifies the minimum number of experiments required for a model to be included in the summary, and `p_status_filter` of type `text`, which specifies the status of experiments to be counted and considered for the summary. The procedure begins by declaring a record variable named `v_model_summary` to hold the results of an iterative query. It then initiates a loop that iterates over a result set obtained by performing a `SELECT` operation. This `SELECT` statement retrieves `model_id` and `model_name` from the `models` table, aliased as `m`, and calculates the count of `experiment_id`s from the `experiments` table, aliased as `e`, naming this count `exp_count`. The `models` table is `LEFT JOIN`ed with the `experiments` table on the condition that `m.model_id` equals `e.model_id` AND `e.status` equals the input parameter `p_status_filter`. The results are then `GROUP BY` `m.model_id` and `m.model_name`. Finally, the `HAVING` clause filters these grouped results, including only those where the `COUNT(e.experiment_id)` is greater than or equal to the input parameter `p_min_experiment_count`. For each `v_model_summary` record returned by this `SELECT` query, the procedure executes an `INSERT` statement into the `experiment_versions` table. The `INSERT` statement populates the following columns: `version_id`, `experiment_id`, `version_number`, `created_at`, `description`, and `version_type`. The value for `version_id` is determined by a subquery that calculates `COALESCE(MAX(version_id), 0) + 1` from the `experiment_versions` table, effectively generating a new sequential ID. The value for `experiment_id` is obtained from another subquery that selects the `experiment_id` from the `experiments` table where `model_id` equals `v_model_summary.model_id` and `status` equals `p_status_filter`, limiting the result to one row. The `version_number` is set to the literal string 'SUMMARY_v1.0'. The `created_at` column is set to the current timestamp converted to `text` using `CURRENT_TIMESTAMP::text`. The `description` column is constructed by concatenating the literal string 'Summary for ', the `model_name` from the current `v_model_summary` record, the literal string ': ', the `exp_count` from the current `v_model_summary` record, the literal string ' ', the `p_status_filter` parameter, and the literal string ' experiments'. The `version_type` column is set to the literal string 'minor'. This `INSERT` operation is performed for each model that meets the specified experiment count and status criteria.",
    "plsql": "CREATE OR REPLACE PROCEDURE generate_model_experiment_summary(p_min_experiment_count integer, p_status_filter text)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_model_summary record;\nBEGIN\n    FOR v_model_summary IN SELECT m.model_id, m.model_name, COUNT(e.experiment_id) as exp_count FROM models m LEFT JOIN experiments e ON m.model_id = e.model_id AND e.status = p_status_filter GROUP BY m.model_id, m.model_name HAVING COUNT(e.experiment_id) >= p_min_experiment_count\n    LOOP\n        INSERT INTO experiment_versions (version_id, experiment_id, version_number, created_at, description, version_type)\n        SELECT COALESCE(MAX(version_id), 0) + 1, (SELECT experiment_id FROM experiments WHERE model_id = v_model_summary.model_id AND status = p_status_filter LIMIT 1), 'SUMMARY_v1.0', CURRENT_TIMESTAMP::text, 'Summary for ' || v_model_summary.model_name || ': ' || v_model_summary.exp_count || ' ' || p_status_filter || ' experiments', 'minor' FROM experiment_versions;\n    END LOOP;\nEND;\n$$;",
    "database_name": "machine_learning_model_performance_tracking_6768",
    "tables": [
      "experiments",
      "experiment_collaborators",
      "experiment_versions",
      "models",
      "users"
    ],
    "call_sqls": [
      "CALL generate_model_experiment_summary(2, 'completed');",
      "CALL generate_model_experiment_summary(1, 'running');",
      "CALL generate_model_experiment_summary(3, 'completed');",
      "CALL generate_model_experiment_summary(0, 'failed');",
      "CALL generate_model_experiment_summary(5, 'pending');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named generate_model_experiment_summary that accepts a minimum experiment count parameter p_min_experiment_count and a status filter parameter p_status_filter to create summary records in the experiment_versions table for each model from the models table that has at least the specified number of experiments with the given status in the experiments table. For each qualifying model, insert a row into experiment_versions with a generated version_id (incremented from the maximum existing one), one associated experiment_id from that model's experiments with the filtered status, version_number 'SUMMARY_v1.0', the current timestamp, a description containing the model name and experiment count, and version_type 'minor'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called generate_model_experiment_summary that takes an integer parameter p_min_experiment_count and a text parameter p_status_filter, and for each model from the models table that has at least the specified number of experiments with the given status in the experiments table, inserts a summary record into the experiment_versions table. Each inserted record should have a version_id generated as the next available integer, an experiment_id from one of the matching experiments, the version_number set to 'SUMMARY_v1.0', the created_at as the current timestamp, a description combining the model name and experiment count with the status, and a version_type of 'minor'.",
    "id": 76,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named generate_model_experiment_summary that accepts two input parameters: p_min_experiment_count of type integer, which specifies the minimum number of experiments a model must have; and p_status_filter of type text, which specifies the status of experiments to filter by. The procedure operates on the database machine_learning_model_performance_tracking_6768.\n\nThe procedure first identifies all models from the models table that meet a specific condition. For each model, it counts the number of associated experiments in the experiments table where the status column exactly matches the p_status_filter parameter. Only models where this count is greater than or equal to the p_min_experiment_count parameter are selected.\n\nFor each qualifying model, the procedure performs an insertion into the experiment_versions table. It generates a new version_id by finding the maximum existing version_id in the experiment_versions table and adding one to it, ensuring it is the next available integer. It selects an experiment_id from one of the experiments associated with the current model that has the matching status; specifically, it chooses the minimum experiment_id among those to ensure a deterministic selection. The version_number column is set to the literal string 'SUMMARY_v1.0'. The created_at column is set to the current system timestamp. The description column is constructed by concatenating the model_name from the models table, the string literal ' has ', the count of experiments (as computed earlier), the string literal ' experiments with status ', and the p_status_filter parameter value. The version_type column is set to the literal string 'minor'. The experiment_id column from the experiments table is included as is, and the description column from the experiments table is not used in this insertion.\n\nThe procedure uses a loop to iterate over each qualifying model, performing the insertion for each one. It does not return a value; it is a void procedure that modifies the experiment_versions table by adding new summary records based on the specified criteria.",
    "original_summary": "Create a stored procedure named generate_model_experiment_summary that accepts an integer parameter p_min_experiment_count and a text parameter p_status_filter. For each model with at least p_min_experiment_count experiments having the specified status, insert a summary record into the experiment_versions table with a generated version_id, one associated experiment_id, version_number 'SUMMARY_v1.0', current timestamp, a description containing the model name and experiment count, and version_type 'minor'.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure called generate_model_experiment_summary that takes an integer parameter p_min_experiment_count and a text parameter p_status_filter, so that for each model with at least the specified number of experiments matching the given status, it inserts a summary record into the experiment_versions table? The record should have a generated version_id, one associated experiment_id, the version_number 'SUMMARY_v1.0', the current timestamp, a description with the model name and experiment count, and a version_type of 'minor'."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named create_payment_record that accepts four input parameters: input_order_id of type BIGINT, payment_method_name of type TEXT, payment_amount of type NUMERIC, and gateway_name of type TEXT. The procedure begins by declaring two local variables: new_payment_id of type BIGINT and transaction_ref of type TEXT. It then executes a SELECT statement to determine the maximum value of payment_id from the payments table, using the COALESCE function to handle null values by defaulting to 0, and increments this maximum value by 1 to generate a new payment_id, storing the result in the new_payment_id variable. Next, it constructs a transaction reference string by concatenating the prefix 'TXN' with the current timestamp in seconds since the epoch, converted to BIGINT, and assigns this string to the transaction_ref variable. The procedure proceeds to insert a new record into the payments table, populating the columns payment_id, order_id, payment_method, amount, payment_date, payment_status, payment_gateway, transaction_id, created_at, and modified_at with the values new_payment_id, input_order_id, payment_method_name, payment_amount converted to TEXT, the current timestamp converted to TEXT, the string 'paid', gateway_name, transaction_ref, and the current timestamp converted to TEXT for both created_at and modified_at, respectively.",
    "plsql": "CREATE OR REPLACE PROCEDURE create_payment_record(\n    IN input_order_id BIGINT,\n    IN payment_method_name TEXT,\n    IN payment_amount NUMERIC,\n    IN gateway_name TEXT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    new_payment_id BIGINT;\n    transaction_ref TEXT;\nBEGIN\n    SELECT COALESCE(MAX(payment_id), 0) + 1 INTO new_payment_id FROM payments;\n    transaction_ref := 'TXN' || EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)::BIGINT;\n    \n    INSERT INTO payments (payment_id, order_id, payment_method, amount, payment_date, payment_status, payment_gateway, transaction_id, created_at, modified_at)\n    VALUES (new_payment_id, input_order_id, payment_method_name, payment_amount::TEXT, CURRENT_TIMESTAMP::TEXT, 'paid', gateway_name, transaction_ref, CURRENT_TIMESTAMP::TEXT, CURRENT_TIMESTAMP::TEXT);\nEND;\n$$;",
    "database_name": "e_commerce_order_management_and_analytics",
    "tables": [
      "orders",
      "order_items",
      "products",
      "payments",
      "shipping"
    ],
    "call_sqls": [
      "CALL create_payment_record(0, 'Credit Card', 23.90, 'Stripe');",
      "CALL create_payment_record(1, 'PayPal', 99.99, 'PayPal');",
      "CALL create_payment_record(0, 'Debit Card', 15.50, 'Square');",
      "CALL create_payment_record(1, 'Bank Transfer', 120.00, 'TransferWise');",
      "CALL create_payment_record(0, 'Apple Pay', 50.00, 'Stripe');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `create_payment_record` that, for a given input_order_id, payment_method_name, payment_amount, and gateway_name, generates a new sequential payment_id from the PAYMENTS table and a unique transaction reference based on the current timestamp, then inserts a new record into the PAYMENTS table with these values, setting the payment_status to 'paid' and using the current timestamp for the payment_date, created_at, and modified_at fields.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called create_payment_record that generates a new payment identifier and a unique transaction reference, then inserts a payment record into the payments table with a status of 'paid' and the current timestamp, using the provided order ID, payment method, amount, and gateway name.",
    "id": 77,
    "generated_ir": "Write a PLpgSQL stored procedure named create_payment_record that accepts four input parameters: input_order_id of type BIGINT, payment_method_name of type TEXT, payment_amount of type NUMERIC, and gateway_name of type TEXT. The procedure begins by declaring two local variables: new_payment_id of type BIGINT and transaction_ref of type TEXT. It then executes a SELECT statement to determine the maximum value of payment_id from the payments table, using the COALESCE function to handle null values by defaulting to 0, and increments this maximum value by 1 to generate a new payment_id, storing the result in the new_payment_id variable. Next, it constructs a transaction reference string by concatenating the prefix 'TXN' with the current timestamp in seconds since the epoch, converted to BIGINT, and assigns this string to the transaction_ref variable. The procedure proceeds to insert a new record into the payments table, populating the columns payment_id, order_id, payment_method, amount, payment_date, payment_status, payment_gateway, transaction_id, created_at, and modified_at with the values new_payment_id, input_order_id, payment_method_name, payment_amount converted to TEXT, the current timestamp converted to TEXT, the string 'paid', gateway_name, transaction_ref, and the current timestamp converted to TEXT for both created_at and modified_at, respectively.",
    "original_summary": "Create a stored procedure named `create_payment_record` that generates a new payment ID and a unique transaction reference, then inserts a payment record with a status of 'paid' and the current timestamp.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as `create_payment_record`. This procedure shall be responsible for generating a new payment identifier and a distinct transaction reference. Subsequently, it must insert a payment record, assigning a status of 'paid' and utilizing the current timestamp for the entry."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named `create_user_status_entry` that accepts three input parameters: `p_user_id` of type `TEXT`, `p_status_text` of type `TEXT`, and `p_status_type` of type `TEXT`. The purpose of this procedure is to insert a new record into the `user_status` table, representing a user's status update.\n\nUpon execution, the procedure first declares two local variables: `new_status_id` of type `BIGINT` and `current_ts` of type `TEXT`.\n\nNext, it calculates a unique identifier for the new status entry by assigning a value to `new_status_id`. This value is determined by querying the `user_status` table to find the maximum existing `status_id`. The `COALESCE` function ensures that if no `status_id` exists (i.e., the table is empty and `MAX(status_id)` returns `NULL`), it defaults to `0`. One is then added to this result, effectively generating the next sequential `status_id`.\n\nSubsequently, it calculates the current timestamp and stores it as a text representation in the `current_ts` variable. This is achieved by first extracting the `EPOCH` (number of seconds since 1970-01-01 00:00:00 UTC) from the `CURRENT_TIMESTAMP`, casting this `BIGINT` epoch value to `TEXT`.\n\nFollowing these initial calculations, the procedure evaluates a conditional statement based on the `p_status_text` parameter. It checks if the length of `p_status_text`, after removing leading and trailing whitespace using `TRIM()`, is greater than `0`.\n\nIf the trimmed `p_status_text` has a length greater than `0`, the procedure executes an `INSERT` statement into the `user_status` table. The values inserted are: `new_status_id` for the `status_id` column, `p_user_id` for the `user_id` column, the uppercase version of `p_status_text` (obtained using the `UPPER()` function) for the `status_text` column, `p_status_type` for the `status_type` column, `current_ts` for the `created_at` column, and `current_ts` again for the `updated_at` column.\n\nIf the trimmed `p_status_text` does not have a length greater than `0` (meaning it is empty or contains only whitespace), the procedure executes an alternative `INSERT` statement into the `user_status` table. In this case, the values inserted are: `new_status_id` for the `status_id` column, `p_user_id` for the `user_id` column, the literal string `'DEFAULT STATUS'` for the `status_text` column, `p_status_type` for the `status_type` column, `current_ts` for the `created_at` column, and `current_ts` again for the `updated_at` column.",
    "plsql": "CREATE OR REPLACE PROCEDURE create_user_status_entry(p_user_id TEXT, p_status_text TEXT, p_status_type TEXT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    new_status_id BIGINT;\n    current_ts TEXT;\nBEGIN\n    new_status_id := (SELECT COALESCE(MAX(status_id), 0) + 1 FROM user_status);\n    current_ts := EXTRACT(EPOCH FROM CURRENT_TIMESTAMP)::BIGINT::TEXT;\n    \n    IF LENGTH(TRIM(p_status_text)) > 0 THEN\n        INSERT INTO user_status (status_id, user_id, status_text, status_type, created_at, updated_at)\n        VALUES (new_status_id, p_user_id, UPPER(p_status_text), p_status_type, current_ts, current_ts);\n    ELSE\n        INSERT INTO user_status (status_id, user_id, status_text, status_type, created_at, updated_at)\n        VALUES (new_status_id, p_user_id, 'DEFAULT STATUS', p_status_type, current_ts, current_ts);\n    END IF;\nEND;\n$$;",
    "database_name": "user_activity_and_status_tracking",
    "tables": [
      "server_info",
      "user_activity",
      "user_server_sync",
      "user_status"
    ],
    "call_sqls": [
      "CALL create_user_status_entry('@spyglass:localhost:8800', 'Working from home', 'busy');",
      "CALL create_user_status_entry('@anon-20191002_181700-11:local...', 'In a meeting', 'away');",
      "CALL create_user_status_entry('@user123:server.com', '', 'online');",
      "CALL create_user_status_entry('@johndoe:matrix.org', 'Available for chat', 'online');",
      "CALL create_user_status_entry('@alice:example.com', 'On vacation', 'offline');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named create_user_status_entry that takes a user ID, status text, and status type, generates a new status ID based on the highest existing status_id in the user_status table, and inserts a record into the user_status table with the new status ID, user ID, status type, and the current epoch timestamp for both created_at and updated_at; if the provided status text is not empty after trimming, it uses the uppercase version of that text for the status_text column, otherwise it uses 'DEFAULT STATUS'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called create_user_status_entry that takes a user ID, status text, and status type, generates a new status ID by incrementing the highest existing status_id from the user_status table, and captures the current timestamp. If the provided status text, after trimming whitespace, is not empty, insert a new record into the user_status table with the generated ID, user ID, status text converted to uppercase, status type, and the timestamp for both created_at and updated_at. If the status text is empty, insert the same record but with 'DEFAULT STATUS' as the status text.",
    "id": 78,
    "generated_ir": "Write a PLpgSQL stored procedure named `create_user_status_entry` that accepts three input parameters: `p_user_id` of type `TEXT`, `p_status_text` of type `TEXT`, and `p_status_type` of type `TEXT`. The purpose of this procedure is to insert a new record into the `user_status` table, representing a user's status update.\n\nUpon execution, the procedure first declares two local variables: `new_status_id` of type `BIGINT` and `current_ts` of type `TEXT`.\n\nNext, it calculates a unique identifier for the new status entry by assigning a value to `new_status_id`. This value is determined by querying the `user_status` table to find the maximum existing `status_id`. The `COALESCE` function ensures that if no `status_id` exists (i.e., the table is empty and `MAX(status_id)` returns `NULL`), it defaults to `0`. One is then added to this result, effectively generating the next sequential `status_id`.\n\nSubsequently, it calculates the current timestamp and stores it as a text representation in the `current_ts` variable. This is achieved by first extracting the `EPOCH` (number of seconds since 1970-01-01 00:00:00 UTC) from the `CURRENT_TIMESTAMP`, casting this `BIGINT` epoch value to `TEXT`.\n\nFollowing these initial calculations, the procedure evaluates a conditional statement based on the `p_status_text` parameter. It checks if the length of `p_status_text`, after removing leading and trailing whitespace using `TRIM()`, is greater than `0`.\n\nIf the trimmed `p_status_text` has a length greater than `0`, the procedure executes an `INSERT` statement into the `user_status` table. The values inserted are: `new_status_id` for the `status_id` column, `p_user_id` for the `user_id` column, the uppercase version of `p_status_text` (obtained using the `UPPER()` function) for the `status_text` column, `p_status_type` for the `status_type` column, `current_ts` for the `created_at` column, and `current_ts` again for the `updated_at` column.\n\nIf the trimmed `p_status_text` does not have a length greater than `0` (meaning it is empty or contains only whitespace), the procedure executes an alternative `INSERT` statement into the `user_status` table. In this case, the values inserted are: `new_status_id` for the `status_id` column, `p_user_id` for the `user_id` column, the literal string `'DEFAULT STATUS'` for the `status_text` column, `p_status_type` for the `status_type` column, `current_ts` for the `created_at` column, and `current_ts` again for the `updated_at` column.",
    "original_summary": "Create a stored procedure named create_user_status_entry that takes a user ID, status text, and status type. Generate a new status ID and get the current epoch timestamp. If the trimmed status text is not empty, insert a record into user_status with the new ID, user ID, the uppercase status text, status type, and the timestamp for both created and updated. If the status text is empty, insert the record with 'DEFAULT STATUS' as the status text instead.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a stored procedure called create_user_status_entry that handles a user ID, some status text, and a status type. You'll need to make up a new status ID and grab the current timestamp. If the status text, after cleaning it up a bit, isn't just empty, then put a new entry into the user_status table using the new ID, the user ID, the status text in all caps, the status type, and that timestamp for when it's made and last changed. If the status text is basically empty, then just put in 'DEFAULT STATUS' for the text instead."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named optimize_inventory that accepts two input parameters: p_brand of type text, which specifies a clothing brand, and p_quantity_threshold of type bigint, which defines a numeric limit for inventory quantity comparisons. The procedure first declares three local bigint variables: v_total_quantity, v_max_inventory_id, and v_default_size_id. It begins execution by calculating the total current inventory quantity for the specified brand: it queries the inventory table, joining it with the clothing_items table on the item_id column, summing the quantity column from inventory for all rows where the brand column in clothing_items matches the p_brand parameter, and stores the result (or 0 if the sum is null) into v_total_quantity. Next, it retrieves the maximum existing inventory_id value from the inventory table, storing it (or 0 if null) into v_max_inventory_id. Then, it finds the smallest size_id from the sizes table and stores it into v_default_size_id. The procedure then uses a conditional IF-ELSIF-ELSE block. If v_total_quantity is less than the p_quantity_threshold parameter, it performs an INSERT into the inventory table: it generates new rows for clothing items of the specified brand that are not currently in the inventory table (i.e., their item_id is not found in the inventory table's item_id column). For each such item from the clothing_items table where the brand equals p_brand, it inserts a row with an inventory_id calculated as v_max_inventory_id plus a row number sequentially assigned by ordering the source item_id values, uses the source item_id, sets the size_id to the v_default_size_id, sets quantity to 100, restock_level to 50, and reorder_level to 20. If the first condition is false and v_total_quantity is greater than twice the p_quantity_threshold (i.e., p_quantity_threshold * 2), it performs a DELETE from the inventory table: it removes rows where the item_id belongs to the specified brand (by checking if the item_id exists in the clothing_items table with a matching brand equal to p_brand) and where the quantity column in inventory is less than 50. If neither of the previous conditions is true (meaning v_total_quantity is between p_quantity_threshold and twice that threshold, inclusive of the upper bound), it performs an UPDATE on the inventory table: it increases the restock_level column by 10 for all rows where the item_id belongs to the specified brand (by checking if the item_id exists in the clothing_items table with a matching brand equal to p_brand).",
    "plsql": "CREATE OR REPLACE PROCEDURE optimize_inventory(p_brand text, p_quantity_threshold bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_total_quantity bigint;\n    v_max_inventory_id bigint;\n    v_default_size_id bigint;\nBEGIN\n    SELECT COALESCE(SUM(i.quantity), 0)\n    INTO v_total_quantity\n    FROM inventory i\n    JOIN clothing_items c ON i.item_id = c.item_id\n    WHERE c.brand = p_brand;\n\n    SELECT COALESCE(MAX(inventory_id), 0)\n    INTO v_max_inventory_id\n    FROM inventory;\n\n    SELECT MIN(size_id)\n    INTO v_default_size_id\n    FROM sizes;\n\n    IF v_total_quantity < p_quantity_threshold THEN\n        INSERT INTO inventory (inventory_id, item_id, size_id, quantity, restock_level, reorder_level)\n        SELECT v_max_inventory_id + ROW_NUMBER() OVER (ORDER BY item_id), item_id, v_default_size_id, 100, 50, 20\n        FROM clothing_items\n        WHERE brand = p_brand AND item_id NOT IN (SELECT item_id FROM inventory);\n    ELSIF v_total_quantity > p_quantity_threshold * 2 THEN\n        DELETE FROM inventory\n        WHERE item_id IN (SELECT item_id FROM clothing_items WHERE brand = p_brand) AND quantity < 50;\n    ELSE\n        UPDATE inventory\n        SET restock_level = restock_level + 10\n        WHERE item_id IN (SELECT item_id FROM clothing_items WHERE brand = p_brand);\n    END IF;\nEND;\n$$;",
    "database_name": "fashion_and_apparel_sizing_guide",
    "tables": [
      "clothing_items",
      "inventory",
      "sizes"
    ],
    "call_sqls": [
      "CALL optimize_inventory('Gucci', 150);",
      "CALL optimize_inventory('Nike', 200);",
      "CALL optimize_inventory('Gucci', 300);",
      "CALL optimize_inventory('Nike', 100);",
      "CALL optimize_inventory('Gucci', 250);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named optimize_inventory that accepts a brand and a quantity threshold, calculates the total inventory quantity for that brand from the INVENTORY and CLOTHING_ITEMS tables, and then: if the total is below the threshold, inserts new inventory records for items of that brand not currently in stock, using the smallest size from SIZES as the default size and setting quantity to 100, restock_level to 50, and reorder_level to 20; if the total exceeds twice the threshold, deletes inventory records for the brand where quantity is below 50; otherwise, increases the restock_level by 10 for all inventory of that brand.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called optimize_inventory that takes a brand identifier and a quantity threshold as inputs, calculates the total inventory quantity for that brand from the inventory and clothing_items tables, and then: if the total is below the threshold, adds new inventory records with a default size and a quantity of 100 for items of that brand missing from stock; if the total exceeds twice the threshold, removes any inventory records for the brand where quantity is less than 50; otherwise, increases the restock_level by 10 for all inventory entries of that brand.",
    "id": 79,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named optimize_inventory that accepts two input parameters: a text parameter p_brand to identify a specific clothing brand, and a bigint parameter p_threshold to define a quantity threshold. The procedure operates on the fashion_and_apparel_sizing_guide database and performs a series of conditional operations based on the total inventory quantity calculated for the specified brand.\n\nFirst, the procedure declares a variable v_total_quantity of type bigint to store the computed total inventory quantity for the given brand.\n\nThe procedure begins by calculating the total inventory quantity for the specified brand. It performs a SELECT statement with a SUM aggregation on the inventory.quantity column, joining the inventory table with the clothing_items table on the item_id column. The join condition ensures that only inventory records associated with clothing items of the specified brand (where clothing_items.brand equals the input parameter p_brand) are included. The result of this sum is stored into the variable v_total_quantity.\n\nNext, the procedure uses an IF-ELSIF-ELSE control structure to execute different logic based on the value of v_total_quantity relative to the input threshold p_threshold.\n\nIf v_total_quantity is less than p_threshold, the procedure performs an INSERT operation. It inserts new rows into the inventory table for clothing items of the specified brand that are currently missing from the inventory. This is achieved via a SELECT subquery that selects item_id from the clothing_items table where the brand equals p_brand and the item_id is not already present in the inventory table (using a NOT EXISTS clause with a correlated subquery on inventory where inventory.item_id matches clothing_items.item_id). For each such missing item_id, the INSERT statement uses a hardcoded size_id value of 0 (representing a default size), a hardcoded quantity value of 100, a hardcoded restock_level value of 50, and a hardcoded reorder_level value of 20.\n\nIf v_total_quantity is greater than twice the p_threshold (i.e., v_total_quantity > 2 * p_threshold), the procedure performs a DELETE operation. It deletes rows from the inventory table where the quantity is less than 50 and the item_id corresponds to a clothing item of the specified brand. This is done by joining the inventory table with the clothing_items table on the item_id column, with a condition that clothing_items.brand equals p_brand and inventory.quantity is less than 50.\n\nOtherwise (if v_total_quantity is between p_threshold and twice p_threshold, inclusive), the procedure performs an UPDATE operation. It increases the restock_level by 10 for all inventory entries associated with the specified brand. This is done by updating the inventory table, joining with the clothing_items table on the item_id column, and setting inventory.restock_level = inventory.restock_level + 10 where clothing_items.brand equals p_brand.\n\nThe procedure does not return a value; it is a void procedure that modifies data based on the conditional logic.",
    "original_summary": "Create a stored procedure named optimize_inventory that accepts a brand and a quantity threshold. It calculates the total inventory quantity for that brand. If the total is below the threshold, insert new inventory records for brand items not currently in stock, using a default size and setting quantity to 100. If the total exceeds twice the threshold, delete inventory records for the brand where quantity is below 50. Otherwise, increase the restock_level by 10 for all inventory of that brand.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as 'optimize_inventory'. This procedure shall accept two input parameters: a brand identifier and a quantity threshold value. Its function is to compute the aggregate inventory quantity for the specified brand. Should the computed total fall beneath the provided threshold, the procedure is to insert new inventory records for items of that brand which are presently absent from stock, assigning a default size and a quantity of 100. Conversely, if the total quantity surpasses twice the threshold amount, the procedure must delete any inventory records associated with the brand where the quantity is less than 50. In all other scenarios, it shall increment the restock_level by 10 units for every inventory entry pertaining to that brand."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named process_user_team_relationships that accepts two input parameters: input_user of type BIGINT, representing a user identifier, and input_team of type BIGINT, representing a team identifier. The procedure begins by declaring four local variables: user_active_status of type BIGINT, team_description_var of type TEXT, role_permissions of type TEXT, and invitation_time_var of type TEXT. It then executes a series of SELECT queries to populate these variables: first, it retrieves the is_active column value from the users table where the user_id matches the input_user parameter and stores it in user_active_status; second, it retrieves the description column value from the teams table where the team_id matches the input_team parameter and stores it in team_description_var; third, it retrieves the permissions column value from the roles table by performing a subquery to first get the role_id from the users table for the input_user, and stores the result in role_permissions; fourth, it retrieves the invitation_time column value from the team_invitations table where both the user_id equals input_user and the team_id equals input_team, storing it in invitation_time_var.\n\nThe procedure then implements a primary conditional logic block based on the value of user_active_status. If user_active_status equals 1, it checks if the team_description_var contains the substring 'Team A' using the LIKE operator; if true, it updates the team_invitations table, setting the message column to the literal string 'Active user in Team A' for the specific record where user_id equals input_user and team_id equals input_team; if false, it deletes from the team_invitations table any record where user_id equals input_user, team_id equals input_team, and the status column equals the literal string 'rejected'.\n\nIf user_active_status equals 0, the procedure checks if the role_permissions variable contains the substring 'manage_team' using the LIKE operator; if true, it updates the users table, setting the is_active column to 1 for the row where user_id equals input_user; if false, it performs an INSERT into the team_invitations table, specifying columns invitation_id, team_id, user_id, invitation_time, invited_by, status, and message. The value for invitation_id is derived from a subquery that calculates the maximum existing invitation_id from the team_invitations table, uses COALESCE to handle nulls by defaulting to 0, and adds 1; the team_id and user_id values are taken from the input parameters input_team and input_user respectively; the invitation_time is set to the current timestamp cast to TEXT; invited_by is set to the literal 0; status is set to the literal string 'reactivation'; and message is set to the literal string 'Reactivation invite'.\n\nFor any other value of user_active_status (i.e., not 1 and not 0), the procedure checks if the invitation_time_var variable is not null; if true, it updates the teams table, setting the updated_at column to the current timestamp cast to TEXT for the row where team_id equals input_team; if false, it deletes from the users table any row where user_id equals input_user and the is_superuser column equals 0.",
    "plsql": "CREATE OR REPLACE PROCEDURE process_user_team_relationships(input_user BIGINT, input_team BIGINT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    user_active_status BIGINT;\n    team_description_var TEXT;\n    role_permissions TEXT;\n    invitation_time_var TEXT;\nBEGIN\n    SELECT is_active INTO user_active_status FROM users WHERE user_id = input_user;\n    SELECT description INTO team_description_var FROM teams WHERE team_id = input_team;\n    SELECT permissions INTO role_permissions FROM roles WHERE role_id = (SELECT role_id FROM users WHERE user_id = input_user);\n    SELECT invitation_time INTO invitation_time_var FROM team_invitations WHERE user_id = input_user AND team_id = input_team;\n    \n    IF user_active_status = 1 THEN\n        IF team_description_var LIKE '%Team A%' THEN\n            UPDATE team_invitations SET message = 'Active user in Team A' WHERE user_id = input_user AND team_id = input_team;\n        ELSE\n            DELETE FROM team_invitations WHERE user_id = input_user AND team_id = input_team AND status = 'rejected';\n        END IF;\n    ELSIF user_active_status = 0 THEN\n        IF role_permissions LIKE '%manage_team%' THEN\n            UPDATE users SET is_active = 1 WHERE user_id = input_user;\n        ELSE\n            INSERT INTO team_invitations (invitation_id, team_id, user_id, invitation_time, invited_by, status, message)\n            VALUES ((SELECT COALESCE(MAX(invitation_id), 0) + 1 FROM team_invitations), input_team, input_user, CURRENT_TIMESTAMP::TEXT, 0, 'reactivation', 'Reactivation invite');\n        END IF;\n    ELSE\n        IF invitation_time_var IS NOT NULL THEN\n            UPDATE teams SET updated_at = CURRENT_TIMESTAMP::TEXT WHERE team_id = input_team;\n        ELSE\n            DELETE FROM users WHERE user_id = input_user AND is_superuser = 0;\n        END IF;\n    END IF;\nEND;\n$$;",
    "database_name": "user_management_and_authorization_system",
    "tables": [
      "users",
      "roles",
      "teams",
      "team_invitations"
    ],
    "call_sqls": [
      "CALL process_user_team_relationships(1, 1);",
      "CALL process_user_team_relationships(2, 1);",
      "CALL process_user_team_relationships(3, 2);",
      "CALL process_user_team_relationships(4, 2);",
      "CALL process_user_team_relationships(5, 1);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named process_user_team_relationships that accepts a user ID and a team ID, and processes the user-team relationship based on the user's active status from the users table, the team description from the teams table, the user's role permissions from the roles table, and any existing invitation time from the team_invitations table. If the user is active (status=1), check if the team description contains 'Team A'; if true, update the invitation message to 'Active user in Team A' in team_invitations, otherwise delete any 'rejected' invitations for that user and team. If the user is inactive (status=0), check if the user's permissions contain 'manage_team'; if true, activate the user in the users table, otherwise insert a new 'reactivation' invitation into team_invitations. For any other user status, if an invitation time exists, update the team's timestamp in the teams table; otherwise, delete the user from the users table if they are not a superuser.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called 'process_user_team_relationships' that takes a user ID and a team ID to manage user-team relationships. It should retrieve the user's active status from the users table, the team description from the teams table, the user's role permissions from the roles table, and any existing invitation time from the team_invitations table. If the user is active (status 1), check if the team description contains 'Team A'; if so, update the invitation message in team_invitations to 'Active user in Team A', otherwise delete any rejected invitations for that user and team. If the user is inactive (status 0), check if their permissions include 'manage_team'; if yes, update the user's status to active in the users table, otherwise insert a new reactivation invitation into team_invitations. For any other user status, if an invitation time exists, update the team's timestamp in the teams table; if not, delete the user from the users table only if they are not a superuser.",
    "id": 80,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named process_user_team_relationships that accepts two input parameters: p_user_id of type bigint to identify a specific user, and p_team_id of type bigint to identify a specific team. The procedure declares several variables: v_is_active of type bigint to store the user's active status, v_team_description of type text to store the team's description, v_permissions of type text to store the user's role permissions, v_invitation_time of type text to store any existing invitation time, and v_is_superuser of type bigint to store the user's superuser status.\n\nFirst, the procedure retrieves data from the database using a single SELECT statement that joins the users, teams, roles, and team_invitations tables. It selects the is_active column from the users table, the description column from the teams table, the permissions column from the roles table, and the invitation_time column from the team_invitations table. The SELECT statement includes conditions to filter by the provided p_user_id and p_team_id, and it uses LEFT JOINs to ensure that rows are returned even if there is no matching role or invitation. The retrieved values are stored into the declared variables.\n\nNext, the procedure implements conditional logic based on the value of v_is_active. If v_is_active equals 1, indicating the user is active, it checks if v_team_description contains the substring 'Team A'. If true, it executes an UPDATE operation on the team_invitations table, setting the message column to 'Active user in Team A' for the row where team_id equals p_team_id and user_id equals p_user_id. If false, it executes a DELETE operation on the team_invitations table, removing any rows where team_id equals p_team_id, user_id equals p_user_id, and the status column equals 'rejected'.\n\nIf v_is_active equals 0, indicating the user is inactive, it checks if v_permissions contains the substring 'manage_team'. If true, it executes an UPDATE operation on the users table, setting the is_active column to 1 for the row where user_id equals p_user_id. If false, it executes an INSERT operation into the team_invitations table, adding a new row with team_id set to p_team_id, user_id set to p_user_id, invitation_time set to the current timestamp, invited_by set to NULL, status set to 'pending', and message set to 'Reactivation invitation'.\n\nFor any other value of v_is_active (i.e., not 0 or 1), the procedure checks if v_invitation_time is not NULL. If v_invitation_time exists, it executes an UPDATE operation on the teams table, setting the updated_at column to the current timestamp for the row where team_id equals p_team_id. If v_invitation_time is NULL, it checks the v_is_superuser variable. If v_is_superuser is not equal to 1, it executes a DELETE operation on the users table, removing the row where user_id equals p_user_id. If v_is_superuser equals 1, no action is taken.\n\nThe procedure does not return a value; it performs the described operations and then exits.",
    "original_summary": "Create a stored procedure named process_user_team_relationships that accepts a user ID and a team ID. It retrieves the user's active status, team description, user's role permissions, and any existing invitation time. If the user is active (status=1), check if the team description contains 'Team A'. If true, update the team invitation message to 'Active user in Team A'. If false, delete any 'rejected' invitations for that user and team. If the user is inactive (status=0), check if the user's permissions contain 'manage_team'. If true, activate the user. If false, insert a new 'reactivation' invitation. For any other user status, if an invitation time exists, update the team's timestamp; otherwise, delete the non-superuser.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Alright, so we need a stored procedure called 'process_user_team_relationships' that takes a user ID and a team ID. Here's what it's gotta do: First, grab the user's active status, what the team's about, the user's role permissions, and if there's already an invite time. If the user is active (like, status is 1), see if the team description has 'Team A' in it. If it does, change the team's invitation message to say 'Active user in Team A'. If it doesn't, then get rid of any 'rejected' invites for that user and team combo. Now, if the user is inactive (status 0), check if their permissions include 'manage_team'. If yes, flip their status to active. If no, then add a new 'reactivation' invitation. For any other user status, if there's an invitation time already, just update the team's timestamp. If there isn't one, then delete the user, but only if they're not a superuser."
  },
  {
    "ir": "Write a PLpgSQL stored procedure that updates the demographics table by setting the hispanic_population column to a specified real number and the white_population column to another specified real number for the row where the county_id column matches a given bigint parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_demographics(p_county_id BIGINT, p_hispanic_population REAL, p_white_population REAL)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE demographics\n    SET hispanic_population = p_hispanic_population,\n        white_population = p_white_population\n    WHERE county_id = p_county_id;\nEND;\n$$;",
    "database_name": "demographic_and_economic_data_for_us_counties_159057",
    "tables": [
      "counties",
      "demographics",
      "education_data",
      "data_validations"
    ],
    "call_sqls": [
      "CALL update_demographics(0, 3.2, 76.1);",
      "CALL update_demographics(1, 5.0, 82.5);",
      "CALL update_demographics(0, 2.9, 75.8);",
      "CALL update_demographics(1, 4.7, 83.3);",
      "CALL update_demographics(0, 3.5, 75.0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_demographics that updates the DEMOGRAPHICS table by setting the HISPANIC_POPULATION and WHITE_POPULATION columns to new specified values for the county identified by a given COUNTY_ID.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named update_demographics that updates the hispanic_population and white_population figures to new approximate values in the demographics table for a specified county identified by its county_id.",
    "id": 81,
    "generated_ir": "Write a PLpgSQL stored procedure that updates the demographics table by setting the hispanic_population column to a specified real number and the white_population column to another specified real number for the row where the county_id column matches a given bigint parameter.",
    "original_summary": "Create a stored procedure that updates the demographics table. It sets the hispanic_population and white_population columns to specified real number values for the row where the county_id matches a given bigint parameter.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a procedure to adjust the demographics data. It should update the figures for hispanic and white population to some new approximate values in the record for a particular county."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named consolidate_small_countries that accepts three parameters: p_min_population of type BIGINT, p_target_region_id of type BIGINT, and p_consolidation_year of type BIGINT. The procedure begins by declaring a cursor named v_small_countries_cursor, which selects the country_id, population, and area from the countries table where the population is less than the value of p_min_population. It also declares a record variable v_country_record to hold each row fetched by the cursor, and initializes two variables, v_total_population of type BIGINT and v_total_area of type REAL, to accumulate the total population and area of the selected countries. The procedure enters a loop to iterate over each record in the cursor. Within the loop, it adds the population and area of the current country to v_total_population and v_total_area, respectively. It then deletes records from the countries_regions, migration_data, demographics, and countries tables where the country_id matches the current country_id from the cursor. After processing all countries, the procedure inserts a new row into the countries table with the following values: a new country_id generated by selecting the maximum country_id from the countries table and adding one, a country_code set to 'CONS', a country_name set to 'Consolidated Territory', the total area and population calculated earlier, and various other fixed values for columns such as population_growth, birth_rate, death_rate, migration_rate, created_at, updated_at, capital_city, currency, official_language, government_form, gdp, gdp_growth_rate, life_expectancy, literacy_rate, last_census_year, and last_data_update_year, with the last two set to the value of p_consolidation_year.",
    "plsql": "CREATE OR REPLACE PROCEDURE consolidate_small_countries(\n    p_min_population BIGINT,\n    p_target_region_id BIGINT,\n    p_consolidation_year BIGINT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_small_countries_cursor CURSOR FOR\n        SELECT country_id, population, area\n        FROM countries\n        WHERE population < p_min_population;\n    v_country_record RECORD;\n    v_total_population BIGINT := 0;\n    v_total_area REAL := 0.0;\nBEGIN\n    FOR v_country_record IN v_small_countries_cursor LOOP\n        v_total_population := v_total_population + v_country_record.population;\n        v_total_area := v_total_area + v_country_record.area;\n        \n        DELETE FROM countries_regions WHERE country_id = v_country_record.country_id;\n        DELETE FROM migration_data WHERE country_id = v_country_record.country_id;\n        DELETE FROM demographics WHERE country_id = v_country_record.country_id;\n        DELETE FROM countries WHERE country_id = v_country_record.country_id;\n    END LOOP;\n    \n    INSERT INTO countries (\n        country_id,\n        country_code,\n        country_name,\n        area,\n        land_area,\n        water_area,\n        population,\n        population_growth,\n        birth_rate,\n        death_rate,\n        migration_rate,\n        created_at,\n        updated_at,\n        capital_city,\n        currency,\n        official_language,\n        government_form,\n        gdp,\n        gdp_growth_rate,\n        life_expectancy,\n        literacy_rate,\n        last_census_year,\n        last_data_update_year\n    ) VALUES (\n        (SELECT COALESCE(MAX(country_id), 0) + 1 FROM countries),\n        substring('CONS' from 1 for 4),\n        'Consolidated Territory',\n        v_total_area,\n        v_total_area * 0.9,\n        v_total_area * 0.1,\n        v_total_population,\n        1.0,\n        15.0,\n        8.0,\n        0.0,\n        '2024-01-01 00:00:00',\n        '2024-01-01 00:00:00',\n        'New Capital',\n        'Universal Currency',\n        'Multiple Languages',\n        'Federal Union',\n        v_total_population * 10000.0,\n        2.5,\n        75.0,\n        90.0,\n        p_consolidation_year,\n        p_consolidation_year\n    );\nEND;\n$$;",
    "database_name": "global_demographic_and_geographic_data_management",
    "tables": [
      "countries",
      "countries_regions",
      "regions",
      "demographics",
      "migration_data"
    ],
    "call_sqls": [
      "CALL consolidate_small_countries(1000000, 5, 2023);",
      "CALL consolidate_small_countries(500000, 2, 2024);",
      "CALL consolidate_small_countries(2000000, 1, 2022);",
      "CALL consolidate_small_countries(750000, 3, 2025);",
      "CALL consolidate_small_countries(1500000, 4, 2023);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named consolidate_small_countries that accepts a minimum population threshold, a target region ID, and a consolidation year, identifies all countries from the COUNTRIES table with a population below the given threshold, calculates their total population and total area, removes all related records for those countries from the COUNTRIES_REGIONS, MIGRATION_DATA, DEMOGRAPHICS, and COUNTRIES tables, and then inserts a new consolidated country record into the COUNTRIES table with the calculated totals, fixed attribute values, and the provided consolidation year.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called consolidate_small_countries that takes a minimum population number, a target region ID, and a consolidation year, and for all countries in the COUNTRIES table with a population below the minimum, it sums their total population and area, removes their data from the COUNTRIES_REGIONS, MIGRATION_DATA, DEMOGRAPHICS, and COUNTRIES tables, and then inserts a new consolidated country record into COUNTRIES with the combined totals, fixed details like 'Consolidated Territory' as the name, and the provided year for last census and data update.",
    "id": 82,
    "generated_ir": "Write a PLpgSQL stored procedure named consolidate_small_countries that accepts three parameters: p_min_population of type BIGINT, p_target_region_id of type BIGINT, and p_consolidation_year of type BIGINT. The procedure begins by declaring a cursor named v_small_countries_cursor, which selects the country_id, population, and area from the countries table where the population is less than the value of p_min_population. It also declares a record variable v_country_record to hold each row fetched by the cursor, and initializes two variables, v_total_population of type BIGINT and v_total_area of type REAL, to accumulate the total population and area of the selected countries. The procedure enters a loop to iterate over each record in the cursor. Within the loop, it adds the population and area of the current country to v_total_population and v_total_area, respectively. It then deletes records from the countries_regions, migration_data, demographics, and countries tables where the country_id matches the current country_id from the cursor. After processing all countries, the procedure inserts a new row into the countries table with the following values: a new country_id generated by selecting the maximum country_id from the countries table and adding one, a country_code set to 'CONS', a country_name set to 'Consolidated Territory', the total area and population calculated earlier, and various other fixed values for columns such as population_growth, birth_rate, death_rate, migration_rate, created_at, updated_at, capital_city, currency, official_language, government_form, gdp, gdp_growth_rate, life_expectancy, literacy_rate, last_census_year, and last_data_update_year, with the last two set to the value of p_consolidation_year.",
    "original_summary": "Create a stored procedure named consolidate_small_countries that accepts minimum population, target region ID, and consolidation year parameters. It identifies countries with population below the threshold, sums their total population and area, deletes their related records from multiple tables, and inserts a new consolidated country record with calculated totals and fixed attribute values.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called consolidate_small_countries? It needs to take in a minimum population number, a target region ID, and a year for the consolidation. Basically, it should find all the countries that are too small (population-wise), add up their total people and land area, wipe their data from a bunch of linked tables, and then create a new, bigger country record. This new record should have the combined totals and some other fixed details."
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `consolidate_book_data` that accepts three input parameters: `p_source_format` of type `text`, `p_target_language` of type `text`, and `p_stock_threshold` of type `bigint`. The purpose of this procedure is to consolidate book data based on specific criteria.\n\nFirst, the procedure declares three local variables: `v_consolidation_id` of type `bigint`, `v_total_stock` of type `bigint`, and `v_avg_price` of type `numeric`.\n\nNext, the procedure executes a `SELECT` statement to calculate the sum of `stock_quantity` and the average of `price` from the `books` table. The `price` column is explicitly cast to a `NUMERIC` type using `TO_NUMBER` with the format mask `'999999.99'` before calculating the average. These aggregated values are then stored into the `v_total_stock` and `v_avg_price` variables, respectively. The selection of rows for this aggregation is filtered by two conditions: the `format` column must be equal to the `p_source_format` parameter, and the `stock_quantity` column must be greater than or equal to the `p_stock_threshold` parameter.\n\nFollowing this, the procedure assigns a new unique identifier to the `v_consolidation_id` variable by calling the `nextval` function on the `books_book_id_seq` sequence.\n\nSubsequently, an `INSERT` statement is executed to add a new row into the `books` table. The `book_id` column of this new row is populated with the value from `v_consolidation_id`. The `book_title` column is set to a concatenated string formed by the literal 'Consolidated Collection - ' and the current date obtained from `CURRENT_DATE`. The `language` column is set to the value of the `p_target_language` parameter. The `format` column is set to the value of the `p_source_format` parameter. The `stock_quantity` column is populated with the value of `v_total_stock`, using `COALESCE(v_total_stock, 0)` to default to 0 if `v_total_stock` is `NULL`. The `price` column is populated with the value of `v_avg_price`, using `COALESCE(v_avg_price, 0)` to default to 0 if `v_avg_price` is `NULL`, and then casting this result to `text` before insertion.\n\nFinally, a `DELETE` statement is executed to remove existing rows from the `books` table. The rows to be deleted are identified by three conditions: the `format` column must be equal to the `p_source_format` parameter, the `stock_quantity` column must be greater than or equal to the `p_stock_threshold` parameter, and crucially, the `book_id` column must not be equal to the `v_consolidation_id` value, ensuring that the newly inserted consolidated record is not deleted.",
    "plsql": "CREATE SEQUENCE books_book_id_seq;\n\nCREATE OR REPLACE PROCEDURE consolidate_book_data(\n    p_source_format text,\n    p_target_language text,\n    p_stock_threshold bigint\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_consolidation_id bigint;\n    v_total_stock bigint;\n    v_avg_price numeric;\nBEGIN\n    SELECT SUM(stock_quantity), AVG(TO_NUMBER(price, '999999.99'))\n    INTO v_total_stock, v_avg_price\n    FROM books\n    WHERE format = p_source_format\n    AND stock_quantity >= p_stock_threshold;\n    \n    v_consolidation_id := nextval('books_book_id_seq');\n    \n    INSERT INTO books (book_id, book_title, language, format, stock_quantity, price)\n    VALUES (v_consolidation_id,\n            CONCAT('Consolidated Collection - ', CURRENT_DATE),\n            p_target_language,\n            p_source_format,\n            COALESCE(v_total_stock, 0),\n            CAST(COALESCE(v_avg_price, 0) AS text));\n    \n    DELETE FROM books\n    WHERE format = p_source_format\n    AND stock_quantity >= p_stock_threshold\n    AND book_id != v_consolidation_id;\nEND;\n$$;",
    "database_name": "book_inventory_and_management_system",
    "tables": [
      "authors",
      "book_authors",
      "books",
      "book_images"
    ],
    "call_sqls": [
      "CALL consolidate_book_data('Paperback', 'English', 50);",
      "CALL consolidate_book_data('Hardcover', 'Spanish', 20);",
      "CALL consolidate_book_data('E-book', 'French', 100);",
      "CALL consolidate_book_data('Audiobook', 'German', 10);",
      "CALL consolidate_book_data('Paperback', 'English', 0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named consolidate_book_data that, given a source format, a target language, and a stock threshold, aggregates the total stock quantity and average price from the books table for all books matching the specified format and having stock quantity at or above the threshold, then inserts a new consolidated book record with a generated ID, a title indicating the consolidation date, the specified target language and source format, the aggregated total stock, and the calculated average price, and finally deletes all original qualifying book records except the newly inserted consolidated one.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called consolidate_book_data that, given a source format, target language, and stock threshold, calculates the total stock quantity and average price from the books table for books matching the specified format and having stock at or above the threshold, inserts a new summary record into books with a generated ID, a title indicating consolidation and the current date, the provided target language and source format, and the calculated totals (using zero if none are found), and then deletes all original books that match the criteria except the newly inserted summary record.",
    "id": 83,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named consolidate_book_data that accepts three input parameters: p_source_format of type TEXT, p_target_language of type TEXT, and p_stock_threshold of type BIGINT. The procedure performs a series of operations to consolidate book data based on the specified criteria.\n\nFirst, the procedure declares two local variables: v_total_stock of type BIGINT and v_avg_price of type NUMERIC. It then calculates the total stock quantity and the average price from the books table for books that match the specified source format (where the format column equals p_source_format) and have a stock quantity greater than or equal to the provided stock threshold (where stock_quantity >= p_stock_threshold). The total stock is computed as the sum of the stock_quantity column, and the average price is computed as the average of the price column after casting it to NUMERIC. If no books match the criteria, both v_total_stock and v_avg_price are set to 0.\n\nNext, the procedure generates a new book_id by finding the maximum existing book_id from the books table and adding 1 to it. It then constructs a book_title as a text string that includes the literal 'Consolidated Books - ' followed by the current date in the format 'YYYY-MM-DD'. It inserts a new record into the books table with the following values: book_id set to the generated new ID, isbn set to NULL, book_title set to the constructed title, genre set to NULL, language set to p_target_language, page_count set to NULL, summary set to NULL, price set to v_avg_price cast to TEXT, stock_quantity set to v_total_stock, format set to p_source_format, year_of_publication set to NULL, and publisher_id set to NULL.\n\nAfter inserting the summary record, the procedure deletes all original books from the books table that match the consolidation criteria (where format equals p_source_format and stock_quantity >= p_stock_threshold) but excludes the newly inserted summary record by ensuring the book_id is not equal to the generated new ID. This ensures that only the summary record remains for the consolidated data.",
    "original_summary": "Create a stored procedure named consolidate_book_data that aggregates stock and price for books matching a format and stock threshold, inserts a new consolidated book record, and deletes the original qualifying records.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create procedure consolidate_book_data to sum stock and price for books by format and minimum stock, insert a summary record, and delete the originals."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named insert_player_match_summary that accepts two mandatory input parameters: p_player_id of type bigint, representing the unique identifier of a player, and p_match_id of type bigint, representing the unique identifier of a match. The procedure begins by declaring two local bigint variables, v_total_runs and v_total_wickets. It then executes a SELECT query on the match_player_stats table to calculate the aggregate sum of the runs_scored column and the aggregate sum of the wickets_taken column for all rows where the player_id column equals the input parameter p_player_id and the match_id column equals the input parameter p_match_id; the COALESCE function is used to return 0 for each sum if no matching rows are found, and the results are stored into the local variables v_total_runs and v_total_wickets respectively. Following this, the procedure performs an INSERT operation into the players table, specifying values for the columns player_id, name, country_id, role, matches_played, runs_scored, wickets_taken, created_at, and updated_at: it uses the input p_player_id for player_id, the literal string 'TEMP_NAME' for name, a NULL value for country_id, the literal string 'TEMP_ROLE' for role, the integer literal 1 for matches_played, the calculated v_total_runs for runs_scored, the calculated v_total_wickets for wickets_taken, and for both created_at and updated_at it uses the result of applying the LOWER function to the string literal '2024-01-01', which converts the string to lowercase but has no effect on the numeric date format. This INSERT statement includes an ON CONFLICT clause targeting the player_id column's unique constraint; if a row with the same player_id already exists in the players table, the conflict is resolved by taking no action (DO NOTHING), meaning the insert is skipped without error.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_player_match_summary(p_player_id bigint, p_match_id bigint)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_total_runs bigint;\n    v_total_wickets bigint;\nBEGIN\n    SELECT COALESCE(SUM(runs_scored), 0), COALESCE(SUM(wickets_taken), 0)\n    INTO v_total_runs, v_total_wickets\n    FROM match_player_stats\n    WHERE player_id = p_player_id AND match_id = p_match_id;\n    \n    INSERT INTO players (player_id, name, country_id, role, matches_played, runs_scored, wickets_taken, created_at, updated_at)\n    VALUES (p_player_id, 'TEMP_NAME', NULL, 'TEMP_ROLE', 1, v_total_runs, v_total_wickets, LOWER('2024-01-01'), LOWER('2024-01-01'))\n    ON CONFLICT (player_id) DO NOTHING;\nEND;\n$$;",
    "database_name": "cricket_player_statistics_and_performance_analysis_292573",
    "tables": [
      "players",
      "match_player_stats"
    ],
    "call_sqls": [
      "CALL insert_player_match_summary(1, 101);",
      "CALL insert_player_match_summary(2, 102);",
      "CALL insert_player_match_summary(3, 103);",
      "CALL insert_player_match_summary(4, 104);",
      "CALL insert_player_match_summary(5, 105);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named insert_player_match_summary that takes a player_id and a match_id, calculates the player's total runs_scored and wickets_taken from the match_player_stats table for that specific match, and inserts a new row into the players table with these totals, using placeholder values for other columns like name, country_id, role, matches_played, created_at, and updated_at, while ignoring the insertion if a row with the same player_id already exists.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called insert_player_match_summary that takes a player_id and match_id, calculates the total runs and wickets for that player in that match from the match_player_stats table, and then inserts a row into the players table with these totals, using placeholder values for the other columns like name and role, but only if a record with that player_id doesn't already exist.",
    "id": 84,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named insert_player_match_summary that accepts two mandatory input parameters: p_player_id of type bigint, representing the unique identifier of a player, and p_match_id of type bigint, representing the unique identifier of a match. The procedure begins by declaring two local bigint variables, v_total_runs and v_total_wickets. It then executes a SELECT query on the match_player_stats table to calculate the aggregate sum of the runs_scored column and the aggregate sum of the wickets_taken column for all rows where the player_id column equals the input parameter p_player_id and the match_id column equals the input parameter p_match_id; the COALESCE function is used to return 0 for each sum if no matching rows are found, and the results are stored into the local variables v_total_runs and v_total_wickets respectively. Following this, the procedure performs an INSERT operation into the players table, specifying values for the columns player_id, name, country_id, role, matches_played, runs_scored, wickets_taken, created_at, and updated_at: it uses the input p_player_id for player_id, the literal string 'TEMP_NAME' for name, a NULL value for country_id, the literal string 'TEMP_ROLE' for role, the integer literal 1 for matches_played, the calculated v_total_runs for runs_scored, the calculated v_total_wickets for wickets_taken, and for both created_at and updated_at it uses the result of applying the LOWER function to the string literal '2024-01-01', which converts the string to lowercase but has no effect on the numeric date format. This INSERT statement includes an ON CONFLICT clause targeting the player_id column's unique constraint; if a row with the same player_id already exists in the players table, the conflict is resolved by taking no action (DO NOTHING), meaning the insert is skipped without error.",
    "original_summary": "Create a stored procedure named insert_player_match_summary that takes a player_id and match_id. Calculate the player's total runs and wickets from match_player_stats for that match. Insert or ignore (on conflict) a row into the players table with these totals, using placeholder values for other columns.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "How can I create a stored procedure named insert_player_match_summary that accepts a player_id and match_id, calculates the player's total runs and wickets from match_player_stats for that specific match, and then inserts or ignores a row into the players table with these totals, using placeholder values for the other columns?"
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `transform_building_records` that accepts three input parameters: `p_year_threshold` of type `bigint`, `p_exterior_filter` of type `text`, and `p_condition_level` of type `bigint`.\n\nUpon execution, the procedure first declares two local variables: `v_transformed_id` of type `bigint` and `v_current_year` of type `bigint`. It then initializes `v_current_year` by extracting the year component from the current date using the `EXTRACT(YEAR FROM CURRENT_DATE)` function.\n\nFollowing this initialization, the procedure enters a `FOR` loop that iterates three times (from `i = 1` to `3`). In each iteration of this loop:\n\n1.  It determines the next available `building_id` for insertion. This is achieved by selecting the maximum `building_id` from the `building_details` table, adding `1` to it, and storing the result in `v_transformed_id`. If `building_details` is empty and `MAX(building_id)` returns `NULL`, the `COALESCE` function ensures that `0` is used instead, making the first `v_transformed_id` equal to `1`.\n\n2.  It then inserts a new record into the `building_details` table. The columns populated are `building_id`, `property_id`, `bldg_type`, `house_style`, `overall_qual`, `overall_cond`, `year_built`, `year_remod_add`, `roof_material`, `roof_style`, `exterior_finishing`, and `interior_finishing`. The values for these columns are derived from a `SELECT` statement that queries the `building_details` table, aliased as `bd`.\n    *   The `building_id` for the new record is set to the current value of `v_transformed_id`.\n    *   `property_id` is taken directly from `bd.property_id`.\n    *   `bldg_type` is taken directly from `bd.bldg_type`.\n    *   `house_style` is taken directly from `bd.house_style`.\n    *   `overall_qual` is calculated by adding the current loop iteration variable `i` to `bd.overall_qual`.\n    *   `overall_cond` is set to the value of the input parameter `p_condition_level`.\n    *   `year_built` is taken directly from `bd.year_built`.\n    *   `year_remod_add` is set to the value of the `v_current_year` variable.\n    *   `roof_material` is taken directly from `bd.roof_material`.\n    *   `roof_style` is taken directly from `bd.roof_style`.\n    *   `exterior_finishing` is set to the value of the input parameter `p_exterior_filter`.\n    *   `interior_finishing` is taken directly from `bd.interior_finishing`.\n    This `SELECT` statement is filtered by a `WHERE` clause that includes three conditions:\n        *   `bd.year_built` must be less than the input parameter `p_year_threshold`.\n        *   `bd.exterior_finishing` must not be equal to the input parameter `p_exterior_filter`.\n        *   `bd.overall_cond` must be greater than or equal to the input parameter `p_condition_level`.\n    Crucially, the `LIMIT 1` clause ensures that only one record matching these criteria is selected from `building_details` for insertion in each iteration.\n\n3.  After the `INSERT` operation, `v_transformed_id` is incremented by `1` (`v_transformed_id := v_transformed_id + 1;`) to prepare for the next potential insertion.\n\nAfter the `FOR` loop completes its three iterations, the procedure proceeds to delete records from the `building_details` table. The `DELETE` operation targets records whose `building_id` is present in a subquery's result set. This subquery selects `building_id` from `building_details` where two conditions are met:\n*   `year_built` is less than the input parameter `p_year_threshold`.\n*   `exterior_finishing` is not equal to the input parameter `p_exterior_filter`.\nThe results of this subquery are ordered by `building_id` in descending order (`ORDER BY building_id DESC`), and only the top `2` `building_id` values are selected (`LIMIT 2`). This means the `DELETE` statement removes the two records with the highest `building_id`s that satisfy the specified `year_built` and `exterior_finishing` conditions.",
    "plsql": "CREATE OR REPLACE PROCEDURE transform_building_records(\n    p_year_threshold bigint,\n    p_exterior_filter text,\n    p_condition_level bigint\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_transformed_id bigint;\n    v_current_year bigint;\nBEGIN\n    v_current_year := EXTRACT(YEAR FROM CURRENT_DATE);\n    \n    FOR i IN 1..3 LOOP\n        SELECT COALESCE(MAX(building_id), 0) + 1 INTO v_transformed_id FROM building_details;\n        \n        INSERT INTO building_details (building_id, property_id, bldg_type, house_style, overall_qual, overall_cond, year_built, year_remod_add, roof_material, roof_style, exterior_finishing, interior_finishing)\n        SELECT \n            v_transformed_id,\n            bd.property_id,\n            bd.bldg_type,\n            bd.house_style,\n            bd.overall_qual + i,\n            p_condition_level,\n            bd.year_built,\n            v_current_year,\n            bd.roof_material,\n            bd.roof_style,\n            p_exterior_filter,\n            bd.interior_finishing\n        FROM building_details bd\n        WHERE bd.year_built < p_year_threshold\n        AND bd.exterior_finishing != p_exterior_filter\n        AND bd.overall_cond >= p_condition_level\n        LIMIT 1;\n        \n        v_transformed_id := v_transformed_id + 1;\n    END LOOP;\n    \n    DELETE FROM building_details \n    WHERE building_id IN (\n        SELECT building_id \n        FROM building_details \n        WHERE year_built < p_year_threshold \n        AND exterior_finishing != p_exterior_filter\n        ORDER BY building_id DESC\n        LIMIT 2\n    );\nEND;\n$$;",
    "database_name": "real_estate_property_analysis_and_management_956249",
    "tables": [
      "properties",
      "building_details",
      "rooms_info",
      "sale_history"
    ],
    "call_sqls": [
      "CALL transform_building_records(1950, 'VinylSd', 5);",
      "CALL transform_building_records(1970, 'Wd Sdng', 6);",
      "CALL transform_building_records(2000, 'MetalSd', 4);",
      "CALL transform_building_records(1985, 'HdBoard', 7);",
      "CALL transform_building_records(1960, 'BrkFace', 5);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named transform_building_records that takes a year threshold, an exterior finishing filter, and a condition level as input, and performs three new record insertions followed by a deletion in the building_details table. For each of three insertions, it creates a new record by copying data from an existing record where year_built is below the threshold, exterior_finishing does not match the filter, and overall_cond is at least the condition level, then modifies it by incrementing overall_qual by the insertion sequence number, setting overall_cond to the input condition level, updating year_remod_add to the current year, and changing exterior_finishing to the filter value. After the insertions, it deletes the two records with the highest building_id that also meet the conditions of year_built below the threshold and exterior_finishing not matching the filter.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named transform_building_records that takes a year threshold, an exterior finishing filter, and a condition level, then performs three transformations: for each, it generates a new building identifier and inserts a new record into the building_details table based on an existing record where the year_built is below the threshold, the exterior_finishing differs from the filter, and the overall_cond meets or exceeds the condition level, updating the new record by increasing the overall_qual by the transformation step number, setting overall_cond to the condition level, updating year_remod_add to the current year, and applying the exterior finishing filter; after these insertions, it deletes the two records with the highest building_id that also have a year_built below the threshold and an exterior_finishing not equal to the filter.",
    "id": 85,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `transform_building_records` that accepts three input parameters: `p_year_threshold` of type `bigint`, `p_exterior_filter` of type `text`, and `p_condition_level` of type `bigint`.\n\nUpon execution, the procedure first declares two local variables: `v_transformed_id` of type `bigint` and `v_current_year` of type `bigint`. It then initializes `v_current_year` by extracting the year component from the current date using the `EXTRACT(YEAR FROM CURRENT_DATE)` function.\n\nFollowing this initialization, the procedure enters a `FOR` loop that iterates three times (from `i = 1` to `3`). In each iteration of this loop:\n\n1.  It determines the next available `building_id` for insertion. This is achieved by selecting the maximum `building_id` from the `building_details` table, adding `1` to it, and storing the result in `v_transformed_id`. If `building_details` is empty and `MAX(building_id)` returns `NULL`, the `COALESCE` function ensures that `0` is used instead, making the first `v_transformed_id` equal to `1`.\n\n2.  It then inserts a new record into the `building_details` table. The columns populated are `building_id`, `property_id`, `bldg_type`, `house_style`, `overall_qual`, `overall_cond`, `year_built`, `year_remod_add`, `roof_material`, `roof_style`, `exterior_finishing`, and `interior_finishing`. The values for these columns are derived from a `SELECT` statement that queries the `building_details` table, aliased as `bd`.\n    *   The `building_id` for the new record is set to the current value of `v_transformed_id`.\n    *   `property_id` is taken directly from `bd.property_id`.\n    *   `bldg_type` is taken directly from `bd.bldg_type`.\n    *   `house_style` is taken directly from `bd.house_style`.\n    *   `overall_qual` is calculated by adding the current loop iteration variable `i` to `bd.overall_qual`.\n    *   `overall_cond` is set to the value of the input parameter `p_condition_level`.\n    *   `year_built` is taken directly from `bd.year_built`.\n    *   `year_remod_add` is set to the value of the `v_current_year` variable.\n    *   `roof_material` is taken directly from `bd.roof_material`.\n    *   `roof_style` is taken directly from `bd.roof_style`.\n    *   `exterior_finishing` is set to the value of the input parameter `p_exterior_filter`.\n    *   `interior_finishing` is taken directly from `bd.interior_finishing`.\n    This `SELECT` statement is filtered by a `WHERE` clause that includes three conditions:\n        *   `bd.year_built` must be less than the input parameter `p_year_threshold`.\n        *   `bd.exterior_finishing` must not be equal to the input parameter `p_exterior_filter`.\n        *   `bd.overall_cond` must be greater than or equal to the input parameter `p_condition_level`.\n    Crucially, the `LIMIT 1` clause ensures that only one record matching these criteria is selected from `building_details` for insertion in each iteration.\n\n3.  After the `INSERT` operation, `v_transformed_id` is incremented by `1` (`v_transformed_id := v_transformed_id + 1;`) to prepare for the next potential insertion.\n\nAfter the `FOR` loop completes its three iterations, the procedure proceeds to delete records from the `building_details` table. The `DELETE` operation targets records whose `building_id` is present in a subquery's result set. This subquery selects `building_id` from `building_details` where two conditions are met:\n*   `year_built` is less than the input parameter `p_year_threshold`.\n*   `exterior_finishing` is not equal to the input parameter `p_exterior_filter`.\nThe results of this subquery are ordered by `building_id` in descending order (`ORDER BY building_id DESC`), and only the top `2` `building_id` values are selected (`LIMIT 2`). This means the `DELETE` statement removes the two records with the highest `building_id`s that satisfy the specified `year_built` and `exterior_finishing` conditions.",
    "original_summary": "Create a stored procedure named transform_building_records with parameters p_year_threshold (bigint), p_exterior_filter (text), and p_condition_level (bigint). Loop three times. In each iteration, get the next available building_id, then insert a new record into building_details. The new record copies data from an existing record where year_built < p_year_threshold, exterior_finishing != p_exterior_filter, and overall_cond >= p_condition_level, but modifies overall_qual by adding the loop index, sets overall_cond = p_condition_level, year_remod_add = current year, and exterior_finishing = p_exterior_filter. After the loop, delete the two records with the highest building_id that also meet the conditions year_built < p_year_threshold and exterior_finishing != p_exterior_filter.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as 'transform_building_records'. This procedure shall accept three parameters: 'p_year_threshold' of type bigint, 'p_exterior_filter' of type text, and 'p_condition_level' of type bigint. The procedure is to execute a loop precisely three times. Within each iteration, it must first ascertain the next available building identifier. Subsequently, it shall insert a new entry into the 'building_details' table. This new record is to be derived from an existing record that satisfies the following criteria: its 'year_built' is less than the provided 'p_year_threshold', its 'exterior_finishing' differs from the supplied 'p_exterior_filter', and its 'overall_cond' is greater than or equal to the specified 'p_condition_level'. For the inserted record, the 'overall_qual' value should be incremented by the current loop index, the 'overall_cond' should be set to the value of 'p_condition_level', the 'year_remod_add' should be updated to the current year, and the 'exterior_finishing' should be assigned the value of 'p_exterior_filter'. Upon completion of the loop, the procedure must delete the two records possessing the highest 'building_id' values that concurrently meet the conditions where 'year_built' is less than 'p_year_threshold' and 'exterior_finishing' is not equal to 'p_exterior_filter'."
  },
  {
    "ir": "Write a PostgreSQL stored procedure named archive_user_sessions that accepts three input parameters: a TEXT parameter named department_name, a BIGINT parameter named session_count, and a TEXT parameter named archive_date; the procedure declares a cursor named user_cursor that selects the user_id and user_name columns from the users table for rows where the user_department column matches the department_name parameter, limiting the result set to the number of rows specified by the session_count parameter; it then declares a variable user_rec of type RECORD to hold cursor rows and a variable new_access_id of type BIGINT; the procedure's logic begins by opening a FOR loop that iterates over each row fetched by the user_cursor; for each iteration, it assigns the current row to user_rec and executes a SELECT statement that calculates a new access_id value by querying the access_logs table, using the COALESCE function to return 0 if the maximum value of the access_id column is NULL, then adding 1 to that result and storing it in the new_access_id variable; it then performs an INSERT operation into the access_logs table, specifying values for the columns access_id (using new_access_id), user_id (using user_rec.user_id), system_id (using the literal integer 1), access_date (using the archive_date parameter), access_type (using the literal string 'archive'), access_ip_address (using the literal string '10.0.0.1'), and access_duration (using the literal integer 0); the loop continues until all rows from the cursor are processed.",
    "plsql": "CREATE OR REPLACE PROCEDURE archive_user_sessions(IN department_name TEXT, IN session_count BIGINT, IN archive_date TEXT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    user_cursor CURSOR FOR \n        SELECT u.user_id, u.user_name\n        FROM users u\n        WHERE u.user_department = department_name\n        LIMIT session_count;\n    user_rec RECORD;\n    new_access_id BIGINT;\nBEGIN\n    FOR user_rec IN user_cursor LOOP\n        SELECT COALESCE(MAX(access_id), 0) + 1 INTO new_access_id FROM access_logs;\n        \n        INSERT INTO access_logs (access_id, user_id, system_id, access_date, access_type, access_ip_address, access_duration)\n        VALUES (new_access_id, user_rec.user_id, 1, archive_date, 'archive', '10.0.0.1', 0);\n    END LOOP;\nEND;\n$$;",
    "database_name": "system_performance_monitoring_and_analysis_481541",
    "tables": [
      "systems",
      "access_logs",
      "users",
      "system_metrics",
      "performance_metrics"
    ],
    "call_sqls": [
      "CALL archive_user_sessions('IT', 5, '2023-05-01');",
      "CALL archive_user_sessions('IT', 10, '2023-05-02');",
      "CALL archive_user_sessions('IT', 3, '2023-05-03');",
      "CALL archive_user_sessions('IT', 7, '2023-05-04');",
      "CALL archive_user_sessions('IT', 2, '2023-05-05');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named archive_user_sessions that accepts a department_name, a session_count to limit the number of users, and an archive_date, and for each user from the users table in the specified department up to the given limit, generates a new sequential access_id and inserts an archive record into the access_logs table with the user's user_id, a fixed system_id of 1, the provided archive_date, an access_type of 'archive', a fixed access_ip_address of '10.0.0.1', and an access_duration of 0.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called archive_user_sessions that takes a department name, a session count, and an archive date, and for the specified number of users from that department in the users table, generates a new access_id for each and inserts an archive entry into the access_logs table.",
    "id": 86,
    "generated_ir": "Write a PostgreSQL stored procedure named archive_user_sessions that accepts three input parameters: a TEXT parameter named department_name, a BIGINT parameter named session_count, and a TEXT parameter named archive_date; the procedure declares a cursor named user_cursor that selects the user_id and user_name columns from the users table for rows where the user_department column matches the department_name parameter, limiting the result set to the number of rows specified by the session_count parameter; it then declares a variable user_rec of type RECORD to hold cursor rows and a variable new_access_id of type BIGINT; the procedure's logic begins by opening a FOR loop that iterates over each row fetched by the user_cursor; for each iteration, it assigns the current row to user_rec and executes a SELECT statement that calculates a new access_id value by querying the access_logs table, using the COALESCE function to return 0 if the maximum value of the access_id column is NULL, then adding 1 to that result and storing it in the new_access_id variable; it then performs an INSERT operation into the access_logs table, specifying values for the columns access_id (using new_access_id), user_id (using user_rec.user_id), system_id (using the literal integer 1), access_date (using the archive_date parameter), access_type (using the literal string 'archive'), access_ip_address (using the literal string '10.0.0.1'), and access_duration (using the literal integer 0); the loop continues until all rows from the cursor are processed.",
    "original_summary": "Create a stored procedure named archive_user_sessions that accepts department_name (TEXT), session_count (BIGINT), and archive_date (TEXT). For a limited number of users from the specified department, generate a new access_id and insert an archive record into the access_logs table for each user.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called archive_user_sessions? It needs to take in a department name (as TEXT), how many sessions to grab (as a BIGINT), and an archive date (as TEXT). Basically, for a bunch of users from that departmentjust the number we specifywe need to make a fresh access_id for each and log an archive entry for 'em in the access_logs table."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named consolidate_property_data that accepts three input parameters: a real number parameter p_max_lot_area, a text parameter p_construction_filter, and a bigint parameter p_min_rooms. The procedure begins by declaring two local variables: v_consolidation_count of type bigint and v_total_value of type real. It then performs a SELECT query that joins the properties table (aliased as p) with the rooms_info table (aliased as ri) on the property_id column. This query counts the number of rows and calculates the sum of the property_value column from the properties table, storing the results into v_consolidation_count and v_total_value respectively. The join is filtered to include only rows where the lot_area from the properties table is less than or equal to the p_max_lot_area parameter, the construction_material from the properties table exactly matches the p_construction_filter parameter, and the tot_rms_abv_grd column from the rooms_info table is greater than or equal to the p_min_rooms parameter.\n\nIf the retrieved v_consolidation_count is greater than zero, the procedure executes a DELETE operation on the sale_history table. The deletion targets rows where the property_id matches any property_id from a subquery on the properties table. This subquery selects property_id from the properties table where the lot_area is less than or equal to p_max_lot_area and the construction_material matches p_construction_filter. Furthermore, the row is only deleted if its sale_price column value is less than the calculated average value, which is v_total_value divided by v_consolidation_count.\n\nFollowing the potential deletion, the procedure performs an INSERT operation into the properties table. It inserts a single new row with specific column values. The property_id for the new row is determined by a scalar subquery that calculates the maximum existing property_id from the properties table, adds one to it, and uses zero as a default if the maximum is null via the COALESCE function. The ms_subclass column is hardcoded to 80, the ms_zoning column to 'RL', and the lot_frontage column is set to the average lot_frontage value from a SELECT on the properties table filtered where construction_material equals p_construction_filter. The lot_area column is set to the input parameter p_max_lot_area. The street column is set to 'Pave', the alley column to 'MISSING', the lot_shape column to 'Reg', the land_contour column to 'Lvl', and the neighborhood_id to 999. The property_type column is set to 'Consolidated', the construction_material column is set to the input parameter p_construction_filter, and the property_condition column is set to 'Good'. The property_value column is set to the calculated average, v_total_value divided by v_consolidation_count. The last_audited column is populated with the current date converted to text using CURRENT_DATE::text. The source for the aggregate AVG(lot_frontage) is a SELECT from the properties table filtered on construction_material = p_construction_filter, limited to one row with the LIMIT 1 clause.",
    "plsql": "CREATE OR REPLACE PROCEDURE consolidate_property_data(\n    p_max_lot_area real,\n    p_construction_filter text,\n    p_min_rooms bigint\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_consolidation_count bigint;\n    v_total_value real;\nBEGIN\n    SELECT COUNT(*), SUM(p.property_value)\n    INTO v_consolidation_count, v_total_value\n    FROM properties p\n    JOIN rooms_info ri ON p.property_id = ri.property_id\n    WHERE p.lot_area <= p_max_lot_area\n    AND p.construction_material = p_construction_filter\n    AND ri.tot_rms_abv_grd >= p_min_rooms;\n    \n    IF v_consolidation_count > 0 THEN\n        DELETE FROM sale_history \n        WHERE property_id IN (\n            SELECT p.property_id \n            FROM properties p\n            WHERE p.lot_area <= p_max_lot_area\n            AND p.construction_material = p_construction_filter\n        )\n        AND sale_price < v_total_value / v_consolidation_count;\n        \n        INSERT INTO properties (property_id, ms_subclass, ms_zoning, lot_frontage, lot_area, street, alley, lot_shape, land_contour, neighborhood_id, property_type, construction_material, property_condition, property_value, last_audited)\n        SELECT \n            (SELECT COALESCE(MAX(property_id), 0) + 1 FROM properties),\n            80,\n            'RL',\n            AVG(lot_frontage),\n            p_max_lot_area,\n            'Pave',\n            'MISSING',\n            'Reg',\n            'Lvl',\n            999,\n            'Consolidated',\n            p_construction_filter,\n            'Good',\n            v_total_value / v_consolidation_count,\n            CURRENT_DATE::text\n        FROM properties\n        WHERE construction_material = p_construction_filter\n        LIMIT 1;\n    END IF;\nEND;\n$$;",
    "database_name": "real_estate_property_analysis_and_management_956249",
    "tables": [
      "properties",
      "building_details",
      "rooms_info",
      "sale_history"
    ],
    "call_sqls": [
      "CALL consolidate_property_data(10000.0, 'Brick', 3);",
      "CALL consolidate_property_data(12000.0, 'Wood', 4);",
      "CALL consolidate_property_data(8000.0, 'VinylSd', 2);",
      "CALL consolidate_property_data(15000.0, 'MetalSd', 5);",
      "CALL consolidate_property_data(9000.0, 'Wd Sdng', 3);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named consolidate_property_data that takes a maximum lot area, a construction material filter, and a minimum number of rooms as inputs, and processes properties meeting those criteria: where the LOT_AREA in the PROPERTIES table is less than or equal to the given maximum, the CONSTRUCTION_MATERIAL matches the filter, and the TOT_RMS_ABV_GRD in the ROOMS_INFO table is at least the minimum. It calculates the count and total PROPERTY_VALUE of these qualifying properties. If any properties are found, it deletes from the SALE_HISTORY table any records for those properties where the SALE_PRICE is below the calculated average property value, and then inserts a new consolidated record into the PROPERTIES table with a generated PROPERTY_ID, the input maximum as the LOT_AREA, the input filter as the CONSTRUCTION_MATERIAL, the calculated average as the PROPERTY_VALUE, today's date as LAST_AUDITED, and hardcoded values for other columns like MS_SUBCLASS, MS_ZONING, STREET, and PROPERTY_TYPE.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called consolidate_property_data that accepts a maximum lot area, a construction material filter, and a minimum number of rooms as inputs. It should calculate the total count and total property value of all properties from the properties table, joined with rooms_info, where the lot_area is less than or equal to the provided maximum, the construction_material matches the filter exactly, and the tot_rms_abv_grd meets or exceeds the minimum. If the count is greater than zero, delete any records from the sale_history table where the property_id corresponds to those filtered properties and the sale_price is below the calculated average property value. Then, insert a new consolidated record into the properties table with a unique property_id, default values for ms_subclass, ms_zoning, street, alley, lot_shape, land_contour, neighborhood_id, property_type, and property_condition, the lot_area set to the provided maximum, the construction_material set to the filter, the property_value set to the calculated average, and the last_audited set to today's date.",
    "id": 87,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named consolidate_property_data that accepts three input parameters: p_max_lot_area of type REAL representing the maximum lot area, p_construction_material of type TEXT representing the construction material filter, and p_min_rooms of type BIGINT representing the minimum number of rooms. The procedure begins by declaring three local variables: v_total_count of type BIGINT to store the total count of filtered properties, v_total_value of type REAL to store the total property value of filtered properties, and v_avg_value of type REAL to store the calculated average property value. It then executes a SELECT statement to compute the total count and total property value from the properties table, inner-joined with the rooms_info table on the property_id column, where the lot_area from the properties table is less than or equal to p_max_lot_area, the construction_material from the properties table matches p_construction_material exactly, and the tot_rms_abv_grd from the rooms_info table is greater than or equal to p_min_rooms, storing the results into v_total_count and v_total_value respectively. Next, it calculates the average property value by dividing v_total_value by v_total_count, assigning the result to v_avg_value, but only if v_total_count is greater than zero; otherwise, v_avg_value remains NULL. The procedure then checks if v_total_count is greater than zero using an IF statement. If true, it executes a DELETE statement on the sale_history table where the property_id is in the set of property_id values from the properties table inner-joined with the rooms_info table on property_id, with the same filtering conditions as the initial SELECT (lot_area <= p_max_lot_area, construction_material = p_construction_material, and tot_rms_abv_grd >= p_min_rooms), and additionally where the sale_price from the sale_history table is less than v_avg_value. After the deletion, the procedure generates a unique property_id for the new consolidated record by selecting the maximum property_id from the properties table and adding 1. It then executes an INSERT statement into the properties table with the following values: property_id set to the generated unique value, ms_subclass set to 60, ms_zoning set to 'RL', lot_frontage set to NULL, lot_area set to p_max_lot_area, street set to 'Pave', alley set to 'MISSING', lot_shape set to 'Reg', land_contour set to 'Lvl', neighborhood_id set to 1, property_type set to 'Single-Family', construction_material set to p_construction_material, property_condition set to 'Good', property_value set to v_avg_value, and last_audited set to the current date using the CURRENT_DATE function. If v_total_count is zero, the procedure skips the deletion and insertion steps and does nothing further. The procedure does not return a value.",
    "original_summary": "Create a stored procedure named consolidate_property_data that takes parameters p_max_lot_area (real), p_construction_filter (text), and p_min_rooms (bigint). It calculates the count and total value of properties meeting criteria: lot_area <= p_max_lot_area, construction_material = p_construction_filter, and tot_rms_abv_grd >= p_min_rooms. If count > 0, delete from sale_history where property_id matches the filtered properties and sale_price is below the calculated average value. Then insert a new consolidated property record with a generated ID, hardcoded values for several columns, lot_area = p_max_lot_area, construction_material = p_construction_filter, property_value = the calculated average, and last_audited as today's date.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Develop a stored procedure called consolidate_property_data, which carefully accepts three distinct input parameters: a real number for the maximum lot area (p_max_lot_area), a text string to filter by construction material (p_construction_filter), and a big integer representing the minimum number of rooms (p_min_rooms). This procedure will meticulously compute both the total number and the aggregate financial value of all properties that satisfy a specific set of detailed conditions: where the lot area is less than or equal to the provided maximum, the construction material exactly matches the specified filter, and the total rooms above grade meet or exceed the stipulated minimum. Should the resulting count be greater than zero, the procedure must then proceed to deliberately remove any corresponding entries from the sale_history table where the property_id aligns with those filtered properties and where the recorded sale_price unfortunately falls below the meticulously calculated average property value. Following this, it will thoughtfully insert a brand-new, consolidated property record, featuring a uniquely generated identifier, several columns populated with sensible, hardcoded default values, the lot_area set to the provided maximum parameter, the construction_material set to the filter parameter, the property_value set precisely to the computed average, and the last_audited date helpfully stamped with today's current date."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named calculate_education_attainment that accepts three input parameters: a mandatory parameter p_county_id of type BIGINT to identify a specific county record, a mandatory parameter p_high_school of type REAL representing a high school attainment value, and a mandatory parameter p_bachelor of type REAL representing a bachelor's degree attainment value, and executes a single UPDATE operation on the table named education_data, setting the value of the column education_attainment_index to the arithmetic mean calculated by adding the parameter p_high_school to the parameter p_bachelor and then dividing the sum by two, exclusively for the row or rows where the value in the county_id column is exactly equal to the value provided in the input parameter p_county_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE calculate_education_attainment(p_county_id BIGINT, p_high_school REAL, p_bachelor REAL)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE education_data\n    SET education_attainment_index = (p_high_school + p_bachelor) / 2\n    WHERE county_id = p_county_id;\nEND;\n$$;",
    "database_name": "demographic_and_economic_data_for_us_counties_159057",
    "tables": [
      "counties",
      "demographics",
      "education_data",
      "data_validations"
    ],
    "call_sqls": [
      "CALL calculate_education_attainment(0, 85.2, 25.1);",
      "CALL calculate_education_attainment(1, 88.3, 30.4);",
      "CALL calculate_education_attainment(2, 90.5, 35.7);",
      "CALL calculate_education_attainment(3, 82.1, 28.9);",
      "CALL calculate_education_attainment(4, 79.8, 22.6);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named calculate_education_attainment that updates the education_attainment_index in the education_data table by calculating the average of a provided high school attainment value and a bachelor's degree attainment value, but only for the specific county identified by the given county_id.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called calculate_education_attainment that updates the education attainment index in the education_data table for a specific county. Given a county_id, a high school completion rate, and a bachelor's degree rate, it calculates the education_attainment_index as the simple average of these two rates and updates the record where the county_id matches.",
    "id": 88,
    "generated_ir": "Write a PostgreSQL PLpgSQL stored procedure named calculate_education_attainment that accepts three input parameters: a mandatory parameter p_county_id of type BIGINT to identify a specific county record, a mandatory parameter p_high_school of type REAL representing a high school attainment value, and a mandatory parameter p_bachelor of type REAL representing a bachelor's degree attainment value, and executes a single UPDATE operation on the table named education_data, setting the value of the column education_attainment_index to the arithmetic mean calculated by adding the parameter p_high_school to the parameter p_bachelor and then dividing the sum by two, exclusively for the row or rows where the value in the county_id column is exactly equal to the value provided in the input parameter p_county_id.",
    "original_summary": "Create a stored procedure named calculate_education_attainment that updates an education attainment index. It takes county_id, a high school attainment value, and a bachelor's degree attainment value as input. The procedure updates the education_data table, setting the education_attainment_index to the average of the two input values, but only for the row(s) where county_id matches the provided parameter.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called calculate_education_attainment? It's gotta update this education attainment index thing. So, you feed it a county_id, the high school completion rate, and the bachelor's degree rate. What it does is, for the county that matches the ID you gave it, it goes into the education_data table and sets the education_attainment_index to the simple average of those two rates you just provided."
  },
  {
    "ir": "Write a PLpgSQL stored procedure that takes a single parameter p_taxon_id of type BIGINT and performs several operations related to publication and citation activity for a specific taxon. First, it declares three local variables: pub_count and citation_count of type INTEGER, and activity_level of type TEXT. The procedure begins by executing a SELECT statement to count the number of rows in the publications table where the taxon_id column matches the provided p_taxon_id, storing the result in the pub_count variable. Next, it executes another SELECT statement to count the number of rows in the citations table where the taxon_id column matches the provided p_taxon_id, storing this result in the citation_count variable. The procedure then evaluates a series of conditional statements: if pub_count is greater than 10, it assigns the value 'high' to the activity_level variable; if not, but citation_count is greater than 20, it assigns 'medium' to activity_level; otherwise, it assigns 'low' to activity_level. Finally, the procedure updates the taxons table by appending a string indicating the activity level to the description column for the row where the taxon_id matches the provided p_taxon_id.",
    "plsql": "CREATE OR REPLACE PROCEDURE analyze_publication_activity(p_taxon_id BIGINT)\nAS $$\nDECLARE\n    pub_count INTEGER;\n    citation_count INTEGER;\n    activity_level TEXT;\nBEGIN\n    SELECT COUNT(*) INTO pub_count\n    FROM publications\n    WHERE taxon_id = p_taxon_id;\n    \n    SELECT COUNT(*) INTO citation_count\n    FROM citations\n    WHERE taxon_id = p_taxon_id;\n    \n    IF pub_count > 10 THEN\n        activity_level := 'high';\n    ELSIF citation_count > 20 THEN\n        activity_level := 'medium';\n    ELSE\n        activity_level := 'low';\n    END IF;\n    \n    UPDATE taxons \n    SET description = description || ' [Activity: ' || activity_level || ']'\n    WHERE taxon_id = p_taxon_id;\nEND;\n$$ LANGUAGE plpgsql;",
    "database_name": "genomic_data_management_and_analysis_867750",
    "tables": [
      "taxons",
      "citations",
      "publications"
    ],
    "call_sqls": [
      "CALL analyze_publication_activity(0);",
      "CALL analyze_publication_activity(1);",
      "CALL analyze_publication_activity(100);",
      "CALL analyze_publication_activity(500);",
      "CALL analyze_publication_activity(999);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_publication_activity that accepts a taxon_id parameter to evaluate research activity for a specific taxon. It should retrieve the total number of publications from the publications table and the total number of citations from the citations table for that taxon_id, then determine an activity level based on these counts: assign 'high' if the publication count exceeds 10, otherwise assign 'medium' if the citation count exceeds 20, otherwise assign 'low'. Finally, update the taxons table by appending this activity level to the existing description for the given taxon_id.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_publication_activity that, for a given taxon_id, calculates the total number of publications from the publications table and the total number of citations from the citations table, then determines an activity level based on these counts: if the publication count exceeds 10, set the level to 'high'; otherwise, if the citation count exceeds 20, set it to 'medium'; if neither condition is met, set it to 'low'. Finally, update the description field in the taxons table for that taxon by appending the derived activity level.",
    "id": 89,
    "generated_ir": "Write a PLpgSQL stored procedure that takes a single parameter p_taxon_id of type BIGINT and performs several operations related to publication and citation activity for a specific taxon. First, it declares three local variables: pub_count and citation_count of type INTEGER, and activity_level of type TEXT. The procedure begins by executing a SELECT statement to count the number of rows in the publications table where the taxon_id column matches the provided p_taxon_id, storing the result in the pub_count variable. Next, it executes another SELECT statement to count the number of rows in the citations table where the taxon_id column matches the provided p_taxon_id, storing this result in the citation_count variable. The procedure then evaluates a series of conditional statements: if pub_count is greater than 10, it assigns the value 'high' to the activity_level variable; if not, but citation_count is greater than 20, it assigns 'medium' to activity_level; otherwise, it assigns 'low' to activity_level. Finally, the procedure updates the taxons table by appending a string indicating the activity level to the description column for the row where the taxon_id matches the provided p_taxon_id.",
    "original_summary": "Create a PL/pgSQL stored procedure that accepts a taxon_id (BIGINT) parameter. Count publications and citations for that taxon. Determine an activity level: 'high' if publication count > 10, else 'medium' if citation count > 20, else 'low'. Update the taxon's description by appending this activity level.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a PL/pgSQL stored procedure that receives a taxon_id parameter of type BIGINT. The procedure should compute the total number of publications and the total number of citations associated with the specified taxon. Subsequently, an activity level must be determined according to the following criteria: assign 'high' if the publication count exceeds 10; otherwise, assign 'medium' if the citation count exceeds 20; if neither condition is met, assign 'low'. Finally, the procedure must update the description field for the given taxon by appending the derived activity level."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `migrate_author_data` that accepts four input parameters: `source_author_id` of type `BIGINT`, representing the unique identifier of the author whose data is to be migrated; `target_author_id` of type `BIGINT`, representing the new unique identifier for the migrated author; `new_platform_id` of type `BIGINT`, representing the new platform identifier to be associated with the migrated author and their posts; and `backup_suffix` of type `TEXT`, which is a string appended to certain identifiers during the migration process.\n\nThe procedure begins by declaring a local variable named `author_rec` of type `RECORD` to temporarily store author data.\n\nFirst, it executes a `SELECT` statement to retrieve all columns (`*`) from the `authors` table into the `author_rec` variable. This selection is filtered by a `WHERE` clause where the `author_id` column in the `authors` table matches the value provided in the `source_author_id` input parameter.\n\nNext, an `INSERT` statement is executed to add a new row into the `authors` table. The values for the new row are constructed as follows:\n- The `author_id` column is set to the value of the `target_author_id` input parameter.\n- The `author_name` column is set by concatenating the `author_name` from the `author_rec` (which holds the original author's name) with the `backup_suffix` input parameter.\n- The `email` column is set to the `email` from the `author_rec`.\n- The `platform_id` column is set to the value of the `new_platform_id` input parameter.\n- The `author_profile_url` column is set to the `author_profile_url` from the `author_rec`.\n- The `author_followers` column is set to the `author_followers` from the `author_rec`.\n\nFollowing this, another `INSERT` statement is executed to add new rows into the `posts` table. This `INSERT` statement uses a `SELECT` subquery to retrieve data from existing posts. The `SELECT` subquery retrieves data from the `posts` table where the `post_author_id` column matches the `source_author_id` input parameter. For each row selected by the subquery, the values for the new `posts` table rows are constructed as follows:\n- The `post_id` column is set by concatenating the `post_id` from the selected row with the `backup_suffix` input parameter.\n- The `platform_id` column is set to the value of the `new_platform_id` input parameter.\n- The `post_url` column is set to the `post_url` from the selected row.\n- The `post_content` column is set to the `post_content` from the selected row.\n- The `post_time` column is set to the `post_time` from the selected row.\n- The `post_author_id` column is set to the value of the `target_author_id` input parameter.\n- The `post_type` column is set to the `post_type` from the selected row.\n- The `post_tags` column is set to the `post_tags` from the selected row.\n- The `post_engagement` column is set to the `post_engagement` from the selected row.\n\nSubsequently, a `DELETE` statement is executed to remove rows from the `posts` table. This deletion is filtered by a `WHERE` clause where the `post_author_id` column matches the value of the `source_author_id` input parameter.\n\nFinally, another `DELETE` statement is executed to remove rows from the `authors` table. This deletion is filtered by a `WHERE` clause where the `author_id` column matches the value of the `source_author_id` input parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE migrate_author_data(\n    IN source_author_id BIGINT,\n    IN target_author_id BIGINT,\n    IN new_platform_id BIGINT,\n    IN backup_suffix TEXT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    author_rec RECORD;\nBEGIN\n    SELECT * INTO author_rec FROM authors WHERE author_id = source_author_id;\n    \n    INSERT INTO authors (author_id, author_name, email, platform_id, author_profile_url, author_followers)\n    VALUES (target_author_id, author_rec.author_name || backup_suffix, author_rec.email, new_platform_id, author_rec.author_profile_url, author_rec.author_followers);\n    \n    INSERT INTO posts (post_id, platform_id, post_url, post_content, post_time, post_author_id, post_type, post_tags, post_engagement)\n    SELECT post_id || backup_suffix, new_platform_id, post_url, post_content, post_time, target_author_id, post_type, post_tags, post_engagement\n    FROM posts WHERE post_author_id = source_author_id;\n    \n    DELETE FROM posts WHERE post_author_id = source_author_id;\n    DELETE FROM authors WHERE author_id = source_author_id;\nEND;\n$$;",
    "database_name": "social_media_post_analysis_and_engagement_metrics",
    "tables": [
      "posts",
      "comments",
      "authors",
      "comment_authors"
    ],
    "call_sqls": [
      "CALL migrate_author_data(1001, 2001, 5, '_backup_2024');",
      "CALL migrate_author_data(1002, 2002, 3, '_migrated');",
      "CALL migrate_author_data(1003, 2003, 5, '_archive');",
      "CALL migrate_author_data(1004, 2004, 7, '_old');",
      "CALL migrate_author_data(1005, 2005, 2, '_legacy');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_author_data that migrates an author and their posts from one author to another by taking a source_author_id and copying its record from the AUTHORS table to a new record with target_author_id, appending the backup_suffix to the author_name and setting the platform_id to new_platform_id, then copies all posts from the POSTS table associated with the source author to the target author by appending the backup_suffix to each post_id and updating the platform_id to new_platform_id, and finally deletes the original posts and the original author record.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called migrate_author_data that accepts source_author_id, target_author_id, new_platform_id, and backup_suffix to migrate an author's data by first copying the author record from the AUTHORS table for the source_author_id to a new record with the target_author_id, appending the backup_suffix to the author_name and setting the platform_id to new_platform_id, then copying all posts from the POSTS table for the source author to the target author, appending the backup_suffix to each post_id and using the new_platform_id, and finally deleting all original posts for the source author and then the original author record from the AUTHORS table.",
    "id": 90,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `migrate_author_data` that accepts four input parameters: `source_author_id` of type `bigint`, `target_author_id` of type `bigint`, `new_platform_id` of type `bigint`, and `backup_suffix` of type `text`. The procedure's purpose is to migrate an author's data from a source author to a target author by performing a series of operations on the `authors` and `posts` tables within the `social_media_post_analysis_and_engagement_metrics` database.\n\nThe procedure begins by copying the author record from the `authors` table for the specified `source_author_id` to create a new author record. This is done using an `INSERT INTO ... SELECT` statement. The new record uses the `target_author_id` as its `author_id`. The `author_name` column is set to the concatenation of the original `author_name` from the source record and the `backup_suffix` parameter. The `platform_id` column is set to the value of the `new_platform_id` parameter. All other columns (`email`, `author_profile_url`, `author_followers`) are copied directly from the source author record.\n\nNext, the procedure copies all posts from the `posts` table that are associated with the `source_author_id` (where `post_author_id` equals `source_author_id`) to new posts for the target author. This is performed using an `INSERT INTO ... SELECT` statement. For each copied post, the `post_id` column is set to the concatenation of the original `post_id` and the `backup_suffix` parameter. The `post_author_id` is updated to the `target_author_id`. The `platform_id` is set to the `new_platform_id` parameter. All other columns (`post_url`, `post_content`, `post_time`, `post_type`, `post_tags`, `post_engagement`) are copied directly from the source posts.\n\nAfter copying the posts, the procedure deletes all original posts for the source author from the `posts` table using a `DELETE` statement. The deletion condition is that the `post_author_id` must equal the `source_author_id`.\n\nFinally, the procedure deletes the original author record from the `authors` table using a `DELETE` statement. The deletion condition is that the `author_id` must equal the `source_author_id`.\n\nThe procedure does not return a value; it performs data migration operations as described.",
    "original_summary": "Create a stored procedure named migrate_author_data with parameters source_author_id, target_author_id, new_platform_id, and backup_suffix. Copy the author record from source_author_id to a new record with target_author_id, appending backup_suffix to the author_name and using new_platform_id. Copy all posts from the source author to the target author, appending backup_suffix to each post_id and using new_platform_id. Finally, delete the original posts and the original author record.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as 'migrate_author_data'. This procedure shall accept the following parameters: source_author_id, target_author_id, new_platform_id, and backup_suffix. The procedure's operations must be executed in the following sequence: First, replicate the author record associated with the source_author_id to generate a new record keyed by the target_author_id. During this replication, the backup_suffix must be appended to the author_name field, and the new_platform_id must be applied. Subsequently, all posts attributed to the source author are to be duplicated and assigned to the target author. For each duplicated post, the backup_suffix must be appended to its post_id, and the new_platform_id must be utilized. Upon successful completion of these copy operations, the procedure must then proceed to delete all original posts from the source author, followed by the deletion of the original author record itself."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named generate_datamart_report that accepts two parameters: p_datamart_id of type TEXT and p_status of type TEXT. The procedure begins by declaring a local variable v_total_queries of type INTEGER. It then executes a SELECT statement to count the number of rows in the queries table where the datamart_id column matches the value of p_datamart_id and the status column matches the value of p_status, storing the result in v_total_queries. Following this, the procedure performs an INSERT operation into the responses table, populating the columns response_id, query_id, response_date, data, created_at, updated_at, status, executed_by, and execution_time. The response_id is set to one more than the current maximum response_id in the responses table, defaulting to 1 if the table is empty. The query_id is set to 0. The response_date is set to the current date, cast to TEXT. The data column is populated with a string that includes the text 'Datamart Report: ' concatenated with the value of v_total_queries and the word 'queries'. Both the created_at and updated_at columns are set to the current timestamp, cast to TEXT. The status column is set to 'success'. The executed_by column is set to 0, and the execution_time column is set to the string '1 minute'.",
    "plsql": "CREATE OR REPLACE PROCEDURE generate_datamart_report(p_datamart_id TEXT, p_status TEXT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_total_queries INTEGER;\nBEGIN\n    SELECT COUNT(*)\n    INTO v_total_queries\n    FROM queries\n    WHERE datamart_id = p_datamart_id\n    AND status = p_status;\n\n    INSERT INTO responses (response_id, query_id, response_date, data, created_at, updated_at, status, executed_by, execution_time)\n    VALUES (\n        (SELECT COALESCE(MAX(response_id), 0) + 1 FROM responses),\n        0,\n        CURRENT_DATE::TEXT,\n        'Datamart Report: ' || v_total_queries || ' queries',\n        CURRENT_TIMESTAMP::TEXT,\n        CURRENT_TIMESTAMP::TEXT,\n        'success',\n        0,\n        '1 minute'\n    );\nEND;\n$$;",
    "database_name": "healthcare_data_management_and_analytics",
    "tables": [
      "datamarts",
      "dispenses",
      "patients",
      "queries",
      "responses",
      "treatments",
      "users"
    ],
    "call_sqls": [
      "CALL generate_datamart_report('0', 'active');",
      "CALL generate_datamart_report('1', 'active');",
      "CALL generate_datamart_report('0', 'completed');",
      "CALL generate_datamart_report('1', 'pending');",
      "CALL generate_datamart_report('1', 'failed');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `generate_datamart_report` that accepts a `p_datamart_id` and a `p_status` to count the number of queries in the `queries` table matching these parameters, then inserts a new report record into the `responses` table with a unique `response_id`, a static `query_id` of 0, a data string containing the query count, the current date as `response_date`, current timestamps as `created_at` and `updated_at`, a status of 'success', an `executed_by` value of 0, and an `execution_time` of '1 minute'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `generate_datamart_report` that takes `p_datamart_id` and `p_status` as parameters to count the queries from the `queries` table matching these parameters, then inserts a report into the `responses` table with a generated `response_id`, a static `query_id` of 0, a data string containing the query count, `response_date` as today's date, `created_at` and `updated_at` as the current timestamp in TEXT format, a status of 'success', `executed_by` as 0, and `execution_time` as '1 minute'.",
    "id": 91,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `generate_datamart_report` that accepts two input parameters: `p_datamart_id` of type `text` and `p_status` of type `text`. The procedure operates within the `healthcare_data_management_and_analytics` database. It begins by declaring a variable named `v_query_count` of type `bigint` to store the result of a count operation. The procedure then performs a `SELECT` statement with a `COUNT(*)` aggregation on the `queries` table. This `SELECT` statement retrieves the total number of rows from the `queries` table where the value in the `datamart_id` column exactly matches the value supplied in the `p_datamart_id` input parameter AND the value in the `status` column exactly matches the value supplied in the `p_status` input parameter. The result of this count is stored in the `v_query_count` variable.\n\nNext, the procedure performs an `INSERT` operation into the `responses` table. It populates the columns as follows: The `response_id` is generated using the `nextval` function on a sequence implicitly associated with the table's primary key (assuming a sequence named `responses_response_id_seq` exists). The `query_id` column is set to the static integer value `0`. The `data` column is set to a text string that concatenates the literal `'Query count: '` with the value of the `v_query_count` variable converted to text. The `response_date` column is set to the current date, obtained via the `CURRENT_DATE` function, and cast to `text`. The `created_at` and `updated_at` columns are both set to the current timestamp, obtained via the `CURRENT_TIMESTAMP` function, and cast to `text`. The `status` column is set to the static string literal `'success'`. The `executed_by` column is set to the static integer value `0`. The `execution_time` column is set to the static string literal `'1 minute'`. The procedure does not explicitly return a value; its effect is the insertion of a single row into the `responses` table.",
    "original_summary": "Create a stored procedure named `generate_datamart_report` that accepts `p_datamart_id` (TEXT) and `p_status` (TEXT). It counts queries matching the parameters, then inserts a report into the `responses` table. The report includes a generated `response_id`, a static `query_id` of 0, a data string containing the query count, `response_date` as the current date, `created_at`/`updated_at` as the current timestamp (TEXT), a status of 'success', `executed_by` as 0, and `execution_time` as '1 minute'.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Write a stored procedure called `generate_datamart_report` that takes `p_datamart_id` (TEXT) and `p_status` (TEXT) as parameters. Count the queries that match these parameters. Then, insert a report into the `responses` table. The report must have a generated `response_id`, a static `query_id` of 0, a data string with the query count, `response_date` as today's date, `created_at` and `updated_at` as the current timestamp in TEXT format, a status of 'success', `executed_by` as 0, and `execution_time` as '1 minute'."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `generate_assessment_report` that accepts two input parameters: `p_class_id` of type `BIGINT`, representing the unique identifier of a class, and `p_min_percentage` of type `REAL`, representing the minimum percentage required for a student to pass an assessment. The procedure initializes three local variables: `v_assessment_record` of type `RECORD` to hold assessment details during iteration, `v_student_count` of type `BIGINT` to store the total number of students who took an assessment, and `v_passing_count` of type `BIGINT` to store the number of students who passed an assessment. The procedure then iterates through each assessment record by performing a `SELECT` operation on the `assessments` table, aliased as `a`, to retrieve `assessment_id`, `assessment_name`, and `total_questions` for all assessments where the `class_id` column matches the input parameter `p_class_id`. Inside this loop, for each `v_assessment_record`: first, it executes a `SELECT COUNT(DISTINCT ar.student_id)` statement on the `assessment_results` table, aliased as `ar`, to count the unique `student_id` values and stores this count into the `v_student_count` variable, considering only results where `ar.assessment_id` matches `v_assessment_record.assessment_id`. Second, it executes another `SELECT COUNT(DISTINCT ar.student_id)` statement on the `assessment_results` table, aliased as `ar`, to count the unique `student_id` values and stores this count into the `v_passing_count` variable, considering only results where `ar.assessment_id` matches `v_assessment_record.assessment_id` AND `ar.percentage` is greater than or equal to the input parameter `p_min_percentage`. Following these counts, a conditional `IF` statement checks if `v_student_count` is greater than 0. If this condition is true, the procedure performs two operations: first, it executes a `DELETE` statement on the `assessment_results` table to remove all records where `assessment_id` matches `v_assessment_record.assessment_id` AND `percentage` is less than the input parameter `p_min_percentage`. Second, it executes an `INSERT` statement into the `assessment_forms` table, populating the columns `form_id`, `assessment_id`, `form_name`, `total_questions`, `difficulty_level`, `date_created`, and `form_description`. The `form_id` is generated by selecting the maximum `form_id` from the `assessment_forms` table, using `COALESCE` to default to 0 if no records exist, and adding 1. The `assessment_id` is set to `v_assessment_record.assessment_id`. The `form_name` is constructed by concatenating the string literal 'Report_Form_' with the `assessment_id` from `v_assessment_record` cast to `TEXT`. The `total_questions` is set to `v_assessment_record.total_questions`. The `difficulty_level` is determined by a `CASE` statement: if the calculated passing percentage (derived by casting `v_passing_count` and `v_student_count` to `REAL`, dividing `v_passing_count` by `v_student_count`, and multiplying by 100) is greater than or equal to 80, it is set to 'Easy'; if it is greater than or equal to 50, it is set to 'Moderate'; otherwise, it is set to 'Difficult'. The `date_created` is set to the `CURRENT_DATE` cast to `TEXT`. The `form_description` is constructed by concatenating the string literal 'Performance report: ', the `v_passing_count` cast to `TEXT`, the string literal ' of ', the `v_student_count` cast to `TEXT`, and the string literal ' students passed'. This `INSERT` operation concludes the conditional block, and the loop continues to the next assessment record until all assessments for the given `p_class_id` have been processed.",
    "plsql": "CREATE OR REPLACE PROCEDURE generate_assessment_report(p_class_id BIGINT, p_min_percentage REAL)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_assessment_record RECORD;\n    v_student_count BIGINT;\n    v_passing_count BIGINT;\nBEGIN\n    FOR v_assessment_record IN \n        SELECT a.assessment_id, a.assessment_name, a.total_questions\n        FROM assessments a\n        WHERE a.class_id = p_class_id\n    LOOP\n        SELECT COUNT(DISTINCT ar.student_id) INTO v_student_count\n        FROM assessment_results ar\n        WHERE ar.assessment_id = v_assessment_record.assessment_id;\n        \n        SELECT COUNT(DISTINCT ar.student_id) INTO v_passing_count\n        FROM assessment_results ar\n        WHERE ar.assessment_id = v_assessment_record.assessment_id\n          AND ar.percentage >= p_min_percentage;\n        \n        IF v_student_count > 0 THEN\n            DELETE FROM assessment_results \n            WHERE assessment_id = v_assessment_record.assessment_id\n              AND percentage < p_min_percentage;\n            \n            INSERT INTO assessment_forms (form_id, assessment_id, form_name, total_questions, difficulty_level, date_created, form_description)\n            VALUES (\n                (SELECT COALESCE(MAX(form_id), 0) + 1 FROM assessment_forms),\n                v_assessment_record.assessment_id,\n                'Report_Form_' || v_assessment_record.assessment_id::TEXT,\n                v_assessment_record.total_questions,\n                CASE \n                    WHEN (v_passing_count::REAL / v_student_count::REAL) * 100 >= 80 THEN 'Easy'\n                    WHEN (v_passing_count::REAL / v_student_count::REAL) * 100 >= 50 THEN 'Moderate'\n                    ELSE 'Difficult'\n                END,\n                CURRENT_DATE::TEXT,\n                'Performance report: ' || v_passing_count::TEXT || ' of ' || v_student_count::TEXT || ' students passed'\n            );\n        END IF;\n    END LOOP;\nEND;\n$$;",
    "database_name": "educational_assessment_and_student_performance_tracking_766875",
    "tables": [
      "assessments",
      "assessment_forms",
      "assessment_questions",
      "assessment_results",
      "incorrect_questions"
    ],
    "call_sqls": [
      "CALL generate_assessment_report(1, 60.0);",
      "CALL generate_assessment_report(2, 70.5);",
      "CALL generate_assessment_report(3, 75.0);",
      "CALL generate_assessment_report(1, 65.0);",
      "CALL generate_assessment_report(0, 50.0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named generate_assessment_report that takes a class_id and a minimum_percentage, and for each assessment in the class from the assessments table, counts the total students and passing students (with percentage from assessment_results at or above the minimum_percentage), then if there are students, deletes results below the minimum percentage from assessment_results and inserts a new form into assessment_forms with a difficulty_level based on the passing rate: 'Easy' if 80% or more passed, 'Moderate' if 50% or more passed, otherwise 'Difficult'.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called 'generate_assessment_report' that takes a class_id and a minimum_percentage. For each assessment in that class from the assessments table, count all students and determine how many passed based on the minimum_percentage in the assessment_results table. If there are any students, delete any results below the minimum_percentage from assessment_results, then insert a new form into the assessment_forms table. For the form's difficulty_level, set it to 'Easy' if the passing rate is 80% or more, 'Moderate' if 50% or more, or 'Difficult' otherwise.",
    "id": 92,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `generate_assessment_report` that accepts two input parameters: `p_class_id` of type `BIGINT`, representing the unique identifier of a class, and `p_min_percentage` of type `REAL`, representing the minimum percentage required for a student to pass an assessment. The procedure initializes three local variables: `v_assessment_record` of type `RECORD` to hold assessment details during iteration, `v_student_count` of type `BIGINT` to store the total number of students who took an assessment, and `v_passing_count` of type `BIGINT` to store the number of students who passed an assessment. The procedure then iterates through each assessment record by performing a `SELECT` operation on the `assessments` table, aliased as `a`, to retrieve `assessment_id`, `assessment_name`, and `total_questions` for all assessments where the `class_id` column matches the input parameter `p_class_id`. Inside this loop, for each `v_assessment_record`: first, it executes a `SELECT COUNT(DISTINCT ar.student_id)` statement on the `assessment_results` table, aliased as `ar`, to count the unique `student_id` values and stores this count into the `v_student_count` variable, considering only results where `ar.assessment_id` matches `v_assessment_record.assessment_id`. Second, it executes another `SELECT COUNT(DISTINCT ar.student_id)` statement on the `assessment_results` table, aliased as `ar`, to count the unique `student_id` values and stores this count into the `v_passing_count` variable, considering only results where `ar.assessment_id` matches `v_assessment_record.assessment_id` AND `ar.percentage` is greater than or equal to the input parameter `p_min_percentage`. Following these counts, a conditional `IF` statement checks if `v_student_count` is greater than 0. If this condition is true, the procedure performs two operations: first, it executes a `DELETE` statement on the `assessment_results` table to remove all records where `assessment_id` matches `v_assessment_record.assessment_id` AND `percentage` is less than the input parameter `p_min_percentage`. Second, it executes an `INSERT` statement into the `assessment_forms` table, populating the columns `form_id`, `assessment_id`, `form_name`, `total_questions`, `difficulty_level`, `date_created`, and `form_description`. The `form_id` is generated by selecting the maximum `form_id` from the `assessment_forms` table, using `COALESCE` to default to 0 if no records exist, and adding 1. The `assessment_id` is set to `v_assessment_record.assessment_id`. The `form_name` is constructed by concatenating the string literal 'Report_Form_' with the `assessment_id` from `v_assessment_record` cast to `TEXT`. The `total_questions` is set to `v_assessment_record.total_questions`. The `difficulty_level` is determined by a `CASE` statement: if the calculated passing percentage (derived by casting `v_passing_count` and `v_student_count` to `REAL`, dividing `v_passing_count` by `v_student_count`, and multiplying by 100) is greater than or equal to 80, it is set to 'Easy'; if it is greater than or equal to 50, it is set to 'Moderate'; otherwise, it is set to 'Difficult'. The `date_created` is set to the `CURRENT_DATE` cast to `TEXT`. The `form_description` is constructed by concatenating the string literal 'Performance report: ', the `v_passing_count` cast to `TEXT`, the string literal ' of ', the `v_student_count` cast to `TEXT`, and the string literal ' students passed'. This `INSERT` operation concludes the conditional block, and the loop continues to the next assessment record until all assessments for the given `p_class_id` have been processed.",
    "original_summary": "Create a stored procedure named 'generate_assessment_report' that takes a class_id and minimum_percentage. For each assessment in the class: count total students and passing students (percentage >= minimum). If there are students, delete results below the minimum percentage and insert a new form into assessment_forms. The form's difficulty_level is determined by the passing rate: >=80% = 'Easy', >=50% = 'Moderate', else 'Difficult'.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Hey, can you whip up a stored procedure called 'generate_assessment_report'? It needs to take a class_id and a minimum_percentage. For every assessment in that class, we gotta count up all the students and figure out how many passed (their percentage is at least the minimum). If there are any students in the class, then we need to clean house: delete any results that are below that minimum percentage. After that, pop a new form into the assessment_forms table. Oh, and for the form's difficulty_level, here's the deal: if the passing rate is 80% or more, call it 'Easy'; if it's 50% or more, call it 'Moderate'; otherwise, it's 'Difficult'."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_return_patterns_with_conditions that accepts a single input parameter target_product_id of type BIGINT, which identifies a specific product for analysis. The procedure begins by declaring a cursor named return_cursor to fetch all records from the returns table where the product_id column matches the input target_product_id, along with record variables return_rec, order_rec, product_rec, item_rec, and store_rec, and counter, price_threshold, max_sale_id, and insert_counter variables of type BIGINT or REAL. It initializes counter to 0, price_threshold to 100.0, and insert_counter to 1. It then executes a SELECT statement to retrieve the current maximum value from the sale_id column in the sales table, storing it in max_sale_id and defaulting to 0 if the result is NULL using the COALESCE function.\n\nThe core logic uses a FOR loop to iterate over each row from the returns table where product_id equals target_product_id, assigning each row to return_rec. Within this loop, a series of conditional IF-ELSIF-ELSE statements examines the value of the reason column in return_rec and increments the counter variable by a specific integer (1 through 11) based on the exact string match: it adds 1 for 'defective product', 2 for 'wrong product', 3 for 'damaged', 4 for 'not satisfied', 5 for 'late delivery', 6 for 'poor quality', 7 for 'size issue', 8 for 'color mismatch', 9 for 'functionality issue', 10 for 'packaging problem', and 11 for any other reason. Following this, a nested FOR loop iterates over rows from the orders table where the order_id matches return_rec.order_id, assigning each to order_rec. Inside this inner loop, if the total column value in order_rec is greater than the price_threshold (100.0), it executes a DELETE operation on the order_items table, removing rows where both the order_id equals order_rec.order_id and the product_id equals the input target_product_id.\n\nAfter processing all return records, the procedure enters another FOR loop that iterates over rows from the products table where product_id equals the input target_product_id, assigning each to product_rec. For each such product, it then loops through all rows in the stores table using a FOR loop with store_rec. Within this nested store loop, it performs an INSERT operation into the sales table with columns sale_id, product_id, store_id, sale_date, sale_price, and quantity_sold. The sale_id is calculated as the previously obtained max_sale_id plus the current insert_counter value; product_id is taken from product_rec.product_id; store_id is from store_rec.store_id; sale_date is the current date converted to text using CURRENT_DATE::text; sale_price is calculated as product_rec.price multiplied by 0.8; and quantity_sold is set to 1. This INSERT uses an ON CONFLICT (sale_id) DO NOTHING clause to silently skip insertion if a duplicate sale_id exists. After each INSERT attempt, the insert_counter variable is incremented by 1.",
    "plsql": "CREATE OR REPLACE PROCEDURE analyze_return_patterns_with_conditions(target_product_id BIGINT)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    return_cursor CURSOR FOR SELECT * FROM returns WHERE product_id = target_product_id;\n    return_rec RECORD;\n    order_rec RECORD;\n    product_rec RECORD;\n    item_rec RECORD;\n    store_rec RECORD;\n    counter BIGINT;\n    price_threshold REAL;\n    max_sale_id BIGINT;\n    insert_counter BIGINT;\nBEGIN\n    counter := 0;\n    price_threshold := 100.0;\n    insert_counter := 1;\n    \n    -- Get the current maximum sale_id once\n    SELECT COALESCE(MAX(sale_id), 0) INTO max_sale_id FROM sales;\n    \n    FOR return_rec IN SELECT * FROM returns WHERE product_id = target_product_id LOOP\n        IF return_rec.reason = 'defective product' THEN\n            counter := counter + 1;\n        ELSIF return_rec.reason = 'wrong product' THEN\n            counter := counter + 2;\n        ELSIF return_rec.reason = 'damaged' THEN\n            counter := counter + 3;\n        ELSIF return_rec.reason = 'not satisfied' THEN\n            counter := counter + 4;\n        ELSIF return_rec.reason = 'late delivery' THEN\n            counter := counter + 5;\n        ELSIF return_rec.reason = 'poor quality' THEN\n            counter := counter + 6;\n        ELSIF return_rec.reason = 'size issue' THEN\n            counter := counter + 7;\n        ELSIF return_rec.reason = 'color mismatch' THEN\n            counter := counter + 8;\n        ELSIF return_rec.reason = 'functionality issue' THEN\n            counter := counter + 9;\n        ELSIF return_rec.reason = 'packaging problem' THEN\n            counter := counter + 10;\n        ELSE\n            counter := counter + 11;\n        END IF;\n        \n        FOR order_rec IN SELECT * FROM orders WHERE order_id = return_rec.order_id LOOP\n            IF order_rec.total > price_threshold THEN\n                DELETE FROM order_items WHERE order_id = order_rec.order_id AND product_id = target_product_id;\n            END IF;\n        END LOOP;\n    END LOOP;\n    \n    FOR product_rec IN SELECT * FROM products WHERE product_id = target_product_id LOOP\n        FOR store_rec IN SELECT * FROM stores LOOP\n            INSERT INTO sales (sale_id, product_id, store_id, sale_date, sale_price, quantity_sold)\n            VALUES (max_sale_id + insert_counter, \n                   product_rec.product_id, store_rec.store_id, CURRENT_DATE::text, \n                   product_rec.price * 0.8, 1)\n            ON CONFLICT (sale_id) DO NOTHING;\n            \n            insert_counter := insert_counter + 1;\n        END LOOP;\n    END LOOP;\nEND;\n$$;",
    "database_name": "retail_sales_and_inventory_management_205102",
    "tables": [
      "order_items",
      "orders",
      "products",
      "returns",
      "sales",
      "stores"
    ],
    "call_sqls": [
      "CALL analyze_return_patterns_with_conditions(0);",
      "CALL analyze_return_patterns_with_conditions(1);",
      "CALL analyze_return_patterns_with_conditions(100);",
      "CALL analyze_return_patterns_with_conditions(2);",
      "CALL analyze_return_patterns_with_conditions(3);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_return_patterns_with_conditions that accepts a target_product_id. For each return of that product in the returns table, increment a counter based on the specific return reason. For each associated order in the orders table where the total exceeds 100, delete the corresponding entries from the order_items table for that product and order. Then, for the specified product from the products table and each store in the stores table, insert a discounted sale record into the sales table with a unique sale_id, using a 20% discount on the product's price, and if a sale_id conflict occurs, take no action.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_return_patterns_with_conditions that takes a target_product_id as input. For each return in the returns table for that product, increment a counter based on the return reason, with specific values assigned to each reason. Then, for any orders linked to these returns where the order total exceeds 100, delete the corresponding items from the order_items table. Finally, for the specified product and each store in the stores table, insert a discounted sale record into the sales table with a unique sale_id, applying an 80% discount to the product price, and use ON CONFLICT DO NOTHING to handle conflicts.",
    "id": 93,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_return_patterns_with_conditions that accepts a single input parameter target_product_id of type BIGINT, which identifies a specific product for analysis. The procedure begins by declaring a cursor named return_cursor to fetch all records from the returns table where the product_id column matches the input target_product_id, along with record variables return_rec, order_rec, product_rec, item_rec, and store_rec, and counter, price_threshold, max_sale_id, and insert_counter variables of type BIGINT or REAL. It initializes counter to 0, price_threshold to 100.0, and insert_counter to 1. It then executes a SELECT statement to retrieve the current maximum value from the sale_id column in the sales table, storing it in max_sale_id and defaulting to 0 if the result is NULL using the COALESCE function.\n\nThe core logic uses a FOR loop to iterate over each row from the returns table where product_id equals target_product_id, assigning each row to return_rec. Within this loop, a series of conditional IF-ELSIF-ELSE statements examines the value of the reason column in return_rec and increments the counter variable by a specific integer (1 through 11) based on the exact string match: it adds 1 for 'defective product', 2 for 'wrong product', 3 for 'damaged', 4 for 'not satisfied', 5 for 'late delivery', 6 for 'poor quality', 7 for 'size issue', 8 for 'color mismatch', 9 for 'functionality issue', 10 for 'packaging problem', and 11 for any other reason. Following this, a nested FOR loop iterates over rows from the orders table where the order_id matches return_rec.order_id, assigning each to order_rec. Inside this inner loop, if the total column value in order_rec is greater than the price_threshold (100.0), it executes a DELETE operation on the order_items table, removing rows where both the order_id equals order_rec.order_id and the product_id equals the input target_product_id.\n\nAfter processing all return records, the procedure enters another FOR loop that iterates over rows from the products table where product_id equals the input target_product_id, assigning each to product_rec. For each such product, it then loops through all rows in the stores table using a FOR loop with store_rec. Within this nested store loop, it performs an INSERT operation into the sales table with columns sale_id, product_id, store_id, sale_date, sale_price, and quantity_sold. The sale_id is calculated as the previously obtained max_sale_id plus the current insert_counter value; product_id is taken from product_rec.product_id; store_id is from store_rec.store_id; sale_date is the current date converted to text using CURRENT_DATE::text; sale_price is calculated as product_rec.price multiplied by 0.8; and quantity_sold is set to 1. This INSERT uses an ON CONFLICT (sale_id) DO NOTHING clause to silently skip insertion if a duplicate sale_id exists. After each INSERT attempt, the insert_counter variable is incremented by 1.",
    "original_summary": "Create a stored procedure named analyze_return_patterns_with_conditions that accepts a target_product_id (BIGINT). For each return of that product, increment a counter based on the return reason. For associated orders with a total over 100, delete corresponding order items. Finally, for the product and each store, insert a discounted sale record with a unique sale_id, using ON CONFLICT DO NOTHING.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as 'analyze_return_patterns_with_conditions' that receives a parameter of type BIGINT named 'target_product_id'. The procedure's logic shall be as follows: for every recorded return pertaining to the specified product, a counter should be incremented according to the associated return reason. Subsequently, for any orders linked to these returns that possess a total value exceeding 100, the corresponding order items are to be deleted. Finally, for the product in question and each distinct store, insert a record for a discounted sale, generating a unique 'sale_id' for each insertion, and employ an ON CONFLICT DO NOTHING clause to handle potential conflicts."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_regional_demographics that accepts three input parameters: a BIGINT parameter p_region_id to identify a specific region, a BIGINT parameter p_min_population to set a minimum population threshold, and a REAL parameter p_fertility_threshold to define a fertility rate limit. The procedure declares a cursor named v_country_cursor that selects data from the countries, countries_regions, and demographics tables, specifically retrieving the country_id, country_name, population, and fertility_rate columns by joining the countries table with the countries_regions table on the country_id column and with the demographics table on the country_id column, filtering the results to include only rows where the region_id in the countries_regions table matches the input parameter p_region_id and the population in the countries table is greater than or equal to the input parameter p_min_population. The procedure then declares a record variable v_country_record to hold each row from the cursor, and two BIGINT counter variables v_total_countries and v_high_fertility_count, both initialized to zero. The procedure opens a FOR loop that iterates over each row fetched by the v_country_cursor, and for each iteration, it increments the v_total_countries counter by one and then checks if the fertility_rate value from the current cursor row is greater than the input parameter p_fertility_threshold, incrementing the v_high_fertility_count counter by one if the condition is true. After the loop completes, the procedure performs an INSERT operation into the regions table, specifying the columns region_id, region_name, region_description, population, area, average_gdp, average_life_expectancy, and average_literacy_rate, where the values are derived from a SELECT statement that calculates the new region_id as the maximum existing region_id from the regions table plus one (or uses 0 if the maximum is null via the COALESCE function), sets the region_name to the literal string 'Analysis Result', sets the region_description to the literal string 'Regional analysis completed', sets the population column to the final value of the v_total_countries counter, sets the area column to the final value of the v_high_fertility_count counter, and sets the average_gdp, average_life_expectancy, and average_literacy_rate columns to the literal value 0.0.",
    "plsql": "CREATE OR REPLACE PROCEDURE analyze_regional_demographics(\n    p_region_id BIGINT,\n    p_min_population BIGINT,\n    p_fertility_threshold REAL\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_country_cursor CURSOR FOR\n        SELECT c.country_id, c.country_name, c.population, d.fertility_rate\n        FROM countries c\n        JOIN countries_regions cr ON c.country_id = cr.country_id\n        JOIN demographics d ON c.country_id = d.country_id\n        WHERE cr.region_id = p_region_id AND c.population >= p_min_population;\n    v_country_record RECORD;\n    v_total_countries BIGINT := 0;\n    v_high_fertility_count BIGINT := 0;\nBEGIN\n    FOR v_country_record IN v_country_cursor LOOP\n        v_total_countries := v_total_countries + 1;\n        \n        IF v_country_record.fertility_rate > p_fertility_threshold THEN\n            v_high_fertility_count := v_high_fertility_count + 1;\n        END IF;\n    END LOOP;\n    \n    INSERT INTO regions (region_id, region_name, region_description, population, area, average_gdp, average_life_expectancy, average_literacy_rate)\n    SELECT \n        COALESCE(MAX(region_id), 0) + 1,\n        'Analysis Result',\n        'Regional analysis completed',\n        v_total_countries,\n        v_high_fertility_count,\n        0.0,\n        0.0,\n        0.0\n    FROM regions;\nEND;\n$$;",
    "database_name": "global_demographic_and_geographic_data_management",
    "tables": [
      "countries",
      "countries_regions",
      "regions",
      "demographics",
      "migration_data"
    ],
    "call_sqls": [
      "CALL analyze_regional_demographics(1, 10000000, 2.1);",
      "CALL analyze_regional_demographics(2, 5000000, 2.0);",
      "CALL analyze_regional_demographics(3, 20000000, 1.8);",
      "CALL analyze_regional_demographics(1, 50000000, 2.5);",
      "CALL analyze_regional_demographics(4, 1000000, 1.9);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_regional_demographics that, for a given region_id, analyzes countries in that region by counting the total number of countries from the countries table with a population at least as large as a provided min_population, and also counts how many of those countries have a fertility_rate from the demographics table exceeding a specified fertility_threshold, then inserts a new record into the regions table with these two counts as the population and area values respectively, using placeholder values for the other columns like region_name, region_description, average_gdp, average_life_expectancy, and average_literacy_rate.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_regional_demographics that takes a region_id, a min_population, and a fertility_threshold as inputs. For the specified region, retrieve all countries from the countries table that have a population at least as large as min_population, joining with the countries_regions and demographics tables. Count the total number of such countries and separately count how many of them have a fertility_rate from the demographics table exceeding the fertility_threshold. Then, insert a new record into the regions table with these counts, using placeholder values for other columns like region_name and region_description.",
    "id": 94,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named analyze_regional_demographics that accepts three input parameters: p_region_id of type bigint to identify a specific region, p_min_population of type bigint to define a minimum population threshold, and p_fertility_threshold of type real to define a fertility rate benchmark. The procedure first declares two local variables: v_total_countries of type bigint to store the count of qualifying countries, and v_high_fertility_countries of type bigint to store the count of countries with fertility rates above the threshold.\n\nThe procedure then calculates the total number of countries in the specified region that meet the population criterion by performing a SELECT COUNT(*) query. This query joins the countries table with the countries_regions table on the country_id column to filter for countries belonging to the region identified by p_region_id, and further filters the countries table rows where the population column is greater than or equal to p_min_population. The result is stored in v_total_countries.\n\nNext, the procedure calculates the number of those qualifying countries that have a fertility rate exceeding the fertility threshold by performing another SELECT COUNT(*) query. This query joins the countries table with the countries_regions table on the country_id column and also joins with the demographics table on the country_id column to access the fertility_rate column. It applies the same filters: countries_regions.region_id must equal p_region_id, countries.population must be greater than or equal to p_min_population, and demographics.fertility_rate must be greater than p_fertility_threshold. The result is stored in v_high_fertility_countries.\n\nFinally, the procedure executes an INSERT operation into the regions table. It inserts a new row with the following values: region_id is set to p_region_id, region_name is set to a placeholder string 'Region ' concatenated with p_region_id cast to text, region_description is set to a placeholder string 'Demographic analysis for region ' concatenated with p_region_id cast to text, population is set to 0 as a placeholder, area is set to 0.0 as a placeholder, average_gdp is set to 0.0 as a placeholder, average_life_expectancy is set to 0.0 as a placeholder, and average_literacy_rate is set to 0.0 as a placeholder. The calculated counts v_total_countries and v_high_fertility_countries are not directly inserted into the regions table as the table schema does not have columns for these values; the insertion is based on the provided schema which includes only the listed columns.",
    "original_summary": "Create a PL/pgSQL stored procedure named analyze_regional_demographics that accepts region_id, min_population (BIGINT), and fertility_threshold (REAL) parameters. Use a cursor to find countries in the region with population >= min_population. Count total countries and those with fertility_rate > threshold. Insert a new record into the regions table with the calculated counts and placeholder values for other fields.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Make a procedure analyze_regional_demographics with region_id, min_population, fertility_threshold. Use a cursor to get countries in the region with sufficient population. Count total countries and those above the fertility rate. Insert results into regions."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named insert_nucleus_data that accepts three parameters: p_sample_id of type bigint, p_area_threshold of type real, and p_shape of type text. The procedure is designed to process data from the nucleus_metrics table. It begins by declaring a cursor named v_nucleus_cursor, which selects the nucleus_id and area columns from the nucleus_metrics table where the sample_id matches the provided p_sample_id parameter. The procedure then opens this cursor and enters a loop to fetch each row into a record variable named v_nucleus_rec. For each fetched record, it checks if the area value in v_nucleus_rec exceeds the p_area_threshold parameter. If this condition is met, the procedure calculates a new nucleus_id by selecting the maximum nucleus_id from the nucleus_metrics table, defaulting to 0 if no records exist, and incrementing it by 1. This new nucleus_id is stored in the variable v_new_nucleus_id. Subsequently, the procedure inserts a new row into the nucleus_metrics table with the following values: v_new_nucleus_id for nucleus_id, p_sample_id for sample_id, the area from v_nucleus_rec for area, and default values for other columns such as perimeter set to 0.0, circularity set to 1.0, max_caliper set to 0.0, min_caliper set to 0.0, eccentricity set to 0.0, nucleus_volume set to 100.0, nucleus_shape set to the p_shape parameter, nucleus_texture set to 'Smooth', nucleus_intensity set to 0.8, and nucleus_area_std_dev set to 0.0. The loop continues until all records are processed, after which the cursor is closed.",
    "plsql": "CREATE OR REPLACE PROCEDURE insert_nucleus_data(\n    p_sample_id bigint,\n    p_area_threshold real,\n    p_shape text\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_nucleus_cursor CURSOR FOR\n        SELECT nucleus_id, area\n        FROM nucleus_metrics\n        WHERE sample_id = p_sample_id;\n    v_nucleus_rec RECORD;\n    v_new_nucleus_id bigint;\nBEGIN\n    OPEN v_nucleus_cursor;\n    \n    LOOP\n        FETCH v_nucleus_cursor INTO v_nucleus_rec;\n        EXIT WHEN NOT FOUND;\n        \n        IF v_nucleus_rec.area > p_area_threshold THEN\n            SELECT COALESCE(MAX(nucleus_id), 0) + 1 INTO v_new_nucleus_id FROM nucleus_metrics;\n            INSERT INTO nucleus_metrics (nucleus_id, sample_id, area, perimeter, circularity, max_caliper, min_caliper, eccentricity, nucleus_volume, nucleus_shape, nucleus_texture, nucleus_intensity, nucleus_area_std_dev)\n            VALUES (v_new_nucleus_id, p_sample_id, v_nucleus_rec.area, 0.0, 1.0, 0.0, 0.0, 0.0, 100.0, p_shape, 'Smooth', 0.8, 0.0);\n        END IF;\n    END LOOP;\n    \n    CLOSE v_nucleus_cursor;\nEND;\n$$;",
    "database_name": "biological_sample_analysis_and_metrics",
    "tables": [
      "cell_metrics",
      "cytoplasm_metrics",
      "nucleus_metrics",
      "nucleus_OD_metrics"
    ],
    "call_sqls": [
      "CALL insert_nucleus_data(1, 25.0, 'Spherical');",
      "CALL insert_nucleus_data(2, 30.0, 'Ellipsoidal');",
      "CALL insert_nucleus_data(1, 20.0, 'Irregular');",
      "CALL insert_nucleus_data(3, 15.5, 'Spherical');",
      "CALL insert_nucleus_data(2, 10.0, 'Oval');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named insert_nucleus_data that, for a given p_sample_id, processes nucleus records from the nucleus_metrics table where the area exceeds a specified p_area_threshold, generating a new nucleus_id by incrementing the maximum existing ID, and inserts a new row with the fetched area, the provided p_shape, and default values for other metrics (perimeter=0.0, circularity=1.0, etc.).",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called insert_nucleus_data that takes a sample ID (p_sample_id), an area threshold (p_area_threshold), and a shape (p_shape). For each nucleus in the nucleus_metrics table with the given sample ID, if its area exceeds the threshold, generate a new nucleus ID by incrementing the current maximum ID, and insert a new record into nucleus_metrics with that new ID, the same sample ID, the fetched area, the provided shape, a perimeter of 0.0, a circularity of 1.0, and default values for all other metrics.",
    "id": 95,
    "generated_ir": "Write a PLpgSQL stored procedure named insert_nucleus_data that accepts three parameters: p_sample_id of type bigint, p_area_threshold of type real, and p_shape of type text. The procedure is designed to process data from the nucleus_metrics table. It begins by declaring a cursor named v_nucleus_cursor, which selects the nucleus_id and area columns from the nucleus_metrics table where the sample_id matches the provided p_sample_id parameter. The procedure then opens this cursor and enters a loop to fetch each row into a record variable named v_nucleus_rec. For each fetched record, it checks if the area value in v_nucleus_rec exceeds the p_area_threshold parameter. If this condition is met, the procedure calculates a new nucleus_id by selecting the maximum nucleus_id from the nucleus_metrics table, defaulting to 0 if no records exist, and incrementing it by 1. This new nucleus_id is stored in the variable v_new_nucleus_id. Subsequently, the procedure inserts a new row into the nucleus_metrics table with the following values: v_new_nucleus_id for nucleus_id, p_sample_id for sample_id, the area from v_nucleus_rec for area, and default values for other columns such as perimeter set to 0.0, circularity set to 1.0, max_caliper set to 0.0, min_caliper set to 0.0, eccentricity set to 0.0, nucleus_volume set to 100.0, nucleus_shape set to the p_shape parameter, nucleus_texture set to 'Smooth', nucleus_intensity set to 0.8, and nucleus_area_std_dev set to 0.0. The loop continues until all records are processed, after which the cursor is closed.",
    "original_summary": "Create a stored procedure named insert_nucleus_data with parameters: p_sample_id (bigint), p_area_threshold (real), p_shape (text). Declare a cursor to fetch nucleus_id and area for the given sample_id. Loop through each record: if the area exceeds the threshold, generate a new nucleus_id by incrementing the maximum existing ID, then insert a new row with the fetched area, the provided shape, and default values for other metrics (perimeter=0.0, circularity=1.0, etc.).",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a stored procedure designated as 'insert_nucleus_data'. This procedure shall accept the following parameters: 'p_sample_id' of type bigint, 'p_area_threshold' of type real, and 'p_shape' of type text. Within the procedure, it is required to declare a cursor for the purpose of retrieving the nucleus_id and area values associated with the specified sample_id. Subsequently, iterate through each fetched record. For every record, if the area value is determined to exceed the provided threshold, it is necessary to generate a new nucleus_id by incrementing the current maximum ID value. Following this generation, insert a new row into the table. This new row should incorporate the fetched area value, the provided shape parameter, and assign default values for the remaining metrics, such as a perimeter of 0.0 and a circularity of 1.0."
  },
  {
    "ir": "Write a PostgreSQL PLpgSQL stored procedure named update_clothing_prices that accepts two input parameters: a text parameter p_brand representing a clothing brand name and a real number parameter p_price_increase representing a monetary amount to add to prices. The procedure first declares two local real variables, v_max_price and v_min_price. It then queries the clothing_items table to retrieve the maximum and minimum price values from the price column for all rows where the brand column matches the input p_brand, using the COALESCE function to substitute a value of 0 if the result of MAX(price) or MIN(price) is NULL, and stores these results into the respective local variables. Following this data retrieval, the procedure executes a conditional IF-ELSIF-ELSE block: if the retrieved v_max_price is less than 50, it performs an UPDATE operation on the clothing_items table, increasing the price column by the p_price_increase amount for every row where the brand column equals p_brand; alternatively, if the first condition is not met and the retrieved v_min_price is greater than 100, it performs a DELETE operation on the clothing_items table, removing all rows where the brand column equals p_brand and the price column is less than 100; if neither of the previous conditions is true, it performs an INSERT operation into the clothing_items table, specifying values for the columns item_id, item_name, description, price, category, sub_category, brand, color, and material, where the item_id value is derived from a subquery that calculates the maximum existing item_id from the clothing_items table (using COALESCE to default to 0 if NULL) and adds 1 to it, the item_name is set to the literal string 'New Item', description to 'Description', price to 75, category to 'category', sub_category to 'sub_category', brand to the input p_brand, color to 'color', and material to 'material'.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_clothing_prices(p_brand text, p_price_increase real)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_max_price real;\n    v_min_price real;\nBEGIN\n    SELECT COALESCE(MAX(price), 0), COALESCE(MIN(price), 0)\n    INTO v_max_price, v_min_price\n    FROM clothing_items\n    WHERE brand = p_brand;\n\n    IF v_max_price < 50 THEN\n        UPDATE clothing_items\n        SET price = price + p_price_increase\n        WHERE brand = p_brand;\n    ELSIF v_min_price > 100 THEN\n        DELETE FROM clothing_items\n        WHERE brand = p_brand AND price < 100;\n    ELSE\n        INSERT INTO clothing_items (item_id, item_name, description, price, category, sub_category, brand, color, material)\n        VALUES ((SELECT COALESCE(MAX(item_id), 0) + 1 FROM clothing_items), 'New Item', 'Description', 75, 'category', 'sub_category', p_brand, 'color', 'material');\n    END IF;\nEND;\n$$;",
    "database_name": "fashion_and_apparel_sizing_guide",
    "tables": [
      "clothing_items",
      "inventory",
      "sizes"
    ],
    "call_sqls": [
      "CALL update_clothing_prices('Gucci', 5.0);",
      "CALL update_clothing_prices('Nike', 10.0);",
      "CALL update_clothing_prices('Adidas', 7.5);",
      "CALL update_clothing_prices('Puma', 3.0);",
      "CALL update_clothing_prices('Reebok', 8.0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named update_clothing_prices that accepts a brand name and a price increase amount, retrieves the maximum and minimum price for that brand from the clothing_items table, and then, if the maximum price is less than 50, increases all prices for the brand by the given amount; otherwise, if the minimum price is greater than 100, deletes all items for that brand with a price under 100; otherwise, inserts a new default item for the brand with a generated item_id, default values for item_name, description, price, category, sub_category, color, and material.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called update_clothing_prices that takes a brand name and a price increase amount, checks the current maximum and minimum prices for that brand in the clothing_items table, and then: if the maximum price is below 50, increases all prices for that brand by the given amount; if the minimum price is above 100, deletes all items for that brand priced under 100; otherwise, inserts a new default item for the brand with a unique item_id.",
    "id": 96,
    "generated_ir": "Write a PostgreSQL PLpgSQL stored procedure named update_clothing_prices that accepts two input parameters: a text parameter p_brand representing a clothing brand name and a real number parameter p_price_increase representing a monetary amount to add to prices. The procedure first declares two local real variables, v_max_price and v_min_price. It then queries the clothing_items table to retrieve the maximum and minimum price values from the price column for all rows where the brand column matches the input p_brand, using the COALESCE function to substitute a value of 0 if the result of MAX(price) or MIN(price) is NULL, and stores these results into the respective local variables. Following this data retrieval, the procedure executes a conditional IF-ELSIF-ELSE block: if the retrieved v_max_price is less than 50, it performs an UPDATE operation on the clothing_items table, increasing the price column by the p_price_increase amount for every row where the brand column equals p_brand; alternatively, if the first condition is not met and the retrieved v_min_price is greater than 100, it performs a DELETE operation on the clothing_items table, removing all rows where the brand column equals p_brand and the price column is less than 100; if neither of the previous conditions is true, it performs an INSERT operation into the clothing_items table, specifying values for the columns item_id, item_name, description, price, category, sub_category, brand, color, and material, where the item_id value is derived from a subquery that calculates the maximum existing item_id from the clothing_items table (using COALESCE to default to 0 if NULL) and adds 1 to it, the item_name is set to the literal string 'New Item', description to 'Description', price to 75, category to 'category', sub_category to 'sub_category', brand to the input p_brand, color to 'color', and material to 'material'.",
    "original_summary": "Create a stored procedure named update_clothing_prices that accepts a brand name and a price increase amount. It retrieves the maximum and minimum price for that brand. If the maximum price is less than 50, increase all prices for the brand by the given amount. Else, if the minimum price is greater than 100, delete all items for that brand with a price under 100. Otherwise, insert a new default item for the brand with a generated ID.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Develop a stored procedure, which should be named update_clothing_prices, that is designed to accept two specific input parameters: a brand name and a numerical amount representing a proposed price increase. This procedure must first retrieve and examine the current maximum and minimum price points for all items associated with the specified brand. In the detailed scenario where the identified maximum price is found to be comfortably below the threshold of 50, then the procedure should comprehensively increase the price of every single item for that particular brand by the precisely supplied increase amount. Alternatively, if the initial condition is not met, but the ascertained minimum price is determined to be substantially greater than 100, the procedure must proceed to delete all product entries for that brand which are currently listed with a price that is under 100. Finally, in all other remaining circumstances where neither of the previous detailed conditions applies, the procedure should insert a brand new default item entry for the specified brand, ensuring this new item is assigned a uniquely generated identifier."
  },
  {
    "ir": "Write a PostgreSQL PL/pgSQL stored procedure named `delete_old_datasheets` that accepts a single input parameter. This parameter, named `p_date_threshold`, is of data type `text`. The purpose of this procedure is to remove records from the `datasheets` table. The deletion operation targets rows where the value in the `upload_date` column is strictly less than the value provided in the `p_date_threshold` parameter. The comparison `upload_date < p_date_threshold` is performed to identify the records that meet the criteria for deletion.",
    "plsql": "CREATE OR REPLACE PROCEDURE delete_old_datasheets(p_date_threshold text)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    DELETE FROM datasheets\n    WHERE upload_date < p_date_threshold;\nEND;\n$$;",
    "database_name": "electronic_component_specification_and_parameter_tracking",
    "tables": [
      "access_logs",
      "components",
      "users",
      "datasheets",
      "component_conditions",
      "component_parameters",
      "conditions"
    ],
    "call_sqls": [
      "CALL delete_old_datasheets('2023-01-01');",
      "CALL delete_old_datasheets('2023-01-02');",
      "CALL delete_old_datasheets('2023-01-03');",
      "CALL delete_old_datasheets('2022-12-31');",
      "CALL delete_old_datasheets('2023-05-01');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named delete_old_datasheets that removes all records from the datasheets table where the upload_date is older than a specified date threshold provided as the input parameter p_date_threshold.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named delete_old_datasheets that removes older entries from the datasheets table where the upload_date is earlier than a specified date threshold provided as input.",
    "id": 97,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `delete_old_datasheets` that accepts a single input parameter. This parameter, named `p_date_threshold`, is of data type `text`. The purpose of this procedure is to remove records from the `datasheets` table. The deletion operation targets rows where the value in the `upload_date` column is strictly less than the value provided in the `p_date_threshold` parameter. The comparison `upload_date < p_date_threshold` is performed to identify the records that meet the criteria for deletion.",
    "original_summary": "Create a stored procedure named `delete_old_datasheets` that deletes records from the `datasheets` table where the `upload_date` is earlier than the provided `p_date_threshold` (TEXT) parameter.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Create a stored procedure to get rid of some older datasheet entries, where the upload date seems a bit too far back compared to a given date cutoff parameter."
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named `update_treatment_status` that accepts two input parameters: `p_treatment_id` of type `BIGINT` which represents the unique identifier for a specific treatment record, and `p_new_status` of type `TEXT` which represents the new status value to be assigned to the treatment. The procedure performs a single `UPDATE` operation on the `treatments` table. This `UPDATE` statement modifies the `status` column of the `treatments` table to the value provided by the `p_new_status` parameter. Additionally, it updates the `updated_at` column of the same table to the current timestamp, which is obtained using the `CURRENT_TIMESTAMP` function and then explicitly cast to a `TEXT` data type. The `UPDATE` operation is conditionally applied only to those rows in the `treatments` table where the value in the `treatment_id` column exactly matches the value provided by the `p_treatment_id` input parameter.",
    "plsql": "CREATE OR REPLACE PROCEDURE update_treatment_status(p_treatment_id BIGINT, p_new_status TEXT)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n    UPDATE treatments\n    SET status = p_new_status,\n        updated_at = CURRENT_TIMESTAMP::TEXT\n    WHERE treatment_id = p_treatment_id;\nEND;\n$$;",
    "database_name": "healthcare_data_management_and_analytics",
    "tables": [
      "datamarts",
      "dispenses",
      "patients",
      "queries",
      "responses",
      "treatments",
      "users"
    ],
    "call_sqls": [
      "CALL update_treatment_status(0, 'completed');",
      "CALL update_treatment_status(1, 'ongoing');",
      "CALL update_treatment_status(0, 'cancelled');",
      "CALL update_treatment_status(1, 'pending');",
      "CALL update_treatment_status(0, 'in progress');"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `update_treatment_status` that updates the status of a specific treatment in the `treatments` table by accepting a treatment identifier and a new status, setting the `status` to the provided new value and recording the current timestamp in the `updated_at` column.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `update_treatment_status` that updates the `status` and `updated_at` fields for a specific treatment entry in the `treatments` table, using a provided treatment identifier and new status text, and setting `updated_at` to the current timestamp formatted as text.",
    "id": 98,
    "generated_ir": "Write a PLpgSQL stored procedure named update_treatment_status that accepts two parameters: p_treatment_id of type BIGINT and p_new_status of type TEXT. The procedure is designed to update the status and updated_at fields for a specific treatment entry in the treatments table. It begins by performing an UPDATE operation on the treatments table, targeting the row where the treatment_id column matches the provided p_treatment_id. The procedure sets the status column to the value of p_new_status and sets the updated_at column to the current timestamp, formatted as a text string using the standard PostgreSQL timestamp formatting. The procedure does not declare any variables, perform any conditional checks, or return any values; it solely executes this single UPDATE statement.",
    "original_summary": "Create a stored procedure named `update_treatment_status` that updates the `status` and `updated_at` columns in the `treatments` table for a specific `treatment_id`. The procedure accepts `p_treatment_id` (BIGINT) and `p_new_status` (TEXT) as parameters. Set `updated_at` to the current timestamp cast to TEXT.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Make a stored procedure called `update_treatment_status` that changes the `status` and `updated_at` fields for a certain treatment entry. It should take a treatment identifier and a new status text as inputs. Update the `updated_at` to be roughly the current time, formatted as text."
  },
  {
    "ir": "Write a PLpgSQL stored procedure named `synchronize_multi_dimensional_data` that accepts four input parameters: `sync_year` of type `bigint`, `region_filter` of type `text`, `score_baseline` of type `real`, and `spending_limit` of type `real`. The procedure's primary purpose is to iterate through a filtered set of countries and, for each country, apply a series of conditional data synchronization and manipulation operations across several related data tables.\n\nThe procedure begins by declaring a cursor named `sync_cursor`. This cursor is defined to select `country_id`, `country_name`, `capital`, and `official_language` from the `countries` table, specifically filtering for rows where the `region` column matches the value provided by the `region_filter` input parameter. A record variable named `sync_record` is also declared to hold the data fetched from this cursor.\n\nThe procedure then opens `sync_cursor`. It enters a loop, and in each iteration, it fetches the next row from `sync_cursor` into `sync_record`. The loop continues until no more rows are found, at which point it exits.\n\nInside the loop, for each `sync_record` (representing a country), the procedure performs a series of nested conditional checks:\n\n1.  **First Condition:** It checks if a record exists in the `freedom_data` table where the `country_id` matches `sync_record.country_id`, the `year` matches `sync_year`, and the `freedom_score` is greater than the `score_baseline` input parameter.\n    *   **If this first condition is TRUE:**\n        *   **Second Condition (nested):** It then checks if a record exists in the `health_data` table where the `country_id` matches `sync_record.country_id`, the `year` matches `sync_year`, and the `healthcare_spending` is less than the `spending_limit` input parameter.\n            *   **If this second condition is TRUE:**\n                *   **Third Condition (nested):** It further checks if a record exists in the `happiness_data` table where the `country_id` matches `sync_record.country_id`, the `year` matches `sync_year`, and the `happiness_rank` is less than or equal to 20.\n                    *   **If this third condition is TRUE:**\n                        *   **Fourth Condition (nested):** It counts the number of records in the `economic_data` table where the `country_id` matches `sync_record.country_id` and the `year` is between `sync_year - 2` (inclusive) and `sync_year` (inclusive). If this count is greater than or equal to 2:\n                            *   It updates the `health_data` table, setting the `life_expectancy` column to its current value multiplied by 1.02. This update applies to the record where `country_id` matches `sync_record.country_id` and `year` matches `sync_year`.\n                        *   **Else (if the count is less than 2):**\n                            *   It inserts a new record into the `economic_data` table. The `economic_id` is generated by finding the maximum `economic_id` in the `economic_data` table and adding 1 to it; if no `economic_id` exists, it defaults to 1. The `country_id` is set to `sync_record.country_id`, `gdp_per_capita` is set to 1.2, `year` is set to `sync_year`, `inflation_rate` is set to 3.5, `unemployment_rate` is set to 4.2, `poverty_rate` is set to 8.1, `data_source` is set to 'synchronized', and `version` is set to '1'.\n                    *   **Else (if the third condition is FALSE, meaning no happiness data record meets the criteria):**\n                        *   It deletes records from the `happiness_data` table where the `country_id` matches `sync_record.country_id`, the `year` is less than `sync_year - 3`, and the `happiness_rank` is greater than 100.\n            *   **Else (if the second condition is FALSE, meaning no health data record meets the criteria):**\n                *   It updates the `freedom_data` table, setting the `freedom_score` column to its current value multiplied by 0.95. This update applies to the record where `country_id` matches `sync_record.country_id` and `year` matches `sync_year`.\n    *   **Else (if the first condition is FALSE, meaning no freedom data record meets the criteria):**\n        *   It inserts a new record into the `freedom_data` table. The `freedom_id` is generated by finding the maximum `freedom_id` in the `freedom_data` table and adding 1 to it; if no `freedom_id` exists, it defaults to 1. The `country_id` is set to `sync_record.country_id`, `freedom_score` is set to the `score_baseline` input parameter multiplied by 0.8, `trust_in_government` is set to 0.25, `year` is set to `sync_year`, `data_source` is set to 'sync_process', and `version` is set to '1'.\n\nAfter the loop completes, the procedure closes `sync_cursor`.",
    "plsql": "CREATE OR REPLACE PROCEDURE synchronize_multi_dimensional_data(IN sync_year bigint, IN region_filter text, IN score_baseline real, IN spending_limit real)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    sync_cursor CURSOR FOR \n        SELECT country_id, country_name, capital, official_language FROM countries WHERE region = region_filter;\n    sync_record RECORD;\nBEGIN\n    OPEN sync_cursor;\n    LOOP\n        FETCH sync_cursor INTO sync_record;\n        EXIT WHEN NOT FOUND;\n        \n        IF EXISTS(SELECT 1 FROM freedom_data WHERE country_id = sync_record.country_id AND year = sync_year AND freedom_score > score_baseline) THEN\n            IF EXISTS(SELECT 1 FROM health_data WHERE country_id = sync_record.country_id AND year = sync_year AND healthcare_spending < spending_limit) THEN\n                IF EXISTS(SELECT 1 FROM happiness_data WHERE country_id = sync_record.country_id AND year = sync_year AND happiness_rank <= 20) THEN\n                    IF (SELECT COUNT(*) FROM economic_data WHERE country_id = sync_record.country_id AND year BETWEEN (sync_year-2)::bigint AND sync_year) >= 2 THEN\n                        UPDATE health_data SET life_expectancy = life_expectancy * 1.02 WHERE country_id = sync_record.country_id AND year = sync_year;\n                    ELSE\n                        INSERT INTO economic_data (economic_id, country_id, gdp_per_capita, year, inflation_rate, unemployment_rate, poverty_rate, data_source, version)\n                        VALUES ((SELECT COALESCE(MAX(economic_id), 0) + 1 FROM economic_data), sync_record.country_id, 1.2, sync_year, 3.5, 4.2, 8.1, 'synchronized', '1');\n                    END IF;\n                ELSE\n                    DELETE FROM happiness_data WHERE country_id = sync_record.country_id AND year < sync_year - 3 AND happiness_rank > 100;\n                END IF;\n            ELSE\n                UPDATE freedom_data SET freedom_score = freedom_score * 0.95 WHERE country_id = sync_record.country_id AND year = sync_year;\n            END IF;\n        ELSE\n            INSERT INTO freedom_data (freedom_id, country_id, freedom_score, trust_in_government, year, data_source, version)\n            VALUES ((SELECT COALESCE(MAX(freedom_id), 0) + 1 FROM freedom_data), sync_record.country_id, score_baseline * 0.8, 0.25, sync_year, 'sync_process', '1');\n        END IF;\n    END LOOP;\n    CLOSE sync_cursor;\nEND;\n$$;",
    "database_name": "global_happiness_and_economic_data_analysis",
    "tables": [
      "countries",
      "economic_data",
      "freedom_data",
      "happiness_data",
      "health_data"
    ],
    "call_sqls": [
      "CALL synchronize_multi_dimensional_data(2023, 'Western Europe', 0.7, 5500.0);",
      "CALL synchronize_multi_dimensional_data(2022, 'Western Europe', 0.65, 6000.0);",
      "CALL synchronize_multi_dimensional_data(2021, 'Western Europe', 0.75, 5000.0);",
      "CALL synchronize_multi_dimensional_data(2023, 'Eastern Europe', 0.7, 5500.0);",
      "CALL synchronize_multi_dimensional_data(2022, 'Eastern Europe', 0.65, 6000.0);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named `synchronize_multi_dimensional_data` that processes countries in a specified region for a given year, using a baseline freedom score and a healthcare spending limit. For each country in the specified region from the COUNTRIES table, if a record exists in the FREEDOM_DATA table for the year with a `freedom_score` greater than the baseline, then check the HEALTH_DATA table for a record with `healthcare_spending` below the limit. If that exists, check the HAPPINESS_DATA table for a record with a `happiness_rank` of 20 or better. If that exists, verify at least two records exist in the ECONOMIC_DATA table for the past three years; if so, increase the `life_expectancy` in the HEALTH_DATA table by 2%; otherwise, insert a default record into the ECONOMIC_DATA table. If the happiness check fails, delete old low-priority records from HAPPINESS_DATA where the year is more than three years prior and the rank is over 100. If the health check fails, reduce the `freedom_score` in the FREEDOM_DATA table by 5%. If the initial freedom check fails, insert a default record into the FREEDOM_DATA table.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure called `synchronize_multi_dimensional_data` that takes a `sync_year`, a `region_filter`, a `score_baseline`, and a `spending_limit`, and for each country in the `countries` table matching the `region_filter`, checks conditions in sequence: if a `freedom_data` record exists for that year with `freedom_score` above the baseline, then if a `health_data` record exists for that year with `healthcare_spending` below the limit, then if a `happiness_data` record exists for that year with `happiness_rank` in the top 20, then if at least two `economic_data` records exist from the last three years, update the `life_expectancy` in `health_data` by increasing it by 2%; otherwise, insert a default record into `economic_data`. If the happiness check fails, delete old, low-priority records from `happiness_data`. If the health check fails, reduce the `freedom_score` in `freedom_data` by 5%. If the initial freedom check fails, insert a default record into `freedom_data`.",
    "id": 99,
    "generated_ir": "Write a PostgreSQL PL/pgSQL stored procedure named `synchronize_multi_dimensional_data` that accepts four input parameters: `sync_year` of type `bigint` representing the target year for synchronization, `region_filter` of type `text` to filter countries by region, `score_baseline` of type `real` as a threshold for freedom scores, and `spending_limit` of type `real` as a maximum threshold for healthcare spending. The procedure operates on the `global_happiness_and_economic_data_analysis` database and processes each country in the `countries` table that matches the specified region.\n\nThe procedure begins by declaring a local variable `country_record` of type `RECORD` to hold data for each country being processed, and a variable `economic_count` of type `bigint` to store the count of economic records.\n\nThe core logic is structured as a `FOR` loop that iterates over a result set obtained from the `countries` table. This `SELECT` statement retrieves `country_id` and `country_name` for all countries where the `region` column exactly matches the `region_filter` parameter. For each `country_record` returned by this query, the procedure executes a sequence of conditional checks and corresponding operations.\n\nFirst, it checks for the existence of a `freedom_data` record for the current country and the specified `sync_year`. It performs a `SELECT` statement on the `freedom_data` table where `country_id` equals `country_record.country_id` and `year` equals `sync_year`. If such a record exists and its `freedom_score` column is greater than the `score_baseline` parameter, the procedure proceeds to the next check. If no such record exists or the `freedom_score` condition is not met, the procedure inserts a default record into the `freedom_data` table. This `INSERT` statement populates the following columns: `freedom_id` is set by selecting the maximum existing `freedom_id` from the `freedom_data` table, adding 1 to it (using 0 if the maximum is null via the `COALESCE` function), `country_id` is set to `country_record.country_id`, `freedom_score` is set to 0.0, `trust_in_government` is set to 0.0, `year` is set to `sync_year`, `data_source` is set to the string literal 'default', and `version` is set to the string literal '0'. After this insertion, the procedure skips the remaining checks for the current country and continues with the next iteration of the loop.\n\nIf the initial freedom check passes, the procedure proceeds to check for the existence of a `health_data` record for the current country and the specified `sync_year`. It performs a `SELECT` statement on the `health_data` table where `country_id` equals `country_record.country_id` and `year` equals `sync_year`. If such a record exists and its `healthcare_spending` column is less than the `spending_limit` parameter, the procedure proceeds to the next check. If no such record exists or the `healthcare_spending` condition is not met, the procedure updates the `freedom_data` table. It executes an `UPDATE` statement on `freedom_data` where `country_id` equals `country_record.country_id` and `year` equals `sync_year`, setting the `freedom_score` column to its current value multiplied by 0.95 (i.e., reducing it by 5%). After this update, the procedure skips the remaining checks for the current country and continues with the next iteration of the loop.\n\nIf the health check passes, the procedure proceeds to check for the existence of a `happiness_data` record for the current country and the specified `sync_year`. It performs a `SELECT` statement on the `happiness_data` table where `country_id` equals `country_record.country_id` and `year` equals `sync_year`. If such a record exists and its `happiness_rank` column is less than or equal to 20 (indicating a rank in the top 20), the procedure proceeds to the next check. If no such record exists or the `happiness_rank` condition is not met, the procedure deletes records from the `happiness_data` table. It executes a `DELETE` statement on `happiness_data` where `country_id` equals `country_record.country_id` and `year` is less than `sync_year` and `data_source` is equal to the string literal 'low_priority'. After this deletion, the procedure skips the remaining checks for the current country and continues with the next iteration of the loop.\n\nIf the happiness check passes, the procedure proceeds to check for the existence of at least two `economic_data` records for the current country from the last three years (i.e., years `sync_year`, `sync_year - 1`, and `sync_year - 2`). It performs a `SELECT` statement with a `COUNT(*)` aggregation on the `economic_data` table where `country_id` equals `country_record.country_id` and `year` is between `sync_year - 2` and `sync_year` (inclusive). This count is stored in the `economic_count` variable. If `economic_count` is greater than or equal to 2, the procedure updates the `health_data` table. It executes an `UPDATE` statement on `health_data` where `country_id` equals `country_record.country_id` and `year` equals `sync_year`, setting the `life_expectancy` column to its current value multiplied by 1.02 (i.e., increasing it by 2%). If `economic_count` is less than 2, the procedure inserts a default record into the `economic_data` table. This `INSERT` statement populates the following columns: `economic_id` is set by selecting the maximum existing `economic_id` from the `economic_data` table, adding 1 to it (using 0 if the maximum is null via the `COALESCE` function), `country_id` is set to `country_record.country_id`, `gdp_per_capita` is set to 0.0, `year` is set to `sync_year`, `inflation_rate` is set to 0.0, `unemployment_rate` is set to 0.0, `poverty_rate` is set to 0.0, `data_source` is set to the string literal 'default', and `version` is set to the string literal '0'.\n\nAfter processing all countries matching the `region_filter`, the loop concludes, and the procedure finishes its execution.",
    "original_summary": "Create a stored procedure named `synchronize_multi_dimensional_data` with parameters `sync_year` (bigint), `region_filter` (text), `score_baseline` (real), and `spending_limit` (real). For each country in the specified region, check if a freedom record exists for the year with `freedom_score` > `score_baseline`. If yes, check if a health record exists with `healthcare_spending` < `spending_limit`. If yes, check if a happiness record exists with `happiness_rank` <= 20. If yes, check if at least 2 economic records exist for the past 3 years. If yes, increase `life_expectancy` by 2%. If not, insert a default economic record. If the happiness check fails, delete old low-priority happiness records. If the health check fails, reduce the `freedom_score` by 5%. If the initial freedom check fails, insert a default freedom record.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Alright, so we need a stored procedure called `synchronize_multi_dimensional_data`. It's gotta take in a few things: `sync_year` (as a big number), `region_filter` (some text), `score_baseline` (a decimal), and `spending_limit` (another decimal). Here's the deal for each country in that region: first, see if there's a freedom record for that year where the `freedom_score` beats the baseline. If it's there, then check for a health record where the `healthcare_spending` is under the spending limit. If that's also good, look for a happiness record with a `happiness_rank` in the top 20. If we're still good, make sure there are at least 2 economic records from the last 3 years. If all that lines up, bump up the `life_expectancy` by 2%. If that last economic check fails, just pop in a default economic record. If the happiness check doesn't pass, get rid of any old, low-priority happiness records. If the health check fails, knock the `freedom_score` down by 5%. And if the very first freedom check comes up empty, just insert a default freedom record."
  },
  {
    "ir": "Write a PL/pgSQL stored procedure named migrate_country_data that accepts three input parameters: p_source_country_id of type BIGINT, representing the unique identifier of the source country; p_target_country_id of type BIGINT, representing the unique identifier of the target country; and p_migration_year of type BIGINT, representing the year for which migration data is being recorded. The procedure begins by declaring four local variables: v_source_demographics of type RECORD, intended to hold a full row of data from the demographics table; v_new_migration_id of type BIGINT, to store a newly generated unique identifier for migration data; v_target_country_exists of type BOOLEAN, to indicate whether the target country exists in the countries table; and v_source_demographics_exists of type BOOLEAN, to indicate whether demographic data exists for the source country.\n\nThe procedure first determines if demographic data exists for the country identified by p_source_country_id by executing a SELECT EXISTS query on the demographics table, checking for any row where the country_id column matches p_source_country_id, and stores the boolean result in v_source_demographics_exists. Next, it determines if the target country exists by executing a SELECT EXISTS query on the countries table, checking for any row where the country_id column matches p_target_country_id, and stores the boolean result in v_target_country_exists.\n\nThe procedure then proceeds only if v_target_country_exists is true. If the target country exists, it generates a new unique migration_id by querying the migration_data table to find the maximum value in the migration_id column, using COALESCE to default to 0 if no records exist, and then adding 1 to this value, storing the result in v_new_migration_id.\n\nFollowing this, a conditional block is executed based on the value of v_source_demographics_exists. If v_source_demographics_exists is true, meaning demographic data for the source country exists, the procedure retrieves all columns from the demographics table for the row where country_id matches p_source_country_id and stores this entire row into the v_source_demographics RECORD variable. Subsequently, it inserts a new record into the migration_data table. The columns populated are: migration_id with v_new_migration_id; country_id with p_target_country_id; immigration_rate with the value of v_source_demographics.fertility_rate multiplied by 0.5; emigration_rate with the value of v_source_demographics.dependency_ratio multiplied by 0.3; net_migration with the value of v_source_demographics.urban_population_percentage multiplied by 0.01; internal_migration_rate with the value of v_source_demographics.median_age multiplied by 0.02; migration_trends with a substring of the concatenated string 'Migration from source country ' and p_source_country_id, truncated to the first 50 characters; and last_migration_data_year with p_migration_year. After inserting the new migration data, the procedure deletes all records from the demographics table where the country_id column matches p_source_country_id.\n\nIf v_source_demographics_exists is false, meaning demographic data for the source country does not exist, the procedure inserts a new record into the migration_data table using default values. The columns populated are: migration_id with v_new_migration_id; country_id with p_target_country_id; immigration_rate with the literal value 1.0; emigration_rate with the literal value 0.5; net_migration with the literal value 0.5; internal_migration_rate with the literal value 0.3; migration_trends with a substring of the concatenated string 'Default migration data for country ' and p_target_country_id, truncated to the first 50 characters; and last_migration_data_year with p_migration_year. The procedure concludes after these operations.",
    "plsql": "CREATE OR REPLACE PROCEDURE migrate_country_data(\n    p_source_country_id BIGINT,\n    p_target_country_id BIGINT,\n    p_migration_year BIGINT\n)\nLANGUAGE plpgsql\nAS $$\nDECLARE\n    v_source_demographics RECORD;\n    v_new_migration_id BIGINT;\n    v_target_country_exists BOOLEAN;\n    v_source_demographics_exists BOOLEAN;\nBEGIN\n    -- Check if source demographics exist\n    SELECT EXISTS(SELECT 1 FROM demographics WHERE country_id = p_source_country_id) \n    INTO v_source_demographics_exists;\n    \n    -- Check if target country exists in countries table\n    SELECT EXISTS(SELECT 1 FROM countries WHERE country_id = p_target_country_id) \n    INTO v_target_country_exists;\n    \n    -- Only proceed if target country exists\n    IF v_target_country_exists THEN\n        -- Generate new migration_id\n        SELECT COALESCE(MAX(migration_id), 0) + 1 INTO v_new_migration_id FROM migration_data;\n        \n        -- If source demographics exist, use them; otherwise use default values\n        IF v_source_demographics_exists THEN\n            SELECT * INTO v_source_demographics \n            FROM demographics \n            WHERE country_id = p_source_country_id;\n            \n            INSERT INTO migration_data (\n                migration_id,\n                country_id,\n                immigration_rate,\n                emigration_rate,\n                net_migration,\n                internal_migration_rate,\n                migration_trends,\n                last_migration_data_year\n            ) VALUES (\n                v_new_migration_id,\n                p_target_country_id,\n                v_source_demographics.fertility_rate * 0.5,\n                v_source_demographics.dependency_ratio * 0.3,\n                v_source_demographics.urban_population_percentage * 0.01,\n                v_source_demographics.median_age * 0.02,\n                substring('Migration from source country ' || p_source_country_id from 1 for 50),\n                p_migration_year\n            );\n            \n            -- Delete source demographics\n            DELETE FROM demographics WHERE country_id = p_source_country_id;\n        ELSE\n            -- Use default values when source demographics don't exist\n            INSERT INTO migration_data (\n                migration_id,\n                country_id,\n                immigration_rate,\n                emigration_rate,\n                net_migration,\n                internal_migration_rate,\n                migration_trends,\n                last_migration_data_year\n            ) VALUES (\n                v_new_migration_id,\n                p_target_country_id,\n                1.0,\n                0.5,\n                0.5,\n                0.3,\n                substring('Default migration data for country ' || p_target_country_id from 1 for 50),\n                p_migration_year\n            );\n        END IF;\n    END IF;\nEND;\n$$;",
    "database_name": "global_demographic_and_geographic_data_management",
    "tables": [
      "countries",
      "countries_regions",
      "regions",
      "demographics",
      "migration_data"
    ],
    "call_sqls": [
      "CALL migrate_country_data(0, 1, 2023);",
      "CALL migrate_country_data(1, 0, 2024);",
      "CALL migrate_country_data(99, 0, 2025);",
      "CALL migrate_country_data(0, 99, 2026);",
      "CALL migrate_country_data(1, 1, 2027);"
    ],
    "summary": "Write a PostgreSQL PL/pgSQL stored procedure named migrate_country_data that accepts a source country ID, a target country ID, and a migration year, and migrates demographic data to the target country only if the target country exists in the countries table. If the target country exists, generate a new migration ID for the migration_data table. If source demographics exist in the demographics table for the source country ID, insert a new record into migration_data for the target country ID with immigration_rate derived as fertility_rate multiplied by 0.5, emigration_rate derived as dependency_ratio multiplied by 0.3, net_migration derived as urban_population_percentage multiplied by 0.01, internal_migration_rate derived as median_age multiplied by 0.02, migration_trends set to a text prefix with the source country ID, and last_migration_data_year set to the provided migration year, then delete the source demographics record from the demographics table. If source demographics do not exist, insert a new record into migration_data for the target country ID with default values: immigration_rate as 1.0, emigration_rate as 0.5, net_migration as 0.5, internal_migration_rate as 0.3, migration_trends set to a default text prefix with the target country ID, and last_migration_data_year set to the provided migration year.",
    "natural_language": "Write a PostgreSQL PL/pgSQL stored procedure named 'migrate_country_data' that accepts a source country ID, a target country ID, and a migration year. The procedure should first verify that the target country exists in the COUNTRIES table. If it does, generate a new migration identifier and then check if source demographic records exist in the DEMOGRAPHICS table for the source country. If source demographics are present, insert migration data into the MIGRATION_DATA table using calculated values derived from those demographicsspecifically, the immigration rate as half the fertility rate, the emigration rate as 30% of the dependency ratio, the net migration as 1% of the urban population percentage, and the internal migration rate as 2% of the median ageand then delete the source demographics from the DEMOGRAPHICS table. If no source demographics are found, insert migration data using default values: 1.0 for immigration rate, 0.5 for emigration rate, 0.5 for net migration, and 0.3 for internal migration rate. In both cases, include a descriptive migration trend and the provided migration year.",
    "id": 100,
    "generated_ir": "Write a PL/pgSQL stored procedure named migrate_country_data that accepts three input parameters: p_source_country_id of type BIGINT, representing the unique identifier of the source country; p_target_country_id of type BIGINT, representing the unique identifier of the target country; and p_migration_year of type BIGINT, representing the year for which migration data is being recorded. The procedure begins by declaring four local variables: v_source_demographics of type RECORD, intended to hold a full row of data from the demographics table; v_new_migration_id of type BIGINT, to store a newly generated unique identifier for migration data; v_target_country_exists of type BOOLEAN, to indicate whether the target country exists in the countries table; and v_source_demographics_exists of type BOOLEAN, to indicate whether demographic data exists for the source country.\n\nThe procedure first determines if demographic data exists for the country identified by p_source_country_id by executing a SELECT EXISTS query on the demographics table, checking for any row where the country_id column matches p_source_country_id, and stores the boolean result in v_source_demographics_exists. Next, it determines if the target country exists by executing a SELECT EXISTS query on the countries table, checking for any row where the country_id column matches p_target_country_id, and stores the boolean result in v_target_country_exists.\n\nThe procedure then proceeds only if v_target_country_exists is true. If the target country exists, it generates a new unique migration_id by querying the migration_data table to find the maximum value in the migration_id column, using COALESCE to default to 0 if no records exist, and then adding 1 to this value, storing the result in v_new_migration_id.\n\nFollowing this, a conditional block is executed based on the value of v_source_demographics_exists. If v_source_demographics_exists is true, meaning demographic data for the source country exists, the procedure retrieves all columns from the demographics table for the row where country_id matches p_source_country_id and stores this entire row into the v_source_demographics RECORD variable. Subsequently, it inserts a new record into the migration_data table. The columns populated are: migration_id with v_new_migration_id; country_id with p_target_country_id; immigration_rate with the value of v_source_demographics.fertility_rate multiplied by 0.5; emigration_rate with the value of v_source_demographics.dependency_ratio multiplied by 0.3; net_migration with the value of v_source_demographics.urban_population_percentage multiplied by 0.01; internal_migration_rate with the value of v_source_demographics.median_age multiplied by 0.02; migration_trends with a substring of the concatenated string 'Migration from source country ' and p_source_country_id, truncated to the first 50 characters; and last_migration_data_year with p_migration_year. After inserting the new migration data, the procedure deletes all records from the demographics table where the country_id column matches p_source_country_id.\n\nIf v_source_demographics_exists is false, meaning demographic data for the source country does not exist, the procedure inserts a new record into the migration_data table using default values. The columns populated are: migration_id with v_new_migration_id; country_id with p_target_country_id; immigration_rate with the literal value 1.0; emigration_rate with the literal value 0.5; net_migration with the literal value 0.5; internal_migration_rate with the literal value 0.3; migration_trends with a substring of the concatenated string 'Default migration data for country ' and p_target_country_id, truncated to the first 50 characters; and last_migration_data_year with p_migration_year. The procedure concludes after these operations.",
    "original_summary": "Create a PL/pgSQL stored procedure named migrate_country_data that accepts source_country_id, target_country_id, and migration_year (all BIGINT) parameters. Check if the target country and source demographics exist. If the target exists, generate a new migration ID. If source demographics exist, insert migration data derived from those demographics and delete the source demographics. If source demographics do not exist, insert migration data with default values.",
    "plsql_type": "PostgreSQL PL/pgSQL",
    "object_type": "procedure",
    "original_natural_language": "Please construct a PL/pgSQL stored procedure entitled 'migrate_country_data'. This procedure must accept three parameters of type BIGINT: 'source_country_id', 'target_country_id', and 'migration_year'. The procedure's logic should first verify the existence of the target country and the source demographics. Provided the target country exists, a new migration identifier shall be generated. Subsequently, if source demographic records are present, migration data derived from those records should be inserted, followed by the deletion of the source demographics. In the event that source demographics are not found, migration data should be inserted utilizing default values."
  }
]